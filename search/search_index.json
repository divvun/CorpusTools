{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CorpusTools documentation","text":""},{"location":"#overview","title":"Overview","text":"<p>CorpusTools is a set of tools to manipulate a giellalt corpus in different ways.</p> <p>A few examples:</p> <ul> <li><code>convert2xml</code> - Converts original files to the Giellatekno-internal xml format.</li> <li><code>analyse_corpus</code> - Orchistrates the hfst (etc) tools to analyse a corpus.</li> <li><code>ccat</code> - Output Corpus WorkBench-readable text files from an analysed or non-analysed corpus.</li> </ul>"},{"location":"#installation-from-apertium-nightly","title":"Installation from apertium nightly","text":"<p>CorpusTools is available as a package in Apertium Nightly. Depending on your system, the package is named slightly differently. Search for <code>corpustools</code>.</p>"},{"location":"#installation-using-pipx","title":"Installation using pipx","text":"<p>pipx lets you install python packages that has runnable scripts easily, onto your system.</p> <ol> <li>Install pipx</li> <li>Run <code>pipx install --force git+https://github.com/giellalt/CorpusTools.git</code></li> </ol>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>python3</li> <li>wvHtml (only needed for convert2xml)</li> <li>pdftohtml (only needed for convert2xml)</li> <li>latex2html (only needed for convert2xml)</li> <li>Java (only needed for parallelize)</li> <li>pandoc (maybe only needed for convert2xml?)</li> </ul> <p>Installation commands</p> MacDebian/UbuntuArch Linux <pre><code>sudo port install wv latex2html poppler pandoc\n</code></pre> <pre><code>sudo apt-get install vw poppler-utils pandoc\n</code></pre> <pre><code>sudo pacman -S wv\n</code></pre>"},{"location":"#and-continued-here","title":"And continued here","text":"<p>This is a paragraph.</p>"},{"location":"corpus-work/","title":"Working with corpora","text":"<p>The corpus for a given language is hosted on github.</p> <p>giellalt/corpus-LANG (.e.g <code>corpus-sme</code>)</p>"},{"location":"corpus-work/#git-lfs","title":"git lfs","text":"<p>The source repositories contains original files, many of which are of some size. The files are therefore stored externally, using git lfs (git large file storage. git lfs is an extension to git, which replaces the data inside of the file with text information, pointing to where the actual data is stored.</p> <p>This does not affect the way you work with the repository, but there are </p> <p>It is an extension to git, which replaces the external files with small text files that points to where the external file is stored.</p>"},{"location":"reference/","title":"Index","text":""},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>corpustools<ul> <li>_version</li> <li>adder</li> <li>analyser</li> <li>argparse_version</li> <li>avvirconverter</li> <li>basicconverter</li> <li>bibel_no_aligner</li> <li>bibel_no_crawler</li> <li>biblexmlconverter</li> <li>ccat</li> <li>ces2homegrown</li> <li>check_para_consistency</li> <li>clean_prestable</li> <li>compare_tmx_goldstandard</li> <li>convert_using_pandoc</li> <li>convert_using_soffice</li> <li>converter</li> <li>convertermanager</li> <li>corpuspath</li> <li>corpusxmlfile</li> <li>counter</li> <li>crawler</li> <li>debug_corpus</li> <li>decode</li> <li>docconverter</li> <li>documentfixer</li> <li>dropbox_adder</li> <li>dupe_finder</li> <li>epubchooser</li> <li>epubconverter</li> <li>errormarkup</li> <li>finder</li> <li>generate_anchor_list</li> <li>html_cleaner</li> <li>htmlcontentconverter</li> <li>htmlconverter</li> <li>iso_ir_197</li> <li>iso_ir_209</li> <li>korp_mono</li> <li>korp_para</li> <li>languagedetector</li> <li>macsami</li> <li>mari</li> <li>modes</li> <li>move_files</li> <li>namechanger</li> <li>normalise_filenames</li> <li>nrk_no_crawler</li> <li>one-off-functions</li> <li>packagetmx</li> <li>parallelize</li> <li>pdfconverter</li> <li>pick_parallel_docs</li> <li>pick_samediggi_se_docs</li> <li>pick_titles</li> <li>plaintextconverter</li> <li>realign</li> <li>saami_crawler</li> <li>samas_crawler</li> <li>samediggi_fi_crawler</li> <li>samediggi_no_crawler</li> <li>sentencedivider</li> <li>svgconverter</li> <li>test<ul> <li>test_adder</li> <li>test_analyser</li> <li>test_avvirconverter</li> <li>test_biblexmlconverter</li> <li>test_ccat</li> <li>test_compare_tmx_goldstandard</li> <li>test_converter</li> <li>test_corpuspath</li> <li>test_corpusxmlfile</li> <li>test_decode</li> <li>test_docconverter</li> <li>test_documentfixer</li> <li>test_docxconverter</li> <li>test_epubchooser</li> <li>test_epubconverter</li> <li>test_errormarkup</li> <li>test_htmlcontentconverter</li> <li>test_htmlconverter</li> <li>test_lang_guessing</li> <li>test_languagedetector</li> <li>test_namechanger</li> <li>test_parallelize</li> <li>test_pdfconverter</li> <li>test_pick_parallel_docs</li> <li>test_plaintextconverter</li> <li>test_rtfconverter</li> <li>test_samediggi_no_crawler</li> <li>test_sentencedivider</li> <li>test_svgconverter</li> <li>test_text_cat</li> <li>test_trainingcorpusmaker</li> <li>test_typosfile</li> <li>test_util</li> <li>test_xhtml2corpus</li> <li>test_xslmaker</li> <li>test_xslsetter</li> <li>xmltester</li> </ul> </li> <li>text_cat</li> <li>tmx</li> <li>trainingcorpusmaker</li> <li>typosfile</li> <li>update_metadata</li> <li>usxconverter</li> <li>util</li> <li>versioncontrol</li> <li>winsami2</li> <li>xmlconverter</li> <li>xslmaker</li> <li>xslsetter</li> </ul> </li> </ul>"},{"location":"reference/_version/","title":"_version","text":"<p>Set the current CorpusTools version.</p>"},{"location":"reference/adder/","title":"adder","text":"<p>This file contains classes to add files to a corpus directory.</p>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus","title":"<code>AddToCorpus</code>","text":"<p>Class to add files, urls and dirs to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>class AddToCorpus:\n\"\"\"Class to add files, urls and dirs to the corpus.\"\"\"\n\n    def __init__(self, corpusdir, mainlang, path):\n\"\"\"Initialise the AddToCorpus class.\n\n        Args:\n            corpusdir: (unicode) the directory where the corpus is\n            mainlang: (unicode) three character long lang id (iso-639)\n            path: (unicode) path below the language directory where the files\n            should be added\n        \"\"\"\n        if not os.path.isdir(corpusdir):\n            raise AdderError(\n                \"The given corpus directory, {}, \" \"does not exist.\".format(corpusdir)\n            )\n\n        if (\n            len(mainlang) != 3\n            or mainlang != mainlang.lower()\n            or mainlang != namechanger.normalise_filename(mainlang)\n        ):\n            raise AdderError(\n                \"Invalid mainlang: {}. \"\n                \"It must consist of three lowercase ascii \"\n                \"letters\".format(mainlang)\n            )\n\n        self.corpusdir = corpusdir\n        self.vcs = versioncontrol.vcs(self.corpusdir)\n        self.goaldir = os.path.join(\n            corpusdir, \"orig\", mainlang, self.__normalise_path(path)\n        )\n        with util.ignored(OSError):\n            os.makedirs(self.goaldir)\n        self.additions = []\n\n    @staticmethod\n    def __normalise_path(path):\n\"\"\"Normalise path.\n\n        Args:\n            path (str): Path that should be normalised.\n\n        Returns:\n            str: a normalised path\n        \"\"\"\n        return \"/\".join(\n            [namechanger.normalise_filename(part) for part in path.split(\"/\")]\n        )\n\n    def copy_url_to_corpus(self, url, wanted_name=\"\", parallelpath=\"\"):\n\"\"\"Add a URL to the corpus.\n\n        Copy a downloaded url to the corpus\n        \"\"\"\n        downloader = UrlDownloader(os.path.join(self.corpusdir, \"tmp\"))\n        (request, tmpname) = downloader.download(url, wanted_name=wanted_name)\n\n        return self.copy_file_to_corpus(\n            origpath=tmpname, metadata_filename=request.url, parallelpath=parallelpath\n        )\n\n    def copy_file_to_corpus(self, origpath, metadata_filename, parallelpath=\"\"):\n\"\"\"Add a file from the hard disk to the corpus.\n\n        Args:\n            orig_path (str): path where the original file exists\n            metadata_filename (str): the value of the filename in the\n                metadata file\n            parallelpath (str): where the parallel file of the original\n                file exists in the corpus\n\n        Returns:\n            str: path to where the origfile exists in the corpus\n        \"\"\"\n        none_dupe_path = self.none_dupe_path(origpath)\n        shutil.copy(origpath, none_dupe_path)\n        self.additions.append(none_dupe_path)\n\n        self.add_metadata_to_corpus(none_dupe_path, metadata_filename)\n        if parallelpath:\n            self.update_parallel_data(util.split_path(none_dupe_path), parallelpath)\n        print(\"Added\", none_dupe_path)\n\n        return none_dupe_path\n\n    def add_metadata_to_corpus(self, none_dupe_path, meta_filename):\n\"\"\"Add the metadata file to the corpus.\"\"\"\n        none_dupe_components = util.split_path(none_dupe_path)\n        new_metadata = xslsetter.MetadataHandler(none_dupe_path + \".xsl\", create=True)\n        new_metadata.set_variable(\"filename\", meta_filename)\n        new_metadata.set_variable(\"mainlang\", none_dupe_components.lang)\n        new_metadata.set_variable(\"genre\", none_dupe_components.genre)\n        new_metadata.write_file()\n        self.additions.append(none_dupe_path + \".xsl\")\n\n    @staticmethod\n    def update_parallel_data(none_dupe_components, parallelpath):\n\"\"\"Update metadata in the parallel files.\n\n        Args:\n            new_components: (util.PathComponents) of none_dupe_path\n            parallelpath: (string) path of the parallel file\n        \"\"\"\n        if not os.path.exists(parallelpath):\n            raise AdderError(f\"{parallelpath} does not exist\")\n\n        parallel_metadata = xslsetter.MetadataHandler(parallelpath + \".xsl\")\n        parallels = parallel_metadata.get_parallel_texts()\n        parallels[none_dupe_components.lang] = none_dupe_components.basename\n\n        parall_components = util.split_path(parallelpath)\n        parallels[parall_components.lang] = parall_components.basename\n\n        for lang, parallel in parallels.items():\n            metadata = xslsetter.MetadataHandler(\n                \"/\".join(\n                    (\n                        none_dupe_components.root,\n                        none_dupe_components.module,\n                        lang,\n                        none_dupe_components.genre,\n                        none_dupe_components.subdirs,\n                        parallel + \".xsl\",\n                    )\n                )\n            )\n\n            for lang1, parallel1 in parallels.items():\n                if lang1 != lang:\n                    metadata.set_parallel_text(lang1, parallel1)\n            metadata.write_file()\n\n    def none_dupe_path(self, path):\n\"\"\"Compute the none duplicate path of the file to be added.\n\n        Args:\n            path: (string) path of the file as given as input\n            This string may contain unwanted chars and\n        \"\"\"\n        return namechanger.compute_new_basename(\n            path,\n            os.path.join(\n                self.goaldir, namechanger.normalise_filename(os.path.basename(path))\n            ),\n        )\n\n    def copy_files_in_dir_to_corpus(self, origpath):\n\"\"\"Add a directory to the corpus.\n\n        * Recursively walks through the given original directory\n            * First checks for duplicates, raises an error printing a list\n              of duplicate files if duplicates are found\n            * For each file, do the \"add file to the corpus\" operations\n              (minus the parallel info).\n\n        \"\"\"\n        self.find_duplicates(origpath)\n        for root, _, files in os.walk(origpath):\n            for file_ in files:\n                orig_f = os.path.join(root, file_)\n                self.copy_file_to_corpus(origpath=orig_f, metadata_filename=orig_f)\n\n    @staticmethod\n    def find_duplicates(origpath):\n\"\"\"Find duplicates based on the hex digests of the corpus files.\"\"\"\n        duplicates = {}\n        for root, _, files in os.walk(origpath):\n            for file_ in files:\n                path = os.path.join(root, file_)\n                with open(path, \"rb\") as content:\n                    file_hash = namechanger.compute_hexdigest(content)\n                    if file_hash in duplicates:\n                        duplicates[file_hash].append(path)\n                    else:\n                        duplicates[file_hash] = [path]\n\n        results = list(x for x in list(duplicates.values()) if len(x) &gt; 1)\n        if results:\n            print(\"Duplicates Found:\")\n            print(\"___\")\n            for result in results:\n                for subresult in result:\n                    print(f\"\\t{subresult}\")\n                print(\"___\")\n\n            raise AdderError(\"Found duplicates\")\n\n    def add_files_to_working_copy(self):\n\"\"\"Add the downloaded files to the working copy.\"\"\"\n        self.vcs.add(self.additions)\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.__init__","title":"<code>__init__(corpusdir, mainlang, path)</code>","text":"<p>Initialise the AddToCorpus class.</p> <p>Parameters:</p> Name Type Description Default <code>corpusdir</code> <p>(unicode) the directory where the corpus is</p> required <code>mainlang</code> <p>(unicode) three character long lang id (iso-639)</p> required <code>path</code> <p>(unicode) path below the language directory where the files</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def __init__(self, corpusdir, mainlang, path):\n\"\"\"Initialise the AddToCorpus class.\n\n    Args:\n        corpusdir: (unicode) the directory where the corpus is\n        mainlang: (unicode) three character long lang id (iso-639)\n        path: (unicode) path below the language directory where the files\n        should be added\n    \"\"\"\n    if not os.path.isdir(corpusdir):\n        raise AdderError(\n            \"The given corpus directory, {}, \" \"does not exist.\".format(corpusdir)\n        )\n\n    if (\n        len(mainlang) != 3\n        or mainlang != mainlang.lower()\n        or mainlang != namechanger.normalise_filename(mainlang)\n    ):\n        raise AdderError(\n            \"Invalid mainlang: {}. \"\n            \"It must consist of three lowercase ascii \"\n            \"letters\".format(mainlang)\n        )\n\n    self.corpusdir = corpusdir\n    self.vcs = versioncontrol.vcs(self.corpusdir)\n    self.goaldir = os.path.join(\n        corpusdir, \"orig\", mainlang, self.__normalise_path(path)\n    )\n    with util.ignored(OSError):\n        os.makedirs(self.goaldir)\n    self.additions = []\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.__normalise_path","title":"<code>__normalise_path(path)</code>  <code>staticmethod</code>","text":"<p>Normalise path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path that should be normalised.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>a normalised path</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>@staticmethod\ndef __normalise_path(path):\n\"\"\"Normalise path.\n\n    Args:\n        path (str): Path that should be normalised.\n\n    Returns:\n        str: a normalised path\n    \"\"\"\n    return \"/\".join(\n        [namechanger.normalise_filename(part) for part in path.split(\"/\")]\n    )\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.add_files_to_working_copy","title":"<code>add_files_to_working_copy()</code>","text":"<p>Add the downloaded files to the working copy.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def add_files_to_working_copy(self):\n\"\"\"Add the downloaded files to the working copy.\"\"\"\n    self.vcs.add(self.additions)\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.add_metadata_to_corpus","title":"<code>add_metadata_to_corpus(none_dupe_path, meta_filename)</code>","text":"<p>Add the metadata file to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def add_metadata_to_corpus(self, none_dupe_path, meta_filename):\n\"\"\"Add the metadata file to the corpus.\"\"\"\n    none_dupe_components = util.split_path(none_dupe_path)\n    new_metadata = xslsetter.MetadataHandler(none_dupe_path + \".xsl\", create=True)\n    new_metadata.set_variable(\"filename\", meta_filename)\n    new_metadata.set_variable(\"mainlang\", none_dupe_components.lang)\n    new_metadata.set_variable(\"genre\", none_dupe_components.genre)\n    new_metadata.write_file()\n    self.additions.append(none_dupe_path + \".xsl\")\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.copy_file_to_corpus","title":"<code>copy_file_to_corpus(origpath, metadata_filename, parallelpath='')</code>","text":"<p>Add a file from the hard disk to the corpus.</p> <p>Parameters:</p> Name Type Description Default <code>orig_path</code> <code>str</code> <p>path where the original file exists</p> required <code>metadata_filename</code> <code>str</code> <p>the value of the filename in the metadata file</p> required <code>parallelpath</code> <code>str</code> <p>where the parallel file of the original file exists in the corpus</p> <code>''</code> <p>Returns:</p> Name Type Description <code>str</code> <p>path to where the origfile exists in the corpus</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def copy_file_to_corpus(self, origpath, metadata_filename, parallelpath=\"\"):\n\"\"\"Add a file from the hard disk to the corpus.\n\n    Args:\n        orig_path (str): path where the original file exists\n        metadata_filename (str): the value of the filename in the\n            metadata file\n        parallelpath (str): where the parallel file of the original\n            file exists in the corpus\n\n    Returns:\n        str: path to where the origfile exists in the corpus\n    \"\"\"\n    none_dupe_path = self.none_dupe_path(origpath)\n    shutil.copy(origpath, none_dupe_path)\n    self.additions.append(none_dupe_path)\n\n    self.add_metadata_to_corpus(none_dupe_path, metadata_filename)\n    if parallelpath:\n        self.update_parallel_data(util.split_path(none_dupe_path), parallelpath)\n    print(\"Added\", none_dupe_path)\n\n    return none_dupe_path\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.copy_files_in_dir_to_corpus","title":"<code>copy_files_in_dir_to_corpus(origpath)</code>","text":"<p>Add a directory to the corpus.</p> <ul> <li>Recursively walks through the given original directory<ul> <li>First checks for duplicates, raises an error printing a list   of duplicate files if duplicates are found</li> <li>For each file, do the \"add file to the corpus\" operations   (minus the parallel info).</li> </ul> </li> </ul> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def copy_files_in_dir_to_corpus(self, origpath):\n\"\"\"Add a directory to the corpus.\n\n    * Recursively walks through the given original directory\n        * First checks for duplicates, raises an error printing a list\n          of duplicate files if duplicates are found\n        * For each file, do the \"add file to the corpus\" operations\n          (minus the parallel info).\n\n    \"\"\"\n    self.find_duplicates(origpath)\n    for root, _, files in os.walk(origpath):\n        for file_ in files:\n            orig_f = os.path.join(root, file_)\n            self.copy_file_to_corpus(origpath=orig_f, metadata_filename=orig_f)\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.copy_url_to_corpus","title":"<code>copy_url_to_corpus(url, wanted_name='', parallelpath='')</code>","text":"<p>Add a URL to the corpus.</p> <p>Copy a downloaded url to the corpus</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def copy_url_to_corpus(self, url, wanted_name=\"\", parallelpath=\"\"):\n\"\"\"Add a URL to the corpus.\n\n    Copy a downloaded url to the corpus\n    \"\"\"\n    downloader = UrlDownloader(os.path.join(self.corpusdir, \"tmp\"))\n    (request, tmpname) = downloader.download(url, wanted_name=wanted_name)\n\n    return self.copy_file_to_corpus(\n        origpath=tmpname, metadata_filename=request.url, parallelpath=parallelpath\n    )\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.find_duplicates","title":"<code>find_duplicates(origpath)</code>  <code>staticmethod</code>","text":"<p>Find duplicates based on the hex digests of the corpus files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>@staticmethod\ndef find_duplicates(origpath):\n\"\"\"Find duplicates based on the hex digests of the corpus files.\"\"\"\n    duplicates = {}\n    for root, _, files in os.walk(origpath):\n        for file_ in files:\n            path = os.path.join(root, file_)\n            with open(path, \"rb\") as content:\n                file_hash = namechanger.compute_hexdigest(content)\n                if file_hash in duplicates:\n                    duplicates[file_hash].append(path)\n                else:\n                    duplicates[file_hash] = [path]\n\n    results = list(x for x in list(duplicates.values()) if len(x) &gt; 1)\n    if results:\n        print(\"Duplicates Found:\")\n        print(\"___\")\n        for result in results:\n            for subresult in result:\n                print(f\"\\t{subresult}\")\n            print(\"___\")\n\n        raise AdderError(\"Found duplicates\")\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.none_dupe_path","title":"<code>none_dupe_path(path)</code>","text":"<p>Compute the none duplicate path of the file to be added.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>(string) path of the file as given as input</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def none_dupe_path(self, path):\n\"\"\"Compute the none duplicate path of the file to be added.\n\n    Args:\n        path: (string) path of the file as given as input\n        This string may contain unwanted chars and\n    \"\"\"\n    return namechanger.compute_new_basename(\n        path,\n        os.path.join(\n            self.goaldir, namechanger.normalise_filename(os.path.basename(path))\n        ),\n    )\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AddToCorpus.update_parallel_data","title":"<code>update_parallel_data(none_dupe_components, parallelpath)</code>  <code>staticmethod</code>","text":"<p>Update metadata in the parallel files.</p> <p>Parameters:</p> Name Type Description Default <code>new_components</code> <p>(util.PathComponents) of none_dupe_path</p> required <code>parallelpath</code> <p>(string) path of the parallel file</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>@staticmethod\ndef update_parallel_data(none_dupe_components, parallelpath):\n\"\"\"Update metadata in the parallel files.\n\n    Args:\n        new_components: (util.PathComponents) of none_dupe_path\n        parallelpath: (string) path of the parallel file\n    \"\"\"\n    if not os.path.exists(parallelpath):\n        raise AdderError(f\"{parallelpath} does not exist\")\n\n    parallel_metadata = xslsetter.MetadataHandler(parallelpath + \".xsl\")\n    parallels = parallel_metadata.get_parallel_texts()\n    parallels[none_dupe_components.lang] = none_dupe_components.basename\n\n    parall_components = util.split_path(parallelpath)\n    parallels[parall_components.lang] = parall_components.basename\n\n    for lang, parallel in parallels.items():\n        metadata = xslsetter.MetadataHandler(\n            \"/\".join(\n                (\n                    none_dupe_components.root,\n                    none_dupe_components.module,\n                    lang,\n                    none_dupe_components.genre,\n                    none_dupe_components.subdirs,\n                    parallel + \".xsl\",\n                )\n            )\n        )\n\n        for lang1, parallel1 in parallels.items():\n            if lang1 != lang:\n                metadata.set_parallel_text(lang1, parallel1)\n        metadata.write_file()\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.AdderError","title":"<code>AdderError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raise this exception when errors happen in this module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>class AdderError(Exception):\n\"\"\"Raise this exception when errors happen in this module.\"\"\"\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.UrlDownloader","title":"<code>UrlDownloader</code>","text":"<p>Download a document from a url.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>class UrlDownloader:\n\"\"\"Download a document from a url.\"\"\"\n\n    def __init__(self, download_dir):\n\"\"\"Initialise the UrlDownloader class.\n\n        Args:\n            download_dir: a string containing the path where the file should\n            be saved.\n        \"\"\"\n        self.download_dir = download_dir\n        self.headers = {\n            \"user-agent\": (\n                \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:21.0) \"\n                \"Gecko/20130331 Firefox/21.0\"\n            )\n        }\n\n    def download(self, url, wanted_name=\"\", params=None):\n\"\"\"Download a url to a temporary file.\n\n        Return the request object and the name of the temporary file\n        \"\"\"\n        try:\n            request = requests.get(url, headers=self.headers, params=params)\n            if request.status_code == requests.codes.ok:\n                filename = wanted_name if wanted_name else url_to_filename(request)\n                tmpname = os.path.join(self.download_dir, filename)\n                with util.ignored(OSError):\n                    os.makedirs(self.download_dir)\n                with open(tmpname, \"wb\") as tmpfile:\n                    tmpfile.write(request.content)\n\n                return (request, tmpname)\n            raise AdderError(\"ERROR:\", url, \"does not exist\")\n        except requests.exceptions.MissingSchema as error:\n            raise AdderError(str(error))\n        except requests.exceptions.ConnectionError as error:\n            raise AdderError(str(error))\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.UrlDownloader.__init__","title":"<code>__init__(download_dir)</code>","text":"<p>Initialise the UrlDownloader class.</p> <p>Parameters:</p> Name Type Description Default <code>download_dir</code> <p>a string containing the path where the file should</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def __init__(self, download_dir):\n\"\"\"Initialise the UrlDownloader class.\n\n    Args:\n        download_dir: a string containing the path where the file should\n        be saved.\n    \"\"\"\n    self.download_dir = download_dir\n    self.headers = {\n        \"user-agent\": (\n            \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:21.0) \"\n            \"Gecko/20130331 Firefox/21.0\"\n        )\n    }\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.UrlDownloader.download","title":"<code>download(url, wanted_name='', params=None)</code>","text":"<p>Download a url to a temporary file.</p> <p>Return the request object and the name of the temporary file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def download(self, url, wanted_name=\"\", params=None):\n\"\"\"Download a url to a temporary file.\n\n    Return the request object and the name of the temporary file\n    \"\"\"\n    try:\n        request = requests.get(url, headers=self.headers, params=params)\n        if request.status_code == requests.codes.ok:\n            filename = wanted_name if wanted_name else url_to_filename(request)\n            tmpname = os.path.join(self.download_dir, filename)\n            with util.ignored(OSError):\n                os.makedirs(self.download_dir)\n            with open(tmpname, \"wb\") as tmpfile:\n                tmpfile.write(request.content)\n\n            return (request, tmpname)\n        raise AdderError(\"ERROR:\", url, \"does not exist\")\n    except requests.exceptions.MissingSchema as error:\n        raise AdderError(str(error))\n    except requests.exceptions.ConnectionError as error:\n        raise AdderError(str(error))\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.add_url_extension","title":"<code>add_url_extension(filename, content_type)</code>","text":"<p>Add an extension to the file depending on the content type.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def add_url_extension(filename, content_type):\n\"\"\"Add an extension to the file depending on the content type.\"\"\"\n    if filename == \"\":\n        filename += \"index\"\n\n    content_type_extension = {\n        \"text/html\": \".html\",\n        \"application/msword\": \".doc\",\n        \"application/pdf\": \".pdf\",\n        \"text/plain\": \".txt\",\n    }\n\n    for name, extension in content_type_extension.items():\n        if name in content_type and not filename.endswith(extension):\n            filename += extension\n\n    return filename\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.main","title":"<code>main()</code>","text":"<p>Add files, directories and urls to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def main():\n\"\"\"Add files, directories and urls to the corpus.\"\"\"\n    args = parse_args()\n\n    if args.parallel_file is None:\n        if args.lang is not None:\n            raise SystemExit(\n                \"The argument -l|--lang is not allowed together with \" \"-d|--directory\"\n            )\n        (root, _, lang, genre, path, _) = util.split_path(\n            os.path.join(args.directory, \"dummy.txt\")\n        )\n        if genre == \"dummy.txt\":\n            raise SystemExit(\n                \"Error!\\n\"\n                \"You must add genre to the directory\\ne.g. {}\".format(\n                    os.path.join(args.directory, \"admin\")\n                )\n            )\n\n        adder = AddToCorpus(root, lang, os.path.join(genre, path))\n        for orig in args.origs:\n            if os.path.isfile(orig):\n                if args.name:\n                    newname = os.path.join(os.path.dirname(orig), args.name)\n                    try:\n                        shutil.copy(orig, newname)\n                    except FileNotFoundError:\n                        raise SystemExit(f\"Not a valid filename: {args.name}\")\n                    orig = newname\n\n                adder.copy_file_to_corpus(\n                    origpath=orig, metadata_filename=os.path.basename(orig)\n                )\n            elif orig.startswith(\"http\"):\n                adder.copy_url_to_corpus(orig, wanted_name=args.name)\n            elif os.path.isdir(orig):\n                if args.name:\n                    raise SystemExit(\n                        \"It makes no sense to use the --name \"\n                        \"option together with --directory.\"\n                    )\n                adder.copy_files_in_dir_to_corpus(orig)\n            else:\n                raise SystemExit(\n                    \"Cannot handle the orig named: {}.\\n\"\n                    \"If you used the --name option and a name with spaces, \"\n                    \"encase it in quote marks.\".format(orig)\n                )\n    else:\n        if args.directory is not None:\n            raise SystemExit(\n                \"The argument -d|--directory is not allowed together with \"\n                \"-p|--parallel\\n\"\n                \"Only -l|--lang is allowed together with -p|--parallel\"\n            )\n        if not os.path.exists(args.parallel_file):\n            raise SystemExit(\n                \"The given parallel file\\n\\t{}\\n\"\n                \"does not exist\".format(args.parallel_file)\n            )\n        if len(args.origs) &gt; 1:\n            raise SystemExit(\n                \"When the -p option is given, it only makes \"\n                \"sense to add one file at a time.\"\n            )\n        if len(args.origs) == 1 and os.path.isdir(args.origs[-1]):\n            raise SystemExit(\n                \"It is not possible to add a directory \" \"when the -p option is given.\"\n            )\n\n        (root, _, lang, genre, path, _) = util.split_path(args.parallel_file)\n        adder = AddToCorpus(root, args.lang, os.path.join(genre, path))\n\n        orig = args.origs[0]\n        if os.path.isfile(orig):\n            if args.name:\n                newname = os.path.join(os.path.dirname(orig), args.name)\n                shutil.copy(orig, newname)\n                orig = newname\n            adder.copy_file_to_corpus(\n                origpath=orig, metadata_filename=orig, parallelpath=args.parallel_file\n            )\n        elif orig.startswith(\"http\"):\n            adder.copy_url_to_corpus(\n                orig, wanted_name=args.name, parallelpath=args.parallel_file\n            )\n\n    adder.add_files_to_working_copy()\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def parse_args():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Add file(s) to a corpus directory. The filenames are \"\n        \"converted to ascii only names. Metadata files containing the \"\n        \"original name, the main language, the genre and possibly parallel \"\n        \"files are also made. The files are added to the working copy.\",\n    )\n    parser.add_argument(\n        \"origs\",\n        nargs=\"+\",\n        help=\"The original files, urls or directories where \"\n        \"the original files reside (not the corpus repository)\",\n    )\n    parser.add_argument(\n        \"--name\",\n        dest=\"name\",\n        help=\"Specify the name of the file in the corpus. \"\n        \"Especially files fetched from the net often have \"\n        \"names that are not human friendly. Use this \"\n        \"option to guard against that.\",\n    )\n\n    parallel = parser.add_argument_group(\"parallel\")\n    parallel.add_argument(\n        \"-p\",\n        \"--parallel\",\n        dest=\"parallel_file\",\n        help=\"Path to an existing file in the corpus that \"\n        \"will be parallel to the orig that is about to be added\",\n    )\n    parallel.add_argument(\n        \"-l\", \"--lang\", dest=\"lang\", help=\"Language of the file to be added\"\n    )\n\n    no_parallel = parser.add_argument_group(\"no_parallel\")\n    no_parallel.add_argument(\n        \"-d\",\n        \"--directory\",\n        dest=\"directory\",\n        help=\"The directory where the origs should be placed\",\n    )\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/adder/#corpustools.adder.url_to_filename","title":"<code>url_to_filename(response)</code>","text":"<p>Compute the filename.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Name of the file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/adder.py</code> <pre><code>def url_to_filename(response):\n\"\"\"Compute the filename.\n\n    Args:\n        response (requests.get response).\n\n    Returns:\n        str: Name of the file.\n    \"\"\"\n    try:\n        _, params = cgi.parse_header(response.headers[\"Content-Disposition\"])\n        return params[\"filename\"]\n    except KeyError:\n        return add_url_extension(\n            os.path.basename(response.url), response.headers[\"content-type\"]\n        )\n</code></pre>"},{"location":"reference/analyser/","title":"analyser","text":"<p>Classes and functions to do syntactic analysis on giellatekno xml docs.</p>"},{"location":"reference/analyser/#corpustools.analyser.analyse","title":"<code>analyse(xml_file, modename)</code>","text":"<p>Analyse a file if it is not ocr'ed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def analyse(xml_file, modename):\n\"\"\"Analyse a file if it is not ocr'ed.\"\"\"\n    try:\n        path = corpuspath.CorpusPath(xml_file)\n\n        if not path.metadata.get_variable(\"ocr\"):\n            dependency_analysis(path, modename)\n        else:\n            print(xml_file, \"is an OCR file and will not be analysed\", file=sys.stderr)\n    except (etree.XMLSyntaxError, UserWarning) as error:\n        print(\"Can not parse\", xml_file, file=sys.stderr)\n        print(\"The error was:\", str(error), file=sys.stderr)\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.analyse_in_parallel","title":"<code>analyse_in_parallel(file_list, modename)</code>","text":"<p>Analyse file in parallel.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def analyse_in_parallel(file_list, modename):\n\"\"\"Analyse file in parallel.\"\"\"\n    pool_size = multiprocessing.cpu_count() * 2\n    pool = multiprocessing.Pool(processes=pool_size)\n    pool.map(partial(analyse, modename=modename), file_list)\n    pool.close()  # no more tasks\n    pool.join()  # wrap up current tasks\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.analyse_serially","title":"<code>analyse_serially(file_list, modename)</code>","text":"<p>Analyse files one by one.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def analyse_serially(file_list, modename):\n\"\"\"Analyse files one by one.\"\"\"\n    xml_files = list(file_list)\n    print(f\"Starting the analysis of {len(xml_files)} files\")\n\n    fileno = 0\n    for xml_file in xml_files:\n        fileno += 1\n        # print some ugly banner cos i want to see progress on local\n        # batch job\n        print(\"*\" * 79, file=sys.stderr)\n        print(\n            \"Analysing {} [{} of {}]\".format(\n                xml_file, fileno, len(xml_files), file=sys.stderr\n            )\n        )\n        print(\"*\" * 79, file=sys.stderr)\n        analyse(xml_file, modename)\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.ccatter","title":"<code>ccatter(path)</code>","text":"<p>Turn an xml formatted file into clean text.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def ccatter(path):\n\"\"\"Turn an xml formatted file into clean text.\"\"\"\n    xml_printer = ccat.XMLPrinter(lang=path.pathcomponents.lang, all_paragraphs=True)\n    xml_printer.parse_file(path.converted)\n    text = xml_printer.process_file().getvalue()\n    if text:\n        # Gruesome hack for mhr\n        # When https://github.com/giellalt/lang-mhr/issues/3\n        # is resolved, remove this\n        if path.pathcomponents.lang == \"mhr\":\n            return \" - \".join(part.strip() for part in text.split(\"-\"))\n        # end of hack\n        return text\n\n    raise UserWarning(f\"Empty file {path.converted}\")\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.dependency_analysis","title":"<code>dependency_analysis(path, modename)</code>","text":"<p>Insert disambiguation and dependency analysis into the body.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def dependency_analysis(path, modename):\n\"\"\"Insert disambiguation and dependency analysis into the body.\"\"\"\n    xml_file = etree.parse(path.converted)\n    oldbody = xml_file.find(\".//body\")\n    parent = oldbody.getparent()\n    parent.remove(oldbody)\n\n    body = etree.SubElement(parent, \"body\")\n    dependency = etree.SubElement(body, \"dependency\")\n    dependency.text = etree.CDATA(\n        do_dependency_analysis(\n            ccatter(path),\n            modename=modename if modename is not None else get_modename(path),\n            lang=path.pathcomponents.lang,\n        )\n    )\n    with util.ignored(OSError):\n        os.makedirs(os.path.dirname(path.analysed))\n    with open(path.analysed, \"wb\") as analysed_stream:\n        analysed_stream.write(\n            etree.tostring(\n                xml_file, xml_declaration=True, encoding=\"utf8\", pretty_print=True\n            )\n        )\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.do_dependency_analysis","title":"<code>do_dependency_analysis(text, modename, lang)</code>","text":"<p>Insert disambiguation and dependency analysis into the body.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def do_dependency_analysis(text, modename, lang):\n\"\"\"Insert disambiguation and dependency analysis into the body.\"\"\"\n    pipeline = modes.Pipeline(modename, lang)\n    pipeline.sanity_check()\n\n    return pipeline.run(text.encode(\"utf8\"))\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.get_modename","title":"<code>get_modename(path)</code>","text":"<p>Get the modename depending on the CorpusPath</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def get_modename(path):\n\"\"\"Get the modename depending on the CorpusPath\"\"\"\n    if path.pathcomponents.lang == \"mhr\":\n        year = path.metadata.get_variable(\"year\")\n        if year:\n            if 1909 &lt; int(year) &lt; 1939:\n                return \"hfst_thirties\"\n    if path.pathcomponents.lang == \"mrj\":\n        year = path.metadata.get_variable(\"year\")\n        if year:\n            if 1909 &lt; int(year) &lt; 1939:\n                return \"hfst_thirties\"\n            if 1939 &lt; int(year) &lt; 1995:\n                return \"hfst_eighties\"\n\n    if path.pathcomponents.lang in [\"nob\", \"fin\"]:\n        return \"hfst_no_korp\"\n\n    return \"hfst\"\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.main","title":"<code>main()</code>","text":"<p>Analyse files in the given directories.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def main():\n\"\"\"Analyse files in the given directories.\"\"\"\n    args = parse_options()\n\n    try:\n        if args.serial:\n            analyse_serially(\n                util.collect_files(args.converted_entities, suffix=\".xml\"),\n                args.modename,\n            )\n        else:\n            analyse_in_parallel(\n                util.collect_files(args.converted_entities, suffix=\".xml\"),\n                args.modename,\n            )\n    except util.ArgumentError as error:\n        print(f\"Cannot do analysis\\n{str(error)}\", file=sys.stderr)\n        raise SystemExit(1)\n</code></pre>"},{"location":"reference/analyser/#corpustools.analyser.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the given options.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/analyser.py</code> <pre><code>def parse_options():\n\"\"\"Parse the given options.\"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser], description=\"Analyse files in parallel.\"\n    )\n\n    parser.add_argument(\n        \"--serial\",\n        action=\"store_true\",\n        help=\"When this argument is used files will be analysed one by one.\",\n    )\n    parser.add_argument(\n        \"-k\",\n        \"--modename\",\n        choices=modes.list_modes(),\n        help=\"You can set the analyser pipeline explicitely if you want.\",\n    )\n    parser.add_argument(\n        \"converted_entities\",\n        nargs=\"+\",\n        help=\"converted files or director(y|ies) where the converted files exist\",\n    )\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/argparse_version/","title":"argparse_version","text":"<p>Add version to the argument parser.</p>"},{"location":"reference/avvirconverter/","title":"avvirconverter","text":"<p>Convert \u00c1vvir-files to the Giella xml format.</p>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.convert2intermediate","title":"<code>convert2intermediate(filename)</code>","text":"<p>Convert \u00c1vvir xml files to the giellatekno xml format.</p> <p>The root node in an \u00c1vvir document is article. article nodes contains one or more story nodes. story nodes contain one or more p nodes. p nodes contain span, br and (since 2013) p nodes.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def convert2intermediate(filename):\n\"\"\"Convert \u00c1vvir xml files to the giellatekno xml format.\n\n    The root node in an \u00c1vvir document is article.\n    article nodes contains one or more story nodes.\n    story nodes contain one or more p nodes.\n    p nodes contain span, br and (since 2013) p nodes.\n    \"\"\"\n    avvir_doc = etree.parse(filename).getroot()\n\n    remove_identical_ids(avvir_doc)\n    convert_p(avvir_doc)\n    convert_story(avvir_doc)\n    fix_quotemarks(avvir_doc)\n\n    return convert_article(avvir_doc)\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.convert_article","title":"<code>convert_article(avvir_doc)</code>","text":"<p>The root element of an \u00c1vvir doc is article, rename it to body.</p> <p>Parameters:</p> Name Type Description Default <code>avvir_doc</code> <code>etree.Element</code> <p>the etree that should be manipulated.</p> required <p>Returns:</p> Type Description <p>etree.Element: The document root of the basic Giella xml document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def convert_article(avvir_doc):\n\"\"\"The root element of an \u00c1vvir doc is article, rename it to body.\n\n    Args:\n        avvir_doc (etree.Element): the etree that should be manipulated.\n\n    Returns:\n        etree.Element: The document root of the basic Giella xml document.\n    \"\"\"\n    avvir_doc.tag = \"body\"\n    document = etree.Element(\"document\")\n    document.append(avvir_doc)\n\n    return document\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.convert_p","title":"<code>convert_p(avvir_doc)</code>","text":"<p>Convert story/p elements to one or more p elements.</p> <p>Parameters:</p> Name Type Description Default <code>avvir_doc</code> <code>etree.Element</code> <p>the etree that should be manipulated.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def convert_p(avvir_doc):\n\"\"\"Convert story/p elements to one or more p elements.\n\n    Args:\n        avvir_doc (etree.Element): the etree that should be manipulated.\n    \"\"\"\n    for para in avvir_doc.findall(\"./story/p\"):\n        if para.get(\"class\") is not None:\n            del para.attrib[\"class\"]\n\n        convert_sub_p(para)\n        convert_subelement(para)\n\n        if para.text is None or para.text.strip() == \"\":\n            story = para.getparent()\n            story.remove(para)\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.convert_story","title":"<code>convert_story(avvir_doc)</code>","text":"<p>Convert story elements in to giellatekno xml elements.</p> <p>Parameters:</p> Name Type Description Default <code>avvir_doc</code> <code>etree.Element</code> <p>the etree that should be manipulated.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def convert_story(avvir_doc):\n\"\"\"Convert story elements in to giellatekno xml elements.\n\n    Args:\n        avvir_doc (etree.Element): the etree that should be manipulated.\n    \"\"\"\n    for title in avvir_doc.findall('.//story[@class=\"Tittel\"]'):\n        for para in title.findall(\"./p\"):\n            para.set(\"type\", \"title\")\n\n        del title.attrib[\"class\"]\n        del title.attrib[\"id\"]\n\n        title.tag = \"section\"\n\n    for title in avvir_doc.findall('.//story[@class=\"Undertittel\"]'):\n        for para in title.findall(\"./p\"):\n            para.set(\"type\", \"title\")\n\n        del title.attrib[\"class\"]\n        del title.attrib[\"id\"]\n\n        title.tag = \"section\"\n\n    for story in avvir_doc.findall(\"./story\"):\n        parent = story.getparent()\n        for i, para in enumerate(story.findall(\"./p\")):\n            parent.insert(parent.index(story) + i + 1, para)\n\n        parent.remove(story)\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.convert_sub_p","title":"<code>convert_sub_p(para)</code>","text":"<p>Convert p element found inside story/p elements.</p> <p>These elements contain erroneous text that an editor has removed. This function removes p.text and saves p.tail</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <p>an lxml element, it is a story/p element</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def convert_sub_p(para):\n\"\"\"Convert p element found inside story/p elements.\n\n    These elements contain erroneous text that an editor has removed.\n    This function removes p.text and saves p.tail\n\n    Args:\n        p: an lxml element, it is a story/p element\n    \"\"\"\n    for sub_p in para.findall(\".//p\"):\n        previous = sub_p.getprevious()\n        if previous is None:\n            parent = sub_p.getparent()\n            if sub_p.tail is not None:\n                if parent.text is not None:\n                    parent.text = parent.text + sub_p.tail\n                else:\n                    parent.text = sub_p.tail\n        else:\n            if sub_p.tail is not None:\n                if previous.tail is not None:\n                    previous.tail = previous.tail + sub_p.tail\n                else:\n                    previous.tail = sub_p.tail\n        para.remove(sub_p)\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.convert_subelement","title":"<code>convert_subelement(para)</code>","text":"<p>Convert subelements of story/p elements to p elements.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <p>an lxml element, it is a story/p element</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def convert_subelement(para):\n\"\"\"Convert subelements of story/p elements to p elements.\n\n    Args:\n        p: an lxml element, it is a story/p element\n    \"\"\"\n    position = 1\n    for subelement in para:\n        position = insert_element(para, subelement.text, position)\n\n        for subsubelement in subelement:\n            for text in [subsubelement.text, subsubelement.tail]:\n                position = insert_element(para, text, position)\n\n        position = insert_element(para, subelement.tail, position)\n\n        para.remove(subelement)\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.fix_quotemarks","title":"<code>fix_quotemarks(avvir_doc)</code>","text":"<p>\u00c1vvir has funky quotemarks that seem to be a conversion error from their side.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def fix_quotemarks(avvir_doc):\n\"\"\"\u00c1vvir has funky quotemarks that seem to be a conversion error from their side.\"\"\"\n    for child in avvir_doc:\n        if child.text:\n            for (error, replacement) in [(\"\u2039\u2039\", \"\u00ab\"), (\"\u203a\u203a\", \"\u00bb\")]:\n                child.text = child.text.replace(error, replacement)\n        if child.tail:\n            for (error, replacement) in [(\"\u2039\u2039\", \"\u00ab\"), (\"\u203a\u203a\", \"\u00bb\")]:\n                child.tail = child.tail.replace(error, replacement)\n        fix_quotemarks(child)\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.insert_element","title":"<code>insert_element(para, text, position)</code>","text":"<p>Insert a new element in p's parent.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <p>an lxml element, it is a story/p element</p> required <code>text</code> <p>(unicode) string</p> required <code>position</code> <p>(integer) the position inside p's parent where the new         element is inserted</p> required <p>Returns:</p> Name Type Description <code>position</code> <p>(integer)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def insert_element(para, text, position):\n\"\"\"Insert a new element in p's parent.\n\n    Args:\n        p: an lxml element, it is a story/p element\n        text: (unicode) string\n        position: (integer) the position inside p's parent where the new\n                    element is inserted\n\n    Returns:\n        position: (integer)\n    \"\"\"\n    if text is not None and text.strip() != \"\":\n        new_p = etree.Element(\"p\")\n        new_p.text = text\n        grandparent = para.getparent()\n        grandparent.insert(grandparent.index(para) + position, new_p)\n        position += 1\n\n    return position\n</code></pre>"},{"location":"reference/avvirconverter/#corpustools.avvirconverter.remove_identical_ids","title":"<code>remove_identical_ids(avvir_doc)</code>","text":"<p>Remove identical ids.</p> <p>Parameters:</p> Name Type Description Default <code>avvir_doc</code> <code>etree.Element</code> <p>the etree that should be manipulated.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/avvirconverter.py</code> <pre><code>def remove_identical_ids(avvir_doc):\n\"\"\"Remove identical ids.\n\n    Args:\n        avvir_doc (etree.Element): the etree that should be manipulated.\n    \"\"\"\n    story_ids = set()\n    for story in avvir_doc.xpath(\".//story[@id]\"):\n        story_id = story.get(\"id\")\n        if story_id not in story_ids:\n            story_ids.add(story_id)\n        else:\n            story.getparent().remove(story)\n</code></pre>"},{"location":"reference/basicconverter/","title":"basicconverter","text":"<p>Base class for converters.</p>"},{"location":"reference/basicconverter/#corpustools.basicconverter.BasicConverter","title":"<code>BasicConverter</code>","text":"<p>Take care of data common to all BasicConverter classes.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/basicconverter.py</code> <pre><code>class BasicConverter:\n\"\"\"Take care of data common to all BasicConverter classes.\"\"\"\n\n    def __init__(self, filename):\n\"\"\"Initialise the BasicConverter class.\n\n        Args:\n            filename: string containing the path to the file that should\n            be converted\n            write_intermediate: boolean which decides whether intermediate\n            versions of the converted document should be written (used for\n            debugging purposes).\n        \"\"\"\n        self.orig = filename\n        self.metadata = xslsetter.MetadataHandler(filename + \".xsl\", create=True)\n</code></pre>"},{"location":"reference/basicconverter/#corpustools.basicconverter.BasicConverter.__init__","title":"<code>__init__(filename)</code>","text":"<p>Initialise the BasicConverter class.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <p>string containing the path to the file that should</p> required <code>write_intermediate</code> <p>boolean which decides whether intermediate</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/basicconverter.py</code> <pre><code>def __init__(self, filename):\n\"\"\"Initialise the BasicConverter class.\n\n    Args:\n        filename: string containing the path to the file that should\n        be converted\n        write_intermediate: boolean which decides whether intermediate\n        versions of the converted document should be written (used for\n        debugging purposes).\n    \"\"\"\n    self.orig = filename\n    self.metadata = xslsetter.MetadataHandler(filename + \".xsl\", create=True)\n</code></pre>"},{"location":"reference/bibel_no_aligner/","title":"bibel_no_aligner","text":"<p>Functions to align bible texts from bibel.no.</p>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.add_filename_id","title":"<code>add_filename_id(filename)</code>","text":"<p>Add the tmx filename as an prop element in the header.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def add_filename_id(filename):\n\"\"\"Add the tmx filename as an prop element in the header.\"\"\"\n    prop = etree.Element(\"prop\")\n    prop.attrib[\"type\"] = \"x-filename\"\n    prop.text = os.path.basename(filename)\n\n    return prop\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.common_verses","title":"<code>common_verses(filename, parallel_path)</code>","text":"<p>Return string pairs from common verses.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def common_verses(filename, parallel_path):\n\"\"\"Return string pairs from common verses.\"\"\"\n\n    orig = etree.parse(filename)\n    parallel = etree.parse(parallel_path)\n\n    orig_dict = {verse.get(\"number\"): verse.text for verse in orig.iter(\"verse\")}\n    parallel_dict = {\n        verse.get(\"number\"): verse.text for verse in parallel.iter(\"verse\")\n    }\n\n    common_verse_numbers = set(orig_dict.keys()).intersection(set(parallel_dict.keys()))\n\n    return [\n        (orig_dict[common_verse], parallel_dict[common_verse])\n        for common_verse in sorted(common_verse_numbers)\n    ]\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.main","title":"<code>main()</code>","text":"<p>Make tmx files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def main():\n\"\"\"Make tmx files.\"\"\"\n    args = parse_options()\n\n    for path in valid_path(args.source_lang, args.target_lang):\n        write_tmx(\n            make_tmx(path, args.source_lang, args.target_lang),\n            path.prestable_tmx(args.target_lang),\n        )\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.make_tmx","title":"<code>make_tmx(path, source_lang, target_lang)</code>","text":"<p>Make a tmx element with verse pairs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def make_tmx(path, source_lang, target_lang):\n\"\"\"Make a tmx element with verse pairs.\"\"\"\n    print(\"Making\", path.prestable_tmx(target_lang))\n    tmx = make_tmx_template(path.orig, source_lang)\n    body = etree.SubElement(tmx, \"body\")\n    for common_verse_pair in common_verses(path.orig, path.parallel(target_lang)):\n        translation_unit = etree.SubElement(body, \"tu\")\n        translation_unit.append(make_tuv(common_verse_pair[0], source_lang))\n        translation_unit.append(make_tuv(common_verse_pair[1], target_lang))\n\n    return tmx\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.make_tmx_header","title":"<code>make_tmx_header(filename, source_lang)</code>","text":"<p>Make a tmx header based on the lang variable.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def make_tmx_header(filename, source_lang):\n\"\"\"Make a tmx header based on the lang variable.\"\"\"\n    header = etree.Element(\"header\")\n\n    # Set various attributes\n    header.attrib[\"segtype\"] = \"sentence\"\n    header.attrib[\"o-tmf\"] = \"OmegaT TMX\"\n    header.attrib[\"adminlang\"] = \"en-US\"\n    header.attrib[\"srclang\"] = source_lang\n    header.attrib[\"datatype\"] = \"plaintext\"\n\n    header.append(add_filename_id(filename))\n\n    return header\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.make_tmx_template","title":"<code>make_tmx_template(filename, source_lang)</code>","text":"<p>Make tmx file based on the output of the aligner.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def make_tmx_template(filename, source_lang):\n\"\"\"Make tmx file based on the output of the aligner.\"\"\"\n    tmx = etree.Element(\"tmx\")\n    header = make_tmx_header(filename, source_lang)\n    tmx.append(header)\n\n    return tmx\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.make_tuv","title":"<code>make_tuv(line, lang)</code>","text":"<p>Make a tuv element given an input line and a lang variable.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def make_tuv(line, lang):\n\"\"\"Make a tuv element given an input line and a lang variable.\"\"\"\n    tuv = etree.Element(\"tuv\")\n    tuv.attrib[\"{http://www.w3.org/XML/1998/namespace}lang\"] = lang\n    seg = etree.Element(\"seg\")\n    seg.text = line.strip()\n    tuv.append(seg)\n\n    return tuv\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.parse_options","title":"<code>parse_options()</code>","text":"<p>Gather options.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def parse_options():\n\"\"\"Gather options.\"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser], description=\"Align bibel.no texts.\"\n    )\n\n    parser.add_argument(\"source_lang\", help=\"Source language\")\n    parser.add_argument(\"target_lang\", help=\"Target language\")\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.valid_path","title":"<code>valid_path(source_lang, target_lang)</code>","text":"<p>Yield a CorpusPath if the parallel file exists.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def valid_path(source_lang, target_lang):\n\"\"\"Yield a CorpusPath if the parallel file exists.\"\"\"\n    for testament in [\"nt\", \"ot\"]:\n        source_dir = os.path.join(\n            os.getenv(\"GTBOUND\"), \"orig\", source_lang, \"bible\", testament, \"bibel.no\"\n        )\n        for filename in glob.glob(f\"{source_dir}/*.xml\"):\n            path = corpuspath.CorpusPath(filename)\n            parallel_path = path.parallel(target_lang)\n\n            if os.path.exists(parallel_path):\n                yield path\n</code></pre>"},{"location":"reference/bibel_no_aligner/#corpustools.bibel_no_aligner.write_tmx","title":"<code>write_tmx(tmx, tmx_filename)</code>","text":"<p>Write a tmx file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_aligner.py</code> <pre><code>def write_tmx(tmx, tmx_filename):\n\"\"\"Write a tmx file.\"\"\"\n    with util.ignored(OSError):\n        os.makedirs(os.path.dirname(tmx_filename))\n\n    with open(tmx_filename, \"wb\") as tmx_stream:\n        tmx_stream.write(\n            etree.tostring(\n                tmx, encoding=\"utf8\", pretty_print=True, xml_declaration=True\n            )\n        )\n</code></pre>"},{"location":"reference/bibel_no_crawler/","title":"bibel_no_crawler","text":"<p>Functions to fetch bible texts from bibel.no.</p>"},{"location":"reference/bibel_no_crawler/#corpustools.bibel_no_crawler.fetch_other_languages","title":"<code>fetch_other_languages(book_name, bookindex, chapternumber, address)</code>","text":"<p>Given an address, fetch all parallels.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_crawler.py</code> <pre><code>def fetch_other_languages(book_name, bookindex, chapternumber, address):\n\"\"\"Given an address, fetch all parallels.\"\"\"\n    languages = {\n        \"nob\": \"bokmal11\",\n        \"sme\": \"nordsamisk19\",\n        \"sma\": \"sorsamisk\",\n        \"smj\": \"lulesamisk\",\n    }\n\n    parallels = []\n    for lang in [\"nob\", \"sme\", \"smj\", \"sma\"]:\n        new_address = f'{address.replace(\"bokmal11\", languages[lang])}'\n        # first_page = html.parse(\"nob_mat11.html\")\n        first_page = fetch_page(new_address)\n        body = get_verses(first_page)\n        if body is not None:\n            header = first_page.find(\".//h1\").text.strip()\n            parallels.append(\n                save_page(\n                    lang,\n                    book_name,\n                    filename=namechanger.normalise_filename(\n                        f\"{bookindex:0&gt;2}_{chapternumber:0&gt;3}_{header}\"\n                    ),\n                    body=body,\n                    address=new_address,\n                )\n            )\n\n        for this_parallel in parallels:\n            for that_parallel in parallels:\n                if this_parallel != that_parallel:\n                    this_parallel.metadata.set_parallel_text(\n                        that_parallel.metadata.get_variable(\"mainlang\"),\n                        os.path.basename(that_parallel.orig),\n                    )\n            this_parallel.metadata.write_file()\n</code></pre>"},{"location":"reference/bibel_no_crawler/#corpustools.bibel_no_crawler.fetch_page","title":"<code>fetch_page(address)</code>  <code>cached</code>","text":"<p>Fetch a page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_crawler.py</code> <pre><code>@functools.lru_cache\ndef fetch_page(address):\n\"\"\"Fetch a page.\"\"\"\n    main_content = requests.get(address)\n    return html.document_fromstring(main_content.text)\n</code></pre>"},{"location":"reference/bibel_no_crawler/#corpustools.bibel_no_crawler.get_books","title":"<code>get_books(tree)</code>","text":"<p>Get the addresses for the books on bible.no.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_crawler.py</code> <pre><code>def get_books(tree):\n\"\"\"Get the addresses for the books on bible.no.\"\"\"\n    books = {\"ot\": [], \"nt\": []}\n    for table_row in tree.xpath(\".//table[@class='booklist']/tr\"):\n        for (index, address) in enumerate(table_row.xpath(\"./td[@class='tablePR']/a\")):\n            if index == 1:\n                books[\"ot\"].append(address.get(\"href\"))\n            if index == 3:\n                books[\"nt\"].append(address.get(\"href\"))\n\n    return books\n</code></pre>"},{"location":"reference/bibel_no_crawler/#corpustools.bibel_no_crawler.get_chapter_addresses","title":"<code>get_chapter_addresses(first_chapter_page)</code>","text":"<p>Extract the addresses to the other chapters.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_crawler.py</code> <pre><code>def get_chapter_addresses(first_chapter_page):\n\"\"\"Extract the addresses to the other chapters.\"\"\"\n    return (\n        (address.text.strip(), address.get(\"href\"))\n        for address in first_chapter_page.xpath(\".//a[@class='versechapter']\")\n    )\n</code></pre>"},{"location":"reference/bibel_no_crawler/#corpustools.bibel_no_crawler.get_verses","title":"<code>get_verses(chapter_page)</code>","text":"<p>Extract the chapter content.</p> <p>If the table does not exist, then this chapter does not exist. This is the case for some s\u00e1mi translations.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_crawler.py</code> <pre><code>def get_verses(chapter_page):\n\"\"\"Extract the chapter content.\n\n    If the table does not exist, then this chapter does not exist. This is the\n    case for some s\u00e1mi translations.\n    \"\"\"\n\n    content_element = chapter_page.find(\".//table[@class='biblesingle']/tr/td\")\n    if content_element is not None:\n\n        for bibleref in content_element.xpath(\".//div[@class='bibleref']\"):\n            bibleref.getparent().remove(bibleref)\n\n        body = etree.Element(\"body\")\n        lastparent = body\n        for element in content_element:\n            if element.get(\"class\") in [\"versenumberdropcap\", \"versenumber\"]:\n                verse_number = element.get(\"name\")\n            if element.get(\"class\") == \"verse\":\n                text = \" \".join(\"\".join(element.itertext()).split())\n                if text:\n                    verse = etree.SubElement(lastparent, \"verse\")\n                    verse.set(\"number\", verse_number)\n                    verse.text = text\n            if element.get(\"class\") == \"verseheader\" and element.text is not None:\n                lastparent = etree.SubElement(body, \"section\")\n                lastparent.set(\"title\", element.text.strip())\n\n        return body\n\n    return None\n</code></pre>"},{"location":"reference/bibel_no_crawler/#corpustools.bibel_no_crawler.main","title":"<code>main()</code>","text":"<p>Fetch bible texts from bibel.no</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_crawler.py</code> <pre><code>def main():\n\"\"\"Fetch bible texts from bibel.no\"\"\"\n    prefix = \"https://bibel.no\"\n    books = get_books(fetch_page(\"https://bibel.no/nettbibelen?slang=bokmal11\"))\n    for book_name in books:\n        for (bookindex, first_address) in enumerate(books[book_name], start=1):\n            address = f\"{prefix}{first_address}\"\n            first_page = fetch_page(address)\n            fetch_other_languages(book_name, bookindex, 1, address)\n            for (chapter_number, chapter_address) in get_chapter_addresses(first_page):\n                chapter_address = f\"{prefix}{chapter_address}\"\n                fetch_other_languages(\n                    book_name, bookindex, chapter_number, chapter_address\n                )\n</code></pre>"},{"location":"reference/bibel_no_crawler/#corpustools.bibel_no_crawler.save_page","title":"<code>save_page(language, bookname, filename, body, address)</code>","text":"<p>Save chapter page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/bibel_no_crawler.py</code> <pre><code>def save_page(language, bookname, filename, body, address):\n\"\"\"Save chapter page.\"\"\"\n    language_year = {\"nob\": 2011, \"sme\": 2019.0}\n    name = os.path.join(\n        os.getenv(\"GTBOUND\"),\n        \"orig\",\n        language,\n        \"bible\",\n        bookname,\n        \"bibel.no\",\n        f\"{filename}.xml\",\n    )\n    with util.ignored(OSError):\n        os.makedirs(os.path.dirname(name))\n\n    path = corpuspath.CorpusPath(name)\n    path.metadata.set_variable(\"filename\", address)\n    path.metadata.set_variable(\"mainlang\", language)\n    path.metadata.set_variable(\"genre\", \"bible\")\n    path.metadata.set_variable(\"monolingual\", \"1\")\n    path.metadata.set_variable(\"license_type\", \"standard\")\n    path.metadata.set_variable(\"publisher\", \"Det Norske Bibelselskap\")\n    path.metadata.set_variable(\"publChannel\", \"https://bibel.no/nettbibelen\")\n    path.metadata.set_variable(\"year\", language_year.get(language, datetime.now().year))\n\n    path.metadata.write_file()\n    root = etree.Element(\"document\")\n    root.append(body)\n\n    with open(name, \"wb\") as page_stream:\n        page_stream.write(etree.tostring(root, encoding=\"utf8\", pretty_print=True))\n\n    return path\n</code></pre>"},{"location":"reference/biblexmlconverter/","title":"biblexmlconverter","text":"<p>Convert bible xml files to the Giella xml format.</p>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.convert2intermediate","title":"<code>convert2intermediate(filename)</code>","text":"<p>Convert the bible xml to intermediate Giella xml format.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def convert2intermediate(filename):\n\"\"\"Convert the bible xml to intermediate Giella xml format.\"\"\"\n\n    document = etree.Element(\"document\")\n    document.append(process_bible(etree.parse(filename)))\n\n    return document\n</code></pre>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.make_p","title":"<code>make_p(verses)</code>","text":"<p>Convert verse strings to p element.</p> <p>Parameters:</p> Name Type Description Default <code>verses</code> <p>a list of strings</p> required <p>Returns:</p> Type Description <p>a Giella xml p element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def make_p(verses):\n\"\"\"Convert verse strings to p element.\n\n    Args:\n        verses: a list of strings\n    Returns:\n        a Giella xml p element\n    \"\"\"\n    paragraph = etree.Element(\"p\")\n    paragraph.text = \"\\n\".join(verses)\n\n    return paragraph\n</code></pre>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.process_bible","title":"<code>process_bible(bible_doc)</code>","text":"<p>Convert a bible xml document to a Giella xml document.</p> <p>Parameters:</p> Name Type Description Default <code>bible_doc</code> <code>etree.Element</code> <p>the bible xml tree</p> required <p>Returns:</p> Type Description <p>a Giella xml body element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def process_bible(bible_doc):\n\"\"\"Convert a bible xml document to a Giella xml document.\n\n    Args:\n        bible_doc (etree.Element): the bible xml tree\n\n    Returns:\n        a Giella xml body element.\n    \"\"\"\n    body = etree.Element(\"body\")\n\n    for book in bible_doc.xpath(\".//book\"):\n        body.append(process_book(book))\n\n    return body\n</code></pre>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.process_book","title":"<code>process_book(book_element)</code>","text":"<p>Convert a bible xml book to a Giella xml section one.</p> <p>Parameters:</p> Name Type Description Default <code>book_element</code> <p>a bible xml book element</p> required <p>Returns:</p> Type Description <p>a Giella xml section element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def process_book(book_element):\n\"\"\"Convert a bible xml book to a Giella xml section one.\n\n    Args:\n        book_element: a bible xml book element\n\n    Returns:\n        a Giella xml section element.\n    \"\"\"\n    section = etree.Element(\"section\")\n\n    title = etree.Element(\"p\")\n    title.set(\"type\", \"title\")\n    title.text = book_element.get(\"title\")\n\n    section.append(title)\n\n    for chapter_element in book_element:\n        if chapter_element.tag != \"chapter\":\n            raise UserWarning(\n                \"{}: Unexpected element in book: {}\".format(chapter_element.tag)\n            )\n\n        section.append(process_chapter(chapter_element))\n\n    return section\n</code></pre>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.process_chapter","title":"<code>process_chapter(chapter_element)</code>","text":"<p>Convert a bible xml chapter to a Giella xml section one.</p> <p>Parameters:</p> Name Type Description Default <code>chapter_element</code> <p>a bible xml chapter element</p> required <p>Returns:</p> Type Description <p>a Giella xml section element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def process_chapter(chapter_element):\n\"\"\"Convert a bible xml chapter to a Giella xml section one.\n\n    Args:\n        chapter_element: a bible xml chapter element\n\n    Returns:\n        a Giella xml section element.\n    \"\"\"\n    section = etree.Element(\"section\")\n\n    text_parts = []\n    if chapter_element.get(\"number\") is not None:\n        text_parts.append(chapter_element.get(\"number\"))\n    if chapter_element.get(\"title\") is not None:\n        text_parts.append(chapter_element.get(\"title\"))\n\n    title = etree.Element(\"p\")\n    title.set(\"type\", \"title\")\n    title.text = \" \".join(text_parts)\n\n    section.append(title)\n\n    for child in chapter_element:\n        if child.tag == \"section\":\n            section.append(process_section(child))\n        elif child.tag == \"verse\":\n            paragraph = etree.Element(\"p\")\n            paragraph.text = child.text\n            section.append(paragraph)\n        else:\n            raise UserWarning(f\"Unexpected element in chapter: {child.tag}\")\n\n    return section\n</code></pre>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.process_p","title":"<code>process_p(paragraph)</code>","text":"<p>Convert bible xml verse elements to p elements.</p> <p>Returns:</p> Type Description <p>a Giella xml p element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def process_p(paragraph):\n\"\"\"Convert bible xml verse elements to p elements.\n\n    Args:\n        p is a bible xml p element.\n    Returns:\n        a Giella xml p element\n    \"\"\"\n    verses = []\n    for child in paragraph:\n        text = process_verse(child)\n        if text:\n            verses.append(text)\n\n    paragraph = etree.Element(\"p\")\n    paragraph.text = \"\\n\".join(verses)\n\n    return paragraph\n</code></pre>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.process_section","title":"<code>process_section(section_element)</code>","text":"<p>Process the section element found in the bible xml documents.</p> <p>Parameters:</p> Name Type Description Default <code>section_element</code> <p>an etree element containing the section element</p> required <p>Returns:</p> Name Type Description <code>section</code> <p>an etree element containing a corpus xml section.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def process_section(section_element):\n\"\"\"Process the section element found in the bible xml documents.\n\n    Args:\n        section_element: an etree element containing the section element\n        found in a bible xml document.\n\n    Returns:\n        section: an etree element containing a corpus xml section.\n    \"\"\"\n    section = etree.Element(\"section\")\n\n    title = etree.Element(\"p\")\n    title.set(\"type\", \"title\")\n    title.text = section_element.get(\"title\")\n\n    section.append(title)\n\n    verses = []\n    for element in section_element:\n        if element.tag == \"p\":\n            if verses:\n                section.append(make_p(verses))\n                verses = []\n            section.append(process_p(element))\n        elif element.tag == \"verse\":\n            text = process_verse(element)\n            if text:\n                verses.append(text)\n        else:\n            raise UserWarning(f\"Unexpected element in section: {element.tag}\")\n\n    section.append(make_p(verses))\n\n    return section\n</code></pre>"},{"location":"reference/biblexmlconverter/#corpustools.biblexmlconverter.process_verse","title":"<code>process_verse(verse_element)</code>","text":"<p>Process the verse element found in bible xml documents.</p> <p>Parameters:</p> Name Type Description Default <code>verse_element</code> <p>an etree element containing the verse element found</p> required <p>Returns:</p> Type Description <p>A string containing the text of the verse element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/biblexmlconverter.py</code> <pre><code>def process_verse(verse_element):\n\"\"\"Process the verse element found in bible xml documents.\n\n    Args:\n        verse_element: an etree element containing the verse element found\n        in a bible xml document.\n\n    Returns:\n        A string containing the text of the verse element.\n    \"\"\"\n    if verse_element.tag != \"verse\":\n        raise UserWarning(f\"Unexpected element in verse: {verse_element.tag}\")\n\n    return verse_element.text\n</code></pre>"},{"location":"reference/ccat/","title":"ccat","text":"<p>Classes and functions to convert giellatekno xml formatted files to text.</p>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter","title":"<code>XMLPrinter</code>","text":"<p>Convert giellatekno xml formatted files to plain text.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>class XMLPrinter:\n\"\"\"Convert giellatekno xml formatted files to plain text.\"\"\"\n\n    def __init__(\n        self,\n        lang=None,\n        all_paragraphs=False,\n        title=False,\n        listitem=False,\n        table=False,\n        correction=False,\n        error=False,\n        errorort=False,\n        errorortreal=False,\n        errormorphsyn=False,\n        errorsyn=False,\n        errorlex=False,\n        errorlang=False,\n        foreign=False,\n        errorformat=False,\n        noforeign=False,\n        withforeign=False,\n        typos=False,\n        print_filename=False,\n        one_word_per_line=False,\n        disambiguation=False,\n        dependency=False,\n        hyph_replacement=\"\",\n    ):\n\"\"\"Setup all the options.\n\n        The handling of error* elements are governed by the error*,\n        noforeign, correction, typos and one_word_per_line arguments.\n\n        If one_word_per_line and typos are False and correction is True, the\n        content of the correct attribute should be printed instead of the\n        .text part of the error element.\n\n        If one_word_per_line or typos are True, the .text part, the correct\n        attribute and the other attributes of the error* element should be\n        printed out on one line.\n\n        If typos is True and some of the error* options are True, only the\n        elements that are True should be output\n\n        If one_word_per_line is True and some of the error* options are True,\n        only the elements that are True should get the error treatment, the\n        other ones get treated as plain elements.\n\n        If noforeign is True, neither the errorlang.text part nor the correct\n        attribute should be printed.\n        \"\"\"\n        self.paragraph = True\n        self.all_paragraphs = all_paragraphs\n\n        if title or listitem or table:\n            self.paragraph = False\n\n        self.title = title\n        self.listitem = listitem\n        self.table = table\n\n        self.correction = correction\n        self.error = error\n        self.errorort = errorort\n        self.errorortreal = errorortreal\n        self.errormorphsyn = errormorphsyn\n        self.errorsyn = errorsyn\n        self.errorlex = errorlex\n        self.errorlang = errorlang\n        self.noforeign = noforeign\n        self.foreign = foreign\n        self.errorformat = errorformat\n\n        self.error_filtering = (\n            error\n            or errorort\n            or errorortreal\n            or errormorphsyn\n            or errorsyn\n            or errorlex\n            or errorlang\n            or errorformat\n        )\n\n        if withforeign:\n            self.correction = False\n            self.error = True\n            self.errorort = True\n            self.errorortreal = True\n            self.errormorphsyn = True\n            self.errorsyn = True\n            self.errorlex = True\n            self.errorformat = True\n            self.errorlang = False\n            self.noforeign = False\n            self.error_filtering = True\n\n        self.typos = typos\n        self.print_filename = print_filename\n        if self.typos:\n            self.one_word_per_line = True\n        else:\n            self.one_word_per_line = one_word_per_line\n\n        if lang and lang.startswith(\"!\"):\n            self.lang = lang[1:]\n            self.invert_lang = True\n        else:\n            self.lang = lang\n            self.invert_lang = False\n\n        self.disambiguation = disambiguation\n        self.dependency = dependency\n\n        if hyph_replacement == \"xml\":\n            self.hyph_replacement = \"&lt;hyph/&gt;\"\n        else:\n            self.hyph_replacement = hyph_replacement\n\n    def get_lang(self):\n\"\"\"Get the lang of the file.\"\"\"\n        return self.etree.getroot().attrib[\"{http://www.w3.org/XML/1998/namespace}lang\"]\n\n    @staticmethod\n    def get_element_language(element, parentlang):\n\"\"\"Get the language of element.\n\n        Elements inherit the parents language if not explicitely set\n        \"\"\"\n        if element.get(\"{http://www.w3.org/XML/1998/namespace}lang\") is None:\n            return parentlang\n        else:\n            return element.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n\n    def collect_not_inline_errors(self, element, textlist):\n\"\"\"Add the formatted errors as strings to the textlist list.\"\"\"\n        error_string = self.error_not_inline(element)\n        if error_string != \"\":\n            textlist.append(error_string)\n\n        for child in element:\n            if self.visit_error_not_inline(child):\n                self.collect_not_inline_errors(child, textlist)\n\n        if not self.typos:\n            if element.tail is not None and element.tail.strip() != \"\":\n                if not self.one_word_per_line:\n                    textlist.append(element.tail)\n                else:\n                    textlist.extend(element.tail.strip().split())\n\n    @staticmethod\n    def corrected_texts(error_element):\n\"\"\"Yield corrected versions of the error element.\"\"\"\n        for correct in error_element.xpath(\"./correct\"):\n            correct_text = \"\" if correct.text is None else correct.text\n            tail_text = \"\" if error_element.tail is None else error_element.tail\n            yield f\"{correct_text}{tail_text}\"\n\n    def error_not_inline(self, element):\n\"\"\"Collect and format parts of the element.\n\n        Also scan the children if there is no error filtering or\n        if the element is filtered\n        \"\"\"\n        text = []\n        if element.text is not None and element.text.strip() != \"\":\n            text.append(element.text)\n\n        if not self.error_filtering or self.include_this_error(element):\n            for child in element:\n                if child.tag != \"correct\":\n                    text.extend(corrected for corrected in self.corrected_texts(child))\n\n        text.extend(\n            self.get_error_attributes(correct) for correct in element.xpath(\"./correct\")\n        )\n        return \"\".join(text)\n\n    @staticmethod\n    def combine(text, text_list):\n\"\"\"Combine a text with a parto f the text_list.\"\"\"\n        return [f\"{text}{part}\" for part in text_list]\n\n    def get_error_attributes(self, correct_element):\n\"\"\"Collect and format the attributes + the filename.\"\"\"\n        text = [\"\\t\"]\n        text.append(\"\" if correct_element.text is None else correct_element.text)\n\n        attributes = correct_element.attrib\n        attr = [key + \"=\" + str(attributes[key]) for key in sorted(attributes)]\n\n        if attr:\n            text.append(\"\\t#\")\n            text.append(\",\".join(attr))\n\n            if self.print_filename:\n                text.append(f\", file: {os.path.basename(self.filename)}\")\n\n        elif self.print_filename:\n            text.append(f\"\\t#file: {os.path.basename(self.filename)}\")\n\n        return \"\".join(text)\n\n    def collect_inline_errors(self, element, textlist, parentlang):\n\"\"\"Add the \"correct\" element to the list textlist.\"\"\"\n        correct = element.find(\"./correct\")\n        if correct is not None and not self.noforeign:\n            textlist.append(\"\" if correct.text is None else correct.text)\n\n        self.get_contents(element.tail, textlist, parentlang)\n\n    def collect_text(self, element, parentlang, buffer):\n\"\"\"Collect text from element, and write the contents to buffer.\"\"\"\n        textlist = []\n\n        self.visit_nonerror_element(element, textlist, parentlang)\n\n        if textlist:\n            if not self.one_word_per_line:\n                textlist[-1] = textlist[-1].rstrip()\n                buffer.write(\"\".join(textlist))\n                buffer.write(\" \u00b6\\n\")\n            else:\n                buffer.write(\"\\n\".join(textlist))\n                buffer.write(\"\\n\")\n\n    def is_correct_lang(self, elt_lang):\n\"\"\"Check if elt_lang is a wanted language.\n\n        Args:\n            elt_lang (str): a three character language.\n\n        Returns:\n            boolean\n        \"\"\"\n        return (\n            self.lang is None\n            or (not self.invert_lang and elt_lang == self.lang)\n            or (self.invert_lang and elt_lang != self.lang)\n        )\n\n    def get_contents(self, elt_contents, textlist, elt_lang):\n\"\"\"Get the contents of a xml document.\n\n        Args:\n            elt_contents (str): the text of an etree element.\n            textlist (list of str): text will be added this list.\n            elt_lang (str): language of the element.\n        \"\"\"\n        if elt_contents is not None:\n            text = elt_contents\n            if self.is_correct_lang(elt_lang):\n                if not self.one_word_per_line:\n                    textlist.append(text)\n                else:\n                    textlist.extend(text.split())\n\n    def visit_children(self, element, textlist, parentlang):\n\"\"\"Visit the children of element, adding their content to textlist.\"\"\"\n        for child in element:\n            if child.tag != \"correct\":\n                if child.tag == \"errorlang\" and self.noforeign and self.typos:\n                    pass\n                elif child.tag == \"errorlang\" and self.noforeign:\n                    self.get_contents(child.tail, textlist, parentlang)\n                elif self.visit_error_inline(child):\n                    self.collect_inline_errors(\n                        child, textlist, self.get_element_language(child, parentlang)\n                    )\n                elif self.visit_error_not_inline(child):\n                    self.collect_not_inline_errors(child, textlist)\n                else:\n                    self.visit_nonerror_element(\n                        child, textlist, self.get_element_language(element, parentlang)\n                    )\n\n    def visit_nonerror_element(self, element, textlist, parentlang):\n\"\"\"Visit and extract text from non error element.\"\"\"\n        if not self.typos:\n            self.get_contents(\n                element.text, textlist, self.get_element_language(element, parentlang)\n            )\n        self.visit_children(element, textlist, parentlang)\n        if not self.typos:\n            self.get_contents(element.tail, textlist, parentlang)\n\n    def visit_this_node(self, element):\n\"\"\"Return True if the element should be visited.\"\"\"\n        return (\n            self.all_paragraphs\n            or (\n                self.paragraph is True\n                and (element.get(\"type\") is None or element.get(\"type\") == \"text\")\n            )\n            or (self.title is True and element.get(\"type\") == \"title\")\n            or (self.listitem is True and element.get(\"type\") == \"listitem\")\n            or (self.table is True and element.get(\"type\") == \"tablecell\")\n        )\n\n    def visit_error_not_inline(self, element):\n\"\"\"Determine whether element should be visited.\"\"\"\n        return (\n            element.tag.startswith(\"error\")\n            and self.one_word_per_line\n            and not self.error_filtering\n            or self.include_this_error(element)\n        )\n\n    def visit_error_inline(self, element):\n\"\"\"Determine whether element should be visited.\"\"\"\n        return (\n            element.tag.startswith(\"error\")\n            and not self.one_word_per_line\n            and (self.correction or self.include_this_error(element))\n        )\n\n    def include_this_error(self, element):\n\"\"\"Determine whether element should be visited.\"\"\"\n        return self.error_filtering and (\n            (element.tag == \"error\" and self.error)\n            or (element.tag == \"errorort\" and self.errorort)\n            or (element.tag == \"errorortreal\" and self.errorortreal)\n            or (element.tag == \"errormorphsyn\" and self.errormorphsyn)\n            or (element.tag == \"errorsyn\" and self.errorsyn)\n            or (element.tag == \"errorlex\" and self.errorlex)\n            or (element.tag == \"errorformat\" and self.errorformat)\n            or (element.tag == \"errorlang\" and self.errorlang)\n            or (element.tag == \"errorlang\" and self.noforeign)\n        )\n\n    def parse_file(self, filename):\n\"\"\"Parse the xml document.\n\n        Args:\n            filename (str): path to the filename.\n        \"\"\"\n        self.filename = filename\n        p = etree.XMLParser(huge_tree=True)\n        self.etree = etree.parse(filename, p)\n\n    def process_file(self):\n\"\"\"Process the given file, adding the text into buffer.\n\n        Returns the buffer\n        \"\"\"\n        buffer = StringIO()\n\n        self.handle_hyph()\n        if self.dependency:\n            self.print_element(self.etree.find(\".//dependency\"), buffer)\n        elif self.disambiguation:\n            self.print_element(self.etree.find(\".//disambiguation\"), buffer)\n        else:\n            for paragraph in self.etree.findall(\".//p\"):\n                if self.is_correct_lang(\n                    self.get_element_language(paragraph, self.get_lang())\n                ) and self.visit_this_node(paragraph):\n                    self.collect_text(paragraph, self.get_lang(), buffer)\n\n        return buffer\n\n    def handle_hyph(self):\n\"\"\"Replace hyph tags.\"\"\"\n        hyph_tails = []\n        for hyph in self.etree.findall(\".//hyph\"):\n            if hyph.tail is not None:\n                hyph_tails.append(hyph.tail)\n\n            if hyph.getnext() is None:\n                if hyph.getparent().text is not None:\n                    hyph_tails.insert(0, hyph.getparent().text)\n                hyph.getparent().text = self.hyph_replacement.join(hyph_tails)\n                hyph_tails[:] = []\n\n            hyph.getparent().remove(hyph)\n\n    def print_element(self, element, buffer):\n\"\"\"Write the text of the element to the buffer.\n\n        Args:\n            element (etree._Element):\n            buffer ():\n        \"\"\"\n        if element is not None and element.text is not None:\n            buffer.write(element.text)\n\n    def print_file(self, file_):\n\"\"\"Print a xml file to stdout.\"\"\"\n        if file_.endswith(\".xml\"):\n            self.parse_file(file_)\n            try:\n                sys.stdout.write(self.process_file().getvalue())\n            except BrokenPipeError:\n                pass\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.__init__","title":"<code>__init__(lang=None, all_paragraphs=False, title=False, listitem=False, table=False, correction=False, error=False, errorort=False, errorortreal=False, errormorphsyn=False, errorsyn=False, errorlex=False, errorlang=False, foreign=False, errorformat=False, noforeign=False, withforeign=False, typos=False, print_filename=False, one_word_per_line=False, disambiguation=False, dependency=False, hyph_replacement='')</code>","text":"<p>Setup all the options.</p> <p>The handling of error elements are governed by the error, noforeign, correction, typos and one_word_per_line arguments.</p> <p>If one_word_per_line and typos are False and correction is True, the content of the correct attribute should be printed instead of the .text part of the error element.</p> <p>If one_word_per_line or typos are True, the .text part, the correct attribute and the other attributes of the error* element should be printed out on one line.</p> <p>If typos is True and some of the error* options are True, only the elements that are True should be output</p> <p>If one_word_per_line is True and some of the error* options are True, only the elements that are True should get the error treatment, the other ones get treated as plain elements.</p> <p>If noforeign is True, neither the errorlang.text part nor the correct attribute should be printed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def __init__(\n    self,\n    lang=None,\n    all_paragraphs=False,\n    title=False,\n    listitem=False,\n    table=False,\n    correction=False,\n    error=False,\n    errorort=False,\n    errorortreal=False,\n    errormorphsyn=False,\n    errorsyn=False,\n    errorlex=False,\n    errorlang=False,\n    foreign=False,\n    errorformat=False,\n    noforeign=False,\n    withforeign=False,\n    typos=False,\n    print_filename=False,\n    one_word_per_line=False,\n    disambiguation=False,\n    dependency=False,\n    hyph_replacement=\"\",\n):\n\"\"\"Setup all the options.\n\n    The handling of error* elements are governed by the error*,\n    noforeign, correction, typos and one_word_per_line arguments.\n\n    If one_word_per_line and typos are False and correction is True, the\n    content of the correct attribute should be printed instead of the\n    .text part of the error element.\n\n    If one_word_per_line or typos are True, the .text part, the correct\n    attribute and the other attributes of the error* element should be\n    printed out on one line.\n\n    If typos is True and some of the error* options are True, only the\n    elements that are True should be output\n\n    If one_word_per_line is True and some of the error* options are True,\n    only the elements that are True should get the error treatment, the\n    other ones get treated as plain elements.\n\n    If noforeign is True, neither the errorlang.text part nor the correct\n    attribute should be printed.\n    \"\"\"\n    self.paragraph = True\n    self.all_paragraphs = all_paragraphs\n\n    if title or listitem or table:\n        self.paragraph = False\n\n    self.title = title\n    self.listitem = listitem\n    self.table = table\n\n    self.correction = correction\n    self.error = error\n    self.errorort = errorort\n    self.errorortreal = errorortreal\n    self.errormorphsyn = errormorphsyn\n    self.errorsyn = errorsyn\n    self.errorlex = errorlex\n    self.errorlang = errorlang\n    self.noforeign = noforeign\n    self.foreign = foreign\n    self.errorformat = errorformat\n\n    self.error_filtering = (\n        error\n        or errorort\n        or errorortreal\n        or errormorphsyn\n        or errorsyn\n        or errorlex\n        or errorlang\n        or errorformat\n    )\n\n    if withforeign:\n        self.correction = False\n        self.error = True\n        self.errorort = True\n        self.errorortreal = True\n        self.errormorphsyn = True\n        self.errorsyn = True\n        self.errorlex = True\n        self.errorformat = True\n        self.errorlang = False\n        self.noforeign = False\n        self.error_filtering = True\n\n    self.typos = typos\n    self.print_filename = print_filename\n    if self.typos:\n        self.one_word_per_line = True\n    else:\n        self.one_word_per_line = one_word_per_line\n\n    if lang and lang.startswith(\"!\"):\n        self.lang = lang[1:]\n        self.invert_lang = True\n    else:\n        self.lang = lang\n        self.invert_lang = False\n\n    self.disambiguation = disambiguation\n    self.dependency = dependency\n\n    if hyph_replacement == \"xml\":\n        self.hyph_replacement = \"&lt;hyph/&gt;\"\n    else:\n        self.hyph_replacement = hyph_replacement\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.collect_inline_errors","title":"<code>collect_inline_errors(element, textlist, parentlang)</code>","text":"<p>Add the \"correct\" element to the list textlist.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def collect_inline_errors(self, element, textlist, parentlang):\n\"\"\"Add the \"correct\" element to the list textlist.\"\"\"\n    correct = element.find(\"./correct\")\n    if correct is not None and not self.noforeign:\n        textlist.append(\"\" if correct.text is None else correct.text)\n\n    self.get_contents(element.tail, textlist, parentlang)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.collect_not_inline_errors","title":"<code>collect_not_inline_errors(element, textlist)</code>","text":"<p>Add the formatted errors as strings to the textlist list.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def collect_not_inline_errors(self, element, textlist):\n\"\"\"Add the formatted errors as strings to the textlist list.\"\"\"\n    error_string = self.error_not_inline(element)\n    if error_string != \"\":\n        textlist.append(error_string)\n\n    for child in element:\n        if self.visit_error_not_inline(child):\n            self.collect_not_inline_errors(child, textlist)\n\n    if not self.typos:\n        if element.tail is not None and element.tail.strip() != \"\":\n            if not self.one_word_per_line:\n                textlist.append(element.tail)\n            else:\n                textlist.extend(element.tail.strip().split())\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.collect_text","title":"<code>collect_text(element, parentlang, buffer)</code>","text":"<p>Collect text from element, and write the contents to buffer.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def collect_text(self, element, parentlang, buffer):\n\"\"\"Collect text from element, and write the contents to buffer.\"\"\"\n    textlist = []\n\n    self.visit_nonerror_element(element, textlist, parentlang)\n\n    if textlist:\n        if not self.one_word_per_line:\n            textlist[-1] = textlist[-1].rstrip()\n            buffer.write(\"\".join(textlist))\n            buffer.write(\" \u00b6\\n\")\n        else:\n            buffer.write(\"\\n\".join(textlist))\n            buffer.write(\"\\n\")\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.combine","title":"<code>combine(text, text_list)</code>  <code>staticmethod</code>","text":"<p>Combine a text with a parto f the text_list.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>@staticmethod\ndef combine(text, text_list):\n\"\"\"Combine a text with a parto f the text_list.\"\"\"\n    return [f\"{text}{part}\" for part in text_list]\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.corrected_texts","title":"<code>corrected_texts(error_element)</code>  <code>staticmethod</code>","text":"<p>Yield corrected versions of the error element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>@staticmethod\ndef corrected_texts(error_element):\n\"\"\"Yield corrected versions of the error element.\"\"\"\n    for correct in error_element.xpath(\"./correct\"):\n        correct_text = \"\" if correct.text is None else correct.text\n        tail_text = \"\" if error_element.tail is None else error_element.tail\n        yield f\"{correct_text}{tail_text}\"\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.error_not_inline","title":"<code>error_not_inline(element)</code>","text":"<p>Collect and format parts of the element.</p> <p>Also scan the children if there is no error filtering or if the element is filtered</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def error_not_inline(self, element):\n\"\"\"Collect and format parts of the element.\n\n    Also scan the children if there is no error filtering or\n    if the element is filtered\n    \"\"\"\n    text = []\n    if element.text is not None and element.text.strip() != \"\":\n        text.append(element.text)\n\n    if not self.error_filtering or self.include_this_error(element):\n        for child in element:\n            if child.tag != \"correct\":\n                text.extend(corrected for corrected in self.corrected_texts(child))\n\n    text.extend(\n        self.get_error_attributes(correct) for correct in element.xpath(\"./correct\")\n    )\n    return \"\".join(text)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.get_contents","title":"<code>get_contents(elt_contents, textlist, elt_lang)</code>","text":"<p>Get the contents of a xml document.</p> <p>Parameters:</p> Name Type Description Default <code>elt_contents</code> <code>str</code> <p>the text of an etree element.</p> required <code>textlist</code> <code>list of str</code> <p>text will be added this list.</p> required <code>elt_lang</code> <code>str</code> <p>language of the element.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def get_contents(self, elt_contents, textlist, elt_lang):\n\"\"\"Get the contents of a xml document.\n\n    Args:\n        elt_contents (str): the text of an etree element.\n        textlist (list of str): text will be added this list.\n        elt_lang (str): language of the element.\n    \"\"\"\n    if elt_contents is not None:\n        text = elt_contents\n        if self.is_correct_lang(elt_lang):\n            if not self.one_word_per_line:\n                textlist.append(text)\n            else:\n                textlist.extend(text.split())\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.get_element_language","title":"<code>get_element_language(element, parentlang)</code>  <code>staticmethod</code>","text":"<p>Get the language of element.</p> <p>Elements inherit the parents language if not explicitely set</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>@staticmethod\ndef get_element_language(element, parentlang):\n\"\"\"Get the language of element.\n\n    Elements inherit the parents language if not explicitely set\n    \"\"\"\n    if element.get(\"{http://www.w3.org/XML/1998/namespace}lang\") is None:\n        return parentlang\n    else:\n        return element.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.get_error_attributes","title":"<code>get_error_attributes(correct_element)</code>","text":"<p>Collect and format the attributes + the filename.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def get_error_attributes(self, correct_element):\n\"\"\"Collect and format the attributes + the filename.\"\"\"\n    text = [\"\\t\"]\n    text.append(\"\" if correct_element.text is None else correct_element.text)\n\n    attributes = correct_element.attrib\n    attr = [key + \"=\" + str(attributes[key]) for key in sorted(attributes)]\n\n    if attr:\n        text.append(\"\\t#\")\n        text.append(\",\".join(attr))\n\n        if self.print_filename:\n            text.append(f\", file: {os.path.basename(self.filename)}\")\n\n    elif self.print_filename:\n        text.append(f\"\\t#file: {os.path.basename(self.filename)}\")\n\n    return \"\".join(text)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.get_lang","title":"<code>get_lang()</code>","text":"<p>Get the lang of the file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def get_lang(self):\n\"\"\"Get the lang of the file.\"\"\"\n    return self.etree.getroot().attrib[\"{http://www.w3.org/XML/1998/namespace}lang\"]\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.handle_hyph","title":"<code>handle_hyph()</code>","text":"<p>Replace hyph tags.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def handle_hyph(self):\n\"\"\"Replace hyph tags.\"\"\"\n    hyph_tails = []\n    for hyph in self.etree.findall(\".//hyph\"):\n        if hyph.tail is not None:\n            hyph_tails.append(hyph.tail)\n\n        if hyph.getnext() is None:\n            if hyph.getparent().text is not None:\n                hyph_tails.insert(0, hyph.getparent().text)\n            hyph.getparent().text = self.hyph_replacement.join(hyph_tails)\n            hyph_tails[:] = []\n\n        hyph.getparent().remove(hyph)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.include_this_error","title":"<code>include_this_error(element)</code>","text":"<p>Determine whether element should be visited.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def include_this_error(self, element):\n\"\"\"Determine whether element should be visited.\"\"\"\n    return self.error_filtering and (\n        (element.tag == \"error\" and self.error)\n        or (element.tag == \"errorort\" and self.errorort)\n        or (element.tag == \"errorortreal\" and self.errorortreal)\n        or (element.tag == \"errormorphsyn\" and self.errormorphsyn)\n        or (element.tag == \"errorsyn\" and self.errorsyn)\n        or (element.tag == \"errorlex\" and self.errorlex)\n        or (element.tag == \"errorformat\" and self.errorformat)\n        or (element.tag == \"errorlang\" and self.errorlang)\n        or (element.tag == \"errorlang\" and self.noforeign)\n    )\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.is_correct_lang","title":"<code>is_correct_lang(elt_lang)</code>","text":"<p>Check if elt_lang is a wanted language.</p> <p>Parameters:</p> Name Type Description Default <code>elt_lang</code> <code>str</code> <p>a three character language.</p> required <p>Returns:</p> Type Description <p>boolean</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def is_correct_lang(self, elt_lang):\n\"\"\"Check if elt_lang is a wanted language.\n\n    Args:\n        elt_lang (str): a three character language.\n\n    Returns:\n        boolean\n    \"\"\"\n    return (\n        self.lang is None\n        or (not self.invert_lang and elt_lang == self.lang)\n        or (self.invert_lang and elt_lang != self.lang)\n    )\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.parse_file","title":"<code>parse_file(filename)</code>","text":"<p>Parse the xml document.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the filename.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def parse_file(self, filename):\n\"\"\"Parse the xml document.\n\n    Args:\n        filename (str): path to the filename.\n    \"\"\"\n    self.filename = filename\n    p = etree.XMLParser(huge_tree=True)\n    self.etree = etree.parse(filename, p)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.print_element","title":"<code>print_element(element, buffer)</code>","text":"<p>Write the text of the element to the buffer.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>etree._Element</code> required <code>buffer</code> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def print_element(self, element, buffer):\n\"\"\"Write the text of the element to the buffer.\n\n    Args:\n        element (etree._Element):\n        buffer ():\n    \"\"\"\n    if element is not None and element.text is not None:\n        buffer.write(element.text)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.print_file","title":"<code>print_file(file_)</code>","text":"<p>Print a xml file to stdout.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def print_file(self, file_):\n\"\"\"Print a xml file to stdout.\"\"\"\n    if file_.endswith(\".xml\"):\n        self.parse_file(file_)\n        try:\n            sys.stdout.write(self.process_file().getvalue())\n        except BrokenPipeError:\n            pass\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.process_file","title":"<code>process_file()</code>","text":"<p>Process the given file, adding the text into buffer.</p> <p>Returns the buffer</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def process_file(self):\n\"\"\"Process the given file, adding the text into buffer.\n\n    Returns the buffer\n    \"\"\"\n    buffer = StringIO()\n\n    self.handle_hyph()\n    if self.dependency:\n        self.print_element(self.etree.find(\".//dependency\"), buffer)\n    elif self.disambiguation:\n        self.print_element(self.etree.find(\".//disambiguation\"), buffer)\n    else:\n        for paragraph in self.etree.findall(\".//p\"):\n            if self.is_correct_lang(\n                self.get_element_language(paragraph, self.get_lang())\n            ) and self.visit_this_node(paragraph):\n                self.collect_text(paragraph, self.get_lang(), buffer)\n\n    return buffer\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.visit_children","title":"<code>visit_children(element, textlist, parentlang)</code>","text":"<p>Visit the children of element, adding their content to textlist.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def visit_children(self, element, textlist, parentlang):\n\"\"\"Visit the children of element, adding their content to textlist.\"\"\"\n    for child in element:\n        if child.tag != \"correct\":\n            if child.tag == \"errorlang\" and self.noforeign and self.typos:\n                pass\n            elif child.tag == \"errorlang\" and self.noforeign:\n                self.get_contents(child.tail, textlist, parentlang)\n            elif self.visit_error_inline(child):\n                self.collect_inline_errors(\n                    child, textlist, self.get_element_language(child, parentlang)\n                )\n            elif self.visit_error_not_inline(child):\n                self.collect_not_inline_errors(child, textlist)\n            else:\n                self.visit_nonerror_element(\n                    child, textlist, self.get_element_language(element, parentlang)\n                )\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.visit_error_inline","title":"<code>visit_error_inline(element)</code>","text":"<p>Determine whether element should be visited.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def visit_error_inline(self, element):\n\"\"\"Determine whether element should be visited.\"\"\"\n    return (\n        element.tag.startswith(\"error\")\n        and not self.one_word_per_line\n        and (self.correction or self.include_this_error(element))\n    )\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.visit_error_not_inline","title":"<code>visit_error_not_inline(element)</code>","text":"<p>Determine whether element should be visited.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def visit_error_not_inline(self, element):\n\"\"\"Determine whether element should be visited.\"\"\"\n    return (\n        element.tag.startswith(\"error\")\n        and self.one_word_per_line\n        and not self.error_filtering\n        or self.include_this_error(element)\n    )\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.visit_nonerror_element","title":"<code>visit_nonerror_element(element, textlist, parentlang)</code>","text":"<p>Visit and extract text from non error element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def visit_nonerror_element(self, element, textlist, parentlang):\n\"\"\"Visit and extract text from non error element.\"\"\"\n    if not self.typos:\n        self.get_contents(\n            element.text, textlist, self.get_element_language(element, parentlang)\n        )\n    self.visit_children(element, textlist, parentlang)\n    if not self.typos:\n        self.get_contents(element.tail, textlist, parentlang)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.XMLPrinter.visit_this_node","title":"<code>visit_this_node(element)</code>","text":"<p>Return True if the element should be visited.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def visit_this_node(self, element):\n\"\"\"Return True if the element should be visited.\"\"\"\n    return (\n        self.all_paragraphs\n        or (\n            self.paragraph is True\n            and (element.get(\"type\") is None or element.get(\"type\") == \"text\")\n        )\n        or (self.title is True and element.get(\"type\") == \"title\")\n        or (self.listitem is True and element.get(\"type\") == \"listitem\")\n        or (self.table is True and element.get(\"type\") == \"tablecell\")\n    )\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.find_files","title":"<code>find_files(targets, extension)</code>","text":"<p>Search for files with extension in targets.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>list of str</code> <p>files or directories</p> required <code>extension</code> <code>str</code> <p>interesting files has this extension.</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>path to the interesting file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def find_files(targets, extension):\n\"\"\"Search for files with extension in targets.\n\n    Args:\n        targets (list of str): files or directories\n        extension (str): interesting files has this extension.\n\n    Yields:\n        str: path to the interesting file\n    \"\"\"\n    for target in targets:\n        if os.path.exists(target):\n            if os.path.isfile(target) and target.endswith(extension):\n                yield target\n            elif os.path.isdir(target):\n                for root, _, files in os.walk(target):\n                    for xml_file in files:\n                        if xml_file.endswith(extension):\n                            yield os.path.join(root, xml_file)\n        else:\n            print(f\"{target} does not exist\", file=sys.stderr)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.main","title":"<code>main()</code>","text":"<p>Set up the XMLPrinter class with the given command line options.</p> <p>Process the given files and directories Print the output to stdout</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>@suppress_broken_pipe_msg\ndef main():\n\"\"\"Set up the XMLPrinter class with the given command line options.\n\n    Process the given files and directories\n    Print the output to stdout\n    \"\"\"\n    args = parse_options()\n\n    xml_printer = XMLPrinter(\n        lang=args.lang,\n        all_paragraphs=args.all_paragraphs,\n        title=args.title,\n        listitem=args.list,\n        table=args.table,\n        correction=args.corrections,\n        error=args.error,\n        errorort=args.errorort,\n        errorortreal=args.errorortreal,\n        errormorphsyn=args.errormorphsyn,\n        errorsyn=args.errorsyn,\n        errorlex=args.errorlex,\n        errorlang=args.errorlang,\n        noforeign=args.noforeign,\n        withforeign=args.withforeign,\n        errorformat=args.errorformat,\n        typos=args.typos,\n        print_filename=args.print_filename,\n        one_word_per_line=args.one_word_per_line,\n        dependency=args.dependency,\n        disambiguation=args.disambiguation,\n        hyph_replacement=args.hyph_replacement,\n    )\n\n    for filename in find_files(args.targets, \".xml\"):\n        xml_printer.print_file(filename)\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the options given to the program.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def parse_options():\n\"\"\"Parse the options given to the program.\"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Print the contents of a corpus in XML format\\n\\\n        The default is to print paragraphs with no type (=text type).\",\n    )\n\n    parser.add_argument(\n        \"-l\",\n        dest=\"lang\",\n        help=\"Print only elements in language LANG. Default \\\n                        is all langs.\",\n    )\n    parser.add_argument(\n        \"-T\", dest=\"title\", action=\"store_true\", help=\"Print paragraphs with title type\"\n    )\n    parser.add_argument(\n        \"-L\", dest=\"list\", action=\"store_true\", help=\"Print paragraphs with list type\"\n    )\n    parser.add_argument(\n        \"-t\", dest=\"table\", action=\"store_true\", help=\"Print paragraphs with table type\"\n    )\n    parser.add_argument(\n        \"-a\", dest=\"all_paragraphs\", action=\"store_true\", help=\"Print all text elements\"\n    )\n\n    parser.add_argument(\n        \"-c\",\n        dest=\"corrections\",\n        action=\"store_true\",\n        help=\"Print corrected text instead of the original \\\n                        typos &amp; errors\",\n    )\n    parser.add_argument(\n        \"-C\",\n        dest=\"error\",\n        action=\"store_true\",\n        help=\"Only print unclassified (\u00a7/&lt;error..&gt;) \\\n                        corrections\",\n    )\n    parser.add_argument(\n        \"-ort\",\n        dest=\"errorort\",\n        action=\"store_true\",\n        help=\"Only print ortoghraphic, non-word \\\n                        ($/&lt;errorort..&gt;) corrections\",\n    )\n    parser.add_argument(\n        \"-ortreal\",\n        dest=\"errorortreal\",\n        action=\"store_true\",\n        help=\"Only print ortoghraphic, real-word \\\n                        (\u00a2/&lt;errorortreal..&gt;) corrections\",\n    )\n    parser.add_argument(\n        \"-morphsyn\",\n        dest=\"errormorphsyn\",\n        action=\"store_true\",\n        help=\"Only print morphosyntactic \\\n                        (\u00a3/&lt;errormorphsyn..&gt;) corrections\",\n    )\n    parser.add_argument(\n        \"-syn\",\n        dest=\"errorsyn\",\n        action=\"store_true\",\n        help=\"Only print syntactic (\u00a5/&lt;errorsyn..&gt;) \\\n                        corrections\",\n    )\n    parser.add_argument(\n        \"-lex\",\n        dest=\"errorlex\",\n        action=\"store_true\",\n        help=\"Only print lexical (\u20ac/&lt;errorlex..&gt;) \\\n                        corrections\",\n    )\n    parser.add_argument(\n        \"-format\",\n        dest=\"errorformat\",\n        action=\"store_true\",\n        help=\"Only print format (\u2030/&lt;errorformat..&gt;) \\\n                        corrections\",\n    )\n    parser.add_argument(\n        \"-foreign\",\n        dest=\"errorlang\",\n        action=\"store_true\",\n        help=\"Only print foreign (\u221e/&lt;errorlang..&gt;) \\\n                        corrections\",\n    )\n    parser.add_argument(\n        \"-noforeign\",\n        dest=\"noforeign\",\n        action=\"store_true\",\n        help=\"Do not print anything from foreign \\\n                        (\u221e/&lt;errorlang..&gt;) corrections\",\n    )\n    parser.add_argument(\n        \"-withforeign\",\n        dest=\"withforeign\",\n        action=\"store_true\",\n        help=\"When printing corrections: include foreign text instead of nothing\",\n    )\n    parser.add_argument(\n        \"-typos\",\n        dest=\"typos\",\n        action=\"store_true\",\n        help=\"Print only the errors/typos in the text, with \\\n                        corrections tab-separated\",\n    )\n    parser.add_argument(\n        \"-f\",\n        dest=\"print_filename\",\n        action=\"store_true\",\n        help=\"Add the source filename as a comment after each \\\n                        error word.\",\n    )\n    parser.add_argument(\n        \"-S\",\n        dest=\"one_word_per_line\",\n        action=\"store_true\",\n        help=\"Print the whole text one word per line; \\\n                        typos have tab separated corrections\",\n    )\n    parser.add_argument(\n        \"-dis\",\n        dest=\"disambiguation\",\n        action=\"store_true\",\n        help=\"Print the disambiguation element\",\n    )\n    parser.add_argument(\n        \"-dep\",\n        dest=\"dependency\",\n        action=\"store_true\",\n        help=\"Print the dependency element\",\n    )\n    parser.add_argument(\n        \"-hyph\",\n        dest=\"hyph_replacement\",\n        default=\"\",\n        help=\"Replace hyph tags with the given argument\",\n    )\n\n    parser.add_argument(\n        \"targets\",\n        nargs=\"+\",\n        help=\"Name of the files or directories to process. \\\n                        If a directory is given, all files in this directory \\\n                        and its subdirectories will be listed.\",\n    )\n\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"reference/ccat/#corpustools.ccat.suppress_broken_pipe_msg","title":"<code>suppress_broken_pipe_msg(function)</code>","text":"<p>Suppress message after a broken pipe error.</p> <p>This code is fetched from: http://stackoverflow.com/questions/14207708/ioerror-errno-32-broken-pipe-python</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <p>the function that should be wrapped by this function.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/ccat.py</code> <pre><code>def suppress_broken_pipe_msg(function):\n\"\"\"Suppress message after a broken pipe error.\n\n    This code is fetched from:\n    http://stackoverflow.com/questions/14207708/ioerror-errno-32-broken-pipe-python\n\n    Args:\n        function: the function that should be wrapped by this function.\n    \"\"\"\n\n    @wraps(function)\n    def wrapper(*args, **kwargs):\n        try:\n            return function(*args, **kwargs)\n        except SystemExit:\n            raise\n        except:\n            print_exc()\n            sys.exit(1)\n        finally:\n            try:\n                sys.stdout.flush()\n            finally:\n                try:\n                    sys.stdout.close()\n                finally:\n                    try:\n                        sys.stderr.flush()\n                    finally:\n                        sys.stderr.close()\n\n    return wrapper\n</code></pre>"},{"location":"reference/ces2homegrown/","title":"ces2homegrown","text":"<p>Turn cesDoc xml into our homegrown xml.</p>"},{"location":"reference/ces2homegrown/#corpustools.ces2homegrown.get_verses","title":"<code>get_verses(chapter)</code>","text":"<p>Extract the chapter content.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ces2homegrown.py</code> <pre><code>def get_verses(chapter):\n\"\"\"Extract the chapter content.\"\"\"\n    body = etree.Element(\"body\")\n    for seg in chapter.iter(\"seg\"):\n        verse = etree.SubElement(body, \"verse\")\n        verse.set(\"number\", seg.get(\"id\").split(\".\")[-1])\n        verse.text = seg.text.strip()\n\n    return body\n</code></pre>"},{"location":"reference/ces2homegrown/#corpustools.ces2homegrown.main","title":"<code>main()</code>","text":"<p>Turn cesDoc to homegrown xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ces2homegrown.py</code> <pre><code>def main():\n\"\"\"Turn cesDoc to homegrown xml.\"\"\"\n    args = parse_options()\n    tree = etree.parse(args.cesdoc)\n\n    chapter_paths = (\n        save_chapter(\n            args.lang,\n            args.testament,\n            f\"{bookindex:0&gt;2}_{chapterindex:0&gt;3}\",\n            get_verses(chapter),\n            os.path.basename(args.cesdoc),\n        )\n        for (bookindex, book) in enumerate(tree.xpath(\".//div[@type='book']\"), start=1)\n        for (chapterindex, chapter) in enumerate(\n            book.xpath(\".//div[@type='chapter']\"), start=1\n        )\n    )\n\n    set_parallels(chapter_paths, args.testament, args.lang)\n</code></pre>"},{"location":"reference/ces2homegrown/#corpustools.ces2homegrown.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the options for this script.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ces2homegrown.py</code> <pre><code>def parse_options():\n\"\"\"Parse the options for this script.\"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Turn cesDoc xml into our homegrown xml.\",\n    )\n\n    parser.add_argument(\"lang\", help=\"Language of the file\")\n    parser.add_argument(\"testament\", choices=[\"ot\", \"nt\"], help=\"Old or new testament\")\n    parser.add_argument(\"cesdoc\", help=\"The cesdoc that should be converted\")\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/ces2homegrown/#corpustools.ces2homegrown.save_chapter","title":"<code>save_chapter(language, testament, filename, body, address)</code>","text":"<p>Save chapter info.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ces2homegrown.py</code> <pre><code>def save_chapter(language, testament, filename, body, address):\n\"\"\"Save chapter info.\"\"\"\n    language_year = {\"nob\": 2011, \"sme\": 2019.0}\n    name = os.path.join(\n        os.getenv(\"GTBOUND\"),\n        \"orig\",\n        language,\n        \"bible\",\n        testament,\n        \"bibel.no\",\n        f\"{filename}.xml\",\n    )\n    with util.ignored(OSError):\n        os.makedirs(os.path.dirname(name))\n\n    path = corpuspath.CorpusPath(name)\n    path.metadata.set_variable(\"filename\", address)\n    path.metadata.set_variable(\"mainlang\", language)\n    path.metadata.set_variable(\"genre\", \"bible\")\n    path.metadata.set_variable(\"monolingual\", \"1\")\n    path.metadata.set_variable(\"license_type\", \"standard\")\n    path.metadata.set_variable(\"year\", language_year.get(language, datetime.now().year))\n\n    path.metadata.write_file()\n    root = etree.Element(\"document\")\n    root.append(body)\n\n    with open(name, \"wb\") as page_stream:\n        page_stream.write(etree.tostring(root, encoding=\"utf8\", pretty_print=True))\n\n    return path\n</code></pre>"},{"location":"reference/ces2homegrown/#corpustools.ces2homegrown.set_parallels","title":"<code>set_parallels(chapter_paths, testament, new_lang)</code>","text":"<p>Set the parallels.</p> <p>Use the nob names as the base, it has all the books and chapters.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/ces2homegrown.py</code> <pre><code>def set_parallels(chapter_paths, testament, new_lang):\n\"\"\"Set the parallels.\n\n    Use the nob names as the base, it has all the books and chapters.\n    \"\"\"\n    nob_names = sorted(\n        glob.glob(\n            f'{os.path.join(os.getenv(\"GTBOUND\"), \"orig/nob/bible\", testament, \"bibel.no\")}/*.xml'\n        )\n    )\n    for (chapter_path, nob_name) in zip(chapter_paths, nob_names):\n        nob_path = corpuspath.CorpusPath(nob_name)\n        nob_meta = nob_path.metadata\n        chapter_meta = chapter_path.metadata\n\n        chapter_meta.set_parallel_text(\"nob\", os.path.basename(nob_name))\n        nob_meta.set_parallel_text(new_lang, os.path.basename(chapter_path.orig))\n        nob_meta.write_file()\n\n        for (lang, filename) in nob_meta.get_parallel_texts().items():\n            chapter_meta.set_parallel_text(lang, filename)\n            parallel_path = corpuspath.CorpusPath(nob_path.parallel(lang))\n            parallel_path.metadata.set_parallel_text(\n                new_lang, os.path.basename(chapter_path.orig)\n            )\n            parallel_path.metadata.write_file()\n\n        chapter_meta.write_file()\n</code></pre>"},{"location":"reference/check_para_consistency/","title":"check_para_consistency","text":"<p>Check the consistency of the parallel entries in the metadata files.</p>"},{"location":"reference/clean_prestable/","title":"clean_prestable","text":"<p>Classes and functions to clean the prestable directories.</p>"},{"location":"reference/clean_prestable/#corpustools.clean_prestable.find_prestable_files","title":"<code>find_prestable_files(corpusdir)</code>","text":"<p>Find interesting files in prestable.</p> <p>Parameters:</p> Name Type Description Default <code>corpusdir</code> <code>src</code> <p>path to a corpus directory</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>path to an interesting prestable file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/clean_prestable.py</code> <pre><code>def find_prestable_files(corpusdir):\n\"\"\"Find interesting files in prestable.\n\n    Args:\n        corpusdir (src): path to a corpus directory\n\n    Yields:\n        str: path to an interesting prestable file\n    \"\"\"\n    for subdir in [\"converted\", \"tmx\"]:\n        prestable_root = os.path.join(corpusdir, \"prestable\", subdir)\n        if os.path.exists(prestable_root):\n            for root, _, files in os.walk(prestable_root):\n                if \"pre_run\" not in root:\n                    for presteable_file in files:\n                        yield os.path.join(root, presteable_file)\n</code></pre>"},{"location":"reference/clean_prestable/#corpustools.clean_prestable.main","title":"<code>main()</code>","text":"<p>Remove files in prestable that don't have original files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/clean_prestable.py</code> <pre><code>def main():\n\"\"\"Remove files in prestable that don't have original files.\"\"\"\n    args = parse_options()\n\n    counter = defaultdict(int)\n    for corpusdir in args.corpusdirs:\n        vcsfactory = versioncontrol.VersionControlFactory()\n        vcs = vcsfactory.vcs(corpusdir)\n        for prestable_path in find_prestable_files(corpusdir):\n            corpus_file = corpuspath.CorpusPath(prestable_path)\n            if not os.path.exists(corpus_file.orig):\n                counter[\"prestable\"] += 1\n                print(f\"Removing {prestable_path}\")\n                print(f\"Orig was {corpus_file.orig}\")\n                try:\n                    vcs.remove(prestable_path)\n                except git.exc.GitCommandError:\n                    util.note(\n                        \"\\nError when trying to remove {}\".format(\n                            corpus_file.prestable_converted\n                        )\n                    )\n                    util.note(f\"Orig was {prestable_path}\\n\")\n\n    for key in counter.keys():\n        print(f\"Removed {counter[key]} files from prestable\")\n</code></pre>"},{"location":"reference/clean_prestable/#corpustools.clean_prestable.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/clean_prestable.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Remove files in prestable that have no original files.\",\n    )\n\n    parser.add_argument(\"corpusdirs\", nargs=\"+\", help=\"Corpus directories\")\n\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/","title":"compare_tmx_goldstandard","text":"<p>Compare prestable tmx files to files produced by the parallelizer.</p>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxComparator","title":"<code>TmxComparator</code>","text":"<p>A class to compare two tmx-files</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>class TmxComparator:\n\"\"\"A class to compare two tmx-files\"\"\"\n\n    def __init__(self, want_tmx, got_tmx):\n        self.want_tmx = want_tmx\n        self.got_tmx = got_tmx\n\n    def get_lines_in_wantedfile(self):\n\"\"\"Return the number of lines in the reference doc\"\"\"\n        return len(self.want_tmx.tmx_to_stringlist())\n\n    def get_number_of_differing_lines(self):\n\"\"\"Find how many lines differ between to tmx documents.\n\n        Given a unified_diff, find out how many lines in the reference doc\n        differs from the doc to be tested. A return value of -1 means that\n        the docs are equal\n        \"\"\"\n        # Start at -1 because a unified diff always starts with a --- line\n        num_diff_lines = -1\n        for line in difflib.unified_diff(\n            self.want_tmx.tmx_to_stringlist(), self.got_tmx.tmx_to_stringlist(), n=0\n        ):\n            if line[:1] == \"-\":\n                num_diff_lines += 1\n\n        return num_diff_lines\n\n    def get_diff_as_text(self):\n\"\"\"Return a stringlist containing the diff lines\"\"\"\n        diff = []\n        for line in difflib.unified_diff(\n            self.want_tmx.tmx_to_stringlist(), self.got_tmx.tmx_to_stringlist(), n=0\n        ):\n            diff.append(line)\n\n        return diff\n\n    def get_lang_diff_as_text(self, lang):\n\"\"\"Return a stringlist containing the diff lines\"\"\"\n        diff = []\n        for line in difflib.unified_diff(\n            self.want_tmx.lang_to_stringlist(lang),\n            self.got_tmx.lang_to_stringlist(lang),\n            n=0,\n        ):\n            diff.append(line + \"\\n\")\n\n        return diff\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxComparator.get_diff_as_text","title":"<code>get_diff_as_text()</code>","text":"<p>Return a stringlist containing the diff lines</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def get_diff_as_text(self):\n\"\"\"Return a stringlist containing the diff lines\"\"\"\n    diff = []\n    for line in difflib.unified_diff(\n        self.want_tmx.tmx_to_stringlist(), self.got_tmx.tmx_to_stringlist(), n=0\n    ):\n        diff.append(line)\n\n    return diff\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxComparator.get_lang_diff_as_text","title":"<code>get_lang_diff_as_text(lang)</code>","text":"<p>Return a stringlist containing the diff lines</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def get_lang_diff_as_text(self, lang):\n\"\"\"Return a stringlist containing the diff lines\"\"\"\n    diff = []\n    for line in difflib.unified_diff(\n        self.want_tmx.lang_to_stringlist(lang),\n        self.got_tmx.lang_to_stringlist(lang),\n        n=0,\n    ):\n        diff.append(line + \"\\n\")\n\n    return diff\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxComparator.get_lines_in_wantedfile","title":"<code>get_lines_in_wantedfile()</code>","text":"<p>Return the number of lines in the reference doc</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def get_lines_in_wantedfile(self):\n\"\"\"Return the number of lines in the reference doc\"\"\"\n    return len(self.want_tmx.tmx_to_stringlist())\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxComparator.get_number_of_differing_lines","title":"<code>get_number_of_differing_lines()</code>","text":"<p>Find how many lines differ between to tmx documents.</p> <p>Given a unified_diff, find out how many lines in the reference doc differs from the doc to be tested. A return value of -1 means that the docs are equal</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def get_number_of_differing_lines(self):\n\"\"\"Find how many lines differ between to tmx documents.\n\n    Given a unified_diff, find out how many lines in the reference doc\n    differs from the doc to be tested. A return value of -1 means that\n    the docs are equal\n    \"\"\"\n    # Start at -1 because a unified diff always starts with a --- line\n    num_diff_lines = -1\n    for line in difflib.unified_diff(\n        self.want_tmx.tmx_to_stringlist(), self.got_tmx.tmx_to_stringlist(), n=0\n    ):\n        if line[:1] == \"-\":\n            num_diff_lines += 1\n\n    return num_diff_lines\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester","title":"<code>TmxGoldstandardTester</code>","text":"<p>A class to test the alignment pipeline against the tmx goldstandard</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>class TmxGoldstandardTester:\n\"\"\"A class to test the alignment pipeline against the tmx goldstandard\"\"\"\n\n    def __init__(self, testresult_filename, dateformat_addition=None):\n\"\"\"Set the name where the testresults should be written\n\n        Find all goldstandard tmx files\n        \"\"\"\n        self.number_of_diff_lines = 0\n        self.testresult_writer = TmxTestDataWriter(testresult_filename)\n        if dateformat_addition is None:\n            self.date = self.dateformat()\n        else:\n            self.date = self.dateformat() + dateformat_addition\n\n    def set_number_of_diff_lines(self, diff_lines):\n\"\"\"Increase the total number of difflines in this test run\"\"\"\n        self.number_of_diff_lines += diff_lines\n\n    def get_number_of_diff_lines(self):\n\"\"\"Get the number of diff lines.\"\"\"\n        return self.number_of_diff_lines\n\n    def dateformat(self):\n\"\"\"Get the date and time, 20111209-1234. Used in a testrun element\"\"\"\n        d = datetime.datetime.fromtimestamp(time.time())\n\n        return d.strftime(\"%Y%m%d-%H%M\")\n\n    def run_test(self):\n\"\"\"Make a testrun element.\n\n        This element contain the result of the test.\n        \"\"\"\n        testrun = self.testresult_writer.make_testrun_element(self.date)\n\n        paralang = \"\"\n        # Go through each tmx goldstandard file\n        for want_tmx_file in self.find_goldstandard_tmx_files():\n            print(f\"testing {want_tmx_file} \u2026\")\n\n            # Calculate the parallel lang, to be used in parallelization\n            if want_tmx_file.find(\"nob2sme\") &gt; -1:\n                paralang = \"sme\"\n            else:\n                paralang = \"nob\"\n\n            # Align files\n            self.align_files(testrun, want_tmx_file, paralang, aligner=\"tca2\")\n\n        # All files have been tested, insert this run at the top of the\n        # paragstest element\n        self.testresult_writer.insert_testrun_element(testrun)\n        # Write data to file\n        self.testresult_writer.write_paragstesting_data()\n\n    def align_files(self, testrun, want_tmx_file, paralang, aligner):\n\"\"\"Align files\n\n        Compare the tmx's of the result of this parallellization and\n        the tmx of the goldstandard file\n        Write the result to a file\n        Write the diffs of these to tmx's to a separate file\n        \"\"\"\n\n        # Compute the name of the main file to parallelize\n        xml_file = self.compute_xmlfilename(want_tmx_file)\n\n        parallelizer = parallelize.Parallelize(xml_file, paralang)\n        got_tmx = parallelizer.parallelize_files()\n\n        # This is the tmx element fetched from the goldstandard file\n        want_tmx = parallelize.Tmx(etree.parse(want_tmx_file))\n\n        # Instantiate a comparator with the two tmxes\n        comparator = TmxComparator(want_tmx, got_tmx)\n\n        # Make a file_element for our results file\n        file_element = self.testresult_writer.make_file_element(\n            filelist[0].get_basename(),\n            str(comparator.get_lines_in_wantedfile()),\n            str(comparator.get_number_of_differing_lines()),\n        )\n\n        self.set_number_of_diff_lines(comparator.get_number_of_differing_lines())\n\n        # Append the result for this file to the testrun element\n        testrun.append(file_element)\n\n        self.write_diff_files(comparator, parallelizer, filelist[0].get_basename())\n\n    def compute_xmlfilename(self, want_tmx_file):\n\"\"\"Compute the name of the xmlfile which should be aligned\"\"\"\n        xml_file = want_tmx_file.replace(\"tmx/goldstandard/\", \"converted/\")\n        xml_file = xml_file.replace(\"nob2sme\", \"nob\")\n        xml_file = xml_file.replace(\"sme2nob\", \"sme\")\n        xml_file = xml_file.replace(\".toktmx\", \".xml\")\n\n        return xml_file\n\n    def write_diff_files(self, comparator, parallelizer, filename):\n\"\"\"Write diffs to a jspwiki file\"\"\"\n        print(f\"write_diff_files {filename}\")\n        filename = f\"{filename}_{self.date}.jspwiki\"\n        dirname = os.path.join(\n            os.path.dirname(self.testresult_writer.get_filename()), \"tca2testing\"\n        )\n\n        with open(os.path.join(dirname, filename), \"w\") as diff_file:\n            diff_file.write(f\"!!!{filename}\\n\")\n            diff_file.write(\"!!TMX diff\\n{{{\\n\")\n            diff_file.writelines(comparator.get_diff_as_text())\n            diff_file.write(\"\\n}}}\\n!! diff\\n{{{\\n\".format(parallelizer.get_lang1()))\n            diff_file.writelines(\n                comparator.get_lang_diff_as_text(parallelizer.get_lang1())\n            )\n            diff_file.write(\"\\n}}}\\n!!{} diff\\n{{{\\n\".format(parallelizer.get_lang2()))\n            diff_file.writelines(\n                comparator.get_lang_diff_as_text(parallelizer.get_lang2())\n            )\n            diff_file.write(\"\\n}}}\\n\")\n\n    def find_goldstandard_tmx_files(self):\n\"\"\"Find the goldstandard tmx files, return them as a list\"\"\"\n        file_list = []\n        for root, dirs, files in os.walk(\n            os.path.join(os.environ[\"GTFREE\"], \"prestable/toktmx\")\n        ):\n            for f in files:\n                if f.endswith(\".toktmx\"):\n                    print(util.lineno(), f)\n                    file_list.append(os.path.join(root, f))\n\n        return file_list\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.__init__","title":"<code>__init__(testresult_filename, dateformat_addition=None)</code>","text":"<p>Set the name where the testresults should be written</p> <p>Find all goldstandard tmx files</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def __init__(self, testresult_filename, dateformat_addition=None):\n\"\"\"Set the name where the testresults should be written\n\n    Find all goldstandard tmx files\n    \"\"\"\n    self.number_of_diff_lines = 0\n    self.testresult_writer = TmxTestDataWriter(testresult_filename)\n    if dateformat_addition is None:\n        self.date = self.dateformat()\n    else:\n        self.date = self.dateformat() + dateformat_addition\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.align_files","title":"<code>align_files(testrun, want_tmx_file, paralang, aligner)</code>","text":"<p>Align files</p> <p>Compare the tmx's of the result of this parallellization and the tmx of the goldstandard file Write the result to a file Write the diffs of these to tmx's to a separate file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def align_files(self, testrun, want_tmx_file, paralang, aligner):\n\"\"\"Align files\n\n    Compare the tmx's of the result of this parallellization and\n    the tmx of the goldstandard file\n    Write the result to a file\n    Write the diffs of these to tmx's to a separate file\n    \"\"\"\n\n    # Compute the name of the main file to parallelize\n    xml_file = self.compute_xmlfilename(want_tmx_file)\n\n    parallelizer = parallelize.Parallelize(xml_file, paralang)\n    got_tmx = parallelizer.parallelize_files()\n\n    # This is the tmx element fetched from the goldstandard file\n    want_tmx = parallelize.Tmx(etree.parse(want_tmx_file))\n\n    # Instantiate a comparator with the two tmxes\n    comparator = TmxComparator(want_tmx, got_tmx)\n\n    # Make a file_element for our results file\n    file_element = self.testresult_writer.make_file_element(\n        filelist[0].get_basename(),\n        str(comparator.get_lines_in_wantedfile()),\n        str(comparator.get_number_of_differing_lines()),\n    )\n\n    self.set_number_of_diff_lines(comparator.get_number_of_differing_lines())\n\n    # Append the result for this file to the testrun element\n    testrun.append(file_element)\n\n    self.write_diff_files(comparator, parallelizer, filelist[0].get_basename())\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.compute_xmlfilename","title":"<code>compute_xmlfilename(want_tmx_file)</code>","text":"<p>Compute the name of the xmlfile which should be aligned</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def compute_xmlfilename(self, want_tmx_file):\n\"\"\"Compute the name of the xmlfile which should be aligned\"\"\"\n    xml_file = want_tmx_file.replace(\"tmx/goldstandard/\", \"converted/\")\n    xml_file = xml_file.replace(\"nob2sme\", \"nob\")\n    xml_file = xml_file.replace(\"sme2nob\", \"sme\")\n    xml_file = xml_file.replace(\".toktmx\", \".xml\")\n\n    return xml_file\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.dateformat","title":"<code>dateformat()</code>","text":"<p>Get the date and time, 20111209-1234. Used in a testrun element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def dateformat(self):\n\"\"\"Get the date and time, 20111209-1234. Used in a testrun element\"\"\"\n    d = datetime.datetime.fromtimestamp(time.time())\n\n    return d.strftime(\"%Y%m%d-%H%M\")\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.find_goldstandard_tmx_files","title":"<code>find_goldstandard_tmx_files()</code>","text":"<p>Find the goldstandard tmx files, return them as a list</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def find_goldstandard_tmx_files(self):\n\"\"\"Find the goldstandard tmx files, return them as a list\"\"\"\n    file_list = []\n    for root, dirs, files in os.walk(\n        os.path.join(os.environ[\"GTFREE\"], \"prestable/toktmx\")\n    ):\n        for f in files:\n            if f.endswith(\".toktmx\"):\n                print(util.lineno(), f)\n                file_list.append(os.path.join(root, f))\n\n    return file_list\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.get_number_of_diff_lines","title":"<code>get_number_of_diff_lines()</code>","text":"<p>Get the number of diff lines.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def get_number_of_diff_lines(self):\n\"\"\"Get the number of diff lines.\"\"\"\n    return self.number_of_diff_lines\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.run_test","title":"<code>run_test()</code>","text":"<p>Make a testrun element.</p> <p>This element contain the result of the test.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def run_test(self):\n\"\"\"Make a testrun element.\n\n    This element contain the result of the test.\n    \"\"\"\n    testrun = self.testresult_writer.make_testrun_element(self.date)\n\n    paralang = \"\"\n    # Go through each tmx goldstandard file\n    for want_tmx_file in self.find_goldstandard_tmx_files():\n        print(f\"testing {want_tmx_file} \u2026\")\n\n        # Calculate the parallel lang, to be used in parallelization\n        if want_tmx_file.find(\"nob2sme\") &gt; -1:\n            paralang = \"sme\"\n        else:\n            paralang = \"nob\"\n\n        # Align files\n        self.align_files(testrun, want_tmx_file, paralang, aligner=\"tca2\")\n\n    # All files have been tested, insert this run at the top of the\n    # paragstest element\n    self.testresult_writer.insert_testrun_element(testrun)\n    # Write data to file\n    self.testresult_writer.write_paragstesting_data()\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.set_number_of_diff_lines","title":"<code>set_number_of_diff_lines(diff_lines)</code>","text":"<p>Increase the total number of difflines in this test run</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def set_number_of_diff_lines(self, diff_lines):\n\"\"\"Increase the total number of difflines in this test run\"\"\"\n    self.number_of_diff_lines += diff_lines\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxGoldstandardTester.write_diff_files","title":"<code>write_diff_files(comparator, parallelizer, filename)</code>","text":"<p>Write diffs to a jspwiki file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def write_diff_files(self, comparator, parallelizer, filename):\n\"\"\"Write diffs to a jspwiki file\"\"\"\n    print(f\"write_diff_files {filename}\")\n    filename = f\"{filename}_{self.date}.jspwiki\"\n    dirname = os.path.join(\n        os.path.dirname(self.testresult_writer.get_filename()), \"tca2testing\"\n    )\n\n    with open(os.path.join(dirname, filename), \"w\") as diff_file:\n        diff_file.write(f\"!!!{filename}\\n\")\n        diff_file.write(\"!!TMX diff\\n{{{\\n\")\n        diff_file.writelines(comparator.get_diff_as_text())\n        diff_file.write(\"\\n}}}\\n!! diff\\n{{{\\n\".format(parallelizer.get_lang1()))\n        diff_file.writelines(\n            comparator.get_lang_diff_as_text(parallelizer.get_lang1())\n        )\n        diff_file.write(\"\\n}}}\\n!!{} diff\\n{{{\\n\".format(parallelizer.get_lang2()))\n        diff_file.writelines(\n            comparator.get_lang_diff_as_text(parallelizer.get_lang2())\n        )\n        diff_file.write(\"\\n}}}\\n\")\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxTestDataWriter","title":"<code>TmxTestDataWriter</code>","text":"<p>A class that writes tmx test data to a file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>class TmxTestDataWriter:\n\"\"\"A class that writes tmx test data to a file\"\"\"\n\n    def __init__(self, filename):\n        self.filename = filename\n\n        try:\n            tree = etree.parse(filename)\n            self.set_parags_testing_element(tree.getroot())\n        except OSError as error:\n            util.note(f\"I/O error({error.errno}): {error.strerror}\")\n            sys.exit(1)\n\n    def get_filename(self):\n        return self.filename\n\n    def make_file_element(self, name, gspairs, diffpairs):\n\"\"\"Make the element file, set the attributes\"\"\"\n        file_element = etree.Element(\"file\")\n        file_element.attrib[\"name\"] = name\n        file_element.attrib[\"gspairs\"] = gspairs\n        file_element.attrib[\"diffpairs\"] = diffpairs\n\n        return file_element\n\n    def set_parags_testing_element(self, paragstesting):\n        self.paragstesting = paragstesting\n\n    def make_testrun_element(self, datetime):\n\"\"\"Make the testrun element, set the attribute\"\"\"\n        testrun_element = etree.Element(\"testrun\")\n        testrun_element.attrib[\"datetime\"] = datetime\n\n        return testrun_element\n\n    def make_paragstesting_element(self):\n\"\"\"Make the paragstesting element\"\"\"\n        paragstesting_element = etree.Element(\"paragstesting\")\n\n        return paragstesting_element\n\n    def insert_testrun_element(self, testrun):\n        self.paragstesting.insert(0, testrun)\n\n    def write_paragstesting_data(self):\n\"\"\"Write the paragstesting data to a file\"\"\"\n        with open(self.filename, \"w\") as paragstesting:\n            et = etree.ElementTree(self.paragstesting)\n            et.write(\n                paragstesting, pretty_print=True, encoding=\"utf-8\", xml_declaration=True\n            )\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxTestDataWriter.make_file_element","title":"<code>make_file_element(name, gspairs, diffpairs)</code>","text":"<p>Make the element file, set the attributes</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def make_file_element(self, name, gspairs, diffpairs):\n\"\"\"Make the element file, set the attributes\"\"\"\n    file_element = etree.Element(\"file\")\n    file_element.attrib[\"name\"] = name\n    file_element.attrib[\"gspairs\"] = gspairs\n    file_element.attrib[\"diffpairs\"] = diffpairs\n\n    return file_element\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxTestDataWriter.make_paragstesting_element","title":"<code>make_paragstesting_element()</code>","text":"<p>Make the paragstesting element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def make_paragstesting_element(self):\n\"\"\"Make the paragstesting element\"\"\"\n    paragstesting_element = etree.Element(\"paragstesting\")\n\n    return paragstesting_element\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxTestDataWriter.make_testrun_element","title":"<code>make_testrun_element(datetime)</code>","text":"<p>Make the testrun element, set the attribute</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def make_testrun_element(self, datetime):\n\"\"\"Make the testrun element, set the attribute\"\"\"\n    testrun_element = etree.Element(\"testrun\")\n    testrun_element.attrib[\"datetime\"] = datetime\n\n    return testrun_element\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.TmxTestDataWriter.write_paragstesting_data","title":"<code>write_paragstesting_data()</code>","text":"<p>Write the paragstesting data to a file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def write_paragstesting_data(self):\n\"\"\"Write the paragstesting data to a file\"\"\"\n    with open(self.filename, \"w\") as paragstesting:\n        et = etree.ElementTree(self.paragstesting)\n        et.write(\n            paragstesting, pretty_print=True, encoding=\"utf-8\", xml_declaration=True\n        )\n</code></pre>"},{"location":"reference/compare_tmx_goldstandard/#corpustools.compare_tmx_goldstandard.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the command line.</p> <p>Expected input is one or more tmx goldstandard files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/compare_tmx_goldstandard.py</code> <pre><code>def parse_options():\n\"\"\"Parse the command line.\n\n    Expected input is one or more tmx goldstandard files.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Compare goldstandard tmx \"\n        \"files to files produced by the \"\n        \"parallelizer pipeline.\"\n    )\n\n    parser.parse_args()\n</code></pre>"},{"location":"reference/convert_using_pandoc/","title":"convert_using_pandoc","text":"<p>Convert files supported by pandoc to the html format.</p>"},{"location":"reference/convert_using_pandoc/#corpustools.convert_using_pandoc.to_html_elt","title":"<code>to_html_elt(filename)</code>","text":"<p>Convert the content of the give file to an lxml element.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the document</p> required <p>Returns:</p> Type Description <p>An lxml element containing the html version of the given file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convert_using_pandoc.py</code> <pre><code>def to_html_elt(filename):\n\"\"\"Convert the content of the give file to an lxml element.\n\n    Args:\n        filename (str): path to the document\n\n    Returns:\n        An lxml element containing the html version of the given file.\n    \"\"\"\n    html_body = subprocess.run(\n        [\"pandoc\", filename], encoding=\"utf-8\", capture_output=True\n    ).stdout\n\n    return html.document_fromstring(f\"&lt;html&gt;&lt;body&gt;{html_body}&lt;/body&gt;&lt;/html&gt;\")\n</code></pre>"},{"location":"reference/convert_using_soffice/","title":"convert_using_soffice","text":"<p>Convert writenow files to the html format.</p>"},{"location":"reference/convert_using_soffice/#corpustools.convert_using_soffice.to_html_elt","title":"<code>to_html_elt(filename)</code>","text":"<p>Convert the content of an writenow file to xhtml.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the document</p> required <p>Returns:</p> Type Description <p>A string containing the html version of the writenow file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convert_using_soffice.py</code> <pre><code>def to_html_elt(filename):\n\"\"\"Convert the content of an writenow file to xhtml.\n\n    Args:\n        filename (str): path to the document\n\n    Returns:\n        A string containing the html version of the writenow file.\n    \"\"\"\n    outdir = os.path.dirname(filename)\n    subprocess.run(\n        [\n            \"soffice\",\n            \"--convert-to\",\n            \"html\",\n            \"--outdir\",\n            outdir,\n            filename,\n        ],\n        encoding=\"utf-8\",\n    )\n\n    outname = f\"{os.path.splitext(filename)[0]}.html\"\n    parsed_html = html.parse(outname)\n    os.remove(outname)\n\n    return parsed_html\n</code></pre>"},{"location":"reference/converter/","title":"converter","text":"<p>This file contains classes to convert files to the Giella xml format.</p>"},{"location":"reference/converter/#corpustools.converter.Converter","title":"<code>Converter</code>","text":"<p>Take care of data common to all Converter classes.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>class Converter:\n\"\"\"Take care of data common to all Converter classes.\"\"\"\n\n    def __init__(self, filename, lazy_conversion=False, write_intermediate=False):\n\"\"\"Initialise the Converter class.\n\n        Args:\n            filename: string containing the path to the file that should\n            be converted\n            write_intermediate: boolean which decides whether intermediate\n            versions of the converted document should be written (used for\n            debugging purposes).\n        \"\"\"\n        codecs.register_error(\"mixed\", self.mixed_decoder)\n        self.names = corpuspath.CorpusPath(filename)\n        self.lazy_conversion = lazy_conversion\n        self.write_intermediate = write_intermediate\n        try:\n            self.metadata = xslsetter.MetadataHandler(self.names.xsl, create=True)\n        except xslsetter.XsltError as error:\n            raise util.ConversionError(error)\n\n        self.metadata.set_lang_genre_xsl()\n        with util.ignored(OSError):\n            os.makedirs(self.tmpdir)\n\n    @property\n    def dependencies(self):\n\"\"\"Return files that converted files depend on.\"\"\"\n        return [self.names.orig, self.names.xsl]\n\n    @property\n    def standard(self):\n\"\"\"Return a boolean indicating if the file is convertable.\"\"\"\n        return self.metadata.get_variable(\"conversion_status\") == \"standard\"\n\n    @property\n    def goldstandard(self):\n\"\"\"Return a boolean indicating if the file is a gold standard doc.\"\"\"\n        return self.metadata.get_variable(\"conversion_status\").startswith(\"correct\")\n\n    @staticmethod\n    def get_dtd_location():\n\"\"\"Return the path to the corpus dtd file.\"\"\"\n        return os.path.join(HERE, \"dtd/corpus.dtd\")\n\n    def validate_complete(self, complete):\n\"\"\"Validate the complete document.\"\"\"\n        dtd = etree.DTD(Converter.get_dtd_location())\n\n        if not dtd.validate(complete):\n            with codecs.open(self.names.log, \"w\", encoding=\"utf8\") as logfile:\n                logfile.write(f\"Error at: {str(util.lineno())}\")\n                for entry in dtd.error_log:\n                    logfile.write(\"\\n\")\n                    logfile.write(str(entry))\n                    logfile.write(\"\\n\")\n                util.print_element(complete, 0, 4, logfile)\n\n            raise util.ConversionError(\n                \"{}: Not valid XML. More info in the log file: \"\n                \"{}\".format(type(self).__name__, self.names.log)\n            )\n\n    def transform_to_complete(self):\n\"\"\"Combine the intermediate xml document with its medatata.\"\"\"\n        try:\n            intermediate = to_giella(self.names.orig)\n        except KeyError as error:\n            raise util.ConversionError(\n                \"{} can not convert files of this format {}:\".format(\n                    self.names.orig, str(error)\n                )\n            )\n        try:\n            self.fix_document(intermediate)\n        except etree.XMLSyntaxError as error:\n            with open(self.names.log, \"w\") as logfile:\n                logfile.write(f\"Error at: {str(util.lineno())}\")\n\n            raise util.ConversionError(\n                f\"Syntax error in: {self.names}\\nError {str(error)}\"\n            )\n\n        try:\n            xsl_maker = xslmaker.XslMaker(self.metadata.tree)\n            complete = xsl_maker.transformer(intermediate)\n\n            return complete.getroot()\n        except etree.XSLTApplyError as error:\n            with open(self.names.log, \"w\") as logfile:\n                logfile.write(f\"Error at: {str(util.lineno())}\")\n\n            raise util.ConversionError(f\"Check the syntax in: {self.names.xsl}\")\n        except etree.XSLTParseError as error:\n            with open(self.names.log, \"w\") as logfile:\n                logfile.write(f\"Error at: {str(util.lineno())}\")\n\n            raise util.ConversionError(\n                f\"XSLTParseError in: {self.names.xsl}\\nError {str(error)}\"\n            )\n\n    def convert_errormarkup(self, complete):\n\"\"\"Convert error markup to xml.\"\"\"\n        if self.goldstandard:\n            try:\n                errormarkup.add_error_markup(complete.find(\"body\"))\n            except errormarkup.ErrorMarkupError as error:\n                with open(self.names.log, \"w\") as logfile:\n                    print(str(error), file=logfile)\n\n                raise util.ConversionError(\n                    \"Markup error. More info in the log file: \" f\"{self.names.log}\"\n                )\n\n    def fix_document(self, complete):\n\"\"\"Fix a misc. issues found in converted document.\"\"\"\n        fixer = documentfixer.DocumentFixer(complete)\n\n        fixer.fix_newstags()\n        fixer.soft_hyphen_to_hyph_tag()\n        self.metadata.set_variable(\"wordcount\", fixer.calculate_wordcount())\n\n        if not self.goldstandard:\n            fixer.detect_quotes()\n\n        # The above line adds text to hyph, fix that\n        for hyph in complete.iter(\"hyph\"):\n            hyph.text = None\n\n        if self.metadata.get_variable(\"mainlang\") in [\n            \"sma\",\n            \"sme\",\n            \"smj\",\n            \"smn\",\n            \"sms\",\n            \"nob\",\n            \"fin\",\n            \"swe\",\n            \"nno\",\n            \"dan\",\n            \"fkv\",\n            \"sju\",\n            \"sje\",\n            \"mhr\",\n            \"mrj\",\n            \"mns\",\n        ]:\n            try:\n                fixer.fix_body_encoding(self.metadata.get_variable(\"mainlang\"))\n            except UserWarning as error:\n                util.print_frame(error)\n                util.print_frame(self.names.orig)\n\n    mixed_to_unicode = {\n        \"e4\": \"\u00e4\",\n        \"85\": \"\u2026\",  # u'\\u2026' ... character.\n        \"96\": \"\u2013\",  # u'\\u2013' en-dash\n        \"97\": \"\u2014\",  # u'\\u2014' em-dash\n        \"91\": \"\u2018\",  # u'\\u2018' left single quote\n        \"92\": \"\u2019\",  # u'\\u2019' right single quote\n        \"93\": \"\u201c\",  # u'\\u201C' left double quote\n        \"94\": \"\u201d\",  # u'\\u201D' right double quote\n        \"95\": \"\u2022\",  # u'\\u2022' bullet\n    }\n\n    def mixed_decoder(self, decode_error):\n\"\"\"Convert text to unicode.\"\"\"\n        badstring = decode_error.object[decode_error.start : decode_error.end]\n        badhex = badstring.encode(\"hex\")\n        repl = self.mixed_to_unicode.get(badhex, \"\\ufffd\")\n        if repl == \"\\ufffd\":  # \ufffd unicode REPLACEMENT CHARACTER\n            LOGGER.warn(\"Skipped bad byte \\\\x%s, seen in %s\", badhex, self.names.orig)\n        return repl, (decode_error.start + len(repl))\n\n    def fix_parallels(self, complete):\n        for parallel in complete.xpath(\".//parallel_text\"):\n            if not parallel.get(\"location\"):\n                parallel.getparent().remove(parallel)\n\n    def make_complete(self, language_guesser):\n\"\"\"Make a complete Giella xml file.\n\n        Combine the intermediate Giella xml file and the metadata into\n        a complete Giella xml file.\n        Fix the character encoding\n        Detect the languages in the xml file\n        \"\"\"\n        complete = self.transform_to_complete()\n        self.validate_complete(complete)\n        self.fix_parallels(complete)\n        self.convert_errormarkup(complete)\n        lang_detector = languagedetector.LanguageDetector(complete, language_guesser)\n        lang_detector.detect_language()\n\n        for para in complete.iter(\"p\"):\n            para.tail = \"\\n\"\n\n        return complete\n\n    @staticmethod\n    def has_content(complete):\n\"\"\"Find out if the xml document has any content.\n\n        Args:\n            complete: a etree element containing the converted document.\n\n        Returns:\n            The length of the content in complete.\n        \"\"\"\n        xml_printer = ccat.XMLPrinter(all_paragraphs=True, hyph_replacement=None)\n        xml_printer.etree = etree.ElementTree(complete)\n\n        return len(xml_printer.process_file().getvalue())\n\n    def write_complete(self, languageguesser):\n\"\"\"Write the complete converted document to disk.\n\n        Args:\n            languageguesser: a text.Classifier\n        \"\"\"\n        if not self.lazy_conversion or (\n            self.lazy_conversion\n            and distutils.dep_util.newer_group(self.dependencies, self.names.converted)\n        ):\n            with util.ignored(OSError):\n                os.makedirs(os.path.dirname(self.names.converted))\n\n            if self.standard or self.goldstandard:\n                complete = self.make_complete(languageguesser)\n\n                if self.has_content(complete):\n                    with open(self.names.converted, \"w\") as converted:\n                        print(\n                            unicodedata.normalize(\n                                \"NFC\", etree.tostring(complete, encoding=\"unicode\")\n                            ),\n                            file=converted,\n                        )\n                else:\n                    LOGGER.error(\"%s has no text\", self.names.orig)\n\n    @property\n    def tmpdir(self):\n\"\"\"Return the directory where temporary files should be placed.\"\"\"\n        return os.path.join(self.names.pathcomponents.root, \"tmp\")\n\n    @property\n    def corpusdir(self):\n\"\"\"Return the directory where the corpus directory is.\"\"\"\n        return self.names.pathcomponents.root\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.corpusdir","title":"<code>corpusdir</code>  <code>property</code>","text":"<p>Return the directory where the corpus directory is.</p>"},{"location":"reference/converter/#corpustools.converter.Converter.dependencies","title":"<code>dependencies</code>  <code>property</code>","text":"<p>Return files that converted files depend on.</p>"},{"location":"reference/converter/#corpustools.converter.Converter.goldstandard","title":"<code>goldstandard</code>  <code>property</code>","text":"<p>Return a boolean indicating if the file is a gold standard doc.</p>"},{"location":"reference/converter/#corpustools.converter.Converter.standard","title":"<code>standard</code>  <code>property</code>","text":"<p>Return a boolean indicating if the file is convertable.</p>"},{"location":"reference/converter/#corpustools.converter.Converter.tmpdir","title":"<code>tmpdir</code>  <code>property</code>","text":"<p>Return the directory where temporary files should be placed.</p>"},{"location":"reference/converter/#corpustools.converter.Converter.__init__","title":"<code>__init__(filename, lazy_conversion=False, write_intermediate=False)</code>","text":"<p>Initialise the Converter class.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <p>string containing the path to the file that should</p> required <code>write_intermediate</code> <p>boolean which decides whether intermediate</p> <code>False</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def __init__(self, filename, lazy_conversion=False, write_intermediate=False):\n\"\"\"Initialise the Converter class.\n\n    Args:\n        filename: string containing the path to the file that should\n        be converted\n        write_intermediate: boolean which decides whether intermediate\n        versions of the converted document should be written (used for\n        debugging purposes).\n    \"\"\"\n    codecs.register_error(\"mixed\", self.mixed_decoder)\n    self.names = corpuspath.CorpusPath(filename)\n    self.lazy_conversion = lazy_conversion\n    self.write_intermediate = write_intermediate\n    try:\n        self.metadata = xslsetter.MetadataHandler(self.names.xsl, create=True)\n    except xslsetter.XsltError as error:\n        raise util.ConversionError(error)\n\n    self.metadata.set_lang_genre_xsl()\n    with util.ignored(OSError):\n        os.makedirs(self.tmpdir)\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.convert_errormarkup","title":"<code>convert_errormarkup(complete)</code>","text":"<p>Convert error markup to xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def convert_errormarkup(self, complete):\n\"\"\"Convert error markup to xml.\"\"\"\n    if self.goldstandard:\n        try:\n            errormarkup.add_error_markup(complete.find(\"body\"))\n        except errormarkup.ErrorMarkupError as error:\n            with open(self.names.log, \"w\") as logfile:\n                print(str(error), file=logfile)\n\n            raise util.ConversionError(\n                \"Markup error. More info in the log file: \" f\"{self.names.log}\"\n            )\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.fix_document","title":"<code>fix_document(complete)</code>","text":"<p>Fix a misc. issues found in converted document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def fix_document(self, complete):\n\"\"\"Fix a misc. issues found in converted document.\"\"\"\n    fixer = documentfixer.DocumentFixer(complete)\n\n    fixer.fix_newstags()\n    fixer.soft_hyphen_to_hyph_tag()\n    self.metadata.set_variable(\"wordcount\", fixer.calculate_wordcount())\n\n    if not self.goldstandard:\n        fixer.detect_quotes()\n\n    # The above line adds text to hyph, fix that\n    for hyph in complete.iter(\"hyph\"):\n        hyph.text = None\n\n    if self.metadata.get_variable(\"mainlang\") in [\n        \"sma\",\n        \"sme\",\n        \"smj\",\n        \"smn\",\n        \"sms\",\n        \"nob\",\n        \"fin\",\n        \"swe\",\n        \"nno\",\n        \"dan\",\n        \"fkv\",\n        \"sju\",\n        \"sje\",\n        \"mhr\",\n        \"mrj\",\n        \"mns\",\n    ]:\n        try:\n            fixer.fix_body_encoding(self.metadata.get_variable(\"mainlang\"))\n        except UserWarning as error:\n            util.print_frame(error)\n            util.print_frame(self.names.orig)\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.get_dtd_location","title":"<code>get_dtd_location()</code>  <code>staticmethod</code>","text":"<p>Return the path to the corpus dtd file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>@staticmethod\ndef get_dtd_location():\n\"\"\"Return the path to the corpus dtd file.\"\"\"\n    return os.path.join(HERE, \"dtd/corpus.dtd\")\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.has_content","title":"<code>has_content(complete)</code>  <code>staticmethod</code>","text":"<p>Find out if the xml document has any content.</p> <p>Parameters:</p> Name Type Description Default <code>complete</code> <p>a etree element containing the converted document.</p> required <p>Returns:</p> Type Description <p>The length of the content in complete.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>@staticmethod\ndef has_content(complete):\n\"\"\"Find out if the xml document has any content.\n\n    Args:\n        complete: a etree element containing the converted document.\n\n    Returns:\n        The length of the content in complete.\n    \"\"\"\n    xml_printer = ccat.XMLPrinter(all_paragraphs=True, hyph_replacement=None)\n    xml_printer.etree = etree.ElementTree(complete)\n\n    return len(xml_printer.process_file().getvalue())\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.make_complete","title":"<code>make_complete(language_guesser)</code>","text":"<p>Make a complete Giella xml file.</p> <p>Combine the intermediate Giella xml file and the metadata into a complete Giella xml file. Fix the character encoding Detect the languages in the xml file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def make_complete(self, language_guesser):\n\"\"\"Make a complete Giella xml file.\n\n    Combine the intermediate Giella xml file and the metadata into\n    a complete Giella xml file.\n    Fix the character encoding\n    Detect the languages in the xml file\n    \"\"\"\n    complete = self.transform_to_complete()\n    self.validate_complete(complete)\n    self.fix_parallels(complete)\n    self.convert_errormarkup(complete)\n    lang_detector = languagedetector.LanguageDetector(complete, language_guesser)\n    lang_detector.detect_language()\n\n    for para in complete.iter(\"p\"):\n        para.tail = \"\\n\"\n\n    return complete\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.mixed_decoder","title":"<code>mixed_decoder(decode_error)</code>","text":"<p>Convert text to unicode.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def mixed_decoder(self, decode_error):\n\"\"\"Convert text to unicode.\"\"\"\n    badstring = decode_error.object[decode_error.start : decode_error.end]\n    badhex = badstring.encode(\"hex\")\n    repl = self.mixed_to_unicode.get(badhex, \"\\ufffd\")\n    if repl == \"\\ufffd\":  # \ufffd unicode REPLACEMENT CHARACTER\n        LOGGER.warn(\"Skipped bad byte \\\\x%s, seen in %s\", badhex, self.names.orig)\n    return repl, (decode_error.start + len(repl))\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.transform_to_complete","title":"<code>transform_to_complete()</code>","text":"<p>Combine the intermediate xml document with its medatata.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def transform_to_complete(self):\n\"\"\"Combine the intermediate xml document with its medatata.\"\"\"\n    try:\n        intermediate = to_giella(self.names.orig)\n    except KeyError as error:\n        raise util.ConversionError(\n            \"{} can not convert files of this format {}:\".format(\n                self.names.orig, str(error)\n            )\n        )\n    try:\n        self.fix_document(intermediate)\n    except etree.XMLSyntaxError as error:\n        with open(self.names.log, \"w\") as logfile:\n            logfile.write(f\"Error at: {str(util.lineno())}\")\n\n        raise util.ConversionError(\n            f\"Syntax error in: {self.names}\\nError {str(error)}\"\n        )\n\n    try:\n        xsl_maker = xslmaker.XslMaker(self.metadata.tree)\n        complete = xsl_maker.transformer(intermediate)\n\n        return complete.getroot()\n    except etree.XSLTApplyError as error:\n        with open(self.names.log, \"w\") as logfile:\n            logfile.write(f\"Error at: {str(util.lineno())}\")\n\n        raise util.ConversionError(f\"Check the syntax in: {self.names.xsl}\")\n    except etree.XSLTParseError as error:\n        with open(self.names.log, \"w\") as logfile:\n            logfile.write(f\"Error at: {str(util.lineno())}\")\n\n        raise util.ConversionError(\n            f\"XSLTParseError in: {self.names.xsl}\\nError {str(error)}\"\n        )\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.validate_complete","title":"<code>validate_complete(complete)</code>","text":"<p>Validate the complete document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def validate_complete(self, complete):\n\"\"\"Validate the complete document.\"\"\"\n    dtd = etree.DTD(Converter.get_dtd_location())\n\n    if not dtd.validate(complete):\n        with codecs.open(self.names.log, \"w\", encoding=\"utf8\") as logfile:\n            logfile.write(f\"Error at: {str(util.lineno())}\")\n            for entry in dtd.error_log:\n                logfile.write(\"\\n\")\n                logfile.write(str(entry))\n                logfile.write(\"\\n\")\n            util.print_element(complete, 0, 4, logfile)\n\n        raise util.ConversionError(\n            \"{}: Not valid XML. More info in the log file: \"\n            \"{}\".format(type(self).__name__, self.names.log)\n        )\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.Converter.write_complete","title":"<code>write_complete(languageguesser)</code>","text":"<p>Write the complete converted document to disk.</p> <p>Parameters:</p> Name Type Description Default <code>languageguesser</code> <p>a text.Classifier</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def write_complete(self, languageguesser):\n\"\"\"Write the complete converted document to disk.\n\n    Args:\n        languageguesser: a text.Classifier\n    \"\"\"\n    if not self.lazy_conversion or (\n        self.lazy_conversion\n        and distutils.dep_util.newer_group(self.dependencies, self.names.converted)\n    ):\n        with util.ignored(OSError):\n            os.makedirs(os.path.dirname(self.names.converted))\n\n        if self.standard or self.goldstandard:\n            complete = self.make_complete(languageguesser)\n\n            if self.has_content(complete):\n                with open(self.names.converted, \"w\") as converted:\n                    print(\n                        unicodedata.normalize(\n                            \"NFC\", etree.tostring(complete, encoding=\"unicode\")\n                        ),\n                        file=converted,\n                    )\n            else:\n                LOGGER.error(\"%s has no text\", self.names.orig)\n</code></pre>"},{"location":"reference/converter/#corpustools.converter.to_giella","title":"<code>to_giella(path)</code>","text":"<p>Convert a document to the giella xml format.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path to the document</p> required <p>Returns:</p> Type Description <p>etree.Element: root of the resulting xml document</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/converter.py</code> <pre><code>def to_giella(path):\n\"\"\"Convert a document to the giella xml format.\n\n    Args:\n        path (str): path to the document\n\n    Returns:\n        etree.Element: root of the resulting xml document\n    \"\"\"\n    chooser = {\n        \".doc\": htmlcontentconverter.convert2intermediate,\n        \".docx\": htmlcontentconverter.convert2intermediate,\n        \".epub\": htmlcontentconverter.convert2intermediate,\n        \".html\": htmlcontentconverter.convert2intermediate,\n        \".odt\": htmlcontentconverter.convert2intermediate,\n        \".pdf\": htmlcontentconverter.convert2intermediate,\n        \".rtf\": htmlcontentconverter.convert2intermediate,\n        \".svg\": svgconverter.convert2intermediate,\n        \".txt\": plaintextconverter.convert2intermediate,\n        \".tex\": htmlcontentconverter.convert2intermediate,\n        \".writenow\": htmlcontentconverter.convert2intermediate,\n        \".usx\": usxconverter.convert2intermediate,\n    }\n\n    if \"avvir_xml\" in path:\n        return avvirconverter.convert2intermediate(path)\n    elif path.endswith(\"bible.xml\"):\n        return biblexmlconverter.convert2intermediate(path)\n    elif \"udhr_\" in path and path.endswith(\".xml\"):\n        return htmlcontentconverter.convert2intermediate(path)\n    else:\n        return chooser[os.path.splitext(path)[1]](path)\n</code></pre>"},{"location":"reference/convertermanager/","title":"convertermanager","text":"<p>This file manages conversion of files to the Giella xml format.</p>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager","title":"<code>ConverterManager</code>","text":"<p>Manage the conversion of original files to corpus xml.</p> <p>Class/static variables:     _languageguesser (text_cat.Classifier): Language guesser to indicate         languages in the converted document.</p> <p>Attributes:</p> Name Type Description <code>write_intermediate</code> <code>bool</code> <p>indicate whether intermediate versions of the converted document should be written to disk.</p> <code>goldstandard</code> <code>bool</code> <p>indicating whether goldstandard documents should be converted.</p> <code>files</code> <code>list of str</code> <p>list of paths to original files that should be converted from original format to xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>class ConverterManager:\n\"\"\"Manage the conversion of original files to corpus xml.\n\n    Class/static variables:\n        _languageguesser (text_cat.Classifier): Language guesser to indicate\n            languages in the converted document.\n    Attributes:\n        write_intermediate (bool): indicate whether intermediate versions\n            of the converted document should be written to disk.\n        goldstandard (bool): indicating whether goldstandard documents\n            should be converted.\n        files (list of str): list of paths to original files that should\n            be converted from original format to xml.\n    \"\"\"\n\n    _languageguesser = None\n\n    def languageguesser(self):\n\"\"\"Return our language guesser.\n        This is a class variable, but since it takes a while to initialise,\n        we don't do it until it's needed.\"\"\"\n        if self._languageguesser is None:\n            ConverterManager._languageguesser = text_cat.Classifier(None)\n        return self._languageguesser\n\n    def __init__(\n        self, lazy_conversion=False, write_intermediate=False, goldstandard=False\n    ):\n\"\"\"Initialise the ConverterManager class.\n\n        Args:\n            lazy_conversion (bool): indicate whether conversion depends on the\n                fact that metadata have changed since last conversion.\n            write_intermediate (bool): indicating whether intermediate versions\n                of the converted document should be written to disk.\n            goldstandard (bool): indicating whether goldstandard documents\n                should be converted.\n        \"\"\"\n        self.lazy_conversion = lazy_conversion\n        self.write_intermediate = write_intermediate\n        self.goldstandard = goldstandard\n        self.files = []\n\n    def convert(self, orig_file):\n\"\"\"Convert file to corpus xml format.\n\n        Args:\n            orig_file: string containing the path to the original file.\n        \"\"\"\n        try:\n            conv = converter.Converter(orig_file, lazy_conversion=self.lazy_conversion)\n            conv.write_complete(self.languageguesser())\n        except (\n            util.ConversionError,\n            ValueError,\n            IndexError,\n        ) as error:\n            LOGGER.warn(\"Could not convert %s\\n%s\", orig_file, error)\n\n    def convert_in_parallel(self):\n\"\"\"Convert files using the multiprocessing module.\"\"\"\n        LOGGER.info(\"Starting the conversion of %d files\", len(self.files))\n\n        pool_size = multiprocessing.cpu_count()\n        pool = multiprocessing.Pool(processes=pool_size)\n        pool.map(unwrap_self_convert, list(zip([self] * len(self.files), self.files)))\n        pool.close()\n        pool.join()\n\n    def convert_serially(self):\n\"\"\"Convert the files in one process.\"\"\"\n        LOGGER.info(\"Starting the conversion of %d files\", len(self.files))\n\n        for orig_file in self.files:\n            LOGGER.debug(\"converting %s\", orig_file)\n            self.convert(orig_file)\n\n    def add_file(self, xsl_file):\n\"\"\"Add file for conversion.\n\n        Args:\n            xsl_file (str): path to a metadata file\n        \"\"\"\n        if os.path.isfile(xsl_file) and os.path.isfile(xsl_file[:-4]):\n            metadata = xslsetter.MetadataHandler(xsl_file)\n            if (\n                metadata.get_variable(\"conversion_status\") == \"standard\"\n                and not self.goldstandard\n            ) or (\n                metadata.get_variable(\"conversion_status\").startswith(\"correct\")\n                and self.goldstandard\n            ):\n                self.files.append(xsl_file[:-4])\n        else:\n            LOGGER.warn(\"%s does not exist\", xsl_file[:-4])\n\n    @staticmethod\n    def make_xsl_file(source):\n\"\"\"Write an xsl file if it does not exist.\"\"\"\n        xsl_file = source if source.endswith(\".xsl\") else source + \".xsl\"\n        if not os.path.isfile(xsl_file):\n            metadata = xslsetter.MetadataHandler(xsl_file, create=True)\n            metadata.set_lang_genre_xsl()\n            metadata.write_file()\n\n        return xsl_file\n\n    def add_directory(self, directory):\n\"\"\"Add all files in a directory for conversion.\"\"\"\n        for root, _, files in os.walk(directory):\n            for file_ in files:\n                if file_.endswith(\".xsl\"):\n                    self.add_file(os.path.join(root, file_))\n\n    def collect_files(self, sources):\n\"\"\"Find all convertible files in sources.\n\n        Args:\n            sources: a list of files or directories where convertable\n            files are found.\n        \"\"\"\n        LOGGER.info(\"Collecting files to convert\")\n\n        for source in sources:\n            if os.path.isfile(source):\n                xsl_file = self.make_xsl_file(source)\n                self.add_file(xsl_file)\n            elif os.path.isdir(source):\n                self.add_directory(source)\n            else:\n                LOGGER.error(\n                    \"Can not process %s\\n\" \"This is neither a file nor a directory.\",\n                    source,\n                )\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.__init__","title":"<code>__init__(lazy_conversion=False, write_intermediate=False, goldstandard=False)</code>","text":"<p>Initialise the ConverterManager class.</p> <p>Parameters:</p> Name Type Description Default <code>lazy_conversion</code> <code>bool</code> <p>indicate whether conversion depends on the fact that metadata have changed since last conversion.</p> <code>False</code> <code>write_intermediate</code> <code>bool</code> <p>indicating whether intermediate versions of the converted document should be written to disk.</p> <code>False</code> <code>goldstandard</code> <code>bool</code> <p>indicating whether goldstandard documents should be converted.</p> <code>False</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def __init__(\n    self, lazy_conversion=False, write_intermediate=False, goldstandard=False\n):\n\"\"\"Initialise the ConverterManager class.\n\n    Args:\n        lazy_conversion (bool): indicate whether conversion depends on the\n            fact that metadata have changed since last conversion.\n        write_intermediate (bool): indicating whether intermediate versions\n            of the converted document should be written to disk.\n        goldstandard (bool): indicating whether goldstandard documents\n            should be converted.\n    \"\"\"\n    self.lazy_conversion = lazy_conversion\n    self.write_intermediate = write_intermediate\n    self.goldstandard = goldstandard\n    self.files = []\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.add_directory","title":"<code>add_directory(directory)</code>","text":"<p>Add all files in a directory for conversion.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def add_directory(self, directory):\n\"\"\"Add all files in a directory for conversion.\"\"\"\n    for root, _, files in os.walk(directory):\n        for file_ in files:\n            if file_.endswith(\".xsl\"):\n                self.add_file(os.path.join(root, file_))\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.add_file","title":"<code>add_file(xsl_file)</code>","text":"<p>Add file for conversion.</p> <p>Parameters:</p> Name Type Description Default <code>xsl_file</code> <code>str</code> <p>path to a metadata file</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def add_file(self, xsl_file):\n\"\"\"Add file for conversion.\n\n    Args:\n        xsl_file (str): path to a metadata file\n    \"\"\"\n    if os.path.isfile(xsl_file) and os.path.isfile(xsl_file[:-4]):\n        metadata = xslsetter.MetadataHandler(xsl_file)\n        if (\n            metadata.get_variable(\"conversion_status\") == \"standard\"\n            and not self.goldstandard\n        ) or (\n            metadata.get_variable(\"conversion_status\").startswith(\"correct\")\n            and self.goldstandard\n        ):\n            self.files.append(xsl_file[:-4])\n    else:\n        LOGGER.warn(\"%s does not exist\", xsl_file[:-4])\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.collect_files","title":"<code>collect_files(sources)</code>","text":"<p>Find all convertible files in sources.</p> <p>Parameters:</p> Name Type Description Default <code>sources</code> <p>a list of files or directories where convertable</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def collect_files(self, sources):\n\"\"\"Find all convertible files in sources.\n\n    Args:\n        sources: a list of files or directories where convertable\n        files are found.\n    \"\"\"\n    LOGGER.info(\"Collecting files to convert\")\n\n    for source in sources:\n        if os.path.isfile(source):\n            xsl_file = self.make_xsl_file(source)\n            self.add_file(xsl_file)\n        elif os.path.isdir(source):\n            self.add_directory(source)\n        else:\n            LOGGER.error(\n                \"Can not process %s\\n\" \"This is neither a file nor a directory.\",\n                source,\n            )\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.convert","title":"<code>convert(orig_file)</code>","text":"<p>Convert file to corpus xml format.</p> <p>Parameters:</p> Name Type Description Default <code>orig_file</code> <p>string containing the path to the original file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def convert(self, orig_file):\n\"\"\"Convert file to corpus xml format.\n\n    Args:\n        orig_file: string containing the path to the original file.\n    \"\"\"\n    try:\n        conv = converter.Converter(orig_file, lazy_conversion=self.lazy_conversion)\n        conv.write_complete(self.languageguesser())\n    except (\n        util.ConversionError,\n        ValueError,\n        IndexError,\n    ) as error:\n        LOGGER.warn(\"Could not convert %s\\n%s\", orig_file, error)\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.convert_in_parallel","title":"<code>convert_in_parallel()</code>","text":"<p>Convert files using the multiprocessing module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def convert_in_parallel(self):\n\"\"\"Convert files using the multiprocessing module.\"\"\"\n    LOGGER.info(\"Starting the conversion of %d files\", len(self.files))\n\n    pool_size = multiprocessing.cpu_count()\n    pool = multiprocessing.Pool(processes=pool_size)\n    pool.map(unwrap_self_convert, list(zip([self] * len(self.files), self.files)))\n    pool.close()\n    pool.join()\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.convert_serially","title":"<code>convert_serially()</code>","text":"<p>Convert the files in one process.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def convert_serially(self):\n\"\"\"Convert the files in one process.\"\"\"\n    LOGGER.info(\"Starting the conversion of %d files\", len(self.files))\n\n    for orig_file in self.files:\n        LOGGER.debug(\"converting %s\", orig_file)\n        self.convert(orig_file)\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.languageguesser","title":"<code>languageguesser()</code>","text":"<p>Return our language guesser. This is a class variable, but since it takes a while to initialise, we don't do it until it's needed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def languageguesser(self):\n\"\"\"Return our language guesser.\n    This is a class variable, but since it takes a while to initialise,\n    we don't do it until it's needed.\"\"\"\n    if self._languageguesser is None:\n        ConverterManager._languageguesser = text_cat.Classifier(None)\n    return self._languageguesser\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.ConverterManager.make_xsl_file","title":"<code>make_xsl_file(source)</code>  <code>staticmethod</code>","text":"<p>Write an xsl file if it does not exist.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>@staticmethod\ndef make_xsl_file(source):\n\"\"\"Write an xsl file if it does not exist.\"\"\"\n    xsl_file = source if source.endswith(\".xsl\") else source + \".xsl\"\n    if not os.path.isfile(xsl_file):\n        metadata = xslsetter.MetadataHandler(xsl_file, create=True)\n        metadata.set_lang_genre_xsl()\n        metadata.write_file()\n\n    return xsl_file\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.main","title":"<code>main()</code>","text":"<p>Convert documents to giellatekno xml format.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def main():\n\"\"\"Convert documents to giellatekno xml format.\"\"\"\n    LOGGER.setLevel(logging.WARNING)\n    try:\n        sanity_check()\n    except (util.SetupError, util.ExecutableMissingError) as error:\n        raise SystemExit(str(error))\n\n    args = parse_options()\n\n    manager = ConverterManager(\n        args.lazy_conversion, args.write_intermediate, args.goldstandard\n    )\n    manager.collect_files(args.sources)\n\n    try:\n        if args.serial:\n            LOGGER.setLevel(logging.DEBUG)\n            manager.convert_serially()\n        else:\n            manager.convert_in_parallel()\n    except util.ExecutableMissingError as error:\n        raise SystemExit(str(error))\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Convert original files to giellatekno xml.\",\n    )\n\n    parser.add_argument(\n        \"--serial\",\n        action=\"store_true\",\n        help=\"use this for debugging the conversion \\\n                        process. When this argument is used files will \\\n                        be converted one by one.\",\n    )\n    parser.add_argument(\n        \"--lazy-conversion\",\n        action=\"store_true\",\n        help=\"Reconvert only if metadata have changed.\",\n    )\n    parser.add_argument(\n        \"--write-intermediate\",\n        action=\"store_true\",\n        help=\"Write the intermediate XML representation \\\n                        to ORIGFILE.im.xml, for debugging the XSLT.\\\n                        (Has no effect if the converted file already exists.)\",\n    )\n    parser.add_argument(\n        \"--goldstandard\",\n        action=\"store_true\",\n        help=\"Convert goldstandard and .correct files\",\n    )\n    parser.add_argument(\n        \"sources\",\n        nargs=\"+\",\n        help=\"The original file(s) or \\\n                        directory/ies where the original files exist\",\n    )\n\n    args = parser.parse_args()\n\n    return args\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.sanity_check","title":"<code>sanity_check()</code>","text":"<p>Check that needed programs and environment variables are set.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def sanity_check():\n\"\"\"Check that needed programs and environment variables are set.\"\"\"\n    # util.sanity_check(['wvHtml', 'pdftotext', 'latex2html'])\n    util.sanity_check([\"pdftotext\", \"latex2html\"])\n    if not os.path.isfile(converter.Converter.get_dtd_location()):\n        raise util.SetupError(\n            \"Couldn't find {}\\n\"\n            \"Check that GTHOME points at the right directory \"\n            \"(currently: {}).\".format(\n                converter.Converter.get_dtd_location(), os.environ[\"GTHOME\"]\n            )\n        )\n</code></pre>"},{"location":"reference/convertermanager/#corpustools.convertermanager.unwrap_self_convert","title":"<code>unwrap_self_convert(arg, **kwarg)</code>","text":"<p>Unpack self from the arguments and call convert again.</p> <p>This is due to how multiprocess works: http://www.rueckstiess.net/research/snippets/show/ca1d7d90</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/convertermanager.py</code> <pre><code>def unwrap_self_convert(arg, **kwarg):\n\"\"\"Unpack self from the arguments and call convert again.\n\n    This is due to how multiprocess works:\n    http://www.rueckstiess.net/research/snippets/show/ca1d7d90\n    \"\"\"\n    return ConverterManager.convert(*arg, **kwarg)\n</code></pre>"},{"location":"reference/corpuspath/","title":"corpuspath","text":"<p>This file contains classes to handle corpus filenames.</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath","title":"<code>CorpusPath</code>","text":"<p>Map filenames in a corpus.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>path to a corpus file</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>class CorpusPath:\n\"\"\"Map filenames in a corpus.\n\n    Args:\n        path: path to a corpus file\n    \"\"\"\n\n    def __init__(self, path):\n\"\"\"Initialise the CorpusPath class.\"\"\"\n        self.pathcomponents = self.split_path(path)\n        self.metadata = xslsetter.MetadataHandler(self.xsl, create=True)\n\n    @staticmethod\n    def split_on_module(path):\n\"\"\"Split the path in three parts.\n\n        Args:\n            path: a path to a corpus file\n\n        Returns:\n            tuple of str: part one is the corpus directory, the second\n                part is the module, the third part is the path of the\n                corpus file inside the corpus\n\n        Raises:\n            ValueError: the path is not part of a corpus.\n        \"\"\"\n        abspath = os.path.normpath(os.path.abspath(path))\n        corpus_match = CORPUS_DIR_RE.search(abspath)\n\n        if corpus_match:\n            corpus_dict = corpus_match.groupdict()\n            corpus_dir_parts = corpus_dict[\"corpusdir\"].split(\"-\")\n\n            if len(corpus_dir_parts) &gt; 2 and corpus_dir_parts[2] == \"orig\":\n                return (\n                    corpus_dict[\"parent\"],\n                    corpus_dir_parts[1],\n                    \"-\" + \"-\".join(corpus_dir_parts[3:])\n                    if len(corpus_dir_parts) &gt; 3\n                    else \"\",\n                    \"\",\n                    corpus_dict[\"corpusfile\"],\n                    \"\",\n                )\n            else:\n                for module in MODULES:\n                    module_dir = \"/\" + module + \"/\"\n                    if corpus_dict[\"corpusfile\"].startswith(module_dir):\n                        corpus_file_parts = corpus_dict[\"corpusfile\"][\n                            len(module_dir) :\n                        ].split(\"/\")\n\n                        return (\n                            corpus_dict[\"parent\"],\n                            corpus_dir_parts[1],\n                            \"-\" + \"-\".join(corpus_dir_parts[3:])\n                            if len(corpus_dir_parts) &gt; 2\n                            else \"\",\n                            module,\n                            \"/\".join(corpus_file_parts[1:])\n                            if module.endswith(\"tmx\")\n                            else \"/\".join(corpus_file_parts),\n                            corpus_file_parts[0] if module.endswith(\"tmx\") else \"\",\n                        )\n\n        raise ValueError(f\"File is not part of a corpus: {path}\")\n\n    def split_path(self, path):\n\"\"\"Map path to the original file.\n\n        Args:\n            path: a path to a corpus file\n\n        Returns:\n            A PathComponents namedtuple containing the components of the\n            original file\n        \"\"\"\n        root, lang, dirsuffix, module, corpusfile, goallang = self.split_on_module(path)\n\n        corpusfile_parts = corpusfile.split(\"/\")\n        (genre, subdirs, basename) = (\n            corpusfile_parts[0],\n            corpusfile_parts[1:-1],\n            corpusfile_parts[-1],\n        )\n\n        if not module:\n            if basename.endswith(\".xsl\"):\n                basename = util.basename_noext(basename, \".xsl\")\n            elif basename.endswith(\".log\"):\n                basename = util.basename_noext(basename, \".log\")\n        elif any(\n            xml_module in module for xml_module in [\"converted\", \"analysed\", \"korp\"]\n        ):\n            basename = util.basename_noext(basename, \".xml\")\n        elif \"tmx\" in module:\n            basename = util.basename_noext(basename, \".tmx\")\n\n        return PathComponents(\n            root, dirsuffix, \"\", lang, genre, \"/\".join(subdirs), basename, goallang\n        )\n\n    @property\n    def orig_corpus_dir(self):\n        return os.path.join(\n            self.pathcomponents.root,\n            f\"corpus-{self.pathcomponents.lang}-orig{self.pathcomponents.dirsuffix}\",\n        )\n\n    @property\n    def converted_corpus_dir(self):\n        return os.path.join(\n            self.pathcomponents.root,\n            f\"corpus-{self.pathcomponents.lang}{self.pathcomponents.dirsuffix}\",\n        )\n\n    @property\n    def orig(self):\n\"\"\"Return the path of the original file.\"\"\"\n        return self.name()\n\n    @property\n    def xsl(self):\n\"\"\"Return the path of the metadata file.\"\"\"\n        return self.orig + \".xsl\"\n\n    @property\n    def log(self):\n\"\"\"Return the path of the log file.\"\"\"\n        return self.orig + \".log\"\n\n    def move_orig(self, lang=None, genre=None, subdirs=None, name=None):\n        return os.path.join(\n            self.pathcomponents.root,\n            f\"corpus-{self.pathcomponents.lang if lang is None else lang}-orig{self.pathcomponents.dirsuffix}\",\n            genre if genre is not None else self.pathcomponents.genre,\n            subdirs if subdirs is not None else self.pathcomponents.subdirs,\n            self.pathcomponents.basename if name is None else name,\n        )\n\n    def name(\n        self, module=\"\", parallel_lang=None, target_lang=None, name=None, extension=\"\"\n    ):\n\"\"\"Return a path based on the module and extension.\n\n        Args:\n            module (str): string containing some corpus module\n            parallel_lang (str): lang of a parallel document\n            target_lang (str): string containing the target language of a tmx file\n            name (str): name of the wanted file\n            extension (str): string containing a file extension\n        \"\"\"\n        this_name = self.pathcomponents.basename if name is None else name\n        this_lang = self.pathcomponents.lang if parallel_lang is None else parallel_lang\n        return os.path.join(\n            self.pathcomponents.root,\n            f\"corpus-{this_lang}{self.pathcomponents.dirsuffix}\"\n            if module\n            else f\"corpus-{this_lang}-orig{self.pathcomponents.dirsuffix}\",\n            module,\n            target_lang if target_lang is not None else \"\",\n            self.pathcomponents.genre,\n            self.pathcomponents.subdirs,\n            this_name + extension,\n        )\n\n    @property\n    def converted(self):\n\"\"\"Return the path to the converted file.\"\"\"\n        module = \"converted\"\n        if self.metadata.get_variable(\"conversion_status\") == \"correct\":\n            module = \"goldstandard/converted\"\n        if self.metadata.get_variable(\"conversion_status\") == \"correct-no-gs\":\n            module = \"correct-no-gs/converted\"\n\n        return self.name(module=module, extension=\".xml\")\n\n    @property\n    def analysed(self):\n\"\"\"Return the path to analysed file.\"\"\"\n        return self.name(module=\"analysed\", extension=\".xml\")\n\n    @property\n    def korp(self):\n\"\"\"Return the path to analysed file.\"\"\"\n        return self.name(module=\"korp\", extension=\".xml\")\n\n    def parallel(self, language):\n\"\"\"Check if there is a parallel for language.\n\n        Args:\n            language (str): language of the parallel file.\n\n        Returns:\n            str: path to the parallel file if it exist, otherwise empty string\n        \"\"\"\n        try:\n            return self.name(\n                parallel_lang=language,\n                name=self.metadata.get_parallel_texts().get(language),\n            )\n        except TypeError:\n            return \"\"\n\n    def parallels(self):\n\"\"\"Return paths to all parallel files.\n\n        Yields:\n            str: path to the orig path of a parallel file.\n        \"\"\"\n        for language, name in self.metadata.get_parallel_texts().items():\n            yield self.name(parallel_lang=language, name=name)\n\n    def tmx(self, target_language):\n\"\"\"Name of the tmx file.\n\n        Args:\n            target_language (str): language of the parallel\n\n        Returns:\n            str: path to the tmx file\n        \"\"\"\n        return self.name(\n            module=\"tmx\",\n            target_lang=target_language,\n            extension=\".tmx\",\n        )\n\n    @property\n    def sent_filename(self):\n\"\"\"Compute the name of the sentence file.\n\n        Args:\n            pfile (str): name of converted corpus file (produced by\n                convert2xml)\n\n        Returns:\n            str: the name of the tca2 input file\n        \"\"\"\n        # Ensure we have 20 bytes of leeway to let TCA2 append\n        # lang_sent_new.txt without going over the 255 byte limit:\n        origfilename = self.crop_to_bytes(self.pathcomponents.basename, (255 - 20))\n        return os.path.join(\n            self.pathcomponents.root,\n            f\"corpus-{self.pathcomponents.lang}{self.pathcomponents.dirsuffix}\",\n            \"tmp\",\n            f\"{origfilename}_{self.pathcomponents.lang}.sent\",\n        )\n\n    @property\n    def tmp_filename(self):\n        return os.path.join(\n            self.pathcomponents.root,\n            f\"corpus-{self.pathcomponents.lang}{self.pathcomponents.dirsuffix}\",\n            \"tmp\",\n            f\"{self.pathcomponents.basename}\",\n        )\n\n    @staticmethod\n    def crop_to_bytes(name, max_bytes):\n\"\"\"Ensure `name` is less than `max_bytes` bytes.\n\n        Do not split name in the middle of a wide byte.\n        \"\"\"\n        while len(name.encode(\"utf-8\")) &gt; max_bytes:\n            name = name[:-1]\n        return name\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.analysed","title":"<code>analysed</code>  <code>property</code>","text":"<p>Return the path to analysed file.</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.converted","title":"<code>converted</code>  <code>property</code>","text":"<p>Return the path to the converted file.</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.korp","title":"<code>korp</code>  <code>property</code>","text":"<p>Return the path to analysed file.</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.log","title":"<code>log</code>  <code>property</code>","text":"<p>Return the path of the log file.</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.orig","title":"<code>orig</code>  <code>property</code>","text":"<p>Return the path of the original file.</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.sent_filename","title":"<code>sent_filename</code>  <code>property</code>","text":"<p>Compute the name of the sentence file.</p> <p>Parameters:</p> Name Type Description Default <code>pfile</code> <code>str</code> <p>name of converted corpus file (produced by convert2xml)</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>the name of the tca2 input file</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.xsl","title":"<code>xsl</code>  <code>property</code>","text":"<p>Return the path of the metadata file.</p>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.__init__","title":"<code>__init__(path)</code>","text":"<p>Initialise the CorpusPath class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>def __init__(self, path):\n\"\"\"Initialise the CorpusPath class.\"\"\"\n    self.pathcomponents = self.split_path(path)\n    self.metadata = xslsetter.MetadataHandler(self.xsl, create=True)\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.crop_to_bytes","title":"<code>crop_to_bytes(name, max_bytes)</code>  <code>staticmethod</code>","text":"<p>Ensure <code>name</code> is less than <code>max_bytes</code> bytes.</p> <p>Do not split name in the middle of a wide byte.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>@staticmethod\ndef crop_to_bytes(name, max_bytes):\n\"\"\"Ensure `name` is less than `max_bytes` bytes.\n\n    Do not split name in the middle of a wide byte.\n    \"\"\"\n    while len(name.encode(\"utf-8\")) &gt; max_bytes:\n        name = name[:-1]\n    return name\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.name","title":"<code>name(module='', parallel_lang=None, target_lang=None, name=None, extension='')</code>","text":"<p>Return a path based on the module and extension.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>string containing some corpus module</p> <code>''</code> <code>parallel_lang</code> <code>str</code> <p>lang of a parallel document</p> <code>None</code> <code>target_lang</code> <code>str</code> <p>string containing the target language of a tmx file</p> <code>None</code> <code>name</code> <code>str</code> <p>name of the wanted file</p> <code>None</code> <code>extension</code> <code>str</code> <p>string containing a file extension</p> <code>''</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>def name(\n    self, module=\"\", parallel_lang=None, target_lang=None, name=None, extension=\"\"\n):\n\"\"\"Return a path based on the module and extension.\n\n    Args:\n        module (str): string containing some corpus module\n        parallel_lang (str): lang of a parallel document\n        target_lang (str): string containing the target language of a tmx file\n        name (str): name of the wanted file\n        extension (str): string containing a file extension\n    \"\"\"\n    this_name = self.pathcomponents.basename if name is None else name\n    this_lang = self.pathcomponents.lang if parallel_lang is None else parallel_lang\n    return os.path.join(\n        self.pathcomponents.root,\n        f\"corpus-{this_lang}{self.pathcomponents.dirsuffix}\"\n        if module\n        else f\"corpus-{this_lang}-orig{self.pathcomponents.dirsuffix}\",\n        module,\n        target_lang if target_lang is not None else \"\",\n        self.pathcomponents.genre,\n        self.pathcomponents.subdirs,\n        this_name + extension,\n    )\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.parallel","title":"<code>parallel(language)</code>","text":"<p>Check if there is a parallel for language.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>str</code> <p>language of the parallel file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>path to the parallel file if it exist, otherwise empty string</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>def parallel(self, language):\n\"\"\"Check if there is a parallel for language.\n\n    Args:\n        language (str): language of the parallel file.\n\n    Returns:\n        str: path to the parallel file if it exist, otherwise empty string\n    \"\"\"\n    try:\n        return self.name(\n            parallel_lang=language,\n            name=self.metadata.get_parallel_texts().get(language),\n        )\n    except TypeError:\n        return \"\"\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.parallels","title":"<code>parallels()</code>","text":"<p>Return paths to all parallel files.</p> <p>Yields:</p> Name Type Description <code>str</code> <p>path to the orig path of a parallel file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>def parallels(self):\n\"\"\"Return paths to all parallel files.\n\n    Yields:\n        str: path to the orig path of a parallel file.\n    \"\"\"\n    for language, name in self.metadata.get_parallel_texts().items():\n        yield self.name(parallel_lang=language, name=name)\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.split_on_module","title":"<code>split_on_module(path)</code>  <code>staticmethod</code>","text":"<p>Split the path in three parts.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>a path to a corpus file</p> required <p>Returns:</p> Type Description <p>tuple of str: part one is the corpus directory, the second part is the module, the third part is the path of the corpus file inside the corpus</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>the path is not part of a corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>@staticmethod\ndef split_on_module(path):\n\"\"\"Split the path in three parts.\n\n    Args:\n        path: a path to a corpus file\n\n    Returns:\n        tuple of str: part one is the corpus directory, the second\n            part is the module, the third part is the path of the\n            corpus file inside the corpus\n\n    Raises:\n        ValueError: the path is not part of a corpus.\n    \"\"\"\n    abspath = os.path.normpath(os.path.abspath(path))\n    corpus_match = CORPUS_DIR_RE.search(abspath)\n\n    if corpus_match:\n        corpus_dict = corpus_match.groupdict()\n        corpus_dir_parts = corpus_dict[\"corpusdir\"].split(\"-\")\n\n        if len(corpus_dir_parts) &gt; 2 and corpus_dir_parts[2] == \"orig\":\n            return (\n                corpus_dict[\"parent\"],\n                corpus_dir_parts[1],\n                \"-\" + \"-\".join(corpus_dir_parts[3:])\n                if len(corpus_dir_parts) &gt; 3\n                else \"\",\n                \"\",\n                corpus_dict[\"corpusfile\"],\n                \"\",\n            )\n        else:\n            for module in MODULES:\n                module_dir = \"/\" + module + \"/\"\n                if corpus_dict[\"corpusfile\"].startswith(module_dir):\n                    corpus_file_parts = corpus_dict[\"corpusfile\"][\n                        len(module_dir) :\n                    ].split(\"/\")\n\n                    return (\n                        corpus_dict[\"parent\"],\n                        corpus_dir_parts[1],\n                        \"-\" + \"-\".join(corpus_dir_parts[3:])\n                        if len(corpus_dir_parts) &gt; 2\n                        else \"\",\n                        module,\n                        \"/\".join(corpus_file_parts[1:])\n                        if module.endswith(\"tmx\")\n                        else \"/\".join(corpus_file_parts),\n                        corpus_file_parts[0] if module.endswith(\"tmx\") else \"\",\n                    )\n\n    raise ValueError(f\"File is not part of a corpus: {path}\")\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.split_path","title":"<code>split_path(path)</code>","text":"<p>Map path to the original file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>a path to a corpus file</p> required <p>Returns:</p> Type Description <p>A PathComponents namedtuple containing the components of the</p> <p>original file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>def split_path(self, path):\n\"\"\"Map path to the original file.\n\n    Args:\n        path: a path to a corpus file\n\n    Returns:\n        A PathComponents namedtuple containing the components of the\n        original file\n    \"\"\"\n    root, lang, dirsuffix, module, corpusfile, goallang = self.split_on_module(path)\n\n    corpusfile_parts = corpusfile.split(\"/\")\n    (genre, subdirs, basename) = (\n        corpusfile_parts[0],\n        corpusfile_parts[1:-1],\n        corpusfile_parts[-1],\n    )\n\n    if not module:\n        if basename.endswith(\".xsl\"):\n            basename = util.basename_noext(basename, \".xsl\")\n        elif basename.endswith(\".log\"):\n            basename = util.basename_noext(basename, \".log\")\n    elif any(\n        xml_module in module for xml_module in [\"converted\", \"analysed\", \"korp\"]\n    ):\n        basename = util.basename_noext(basename, \".xml\")\n    elif \"tmx\" in module:\n        basename = util.basename_noext(basename, \".tmx\")\n\n    return PathComponents(\n        root, dirsuffix, \"\", lang, genre, \"/\".join(subdirs), basename, goallang\n    )\n</code></pre>"},{"location":"reference/corpuspath/#corpustools.corpuspath.CorpusPath.tmx","title":"<code>tmx(target_language)</code>","text":"<p>Name of the tmx file.</p> <p>Parameters:</p> Name Type Description Default <code>target_language</code> <code>str</code> <p>language of the parallel</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>path to the tmx file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpuspath.py</code> <pre><code>def tmx(self, target_language):\n\"\"\"Name of the tmx file.\n\n    Args:\n        target_language (str): language of the parallel\n\n    Returns:\n        str: path to the tmx file\n    \"\"\"\n    return self.name(\n        module=\"tmx\",\n        target_lang=target_language,\n        extension=\".tmx\",\n    )\n</code></pre>"},{"location":"reference/corpusxmlfile/","title":"corpusxmlfile","text":"<p>Classes and functions to sentence align two files.</p>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile","title":"<code>CorpusXMLFile</code>","text":"<p>A class to handle all the info of a corpus xml file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>class CorpusXMLFile:\n\"\"\"A class to handle all the info of a corpus xml file.\"\"\"\n\n    def __init__(self, name):\n\"\"\"Initialise the CorpusXMLFile class.\n\n        Args:\n            name (str): path to the xml file.\n        \"\"\"\n        self.corpus_path = corpuspath.CorpusPath(name)\n        self.etree = etree.parse(name)\n        self.root = self.etree.getroot()\n        self.sanity_check()\n\n    def sanity_check(self):\n\"\"\"Check if the file really is a corpus xml file.\"\"\"\n        if self.root.tag != \"document\":\n            raise util.ArgumentError(\n                \"Expected Corpus XML file (output of convert2xml) with \"\n                \"&lt;document&gt; as the root tag, got {} -- did you pass the \"\n                \"wrong file?\".format(\n                    self.root.tag,\n                )\n            )\n\n    @property\n    def lang(self):\n\"\"\"Get the lang of the file.\"\"\"\n        return self.corpus_path.pathcomponents.lang\n\n    @property\n    def word_count(self):\n\"\"\"Return the word count of the file.\"\"\"\n        word_count = self.root.find(\".//wordcount\")\n        if word_count is not None:\n            return word_count.text\n        else:\n            raise AttributeError(\"wordcount not found!\")\n\n    @property\n    def ocr(self):\n\"\"\"Check if the ocr element exists.\n\n        :returns: the ocr element or None\n        \"\"\"\n        return self.root.find(\".//ocr\")\n\n    @property\n    def translated_from(self):\n\"\"\"Get the translated_from element from the orig doc.\"\"\"\n        translated_from = self.root.find(\".//translated_from\")\n\n        if translated_from is not None:\n            return translated_from.attrib[\"{http://www.w3.org/XML/1998/namespace}lang\"]\n\n    def remove_version(self):\n\"\"\"Remove the version element.\n\n        This is often the only difference between the otherwise\n        identical files in converted and prestable/converted\n        \"\"\"\n        version_element = self.root.find(\".//version\")\n        version_element.getparent().remove(version_element)\n\n    def remove_skip(self):\n\"\"\"Remove the skip element.\n\n        This contains text that is not wanted in e.g. sentence alignment\n        \"\"\"\n        skip_list = self.root.findall(\".//skip\")\n\n        for skip_element in skip_list:\n            skip_element.getparent().remove(skip_element)\n\n    def move_later(self):\n\"\"\"Move the later elements to the end of the body element.\"\"\"\n        body = self.root.xpath(\"/document/body\")[0]\n\n        later_list = self.root.xpath(\".//later\")\n\n        for later_element in later_list:\n            body.append(later_element)\n\n    def set_body(self, new_body):\n\"\"\"Replace the body element with new_body element.\"\"\"\n        if new_body.tag == \"body\":\n            oldbody = self.etree.find(\".//body\")\n            oldbody.getparent().replace(oldbody, new_body)\n\n    def write(self, file_name=None):\n\"\"\"Write self.etree.\"\"\"\n        if file_name is None:\n            file_name = self.corpus_path\n\n        self.etree.write(\n            file_name, encoding=\"utf8\", pretty_print=True, xml_declaration=True\n        )\n</code></pre>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.lang","title":"<code>lang</code>  <code>property</code>","text":"<p>Get the lang of the file.</p>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.ocr","title":"<code>ocr</code>  <code>property</code>","text":"<p>Check if the ocr element exists.</p> <p>:returns: the ocr element or None</p>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.translated_from","title":"<code>translated_from</code>  <code>property</code>","text":"<p>Get the translated_from element from the orig doc.</p>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.word_count","title":"<code>word_count</code>  <code>property</code>","text":"<p>Return the word count of the file.</p>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.__init__","title":"<code>__init__(name)</code>","text":"<p>Initialise the CorpusXMLFile class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>path to the xml file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>def __init__(self, name):\n\"\"\"Initialise the CorpusXMLFile class.\n\n    Args:\n        name (str): path to the xml file.\n    \"\"\"\n    self.corpus_path = corpuspath.CorpusPath(name)\n    self.etree = etree.parse(name)\n    self.root = self.etree.getroot()\n    self.sanity_check()\n</code></pre>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.move_later","title":"<code>move_later()</code>","text":"<p>Move the later elements to the end of the body element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>def move_later(self):\n\"\"\"Move the later elements to the end of the body element.\"\"\"\n    body = self.root.xpath(\"/document/body\")[0]\n\n    later_list = self.root.xpath(\".//later\")\n\n    for later_element in later_list:\n        body.append(later_element)\n</code></pre>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.remove_skip","title":"<code>remove_skip()</code>","text":"<p>Remove the skip element.</p> <p>This contains text that is not wanted in e.g. sentence alignment</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>def remove_skip(self):\n\"\"\"Remove the skip element.\n\n    This contains text that is not wanted in e.g. sentence alignment\n    \"\"\"\n    skip_list = self.root.findall(\".//skip\")\n\n    for skip_element in skip_list:\n        skip_element.getparent().remove(skip_element)\n</code></pre>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.remove_version","title":"<code>remove_version()</code>","text":"<p>Remove the version element.</p> <p>This is often the only difference between the otherwise identical files in converted and prestable/converted</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>def remove_version(self):\n\"\"\"Remove the version element.\n\n    This is often the only difference between the otherwise\n    identical files in converted and prestable/converted\n    \"\"\"\n    version_element = self.root.find(\".//version\")\n    version_element.getparent().remove(version_element)\n</code></pre>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.sanity_check","title":"<code>sanity_check()</code>","text":"<p>Check if the file really is a corpus xml file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>def sanity_check(self):\n\"\"\"Check if the file really is a corpus xml file.\"\"\"\n    if self.root.tag != \"document\":\n        raise util.ArgumentError(\n            \"Expected Corpus XML file (output of convert2xml) with \"\n            \"&lt;document&gt; as the root tag, got {} -- did you pass the \"\n            \"wrong file?\".format(\n                self.root.tag,\n            )\n        )\n</code></pre>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.set_body","title":"<code>set_body(new_body)</code>","text":"<p>Replace the body element with new_body element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>def set_body(self, new_body):\n\"\"\"Replace the body element with new_body element.\"\"\"\n    if new_body.tag == \"body\":\n        oldbody = self.etree.find(\".//body\")\n        oldbody.getparent().replace(oldbody, new_body)\n</code></pre>"},{"location":"reference/corpusxmlfile/#corpustools.corpusxmlfile.CorpusXMLFile.write","title":"<code>write(file_name=None)</code>","text":"<p>Write self.etree.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/corpusxmlfile.py</code> <pre><code>def write(self, file_name=None):\n\"\"\"Write self.etree.\"\"\"\n    if file_name is None:\n        file_name = self.corpus_path\n\n    self.etree.write(\n        file_name, encoding=\"utf8\", pretty_print=True, xml_declaration=True\n    )\n</code></pre>"},{"location":"reference/counter/","title":"counter","text":"<p>This file contains classes to convert files to the giellatekno xml format.</p>"},{"location":"reference/counter/#corpustools.counter.count_files","title":"<code>count_files(path)</code>","text":"<p>Count files in the given language.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/counter.py</code> <pre><code>def count_files(path):\n\"\"\"Count files in the given language.\"\"\"\n    today = date.today()\n\n    cm = convertermanager.ConverterManager(False, False)\n    cm.collect_files([path])\n    counter = defaultdict(int)\n    lacking_files = defaultdict(set)\n    for f in cm.files:\n        c = converter.Converter(f)\n        if os.path.exists(c.names.converted):\n            counter[\"con\"] += 1\n        else:\n            lacking_files[\"con\"].add(c.names.orig)\n\n        for fst in [\"xfst\", \"hfst\"]:\n            todays_analysed = f\"/analysed.{today}/{fst}/\"\n            if os.path.exists(c.names.analysed.replace(\"/analysed/\", todays_analysed)):\n                counter[fst] += 1\n        else:\n            if os.path.exists(c.names.converted):\n                lacking_files[\"ana\"].add(c.names.converted)\n    return (\n        len(cm.files),\n        counter[\"con\"],\n        counter[\"xfst\"],\n        counter[\"hfst\"],\n        lacking_files,\n    )\n</code></pre>"},{"location":"reference/counter/#corpustools.counter.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/counter.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Count corpus files. List them if called for.\",\n    )\n\n    parser.add_argument(\n        \"--listfiles\",\n        action=\"store_true\",\n        help=\"List lacking converted and analysed files.\",\n    )\n\n    args = parser.parse_args()\n\n    return args\n</code></pre>"},{"location":"reference/crawler/","title":"crawler","text":"<p>This file contains routines to crawl sites containing saami text.</p>"},{"location":"reference/crawler/#corpustools.crawler.Crawler","title":"<code>Crawler</code>","text":"<p>A base class to save downloaded files to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/crawler.py</code> <pre><code>class Crawler:\n\"\"\"A base class to save downloaded files to the corpus.\"\"\"\n\n    def __init__(self):\n\"\"\"Initialise the Crawler class.\"\"\"\n        self.goaldir = str(os.getenv(\"GTFREE\"))\n        self.unvisited_links = set()\n        self.visited_links = set()\n        self.download_links = set()\n        self.corpus_adders = {}\n        self.downloader = adder.UrlDownloader(os.path.join(self.goaldir, \"tmp\"))\n\n    def __del__(self):\n\"\"\"Add all files to the corpus.\"\"\"\n        for (_, corpus_adder) in self.corpus_adders.items():\n            corpus_adder.add_files_to_working_copy()\n\n    def save_pages(self, pages):\n\"\"\"Write pages to disk.\n\n        pages is a list of url, lang tuples\n        \"\"\"\n        parallelpath = \"\"\n\n        for (url, lang) in pages:\n            try:\n                (_, tmpname) = self.downloader.download(url)\n            except adder.AdderError as error:\n                util.print_frame(debug=str(error) + \"\\n\")\n            else:\n                normalised_name = namechanger.normalise_filename(\n                    os.path.basename(tmpname)\n                )\n                normalised_path = os.path.join(\n                    self.corpus_adders[lang].goaldir, normalised_name\n                )\n\n                if not os.path.exists(normalised_path):\n                    parallelpath = self.corpus_adders[lang].copy_file_to_corpus(\n                        tmpname, url, parallelpath=parallelpath\n                    )\n                    util.print_frame(debug=f\"adding {parallelpath}\")\n                else:\n                    parallelpath = normalised_path\n        print(file=sys.stderr)\n</code></pre>"},{"location":"reference/crawler/#corpustools.crawler.Crawler.__del__","title":"<code>__del__()</code>","text":"<p>Add all files to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/crawler.py</code> <pre><code>def __del__(self):\n\"\"\"Add all files to the corpus.\"\"\"\n    for (_, corpus_adder) in self.corpus_adders.items():\n        corpus_adder.add_files_to_working_copy()\n</code></pre>"},{"location":"reference/crawler/#corpustools.crawler.Crawler.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the Crawler class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/crawler.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the Crawler class.\"\"\"\n    self.goaldir = str(os.getenv(\"GTFREE\"))\n    self.unvisited_links = set()\n    self.visited_links = set()\n    self.download_links = set()\n    self.corpus_adders = {}\n    self.downloader = adder.UrlDownloader(os.path.join(self.goaldir, \"tmp\"))\n</code></pre>"},{"location":"reference/crawler/#corpustools.crawler.Crawler.save_pages","title":"<code>save_pages(pages)</code>","text":"<p>Write pages to disk.</p> <p>pages is a list of url, lang tuples</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/crawler.py</code> <pre><code>def save_pages(self, pages):\n\"\"\"Write pages to disk.\n\n    pages is a list of url, lang tuples\n    \"\"\"\n    parallelpath = \"\"\n\n    for (url, lang) in pages:\n        try:\n            (_, tmpname) = self.downloader.download(url)\n        except adder.AdderError as error:\n            util.print_frame(debug=str(error) + \"\\n\")\n        else:\n            normalised_name = namechanger.normalise_filename(\n                os.path.basename(tmpname)\n            )\n            normalised_path = os.path.join(\n                self.corpus_adders[lang].goaldir, normalised_name\n            )\n\n            if not os.path.exists(normalised_path):\n                parallelpath = self.corpus_adders[lang].copy_file_to_corpus(\n                    tmpname, url, parallelpath=parallelpath\n                )\n                util.print_frame(debug=f\"adding {parallelpath}\")\n            else:\n                parallelpath = normalised_path\n    print(file=sys.stderr)\n</code></pre>"},{"location":"reference/debug_corpus/","title":"debug_corpus","text":"<p>Find out why conversion or analysis stops when ran in multiprocess mode.</p>"},{"location":"reference/decode/","title":"decode","text":"<p>Code to detect and fix semi official and unofficial encodings.</p> <p>(Northern) sami character eight bit encodings have been semi or non official standards and have been converted to the various systems' internal encodings. This module has functions that revert the damage done.</p>"},{"location":"reference/decode/#corpustools.decode.decode_para","title":"<code>decode_para(position, text)</code>","text":"<p>Decode the text given to this function.</p> <p>Replace letters in text with the ones from the dict at position position in CTYPES</p> <p>@param position which place the encoding has in the CTYPES list @param text str @return str</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def decode_para(position, text):\n\"\"\"Decode the text given to this function.\n\n    Replace letters in text with the ones from the dict at\n    position position in CTYPES\n\n    @param position which place the encoding has in the CTYPES list\n    @param text str\n    @return str\n    \"\"\"\n    which_decoder = {\n        \"mac-sami_to_cp1252\": fix_macsami_cp1252,\n        \"mac-sami_to_latin1\": fix_macsami_latin1,\n        \"mac-sami_to_mac\": fix_macsami_mac,\n        \"winsami2_to_cp1252\": fix_winsami2_cp1252,\n        \"cp1251_cp1252\": fix_meadowmari_cp1252,\n    }\n\n    try:\n        return which_decoder[position](text)\n    except KeyError:\n        return default_decoder(position, text)\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.default_decoder","title":"<code>default_decoder(position, text)</code>","text":"<p>The default decoder.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The string that should be decoded.</p> required <p>Returns:</p> Type Description <p>str</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def default_decoder(position, text):\n\"\"\"The default decoder.\n\n    Args:\n        position\n        text (str): The string that should be decoded.\n\n    Returns:\n        str\n    \"\"\"\n    if position is not None:\n        for key, value in CTYPES[position].items():\n            text = text.replace(key, value)\n\n    return text\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.fix_macsami_cp1252","title":"<code>fix_macsami_cp1252(instring)</code>","text":"<p>Fix instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>A bytestring that originally was encoded as macsami but has been decoded to unicode as if it was cp1252.</p> required <p>Returns:</p> Type Description <p>str with fixed encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def fix_macsami_cp1252(instring):\n\"\"\"Fix instring.\n\n    Args:\n        instring (str): A bytestring that originally was encoded as\n            macsami but has been decoded to unicode as if it was\n            cp1252.\n\n    Returns:\n        str with fixed encoding.\n    \"\"\"\n    bytestring = instring.encode(\"1252\", errors=\"xmlcharrefreplace\")\n    encoded_unicode = bytestring.decode(\"macsami\").replace(\"&amp;#129;\", \"\u00c5\")\n    return encoded_unicode\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.fix_macsami_latin1","title":"<code>fix_macsami_latin1(instring)</code>","text":"<p>Fix instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>A bytestring that originally was encoded as macsami but has been decoded to unicode as if it was latin1.</p> required <p>Returns:</p> Type Description <p>str with fixed encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def fix_macsami_latin1(instring):\n\"\"\"Fix instring.\n\n    Args:\n        instring (str): A bytestring that originally was encoded as\n            macsami but has been decoded to unicode as if it was\n            latin1.\n\n    Returns:\n        str with fixed encoding.\n    \"\"\"\n    return instring.encode(\"latin1\", errors=\"xmlcharrefreplace\").decode(\"macsami\")\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.fix_macsami_mac","title":"<code>fix_macsami_mac(instring)</code>","text":"<p>Fix instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>A bytestring that originally was encoded as macsami but has been decoded to unicode as if it was macroman.</p> required <p>Returns:</p> Type Description <p>str with fixed encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def fix_macsami_mac(instring):\n\"\"\"Fix instring.\n\n    Args:\n        instring (str): A bytestring that originally was encoded as\n            macsami but has been decoded to unicode as if it was\n            macroman.\n\n    Returns:\n        str with fixed encoding.\n    \"\"\"\n    bytestring = instring.encode(\"macroman\", \"xmlcharrefreplace\")\n    encoded_string = bytestring.decode(\"macsami\").replace(\"&amp;#8486;\", \"\u017e\")\n\n    return encoded_string\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.fix_meadowmari_cp1252","title":"<code>fix_meadowmari_cp1252(instring)</code>","text":"<p>Fix instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>A bytestring that originally was encoded as meadowmari but has been decoded to unicode as if it was cp1252.</p> required <p>Returns:</p> Type Description <p>str with fixed encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def fix_meadowmari_cp1252(instring):\n\"\"\"Fix instring.\n\n    Args:\n        instring (str): A bytestring that originally was encoded as\n            meadowmari but has been decoded to unicode as if it was\n            cp1252.\n\n    Returns:\n        str with fixed encoding.\n    \"\"\"\n    mari_replacements = [\n        (\"&amp;#1118;\", \"\u04f1\"),  # xml char ref CYRILLIC SMALL LETTER SHORT U\n        (\"&amp;#1038;\", \"\u04f0\"),  # xml char ref CYRILLIC CAPITAL LETTER SHORT U\n        (\"\u040e\", \"\u04f0\"),\n        (\"&amp;#1108;\", \"\u04e7\"),  # xml char ref CYRILLIC SMALL LETTER UKRAINIAN IE\n        (\"&amp;#1028;\", \"\u04e6\"),  # xml char ref CYRILLIC CAPITAL LETTER UKRAINIAN IE\n    ]\n\n    return util.replace_all(\n        mari_replacements,\n        instring.encode(\"cp1252\", errors=\"xmlcharrefreplace\").decode(\"meadowmari\"),\n    )\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.fix_winsami2_cp1252","title":"<code>fix_winsami2_cp1252(instring)</code>","text":"<p>Fix instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>A bytestring that originally was encoded as winsami2 but has been decoded to unicode as if it was cp1252.</p> required <p>Returns:</p> Type Description <p>str with fixed encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def fix_winsami2_cp1252(instring):\n\"\"\"Fix instring.\n\n    Args:\n        instring (str): A bytestring that originally was encoded as\n            winsami2 but has been decoded to unicode as if it was\n            cp1252.\n\n    Returns:\n        str with fixed encoding.\n    \"\"\"\n    return instring.encode(\"cp1252\", errors=\"xmlcharrefreplace\").decode(\"ws2\")\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.guess_body_encoding","title":"<code>guess_body_encoding(content, mainlang)</code>","text":"<p>Guess the encoding of the string content.</p> <p>First get the frequencies of the \"sami letters\" Then get the frequencies of the letters in the encodings in CTYPES</p> <p>If \"sami letters\" that the encoding tries to fix exist in \"content\", disregard the encoding</p> <p>@param content a unicode string @return winner is a key from CTYPES or None to tell that no known encoding is found</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def guess_body_encoding(content, mainlang):\n\"\"\"Guess the encoding of the string content.\n\n    First get the frequencies of the \"sami letters\"\n    Then get the frequencies of the letters in the encodings in CTYPES\n\n    If \"sami letters\" that the encoding tries to fix exist in \"content\",\n    disregard the encoding\n\n    @param content a unicode string\n    @return winner is a key from CTYPES or None to tell that no known\n    encoding is found\n    \"\"\"\n    winner = None\n    if \"\u00ec\" in content and \"\u00f2\" in content and mainlang in CYRILLIC_LANGUAGES:\n        winner = \"cyrillic_in_pdf\"\n    elif \"\u00e0\" in content and \"\u00fb\" in content and mainlang in CYRILLIC_LANGUAGES:\n        winner = \"cp1251_cp1252\"\n    elif (\"\u2021\" in content and \"\u00e3\" not in content) or (\n        \"\u0152\" in content and \"\u00c4\u0152\" not in content and \"\u00e5\" not in content\n    ):\n        winner = \"mac-sami_to_cp1252\"\n    elif (\n        (\"\u0087\" in content and \"\u00e3\" not in content)\n        or (\"\u008c\" in content)\n        or (\"\u00af\" in content and \"\u00e1\" not in content)\n    ):\n        winner = \"mac-sami_to_latin1\"\n    elif \"\u0087\" in content and \"\u00e3\":\n        winner = \"mix-mac-sami-and-some-unknown-encoding\"\n    elif \"\u00b3\" in content and \"\u00a2\" in content and \"\u00a4\" in content:\n        winner = \"iso-ir-197_to_cp1252\"\n    elif \"\u00e1\" in content and (\"\u00aa\" in content or \"\u222b\" in content):\n        winner = \"mac-sami_to_mac\"\n    elif \"\u00f3\" in content and \"\u00e7\" in content and \"\u00f0\" in content:\n        winner = \"winsam_to_cp1252\"\n    elif \"\u00e1\" in content and \"\u00e8\" in content and \"\u00f0\" in content:\n        winner = \"latin4_to_cp1252\"\n    elif \"\u00f3\" in content and \"\u00e7\" in content and \"\u00a4\" in content:\n        winner = \"mix-of-latin4-and-iso-ir-197_to_cp1252\"\n    elif \"\u201e\" in content and (\"\u02dc\" in content or \"\u00b9\" in content):\n        winner = \"winsami2_to_cp1252\"\n    elif \"\u00fe\" in content and \"\u0161\" in content and \"\u00e1\" in content:\n        winner = \"finnish-lawtexts-in-pdf\"\n    elif \"\u00c3\u00a1\" in content:\n        winner = \"double-utf8\"\n\n    return winner\n</code></pre>"},{"location":"reference/decode/#corpustools.decode.guess_file_encoding","title":"<code>guess_file_encoding(filename, mainlang)</code>","text":"<p>Guess the encoding of a file.</p> <p>@param filename name of an utf-8 encoded file @return winner is an int, pointing to a position in CTYPES, or -1</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/decode.py</code> <pre><code>def guess_file_encoding(filename, mainlang):\n\"\"\"Guess the encoding of a file.\n\n    @param filename name of an utf-8 encoded file\n    @return winner is an int, pointing to a position in CTYPES, or -1\n    \"\"\"\n    with open(filename) as infile:\n        content = infile.read()\n        winner = guess_body_encoding(content, mainlang)\n\n        return winner\n</code></pre>"},{"location":"reference/docconverter/","title":"docconverter","text":"<p>Convert doc files to the Giella xml format.</p>"},{"location":"reference/docconverter/#corpustools.docconverter.DocError","title":"<code>DocError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Use this when errors occur in this module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/docconverter.py</code> <pre><code>class DocError(Exception):\n\"\"\"Use this when errors occur in this module.\"\"\"\n</code></pre>"},{"location":"reference/docconverter/#corpustools.docconverter.doc_to_unicodehtml","title":"<code>doc_to_unicodehtml(filename)</code>","text":"<p>Convert a doc file to xhtml.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the file</p> required <p>Returns:</p> Type Description <p>A string containing the xhtml version of the doc file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/docconverter.py</code> <pre><code>def doc_to_unicodehtml(filename):\n\"\"\"Convert a doc file to xhtml.\n\n    Args:\n        filename (str): path to the file\n\n    Returns:\n        A string containing the xhtml version of the doc file.\n    \"\"\"\n    text = extract_text(filename)\n    try:\n        return text.decode(\"utf8\")\n    except UnicodeDecodeError:\n        # remove control characters\n        remove_re = re.compile(\"[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F{}]\")\n\n        return remove_re.subn(\"\", text.decode(\"windows-1252\"))[0]\n</code></pre>"},{"location":"reference/docconverter/#corpustools.docconverter.extract_text","title":"<code>extract_text(filename)</code>","text":"<p>Extract the text from a document.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the document</p> required <code>command</code> <code>list of str</code> <p>the command and the arguments sent to ExternalCommandRunner.</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <p>the output of the program</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/docconverter.py</code> <pre><code>def extract_text(filename):\n\"\"\"Extract the text from a document.\n\n    Args:\n        filename (str): path to the document\n        command (list of str): the command and the arguments sent to\n            ExternalCommandRunner.\n\n    Returns:\n        bytes: the output of the program\n    \"\"\"\n    command = [\"wvHtml\", filename, \"-\"]\n    runner = util.ExternalCommandRunner()\n    runner.run(command, cwd=\"/tmp\")\n\n    if runner.returncode != 0:\n        with open(filename + \".log\", \"w\") as logfile:\n            print(f\"stdout\\n{runner.stdout}\\n\", file=logfile)\n            print(f\"stderr\\n{runner.stderr}\\n\", file=logfile)\n            raise util.ConversionError(\n                \"{} failed. More info in the log file: {}\".format(\n                    command[0], filename + \".log\"\n                )\n            )\n\n    return runner.stdout\n</code></pre>"},{"location":"reference/docconverter/#corpustools.docconverter.fix_wv_output","title":"<code>fix_wv_output()</code>","text":"<p>Fix headers in the docx xhtml output.</p> <p>Examples of headings:</p> <p>h1:                           OVTTASKASOLBMOT                      </p> <p>h2:                           \u010doahkk\u00e1igeassu                      </p> <p>                              Ulbmil ja v\u00e1ldooasit                          </p> <p>h3:                                   Geaogr\u00e1fala\u0161                                                               r\u00e1ddjen                              <pre><code>                &lt;/html:p&gt;\n            &lt;/html:div&gt;\n        &lt;/html:li&gt;\n\n    &lt;/html:ol&gt;\n&lt;/html:ol&gt;\n</code></pre> <p></p> <p> Iskanjoavku ja s\u00e1megielaga                         defini\u0161uvdn a <pre><code>    &lt;/html:ol&gt;\n&lt;/html:ol&gt;\n</code></pre> <p></p> <p>h4:                       Mildosat:                  </p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/docconverter.py</code> <pre><code>def fix_wv_output():\n\"\"\"Fix headers in the docx xhtml output.\n\n    Examples of headings:\n\n    h1:\n    &lt;html:ul&gt;\n        &lt;html:li value=\"2\"&gt;\n            &lt;html:p/&gt;\n            &lt;html:div align=\"left\" name=\"Overskrift 1\"&gt;\n                &lt;html:p&gt;\n                    &lt;html:b&gt;\n                        &lt;html:span&gt;\n                            OVTTASKASOLBMOT\n                        &lt;/html:span&gt;\n                    &lt;/html:b&gt;\n                &lt;/html:p&gt;\n            &lt;/html:div&gt;\n        &lt;/html:li&gt;\n    &lt;/html:ul&gt;\n\n    h2:\n    &lt;html:ol type=\"1\"&gt;\n        &lt;html:li value=\"1\"&gt;\n            &lt;html:p/&gt;\n            &lt;html:div align=\"left\" name=\"Overskrift 2\"&gt;\n                &lt;html:p&gt;\n                    &lt;html:b&gt;\n                        &lt;html:span&gt;\n                            \u010doahkk\u00e1igeassu\n                        &lt;/html:span&gt;\n                    &lt;/html:b&gt;\n                &lt;/html:p&gt;\n            &lt;/html:div&gt;\n        &lt;/html:li&gt;\n    &lt;/html:ol&gt;\n\n    &lt;html:ol type=\"1\"&gt;\n        &lt;html:ol type=\"1\"&gt;\n            &lt;html:li value=\"2\"&gt;\n                &lt;html:p/&gt;\n                &lt;html:div align=\"left\" name=\"Overskrift 2\"&gt;\n                    &lt;html:p&gt;\n                        &lt;html:b&gt;\n                            &lt;html:span&gt;\n                                Ulbmil ja v\u00e1ldooasit\n                            &lt;/html:span&gt;\n                        &lt;/html:b&gt;\n                    &lt;/html:p&gt;\n                &lt;/html:div&gt;\n            &lt;/html:li&gt;\n        &lt;/html:ol&gt;\n    &lt;/html:ol&gt;\n\n    h3:\n    &lt;html:ol type=\"1\"&gt;\n        &lt;html:ol type=\"1\"&gt;\n            &lt;html:ol type=\"1\"&gt;\n                &lt;html:li value=\"1\"&gt;\n                    &lt;html:p&gt;\n                    &lt;/html:p&gt;\n                    &lt;html:div align=\"left\" name=\"Overskrift 3\"&gt;\n                        &lt;html:p&gt;\n                            &lt;html:b&gt;\n                                &lt;html:span&gt;\n                                    Geaogr\u00e1fala\u0161\n                                &lt;/html:span&gt;\n                            &lt;/html:b&gt;\n                            &lt;html:b&gt;\n                                &lt;html:span&gt;\n                                    r\u00e1ddjen\n                                &lt;/html:span&gt;\n                            &lt;/html:b&gt;\n\n                        &lt;/html:p&gt;\n                    &lt;/html:div&gt;\n                &lt;/html:li&gt;\n\n            &lt;/html:ol&gt;\n        &lt;/html:ol&gt;\n    &lt;/html:ol&gt;\n\n    &lt;html:ol type=\"1\"&gt;\n        &lt;html:ol type=\"1\"&gt;\n            &lt;html:ol type=\"1\"&gt;\n                &lt;html:li value=\"1\"&gt;\n                    &lt;html:p&gt;\n                    &lt;/html:p&gt;\n                    &lt;html:div align=\"left\" name=\"Overskrift 3\"&gt;\n                        &lt;html:p&gt;\n                            &lt;html:b&gt;\n                            &lt;html:span&gt;Iskanjoavku ja s\u00e1megielaga\n                            defini\u0161uvdn&lt;/html:span&gt;&lt;/html:b&gt;\n                            &lt;html:b&gt;&lt;html:span&gt;a&lt;/html:span&gt;&lt;/html:b&gt;\n                        &lt;/html:p&gt;\n                    &lt;/html:div&gt;\n                &lt;/html:li&gt;\n\n            &lt;/html:ol&gt;\n        &lt;/html:ol&gt;\n    &lt;/html:ol&gt;\n\n    h4:\n    &lt;html:div align=\"left\" name=\"Overskrift 4\"&gt;\n        &lt;html:p&gt;\n            &lt;html:b&gt;\n                &lt;html:i&gt;\n                    &lt;html:span&gt;\n                        Mildosat:\n                    &lt;/html:span&gt;\n                &lt;/html:i&gt;\n            &lt;/html:b&gt;\n        &lt;/html:p&gt;\n    &lt;/html:div&gt;\n\n    \"\"\"\n</code></pre>"},{"location":"reference/documentfixer/","title":"documentfixer","text":"<p>This file contains classes fix converted documents.</p>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer","title":"<code>DocumentFixer</code>","text":"<p>Fix the content of a Giella xml document.</p> <p>Receive a stringified etree from one of the raw converters, replace ligatures, fix the encoding and return an etree with correct characters</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>class DocumentFixer:\n\"\"\"Fix the content of a Giella xml document.\n\n    Receive a stringified etree from one of the raw converters,\n    replace ligatures, fix the encoding and return an etree with correct\n    characters\n    \"\"\"\n\n    newstags = re.compile(\n        r\"(@*logo:|[\\s+\\']*@*\\s*ingres+[\\.:]*|.*@*.*bilde\\s*\\d*:|\\W*(@|\"\n        r\"LED|bilde)*tekst:|@*foto:|@fotobyline:|@*bildetitt:|\"\n        r\"&lt;pstyle:bilde&gt;|&lt;pstyle:ingress&gt;|&lt;pstyle:tekst&gt;|\"\n        r\"@*Samleingress:*|tekst/ingress:|billedtekst:|.@tekst:)\",\n        re.IGNORECASE,\n    )\n    titletags = re.compile(\n        r\"\\s*@m.titt[\\.:]|\\s*@*stikk:|Mellomtittel:|@*(stikk\\.*|\"\n        r\"under)titt(el)*:|@ttt:|\\s*@*[utm]*[:\\.]*tit+:|&lt;pstyle:m.titt&gt;|\"\n        r\"undertittel:\",\n        re.IGNORECASE,\n    )\n    headertitletags = re.compile(\n        r\"(\\s*@*(led)*tittel:|\\s*@*titt(\\s\\d)*:|@LEDtitt:|\"\n        r\"&lt;pstyle:tittel&gt;|@*(hoved|over)titt(el)*:)\",\n        re.IGNORECASE,\n    )\n    bylinetags = re.compile(\n        r\"(&lt;pstyle:|\\s*@*)[Bb]yline[:&gt;]*\\s*(\\S+:)*\", re.UNICODE | re.IGNORECASE\n    )\n    boldtags = re.compile(r\"@bold\\s*:\")\n\n    def __init__(self, document):\n\"\"\"Initialise the DocumentFixer class.\"\"\"\n        self.root = document\n\n    def get_etree(self):\n\"\"\"Get the root of the xml document.\"\"\"\n        return self.root\n\n    def compact_ems(self):\n\"\"\"Compact consecutive em elements into a single em if possible.\"\"\"\n        word = re.compile(r\"\\w+\", re.UNICODE)\n        for element in self.root.iter(\"p\"):\n            if len(element.xpath(\".//em\")) &gt; 1:\n                lines = []\n                for emphasis in element.iter(\"em\"):\n                    next_elt = emphasis.getnext()\n                    if (\n                        next_elt is not None\n                        and next_elt.tag == \"em\"\n                        and (emphasis.tail is None or not word.search(emphasis.tail))\n                    ):\n                        if emphasis.text is not None:\n                            lines.append(emphasis.text.strip())\n                        emphasis.getparent().remove(emphasis)\n                    else:\n                        if emphasis.text is not None:\n                            lines.append(emphasis.text.strip())\n                        emphasis.text = \" \".join(lines)\n                        if emphasis.tail is not None:\n                            emphasis.tail = f\" {emphasis.tail}\"\n                        del lines[:]\n\n    def soft_hyphen_to_hyph_tag(self):\n\"\"\"Replace soft hyphen chars with hyphen tags.\"\"\"\n        for element in self.root.iter(\"p\"):\n            self.replace_shy(element)\n\n    def replace_shy(self, element):\n\"\"\"Replace shy with a hyph element.\n\n        Args:\n            element: an etree element\n        \"\"\"\n        for child in element:\n            self.replace_shy(child)\n\n        text = element.text\n        if text is not None:\n            parts = text.split(\"\u00ad\")\n            if len(parts) &gt; 1:\n                element.text = parts[0]\n                for index, part in enumerate(parts[1:]):\n                    hyph = etree.Element(\"hyph\")\n                    hyph.tail = part\n                    element.insert(index, hyph)\n\n        text = element.tail\n        if text is not None:\n            parts = text.split(\"\u00ad\")\n            if len(parts) &gt; 1:\n                element.tail = parts[0]\n                for part in parts[1:]:\n                    hyph = etree.Element(\"hyph\")\n                    hyph.tail = part\n                    element.getparent().append(hyph)\n\n    def insert_spaces_after_semicolon(self):\n\"\"\"Insert space after semicolon where needed.\"\"\"\n        irritating_words_regex = re.compile(\n            \"(govv(a|en|ejeaddji):)([^ ])\", re.UNICODE | re.IGNORECASE\n        )\n        for child in self.root.find(\".//body\"):\n            self.insert_space_after_semicolon(child, irritating_words_regex)\n\n    def insert_space_after_semicolon(self, element, irritating_words_regex):\n\"\"\"Insert space after words needing it.\n\n        Args:\n            element: an etree element\n            irritating_words_regex: regex\n        \"\"\"\n        if element.text is not None:\n            element.text = irritating_words_regex.sub(r\"\\1 \\3\", element.text)\n        for child in element:\n            self.insert_space_after_semicolon(child, irritating_words_regex)\n        if element.tail is not None:\n            element.tail = irritating_words_regex.sub(r\"\\1 \\3\", element.tail)\n\n    def replace_ligatures(self):\n\"\"\"Replace unwanted chars.\"\"\"\n        replacements = {\n            \"[dstrok]\": \"\u0111\",\n            \"[Dstrok]\": \"\u0110\",\n            \"[tstrok]\": \"\u0167\",\n            \"[Tstrok]\": \"\u0166\",\n            \"[scaron]\": \"\u0161\",\n            \"[Scaron]\": \"\u0160\",\n            \"[zcaron]\": \"\u017e\",\n            \"[Zcaron]\": \"\u017d\",\n            \"[ccaron]\": \"\u010d\",\n            \"[Ccaron]\": \"\u010c\",\n            \"[eng\": \"\u014b\",\n            \" ]\": \"\",\n            \"\u010e\": \"\u0111\",  # cough\n            \"\u010f\": \"\u0111\",  # cough\n            \"\\x03\": \"\",\n            \"\\x04\": \"\",\n            \"\\x07\": \"\",\n            \"\\x08\": \"\",\n            \"\\x0F\": \"\",\n            \"\\x10\": \"\",\n            \"\\x11\": \"\",\n            \"\\x13\": \"\",\n            \"\\x14\": \"\",\n            \"\\x15\": \"\",\n            \"\\x17\": \"\",\n            \"\\x18\": \"\",\n            \"\\x1A\": \"\",\n            \"\\x1B\": \"\",\n            \"\\x1C\": \"\",\n            \"\\x1D\": \"\",\n            \"\\x1E\": \"\",\n            \"\ufb01\": \"fi\",\n            \"\ufb02\": \"fl\",\n            \"\ufb00\": \"ff\",\n            \"\ufb03\": \"ffi\",\n            \"\ufb04\": \"ffl\",\n            \"\ufb05\": \"ft\",\n        }\n\n        for element in self.root.iter(\"p\"):\n            if element.text:\n                for key, value in replacements.items():\n                    element.text = element.text.replace(key + \" \", value)\n                    element.text = element.text.replace(key, value)\n\n    def replace_bad_unicode(self):\n\"\"\"Replace some chars in an otherwise 'valid utf-8' document.\n\n        These chars e.g. 'valid utf-8' (don't give UnicodeDecodeErrors), but\n        we still want to replace them to what they most likely were\n        meant to be.\n\n        :param content: a unicode string\n        :returns: a cleaned up unicode string\n        \"\"\"\n        # u'\u0161'.encode('windows-1252') gives '\\x9a', which sometimes\n        # appears in otherwise utf-8-encoded documents with the\n        # meaning '\u0161'\n        replacements = [\n            (\"\\x9a\", \"\u0161\"),\n            (\"\\x8a\", \"\u0160\"),\n            (\"\\x9e\", \"\u017e\"),\n            (\"\\x8e\", \"\u017d\"),\n        ]\n        for element in self.root.iter(\"p\"):\n            if element.text:\n                element.text = util.replace_all(replacements, element.text)\n\n    def fix_lang(self, element, lang):\n\"\"\"Replace invalid accents with valid ones for the sms language.\"\"\"\n\n        replacement_pairs = {\n            \"sms\": [\n                (\"\\u2019\", \"\\u02BC\"),  # RIGHT SINGLE QUOTATION MARK,\n                # MODIFIER LETTER APOSTROPHE\n                (\"\\u0027\", \"\\u02BC\"),  # apostrophe,\n                # MODIFIER LETTER APOSTROPHE\n                (\"\\u2032\", \"\\u02B9\"),  # PRIME, MODIFIER LETTER PRIME\n                (\"\\u00B4\", \"\\u02B9\"),  # ACUTE ACCENT,\n                # MODIFIER LETTER PRIME\n                (\"\\u0301\", \"\\u02B9\"),  # COMBINING ACUTE ACCENT,\n                # MODIFIER LETTER PRIME\n            ],\n            \"mns\": [\n                (\"\\uf50e\", \"\u0410\u0304\"),  # CYRILLIC VOWELS WITH LENGTH MARK\n                (\"\\uf50f\", \"\u0430\u0304\"),\n                (\"\\uf510\", \"\u0415\u0304\"),\n                (\"\\uf511\", \"\u0435\u0304\"),\n                (\"\\uf512\", \"\u0401\u0304\"),  #\n                (\"\\uf513\", \"\u0451\u0304\"),\n                (\"\\uf517\", \"\u041e\u0304\"),  # 17? Just guessing\n                (\"\\uf518\", \"\u041e\u0304\"),  # CYRILLIC LONG CAPITAL O\n                (\"\\uf519\", \"\u043e\u0304\"),  # CYRILLIC LONG SMALL O\n                (\"\\uf520\", \"\u042b\u0304\"),  #\n                (\"\\uf521\", \"\u044b\u0304\"),  #\n                (\"\\uf522\", \"\u042d\u0304\"),\n                (\"\\uf523\", \"\u044d\u0304\"),\n                (\"\\uf52c\", \"\u042e\u0304\"),  #\n                (\"\\uf52d\", \"\u044e\u0304\"),\n                (\"\\uf528\", \"\u042f\u0304\"),\n                (\"\\uf529\", \"\u044f\u0304\"),\n            ],\n        }\n\n        if element.text:\n            element.text = util.replace_all(replacement_pairs[lang], element.text)\n        if element.tail:\n            element.tail = util.replace_all(replacement_pairs[lang], element.tail)\n        for child in element:\n            self.fix_lang(child, lang)\n\n    def fix_body_encoding(self, mainlang):\n\"\"\"Replace wrongly encoded saami chars with proper ones.\n\n        Send a stringified version of the body into the EncodingGuesser class.\n        It returns the same version, but with fixed characters.\n        Parse the returned string, insert it into the document\n        \"\"\"\n        self.replace_ligatures()\n\n        body = self.root.find(\"body\")\n        # Weird bug(?) in MacOS, the end tag of document lingers \u2026\n        body_string = etree.tostring(body, encoding=\"unicode\").replace(\n            \"&lt;/document&gt;\", \"\"\n        )\n        body.getparent().remove(body)\n\n        encoding = decode.guess_body_encoding(body_string, mainlang)\n\n        try:\n            body = etree.fromstring(decode.decode_para(encoding, body_string))\n        except UnicodeEncodeError as error:\n            raise UserWarning(str(error))\n        self.root.append(body)\n\n        if mainlang in [\"sms\", \"mns\"]:\n            self.fix_lang(self.root.find(\"body\"), lang=mainlang)\n\n    def fix_title_person(self, encoding):\n\"\"\"Fix encoding problems.\"\"\"\n        title = self.root.find(\".//title\")\n        if title is not None and title.text is not None:\n            text = title.text\n\n            text = text\n            util.print_frame(encoding)\n            title.text = decode.decode_para(encoding, text)\n\n        persons = self.root.findall(\".//person\")\n        for person in persons:\n            if person is not None:\n                lastname = person.get(\"lastname\")\n\n                if encoding == \"mac-sami_to_latin1\":\n                    lastname = lastname.replace(\"\u2021\", \"\u00e1\")\n                    lastname = lastname.replace(\"\u0152\", \"\u00e5\")\n\n                person.set(\"lastname\", decode.decode_para(encoding, lastname))\n\n                firstname = person.get(\"firstname\")\n\n                if encoding == \"mac-sami_to_latin1\":\n                    firstname = firstname.replace(\"\u2021\", \"\u00e1\")\n                    firstname = firstname.replace(\"\u0152\", \"\u00e5\")\n\n                person.set(\"firstname\", decode.decode_para(encoding, firstname))\n\n    @staticmethod\n    def get_quote_list(text):\n\"\"\"Get list of quotes from the given text.\n\n        Args:\n            text: string\n\n        Returns:\n            A list of span tuples containing indexes to quotes found in text.\n        \"\"\"\n        unwanted = r\"[^:,!?.\\s]\"\n        quote_regexes = [\n            re.compile('\"{0}.+?{0}\"'.format(unwanted)),\n            re.compile(\"\u00ab.+?\u00bb\"),\n            re.compile(\"\u201c.+?\u201d\"),\n            re.compile(\"\u201d{0}.+?{0}\u201d\".format(unwanted)),\n        ]\n        quote_list = [\n            m.span()\n            for quote_regex in quote_regexes\n            for m in quote_regex.finditer(text)\n        ]\n        quote_list.sort()\n\n        return quote_list\n\n    @staticmethod\n    def append_quotes(element, text, quote_list):\n\"\"\"Append quotes to an element.\n\n        Args:\n            text: a string that contains the plain text of the element.\n            quote_list: A list of span tuples containing indexes to quotes\n            found in text.\n        \"\"\"\n        for index in range(0, len(quote_list)):\n            span = etree.Element(\"span\")\n            span.set(\"type\", \"quote\")\n            span.text = text[quote_list[index][0] : quote_list[index][1]]\n            if index + 1 &lt; len(quote_list):\n                span.tail = text[quote_list[index][1] : quote_list[index + 1][0]]\n            else:\n                span.tail = text[quote_list[index][1] :]\n            element.append(span)\n\n    def _detect_quote(self, element):\n\"\"\"Insert span elements around quotes.\n\n        Args:\n            element: an etree element.\n        \"\"\"\n        newelement = deepcopy(element)\n\n        element.text = \"\"\n        for child in element:\n            child.getparent().remove(child)\n\n        text = newelement.text\n        if text:\n            quote_list = self.get_quote_list(text)\n            if quote_list:\n                element.text = text[0 : quote_list[0][0]]\n                self.append_quotes(element, text, quote_list)\n            else:\n                element.text = text\n\n        for child in newelement:\n            if child.tag == \"span\" and child.get(\"type\") == \"quote\":\n                element.append(child)\n            else:\n                element.append(self._detect_quote(child))\n\n            if child.tail:\n                text = child.tail\n                quote_list = self.get_quote_list(text)\n                if quote_list:\n                    child.tail = text[0 : quote_list[0][0]]\n                    self.append_quotes(element, text, quote_list)\n\n        return element\n\n    def detect_quotes(self):\n\"\"\"Detect quotes in all paragraphs.\"\"\"\n        for paragraph in self.root.iter(\"p\"):\n            paragraph = self._detect_quote(paragraph)\n\n    def calculate_wordcount(self):\n\"\"\"Count the words in the file.\"\"\"\n        plist = [\n            etree.tostring(paragraph, method=\"text\", encoding=\"unicode\")\n            for paragraph in self.root.iter(\"p\")\n        ]\n\n        return str(len(re.findall(r\"\\S+\", \" \".join(plist))))\n\n    @staticmethod\n    def _make_element(name, text, attributes=None):\n\"\"\"Make an xml element.\n\n        :param name: the name of the element\n        :param text: the content of the element\n        :param attributes: the elements attributes\n\n        :returns: lxml.etree.Element\n        \"\"\"\n        attributes = attributes or {}\n        element = etree.Element(name)\n        for key in attributes:\n            element.set(key, attributes[key])\n\n        element.text = text\n\n        return element\n\n    def _fix_emphasises(self):\n        for emphasis in self.root.iter(\"em\"):\n            paragraph = emphasis.getparent()\n            if not len(emphasis) and emphasis.text:\n                if self.bylinetags.match(emphasis.text):\n                    line = self.bylinetags.sub(\"\", emphasis.text).strip()\n                    unknown = self.root.find(\".//unknown\")\n                    if unknown is not None:\n                        person = etree.Element(\"person\")\n                        person.set(\"lastname\", line)\n                        person.set(\"firstname\", \"\")\n                        unknown.getparent().replace(unknown, person)\n                        paragraph.getparent().remove(paragraph)\n                elif self.titletags.match(emphasis.text):\n                    emphasis.text = self.titletags.sub(\"\", emphasis.text).strip()\n                    paragraph.set(\"type\", \"title\")\n                elif self.newstags.match(emphasis.text):\n                    emphasis.text = self.newstags.sub(\"\", emphasis.text).strip()\n\n    def _add_paragraph(self, line, index, paragraph, attributes):\n        if line:\n            index += 1\n            paragraph.getparent().insert(\n                index, self._make_element(\"p\", line, attributes=attributes)\n            )\n\n        return index\n\n    def _add_emphasis(self, index, line, attributes, paragraph):\n        index += 1\n        element = etree.Element(\"p\")\n        element.append(self._make_element(\"em\", line, attributes))\n\n        paragraph.getparent().insert(index, element)\n\n        return index\n\n    def _handle_line(self, line, index, lines, paragraph):\n        if self.newstags.match(line):\n            index = self._add_paragraph(\n                \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n            )\n            del lines[:]\n\n            lines.append(self.newstags.sub(\"\", line))\n\n        elif self.bylinetags.match(line):\n            index = self._add_paragraph(\n                \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n            )\n            del lines[:]\n\n            unknown = self.root.find(\".//unknown\")\n            if unknown is not None:\n                person = etree.Element(\"person\")\n                person.set(\"lastname\", self.bylinetags.sub(\"\", line).strip())\n                person.set(\"firstname\", \"\")\n\n                unknown.getparent().replace(unknown, person)\n\n        elif self.boldtags.match(line):\n            index = self._add_paragraph(\n                \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n            )\n            index = self._add_emphasis(\n                index, self.boldtags.sub(\"\", line).strip(), {\"type\": \"bold\"}, paragraph\n            )\n            del lines[:]\n\n        elif line.startswith(\"@kursiv:\"):\n            index = self._add_paragraph(\n                \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n            )\n            index = self._add_emphasis(\n                index,\n                line.replace(\"@kursiv:\", \"\").strip(),\n                {\"type\": \"italic\"},\n                paragraph,\n            )\n            del lines[:]\n\n        elif self.headertitletags.match(line):\n            index = self._add_paragraph(\n                \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n            )\n            del lines[:]\n\n            header = self.root.find(\".//header\")\n            title = header.find(\"./title\")\n            if title is not None and title.text is None:\n                title.text = self.headertitletags.sub(\"\", line).strip()\n\n            index = self._add_paragraph(\n                self.headertitletags.sub(\"\", line).strip(),\n                index,\n                paragraph,\n                {\"type\": \"title\"},\n            )\n        elif self.titletags.match(line):\n            index = self._add_paragraph(\n                \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n            )\n            del lines[:]\n\n            index += 1\n            paragraph.getparent().insert(\n                index,\n                self._make_element(\n                    \"p\", self.titletags.sub(\"\", line).strip(), {\"type\": \"title\"}\n                ),\n            )\n        elif line == \"\" and lines:\n            index = self._add_paragraph(\n                \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n            )\n            del lines[:]\n\n        else:\n            lines.append(line)\n\n        return index\n\n    def _fix_paragraphs(self):\n        for paragraph in self.root.iter(\"p\"):\n            if not len(paragraph) and paragraph.text:\n                index = paragraph.getparent().index(paragraph)\n                lines = []\n\n                for line in paragraph.text.split(\"\\n\"):\n                    index = self._handle_line(line, index, lines, paragraph)\n\n                index = self._add_paragraph(\n                    \" \".join(lines).strip(), index, paragraph, paragraph.attrib\n                )\n\n                paragraph.getparent().remove(paragraph)\n\n    def fix_newstags(self):\n\"\"\"Convert newstags found in text to xml elements.\"\"\"\n        self._fix_emphasises()\n        self._fix_paragraphs()\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.__init__","title":"<code>__init__(document)</code>","text":"<p>Initialise the DocumentFixer class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def __init__(self, document):\n\"\"\"Initialise the DocumentFixer class.\"\"\"\n    self.root = document\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.append_quotes","title":"<code>append_quotes(element, text, quote_list)</code>  <code>staticmethod</code>","text":"<p>Append quotes to an element.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>a string that contains the plain text of the element.</p> required <code>quote_list</code> <p>A list of span tuples containing indexes to quotes</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>@staticmethod\ndef append_quotes(element, text, quote_list):\n\"\"\"Append quotes to an element.\n\n    Args:\n        text: a string that contains the plain text of the element.\n        quote_list: A list of span tuples containing indexes to quotes\n        found in text.\n    \"\"\"\n    for index in range(0, len(quote_list)):\n        span = etree.Element(\"span\")\n        span.set(\"type\", \"quote\")\n        span.text = text[quote_list[index][0] : quote_list[index][1]]\n        if index + 1 &lt; len(quote_list):\n            span.tail = text[quote_list[index][1] : quote_list[index + 1][0]]\n        else:\n            span.tail = text[quote_list[index][1] :]\n        element.append(span)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.calculate_wordcount","title":"<code>calculate_wordcount()</code>","text":"<p>Count the words in the file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def calculate_wordcount(self):\n\"\"\"Count the words in the file.\"\"\"\n    plist = [\n        etree.tostring(paragraph, method=\"text\", encoding=\"unicode\")\n        for paragraph in self.root.iter(\"p\")\n    ]\n\n    return str(len(re.findall(r\"\\S+\", \" \".join(plist))))\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.compact_ems","title":"<code>compact_ems()</code>","text":"<p>Compact consecutive em elements into a single em if possible.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def compact_ems(self):\n\"\"\"Compact consecutive em elements into a single em if possible.\"\"\"\n    word = re.compile(r\"\\w+\", re.UNICODE)\n    for element in self.root.iter(\"p\"):\n        if len(element.xpath(\".//em\")) &gt; 1:\n            lines = []\n            for emphasis in element.iter(\"em\"):\n                next_elt = emphasis.getnext()\n                if (\n                    next_elt is not None\n                    and next_elt.tag == \"em\"\n                    and (emphasis.tail is None or not word.search(emphasis.tail))\n                ):\n                    if emphasis.text is not None:\n                        lines.append(emphasis.text.strip())\n                    emphasis.getparent().remove(emphasis)\n                else:\n                    if emphasis.text is not None:\n                        lines.append(emphasis.text.strip())\n                    emphasis.text = \" \".join(lines)\n                    if emphasis.tail is not None:\n                        emphasis.tail = f\" {emphasis.tail}\"\n                    del lines[:]\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.detect_quotes","title":"<code>detect_quotes()</code>","text":"<p>Detect quotes in all paragraphs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def detect_quotes(self):\n\"\"\"Detect quotes in all paragraphs.\"\"\"\n    for paragraph in self.root.iter(\"p\"):\n        paragraph = self._detect_quote(paragraph)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.fix_body_encoding","title":"<code>fix_body_encoding(mainlang)</code>","text":"<p>Replace wrongly encoded saami chars with proper ones.</p> <p>Send a stringified version of the body into the EncodingGuesser class. It returns the same version, but with fixed characters. Parse the returned string, insert it into the document</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def fix_body_encoding(self, mainlang):\n\"\"\"Replace wrongly encoded saami chars with proper ones.\n\n    Send a stringified version of the body into the EncodingGuesser class.\n    It returns the same version, but with fixed characters.\n    Parse the returned string, insert it into the document\n    \"\"\"\n    self.replace_ligatures()\n\n    body = self.root.find(\"body\")\n    # Weird bug(?) in MacOS, the end tag of document lingers \u2026\n    body_string = etree.tostring(body, encoding=\"unicode\").replace(\n        \"&lt;/document&gt;\", \"\"\n    )\n    body.getparent().remove(body)\n\n    encoding = decode.guess_body_encoding(body_string, mainlang)\n\n    try:\n        body = etree.fromstring(decode.decode_para(encoding, body_string))\n    except UnicodeEncodeError as error:\n        raise UserWarning(str(error))\n    self.root.append(body)\n\n    if mainlang in [\"sms\", \"mns\"]:\n        self.fix_lang(self.root.find(\"body\"), lang=mainlang)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.fix_lang","title":"<code>fix_lang(element, lang)</code>","text":"<p>Replace invalid accents with valid ones for the sms language.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def fix_lang(self, element, lang):\n\"\"\"Replace invalid accents with valid ones for the sms language.\"\"\"\n\n    replacement_pairs = {\n        \"sms\": [\n            (\"\\u2019\", \"\\u02BC\"),  # RIGHT SINGLE QUOTATION MARK,\n            # MODIFIER LETTER APOSTROPHE\n            (\"\\u0027\", \"\\u02BC\"),  # apostrophe,\n            # MODIFIER LETTER APOSTROPHE\n            (\"\\u2032\", \"\\u02B9\"),  # PRIME, MODIFIER LETTER PRIME\n            (\"\\u00B4\", \"\\u02B9\"),  # ACUTE ACCENT,\n            # MODIFIER LETTER PRIME\n            (\"\\u0301\", \"\\u02B9\"),  # COMBINING ACUTE ACCENT,\n            # MODIFIER LETTER PRIME\n        ],\n        \"mns\": [\n            (\"\\uf50e\", \"\u0410\u0304\"),  # CYRILLIC VOWELS WITH LENGTH MARK\n            (\"\\uf50f\", \"\u0430\u0304\"),\n            (\"\\uf510\", \"\u0415\u0304\"),\n            (\"\\uf511\", \"\u0435\u0304\"),\n            (\"\\uf512\", \"\u0401\u0304\"),  #\n            (\"\\uf513\", \"\u0451\u0304\"),\n            (\"\\uf517\", \"\u041e\u0304\"),  # 17? Just guessing\n            (\"\\uf518\", \"\u041e\u0304\"),  # CYRILLIC LONG CAPITAL O\n            (\"\\uf519\", \"\u043e\u0304\"),  # CYRILLIC LONG SMALL O\n            (\"\\uf520\", \"\u042b\u0304\"),  #\n            (\"\\uf521\", \"\u044b\u0304\"),  #\n            (\"\\uf522\", \"\u042d\u0304\"),\n            (\"\\uf523\", \"\u044d\u0304\"),\n            (\"\\uf52c\", \"\u042e\u0304\"),  #\n            (\"\\uf52d\", \"\u044e\u0304\"),\n            (\"\\uf528\", \"\u042f\u0304\"),\n            (\"\\uf529\", \"\u044f\u0304\"),\n        ],\n    }\n\n    if element.text:\n        element.text = util.replace_all(replacement_pairs[lang], element.text)\n    if element.tail:\n        element.tail = util.replace_all(replacement_pairs[lang], element.tail)\n    for child in element:\n        self.fix_lang(child, lang)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.fix_newstags","title":"<code>fix_newstags()</code>","text":"<p>Convert newstags found in text to xml elements.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def fix_newstags(self):\n\"\"\"Convert newstags found in text to xml elements.\"\"\"\n    self._fix_emphasises()\n    self._fix_paragraphs()\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.fix_title_person","title":"<code>fix_title_person(encoding)</code>","text":"<p>Fix encoding problems.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def fix_title_person(self, encoding):\n\"\"\"Fix encoding problems.\"\"\"\n    title = self.root.find(\".//title\")\n    if title is not None and title.text is not None:\n        text = title.text\n\n        text = text\n        util.print_frame(encoding)\n        title.text = decode.decode_para(encoding, text)\n\n    persons = self.root.findall(\".//person\")\n    for person in persons:\n        if person is not None:\n            lastname = person.get(\"lastname\")\n\n            if encoding == \"mac-sami_to_latin1\":\n                lastname = lastname.replace(\"\u2021\", \"\u00e1\")\n                lastname = lastname.replace(\"\u0152\", \"\u00e5\")\n\n            person.set(\"lastname\", decode.decode_para(encoding, lastname))\n\n            firstname = person.get(\"firstname\")\n\n            if encoding == \"mac-sami_to_latin1\":\n                firstname = firstname.replace(\"\u2021\", \"\u00e1\")\n                firstname = firstname.replace(\"\u0152\", \"\u00e5\")\n\n            person.set(\"firstname\", decode.decode_para(encoding, firstname))\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.get_etree","title":"<code>get_etree()</code>","text":"<p>Get the root of the xml document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def get_etree(self):\n\"\"\"Get the root of the xml document.\"\"\"\n    return self.root\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.get_quote_list","title":"<code>get_quote_list(text)</code>  <code>staticmethod</code>","text":"<p>Get list of quotes from the given text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>string</p> required <p>Returns:</p> Type Description <p>A list of span tuples containing indexes to quotes found in text.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>@staticmethod\ndef get_quote_list(text):\n\"\"\"Get list of quotes from the given text.\n\n    Args:\n        text: string\n\n    Returns:\n        A list of span tuples containing indexes to quotes found in text.\n    \"\"\"\n    unwanted = r\"[^:,!?.\\s]\"\n    quote_regexes = [\n        re.compile('\"{0}.+?{0}\"'.format(unwanted)),\n        re.compile(\"\u00ab.+?\u00bb\"),\n        re.compile(\"\u201c.+?\u201d\"),\n        re.compile(\"\u201d{0}.+?{0}\u201d\".format(unwanted)),\n    ]\n    quote_list = [\n        m.span()\n        for quote_regex in quote_regexes\n        for m in quote_regex.finditer(text)\n    ]\n    quote_list.sort()\n\n    return quote_list\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.insert_space_after_semicolon","title":"<code>insert_space_after_semicolon(element, irritating_words_regex)</code>","text":"<p>Insert space after words needing it.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <p>an etree element</p> required <code>irritating_words_regex</code> <p>regex</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def insert_space_after_semicolon(self, element, irritating_words_regex):\n\"\"\"Insert space after words needing it.\n\n    Args:\n        element: an etree element\n        irritating_words_regex: regex\n    \"\"\"\n    if element.text is not None:\n        element.text = irritating_words_regex.sub(r\"\\1 \\3\", element.text)\n    for child in element:\n        self.insert_space_after_semicolon(child, irritating_words_regex)\n    if element.tail is not None:\n        element.tail = irritating_words_regex.sub(r\"\\1 \\3\", element.tail)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.insert_spaces_after_semicolon","title":"<code>insert_spaces_after_semicolon()</code>","text":"<p>Insert space after semicolon where needed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def insert_spaces_after_semicolon(self):\n\"\"\"Insert space after semicolon where needed.\"\"\"\n    irritating_words_regex = re.compile(\n        \"(govv(a|en|ejeaddji):)([^ ])\", re.UNICODE | re.IGNORECASE\n    )\n    for child in self.root.find(\".//body\"):\n        self.insert_space_after_semicolon(child, irritating_words_regex)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.replace_bad_unicode","title":"<code>replace_bad_unicode()</code>","text":"<p>Replace some chars in an otherwise 'valid utf-8' document.</p> <p>These chars e.g. 'valid utf-8' (don't give UnicodeDecodeErrors), but we still want to replace them to what they most likely were meant to be.</p> <p>:param content: a unicode string :returns: a cleaned up unicode string</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def replace_bad_unicode(self):\n\"\"\"Replace some chars in an otherwise 'valid utf-8' document.\n\n    These chars e.g. 'valid utf-8' (don't give UnicodeDecodeErrors), but\n    we still want to replace them to what they most likely were\n    meant to be.\n\n    :param content: a unicode string\n    :returns: a cleaned up unicode string\n    \"\"\"\n    # u'\u0161'.encode('windows-1252') gives '\\x9a', which sometimes\n    # appears in otherwise utf-8-encoded documents with the\n    # meaning '\u0161'\n    replacements = [\n        (\"\\x9a\", \"\u0161\"),\n        (\"\\x8a\", \"\u0160\"),\n        (\"\\x9e\", \"\u017e\"),\n        (\"\\x8e\", \"\u017d\"),\n    ]\n    for element in self.root.iter(\"p\"):\n        if element.text:\n            element.text = util.replace_all(replacements, element.text)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.replace_ligatures","title":"<code>replace_ligatures()</code>","text":"<p>Replace unwanted chars.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def replace_ligatures(self):\n\"\"\"Replace unwanted chars.\"\"\"\n    replacements = {\n        \"[dstrok]\": \"\u0111\",\n        \"[Dstrok]\": \"\u0110\",\n        \"[tstrok]\": \"\u0167\",\n        \"[Tstrok]\": \"\u0166\",\n        \"[scaron]\": \"\u0161\",\n        \"[Scaron]\": \"\u0160\",\n        \"[zcaron]\": \"\u017e\",\n        \"[Zcaron]\": \"\u017d\",\n        \"[ccaron]\": \"\u010d\",\n        \"[Ccaron]\": \"\u010c\",\n        \"[eng\": \"\u014b\",\n        \" ]\": \"\",\n        \"\u010e\": \"\u0111\",  # cough\n        \"\u010f\": \"\u0111\",  # cough\n        \"\\x03\": \"\",\n        \"\\x04\": \"\",\n        \"\\x07\": \"\",\n        \"\\x08\": \"\",\n        \"\\x0F\": \"\",\n        \"\\x10\": \"\",\n        \"\\x11\": \"\",\n        \"\\x13\": \"\",\n        \"\\x14\": \"\",\n        \"\\x15\": \"\",\n        \"\\x17\": \"\",\n        \"\\x18\": \"\",\n        \"\\x1A\": \"\",\n        \"\\x1B\": \"\",\n        \"\\x1C\": \"\",\n        \"\\x1D\": \"\",\n        \"\\x1E\": \"\",\n        \"\ufb01\": \"fi\",\n        \"\ufb02\": \"fl\",\n        \"\ufb00\": \"ff\",\n        \"\ufb03\": \"ffi\",\n        \"\ufb04\": \"ffl\",\n        \"\ufb05\": \"ft\",\n    }\n\n    for element in self.root.iter(\"p\"):\n        if element.text:\n            for key, value in replacements.items():\n                element.text = element.text.replace(key + \" \", value)\n                element.text = element.text.replace(key, value)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.replace_shy","title":"<code>replace_shy(element)</code>","text":"<p>Replace shy with a hyph element.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <p>an etree element</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def replace_shy(self, element):\n\"\"\"Replace shy with a hyph element.\n\n    Args:\n        element: an etree element\n    \"\"\"\n    for child in element:\n        self.replace_shy(child)\n\n    text = element.text\n    if text is not None:\n        parts = text.split(\"\u00ad\")\n        if len(parts) &gt; 1:\n            element.text = parts[0]\n            for index, part in enumerate(parts[1:]):\n                hyph = etree.Element(\"hyph\")\n                hyph.tail = part\n                element.insert(index, hyph)\n\n    text = element.tail\n    if text is not None:\n        parts = text.split(\"\u00ad\")\n        if len(parts) &gt; 1:\n            element.tail = parts[0]\n            for part in parts[1:]:\n                hyph = etree.Element(\"hyph\")\n                hyph.tail = part\n                element.getparent().append(hyph)\n</code></pre>"},{"location":"reference/documentfixer/#corpustools.documentfixer.DocumentFixer.soft_hyphen_to_hyph_tag","title":"<code>soft_hyphen_to_hyph_tag()</code>","text":"<p>Replace soft hyphen chars with hyphen tags.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/documentfixer.py</code> <pre><code>def soft_hyphen_to_hyph_tag(self):\n\"\"\"Replace soft hyphen chars with hyphen tags.\"\"\"\n    for element in self.root.iter(\"p\"):\n        self.replace_shy(element)\n</code></pre>"},{"location":"reference/dropbox_adder/","title":"dropbox_adder","text":"<p>Add files received from S\u00e1mediggi as zipfiles to freecorpus.</p>"},{"location":"reference/dropbox_adder/#corpustools.dropbox_adder.main","title":"<code>main()</code>","text":"<p>Add files from zip files</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/dropbox_adder.py</code> <pre><code>def main():\n\"\"\"Add files from zip files\"\"\"\n    dropbox_adders = {\n        lang: adder.AddToCorpus(\n            os.getenv(\"GTFREE\"), lang, os.path.join(\"admin\", \"sd\", \"dropbox\")\n        )\n        for lang in [\"nob\"] + LANGUAGES.keys()\n    }\n\n    sami_zip = sys.argv[1]\n    subdir = f'/tmp/{os.path.basename(sami_zip.replace(\".zip\", \"\"))}'\n    zipfile.ZipFile(sami_zip).extractall(subdir)\n\n    for (nob, smi, sami_lang) in pairs(\n        {os.path.join(root, f) for root, _, files in os.walk(subdir) for f in files}\n    ):\n        try:\n            nob_in_free = dropbox_adders[\"nob\"].copy_file_to_corpus(\n                origpath=nob, metadata_filename=os.path.basename(nob)\n            )\n            dropbox_adders[sami_lang].copy_file_to_corpus(\n                origpath=smi,\n                metadata_filename=os.path.basename(smi),\n                parallelpath=nob_in_free,\n            )\n        except UserWarning:\n            pass\n        os.remove(nob)\n        os.remove(smi)\n\n    for dropbox_adder in dropbox_adders.values():\n        dropbox_adder.add_files_to_working_copy()\n</code></pre>"},{"location":"reference/dupe_finder/","title":"dupe_finder","text":"<p>Classes to find and handle duplicate files in the repository.</p> <p>The classes work on converted files.</p>"},{"location":"reference/dupe_finder/#corpustools.dupe_finder.DupeFinder","title":"<code>DupeFinder</code>","text":"<p>Handle duplicates in the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/dupe_finder.py</code> <pre><code>class DupeFinder:\n\"\"\"Handle duplicates in the corpus.\"\"\"\n\n    def __init__(self, directory):\n        self.files = self._get_files(directory)\n        self.dupe_files = set()\n\n    @staticmethod\n    def _get_files(directory):\n\"\"\"Get the xml documents from the directory.\n\n        Args:\n            directory (str): the directory to collect xml files from.\n        \"\"\"\n        files = {}\n        xmlprinter = ccat.XMLPrinter(all_paragraphs=True)\n        for f in os.listdir(directory):\n            if f.endswith(\".xml\"):\n                filename = os.path.join(directory, f)\n                xmlprinter.parse_file(filename)\n                files[filename] = xmlprinter.process_file().getvalue()\n\n        return files\n\n    @staticmethod\n    def get_parallel_texts(filename1):\n\"\"\"Get the names of the parallel files.\n\n        filename (str): name of the file that should be searched.\n        \"\"\"\n        return etree.parse(filename1).xpath(\".//parallel_text\")\n\n    def remove_dupe_file(self, filename1, filename2):\n\"\"\"Remove duplicate files.\n\n        filename1 (str): name of the first file to be compared.\n        filename2 (str): name of the second file to be compared.\n        \"\"\"\n        result = list(\n            difflib.unified_diff(\n                self.files[filename1].splitlines(1), self.files[filename2].splitlines(1)\n            )\n        )\n        if not result:\n            print(\"Parallels:\", filename1, filename2)\n            to_remove = filename1\n            if self.get_parallel_texts(filename1) &gt; self.get_parallel_texts(filename2):\n                to_remove = filename2\n\n            self.dupe_files.add(to_remove)\n            origname = corpuspath.CorpusPath(to_remove)\n            if os.path.exists(origname.orig):\n                move_files.mover(origname.orig, \"\")\n            print()\n\n    @staticmethod\n    def get_wc(filename):\n\"\"\"Get the wordcount of a file.\n\n        Args:\n            filename (str): name of the file to retrieve the word count from.\n\n        Returns:\n            float\n        \"\"\"\n        tree = etree.parse(filename)\n        w = tree.find(\".//wordcount\").text\n\n        return float(w)\n\n    def good_word_ratio(self, filename1, filename2):\n\"\"\"Check if the word ratio of two files are nearly equal.\n\n        Args:\n            filename1 (str): name of the first file.\n            filename2 (str): name of the second file.\n\n        Returns:\n            bool: True if the ratio is larger than 0.9, False if it is less.\n        \"\"\"\n        w1 = self.get_wc(filename1)\n        w2 = self.get_wc(filename2)\n\n        ratio = min(w1, w2) / max(w1, w2)\n\n        return ratio &gt; 0.9\n\n    def compare_files(self, filename1, filename2):\n\"\"\"Compare two files.\n\n        Args:\n            filename1 (str): name of the first file.\n            filename2 (str): name of the second file.\n        \"\"\"\n        sm = difflib.SequenceMatcher(a=self.files[filename1], b=self.files[filename2])\n        ratio = sm.ratio()\n        if ratio &gt; 0.90:\n            self.dupe_files.add((filename1, filename2))\n            print()\n            print(round(ratio, 2), filename1, filename2)\n\n            result = difflib.unified_diff(\n                self.files[filename1].splitlines(1),\n                self.files[filename2].splitlines(1),\n                fromfile=os.path.basename(filename1),\n                tofile=os.path.basename(filename2),\n            )\n            sys.stdout.writelines(result)\n\n    def iterate_all_files(self, remove=False):\n\"\"\"Compare all files to each other.\n\n        Args:\n            remove (bool): Defaults to False. If True, remove files,\n                otherwise keep files.\n        \"\"\"\n        wrong_ratio = 0\n        good_ratio = 0\n        checked_files = collections.defaultdict(set)\n        for filename1 in self.files.keys():\n            for filename2 in self.files.keys():\n                if filename1 != filename2 and filename1 not in checked_files[filename2]:\n                    if self.good_word_ratio(filename1, filename2):\n                        good_ratio += 1\n                        if remove:\n                            self.remove_dupe_file(filename1, filename2)\n                        else:\n                            self.compare_files(filename1, filename2)\n\n                    checked_files[filename1].add(filename2)\n                    checked_files[filename2].add(filename1)\n                else:\n                    wrong_ratio += 1\n\n        util.print_frame(debug=good_ratio)\n        util.print_frame(debug=wrong_ratio)\n        print(\"Almost dupes\", len(self.dupe_files))\n</code></pre>"},{"location":"reference/dupe_finder/#corpustools.dupe_finder.DupeFinder.compare_files","title":"<code>compare_files(filename1, filename2)</code>","text":"<p>Compare two files.</p> <p>Parameters:</p> Name Type Description Default <code>filename1</code> <code>str</code> <p>name of the first file.</p> required <code>filename2</code> <code>str</code> <p>name of the second file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/dupe_finder.py</code> <pre><code>def compare_files(self, filename1, filename2):\n\"\"\"Compare two files.\n\n    Args:\n        filename1 (str): name of the first file.\n        filename2 (str): name of the second file.\n    \"\"\"\n    sm = difflib.SequenceMatcher(a=self.files[filename1], b=self.files[filename2])\n    ratio = sm.ratio()\n    if ratio &gt; 0.90:\n        self.dupe_files.add((filename1, filename2))\n        print()\n        print(round(ratio, 2), filename1, filename2)\n\n        result = difflib.unified_diff(\n            self.files[filename1].splitlines(1),\n            self.files[filename2].splitlines(1),\n            fromfile=os.path.basename(filename1),\n            tofile=os.path.basename(filename2),\n        )\n        sys.stdout.writelines(result)\n</code></pre>"},{"location":"reference/dupe_finder/#corpustools.dupe_finder.DupeFinder.get_parallel_texts","title":"<code>get_parallel_texts(filename1)</code>  <code>staticmethod</code>","text":"<p>Get the names of the parallel files.</p> <p>filename (str): name of the file that should be searched.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/dupe_finder.py</code> <pre><code>@staticmethod\ndef get_parallel_texts(filename1):\n\"\"\"Get the names of the parallel files.\n\n    filename (str): name of the file that should be searched.\n    \"\"\"\n    return etree.parse(filename1).xpath(\".//parallel_text\")\n</code></pre>"},{"location":"reference/dupe_finder/#corpustools.dupe_finder.DupeFinder.get_wc","title":"<code>get_wc(filename)</code>  <code>staticmethod</code>","text":"<p>Get the wordcount of a file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of the file to retrieve the word count from.</p> required <p>Returns:</p> Type Description <p>float</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/dupe_finder.py</code> <pre><code>@staticmethod\ndef get_wc(filename):\n\"\"\"Get the wordcount of a file.\n\n    Args:\n        filename (str): name of the file to retrieve the word count from.\n\n    Returns:\n        float\n    \"\"\"\n    tree = etree.parse(filename)\n    w = tree.find(\".//wordcount\").text\n\n    return float(w)\n</code></pre>"},{"location":"reference/dupe_finder/#corpustools.dupe_finder.DupeFinder.good_word_ratio","title":"<code>good_word_ratio(filename1, filename2)</code>","text":"<p>Check if the word ratio of two files are nearly equal.</p> <p>Parameters:</p> Name Type Description Default <code>filename1</code> <code>str</code> <p>name of the first file.</p> required <code>filename2</code> <code>str</code> <p>name of the second file.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the ratio is larger than 0.9, False if it is less.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/dupe_finder.py</code> <pre><code>def good_word_ratio(self, filename1, filename2):\n\"\"\"Check if the word ratio of two files are nearly equal.\n\n    Args:\n        filename1 (str): name of the first file.\n        filename2 (str): name of the second file.\n\n    Returns:\n        bool: True if the ratio is larger than 0.9, False if it is less.\n    \"\"\"\n    w1 = self.get_wc(filename1)\n    w2 = self.get_wc(filename2)\n\n    ratio = min(w1, w2) / max(w1, w2)\n\n    return ratio &gt; 0.9\n</code></pre>"},{"location":"reference/dupe_finder/#corpustools.dupe_finder.DupeFinder.iterate_all_files","title":"<code>iterate_all_files(remove=False)</code>","text":"<p>Compare all files to each other.</p> <p>Parameters:</p> Name Type Description Default <code>remove</code> <code>bool</code> <p>Defaults to False. If True, remove files, otherwise keep files.</p> <code>False</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/dupe_finder.py</code> <pre><code>def iterate_all_files(self, remove=False):\n\"\"\"Compare all files to each other.\n\n    Args:\n        remove (bool): Defaults to False. If True, remove files,\n            otherwise keep files.\n    \"\"\"\n    wrong_ratio = 0\n    good_ratio = 0\n    checked_files = collections.defaultdict(set)\n    for filename1 in self.files.keys():\n        for filename2 in self.files.keys():\n            if filename1 != filename2 and filename1 not in checked_files[filename2]:\n                if self.good_word_ratio(filename1, filename2):\n                    good_ratio += 1\n                    if remove:\n                        self.remove_dupe_file(filename1, filename2)\n                    else:\n                        self.compare_files(filename1, filename2)\n\n                checked_files[filename1].add(filename2)\n                checked_files[filename2].add(filename1)\n            else:\n                wrong_ratio += 1\n\n    util.print_frame(debug=good_ratio)\n    util.print_frame(debug=wrong_ratio)\n    print(\"Almost dupes\", len(self.dupe_files))\n</code></pre>"},{"location":"reference/dupe_finder/#corpustools.dupe_finder.DupeFinder.remove_dupe_file","title":"<code>remove_dupe_file(filename1, filename2)</code>","text":"<p>Remove duplicate files.</p> <p>filename1 (str): name of the first file to be compared. filename2 (str): name of the second file to be compared.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/dupe_finder.py</code> <pre><code>def remove_dupe_file(self, filename1, filename2):\n\"\"\"Remove duplicate files.\n\n    filename1 (str): name of the first file to be compared.\n    filename2 (str): name of the second file to be compared.\n    \"\"\"\n    result = list(\n        difflib.unified_diff(\n            self.files[filename1].splitlines(1), self.files[filename2].splitlines(1)\n        )\n    )\n    if not result:\n        print(\"Parallels:\", filename1, filename2)\n        to_remove = filename1\n        if self.get_parallel_texts(filename1) &gt; self.get_parallel_texts(filename2):\n            to_remove = filename2\n\n        self.dupe_files.add(to_remove)\n        origname = corpuspath.CorpusPath(to_remove)\n        if os.path.exists(origname.orig):\n            move_files.mover(origname.orig, \"\")\n        print()\n</code></pre>"},{"location":"reference/epubchooser/","title":"epubchooser","text":"<p>Set which parts of an epub should be omitted.</p> <p>It is possible to filter away chapters and ranges of elements from an epub file. This is a helper program for that purpose.</p>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubChooser","title":"<code>EpubChooser</code>","text":"<p>Class to determine which parts of an epub should be omitted.</p> <p>Attributes:</p> Name Type Description <code>presenter</code> <code>EpubPresenter</code> <p>the presenter of the metadata and content of the epub file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>class EpubChooser:\n\"\"\"Class to determine which parts of an epub should be omitted.\n\n    Attributes:\n        presenter (EpubPresenter): the presenter of the metadata and content\n            of the epub file.\n    \"\"\"\n\n    def __init__(self, path):\n\"\"\"Initialise the EpubChooser class.\n\n        Args:\n            path (str): path to the document\n        \"\"\"\n        self.presenter = EpubPresenter(path)\n\n    def exclude_chapters(self):\n\"\"\"Choose which chapters should be omitted from the epub file.\"\"\"\n        while 1:\n            self.presenter.print_choice()\n            text = prompt(\n                \"\\nWould you like to \\n\"\n                \"* [c]lear and edit empty range\\n\"\n                \"* s[a]ve this and go to next step\\n\"\n                \"* [s]ave and quit\\n* [q]uit without saving\\n\"\n                \"[c/a/s/q]: \"\n            )\n            if text == \"c\":\n                edits = prompt(\"Make new range: \")\n                new_excluded = [int(index) for index in edits.split()]\n                self.presenter.excluded_chapters = new_excluded\n            elif text == \"a\":\n                break\n            elif text == \"s\":\n                self.presenter.save()\n                raise SystemExit(\"Saved your choices\")\n            elif text == \"q\":\n                raise SystemExit(\"Did not save anything\")\n            else:\n                print(\"Invalid choice, trying again.\")\n\n    def do_xpaths_exist(self):\n\"\"\"Check if xpaths exist in this document.\"\"\"\n        if self.presenter.skip_elements:\n            print(\"Original:\", self.presenter.skip_elements)\n\n        pairs = [pair.strip() for pair in self.presenter.skip_elements.split(\",\")]\n        for pair in pairs:\n            try:\n                self.presenter.rangehandler.add_range(tuple(pair.split(\";\")))\n            except (KeyError, IndexError):\n                self.presenter.rangehandler.clear_ranges()\n                print(\"Original skip_elements is invalid, clearing it.\")\n\n    def exclude_tags(self):\n\"\"\"Choose which html tags should be removed from epub file.\"\"\"\n        self.presenter.present_html()\n        self.do_xpaths_exist()\n        while 1:\n            text = prompt(\n                \"Choose html ranges that should be removed\\n\"\n                'Existing ranges are: \"{}\"\\n'\n                \"* [c]lear and make new range\\n\"\n                \"* [a]add range\\n\"\n                \"* [s]ave and quit\\n\"\n                \"* [q]uit without saving\\n\"\n                \"[c/a/s/q]: \".format(self.presenter.rangehandler.ranges)\n            )\n            if text == \"c\":\n                self.presenter.rangehandler.clear_ranges()\n                start = prompt(\n                    \"Cut and paste xpath expressions found in \"\n                    \"the text above\\nFirst xpath: \"\n                )\n                end = prompt(\"Second xpath: \")\n\n                try:\n                    self.presenter.rangehandler.add_range((start, end))\n                except (IndexError, KeyError):\n                    print(\"Invalid range\")\n                    break\n            elif text == \"a\":\n                start = prompt(\n                    \"Cut and paste xpath expressions found in \"\n                    \"the text above\\nFirst xpath: \"\n                )\n                end = prompt(\"Second xpath: \")\n\n                try:\n                    self.presenter.rangehandler.add_range((start, end))\n                except (IndexError, KeyError):\n                    print(\"Invalid range\")\n                    break\n            elif text == \"s\":\n                self.presenter.save()\n                raise SystemExit(\"Saved your choices\")\n            elif text == \"q\":\n                raise SystemExit(\"Did not save anything\")\n            else:\n                print(\"Invalid choice, trying again.\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubChooser.__init__","title":"<code>__init__(path)</code>","text":"<p>Initialise the EpubChooser class.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path to the document</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def __init__(self, path):\n\"\"\"Initialise the EpubChooser class.\n\n    Args:\n        path (str): path to the document\n    \"\"\"\n    self.presenter = EpubPresenter(path)\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubChooser.do_xpaths_exist","title":"<code>do_xpaths_exist()</code>","text":"<p>Check if xpaths exist in this document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def do_xpaths_exist(self):\n\"\"\"Check if xpaths exist in this document.\"\"\"\n    if self.presenter.skip_elements:\n        print(\"Original:\", self.presenter.skip_elements)\n\n    pairs = [pair.strip() for pair in self.presenter.skip_elements.split(\",\")]\n    for pair in pairs:\n        try:\n            self.presenter.rangehandler.add_range(tuple(pair.split(\";\")))\n        except (KeyError, IndexError):\n            self.presenter.rangehandler.clear_ranges()\n            print(\"Original skip_elements is invalid, clearing it.\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubChooser.exclude_chapters","title":"<code>exclude_chapters()</code>","text":"<p>Choose which chapters should be omitted from the epub file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def exclude_chapters(self):\n\"\"\"Choose which chapters should be omitted from the epub file.\"\"\"\n    while 1:\n        self.presenter.print_choice()\n        text = prompt(\n            \"\\nWould you like to \\n\"\n            \"* [c]lear and edit empty range\\n\"\n            \"* s[a]ve this and go to next step\\n\"\n            \"* [s]ave and quit\\n* [q]uit without saving\\n\"\n            \"[c/a/s/q]: \"\n        )\n        if text == \"c\":\n            edits = prompt(\"Make new range: \")\n            new_excluded = [int(index) for index in edits.split()]\n            self.presenter.excluded_chapters = new_excluded\n        elif text == \"a\":\n            break\n        elif text == \"s\":\n            self.presenter.save()\n            raise SystemExit(\"Saved your choices\")\n        elif text == \"q\":\n            raise SystemExit(\"Did not save anything\")\n        else:\n            print(\"Invalid choice, trying again.\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubChooser.exclude_tags","title":"<code>exclude_tags()</code>","text":"<p>Choose which html tags should be removed from epub file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def exclude_tags(self):\n\"\"\"Choose which html tags should be removed from epub file.\"\"\"\n    self.presenter.present_html()\n    self.do_xpaths_exist()\n    while 1:\n        text = prompt(\n            \"Choose html ranges that should be removed\\n\"\n            'Existing ranges are: \"{}\"\\n'\n            \"* [c]lear and make new range\\n\"\n            \"* [a]add range\\n\"\n            \"* [s]ave and quit\\n\"\n            \"* [q]uit without saving\\n\"\n            \"[c/a/s/q]: \".format(self.presenter.rangehandler.ranges)\n        )\n        if text == \"c\":\n            self.presenter.rangehandler.clear_ranges()\n            start = prompt(\n                \"Cut and paste xpath expressions found in \"\n                \"the text above\\nFirst xpath: \"\n            )\n            end = prompt(\"Second xpath: \")\n\n            try:\n                self.presenter.rangehandler.add_range((start, end))\n            except (IndexError, KeyError):\n                print(\"Invalid range\")\n                break\n        elif text == \"a\":\n            start = prompt(\n                \"Cut and paste xpath expressions found in \"\n                \"the text above\\nFirst xpath: \"\n            )\n            end = prompt(\"Second xpath: \")\n\n            try:\n                self.presenter.rangehandler.add_range((start, end))\n            except (IndexError, KeyError):\n                print(\"Invalid range\")\n                break\n        elif text == \"s\":\n            self.presenter.save()\n            raise SystemExit(\"Saved your choices\")\n        elif text == \"q\":\n            raise SystemExit(\"Did not save anything\")\n        else:\n            print(\"Invalid choice, trying again.\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter","title":"<code>EpubPresenter</code>","text":"<p>Class to present metadata and content.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>str</code> <p>path to the epub document</p> <code>book</code> <code>epub.Book</code> <p>the epub document to handle.</p> <code>metadata</code> <code>xslsetter.MetadataHandler</code> <p>the corpus metadata attached to the book.</p> <code>xpaths</code> <code>list of str</code> <p>the xpaths of the remaining html document after unwanted chapters have been removed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>class EpubPresenter:\n\"\"\"Class to present metadata and content.\n\n    Attributes:\n        path (str): path to the epub document\n        book (epub.Book): the epub document to handle.\n        metadata (xslsetter.MetadataHandler): the corpus metadata\n            attached to the book.\n        xpaths (list of str): the xpaths of the remaining html document\n            after unwanted chapters have been removed.\n    \"\"\"\n\n    def __init__(self, path):\n\"\"\"Initialise the EpubPresenter class.\n\n        Args:\n            path (str): path to the epub document\n        \"\"\"\n        self.path = path\n        self.book = epub.Book(epub.open_epub(sys.argv[1]))\n        self.metadata = xslsetter.MetadataHandler(sys.argv[1] + \".xsl\")\n        self.rangehandler = RangeHandler()\n\n    @property\n    def book_titles(self):\n\"\"\"Get the all linear chapters of the epub book.\n\n        Args:\n            book (epub.Book): The epub book element\n\n        Yields:\n            etree._Element: The body of an xhtml file found in the epub file.\n        \"\"\"\n        return [\n            epubconverter.read_chapter(chapter)\n            .find(\".//{http://www.w3.org/1999/xhtml}title\")\n            .text\n            for chapter in self.book.chapters\n        ]\n\n    @property\n    def excluded_chapters(self):\n\"\"\"Show the excluded chapters.\"\"\"\n        return self.metadata.epub_excluded_chapters\n\n    @excluded_chapters.setter\n    def excluded_chapters(self, new_excluded):\n\"\"\"Set the exluded chapters in the metadata file.\n\n        Args:\n            new_excluded (list of int): the chapters to exclude.\n        \"\"\"\n        self.metadata.set_variable(\n            \"epub_excluded_chapters\", \", \".join([str(index) for index in new_excluded])\n        )\n\n    def print_choice(self):\n\"\"\"Present omitted and present chapters.\"\"\"\n        print(\"\\nIncluded chapters:\")\n        for index in self.not_chosen:\n            print(f\"[{index}]:\\t{self.book_titles[index]}\")\n\n        print(\"\\nExcluded chapters:\")\n        for index in self.excluded_chapters:\n            print(f\"[{index}]:\\t{self.book_titles[index]}\")\n\n    @property\n    def not_chosen(self):\n\"\"\"The chapter that are not excluded.\"\"\"\n        return list(\n            {x for x in range(len(self.book_titles))} - set(self.excluded_chapters)\n        )\n\n    def save(self):\n\"\"\"Save metadata.\"\"\"\n        self.metadata.set_variable(\"skip_elements\", self.rangehandler.ranges)\n        self.metadata.write_file()\n\n    @property\n    def skip_elements(self):\n\"\"\"Return a string representing the html elements that is omitted.\"\"\"\n        return self.rangehandler.ranges\n\n    @skip_elements.setter\n    def skip_elements(self, elements):\n\"\"\"Set the md set_variable skip_elements.\n\n        Args:\n            elements (str): the elements that should be skip\n        \"\"\"\n        self.metadata.set_variable(\"skip_elements\", elements)\n\n    def present_html(self):\n\"\"\"Print the html that is left after omitting chapters.\"\"\"\n        self.print_xpath(\n            epubconverter.extract_content(self.path, self.metadata), 0, 4, sys.stdout\n        )\n\n    def print_xpath(self, element, level, indent, out, xpath=\"\", element_no=1):\n\"\"\"Format an html document and write xpaths at tags openings.\n\n        This function formats html documents for readability and prints\n        xpaths to at tag openings, to see the structure of the given document\n        and make it possible to choose xpaths. It ruins white space in\n        text parts.\n\n        Args:\n            element (etree._Element): the element to format.\n            level (int): indicate at what level this element is.\n            indent (int): indicate how many spaces this element should be\n                indented\n            out (stream): a buffer where the formatted element is written.\n            xpath (string): The xpath of the parent of this element.\n            tag_no (int): the position of the element tag\n        \"\"\"\n        counter = {}\n        tag = element.tag.replace(\"{http://www.w3.org/1999/xhtml}\", \"\")\n\n        out.write(\" \" * (level * indent))\n        out.write(f\"&lt;{tag}\")\n\n        for att_tag, att_value in element.attrib.items():\n            out.write(\" \")\n            out.write(att_tag)\n            out.write('=\"')\n            out.write(att_value)\n            out.write('\"')\n\n        out.write(\"&gt;\")\n        if xpath and \"/body\" in xpath:\n            new_xpath = \"{}/{}\".format(xpath.replace(\"/html/\", \".//\"), tag)\n            if element_no &gt; 1:\n                new_xpath = f\"{new_xpath}[{element_no}]\"\n            out.write(\"\\t\")\n            out.write(new_xpath)\n            self.rangehandler.xpaths.append(new_xpath)\n\n        out.write(\"\\n\")\n\n        if element.text is not None and element.text.strip():\n            out.write(\" \" * ((level + 1) * indent))\n            out.write(element.text.strip())\n            out.write(\"\\n\")\n\n        for child in element:\n            if not counter.get(child.tag):\n                counter[child.tag] = 0\n            counter[child.tag] += 1\n            if element_no &gt; 1:\n                new_xpath = xpath + \"/\" + tag + \"[\" + str(element_no) + \"]\"\n            else:\n                new_xpath = xpath + \"/\" + tag\n            self.print_xpath(\n                child,\n                level + 1,\n                indent,\n                out,\n                xpath=new_xpath,\n                element_no=counter[child.tag],\n            )\n\n        out.write(\" \" * (level * indent))\n        out.write(f\"&lt;/{tag}&gt;\\n\")\n\n        if level &gt; 0 and element.tail is not None and element.tail.strip():\n            for _ in range(0, (level - 1) * indent):\n                out.write(\" \")\n            out.write(element.tail.strip())\n            out.write(\"\\n\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.book_titles","title":"<code>book_titles</code>  <code>property</code>","text":"<p>Get the all linear chapters of the epub book.</p> <p>Parameters:</p> Name Type Description Default <code>book</code> <code>epub.Book</code> <p>The epub book element</p> required <p>Yields:</p> Type Description <p>etree._Element: The body of an xhtml file found in the epub file.</p>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.excluded_chapters","title":"<code>excluded_chapters</code>  <code>property</code> <code>writable</code>","text":"<p>Show the excluded chapters.</p>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.not_chosen","title":"<code>not_chosen</code>  <code>property</code>","text":"<p>The chapter that are not excluded.</p>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.skip_elements","title":"<code>skip_elements</code>  <code>property</code> <code>writable</code>","text":"<p>Return a string representing the html elements that is omitted.</p>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.__init__","title":"<code>__init__(path)</code>","text":"<p>Initialise the EpubPresenter class.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path to the epub document</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def __init__(self, path):\n\"\"\"Initialise the EpubPresenter class.\n\n    Args:\n        path (str): path to the epub document\n    \"\"\"\n    self.path = path\n    self.book = epub.Book(epub.open_epub(sys.argv[1]))\n    self.metadata = xslsetter.MetadataHandler(sys.argv[1] + \".xsl\")\n    self.rangehandler = RangeHandler()\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.present_html","title":"<code>present_html()</code>","text":"<p>Print the html that is left after omitting chapters.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def present_html(self):\n\"\"\"Print the html that is left after omitting chapters.\"\"\"\n    self.print_xpath(\n        epubconverter.extract_content(self.path, self.metadata), 0, 4, sys.stdout\n    )\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.print_choice","title":"<code>print_choice()</code>","text":"<p>Present omitted and present chapters.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def print_choice(self):\n\"\"\"Present omitted and present chapters.\"\"\"\n    print(\"\\nIncluded chapters:\")\n    for index in self.not_chosen:\n        print(f\"[{index}]:\\t{self.book_titles[index]}\")\n\n    print(\"\\nExcluded chapters:\")\n    for index in self.excluded_chapters:\n        print(f\"[{index}]:\\t{self.book_titles[index]}\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.print_xpath","title":"<code>print_xpath(element, level, indent, out, xpath='', element_no=1)</code>","text":"<p>Format an html document and write xpaths at tags openings.</p> <p>This function formats html documents for readability and prints xpaths to at tag openings, to see the structure of the given document and make it possible to choose xpaths. It ruins white space in text parts.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>etree._Element</code> <p>the element to format.</p> required <code>level</code> <code>int</code> <p>indicate at what level this element is.</p> required <code>indent</code> <code>int</code> <p>indicate how many spaces this element should be indented</p> required <code>out</code> <code>stream</code> <p>a buffer where the formatted element is written.</p> required <code>xpath</code> <code>string</code> <p>The xpath of the parent of this element.</p> <code>''</code> <code>tag_no</code> <code>int</code> <p>the position of the element tag</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def print_xpath(self, element, level, indent, out, xpath=\"\", element_no=1):\n\"\"\"Format an html document and write xpaths at tags openings.\n\n    This function formats html documents for readability and prints\n    xpaths to at tag openings, to see the structure of the given document\n    and make it possible to choose xpaths. It ruins white space in\n    text parts.\n\n    Args:\n        element (etree._Element): the element to format.\n        level (int): indicate at what level this element is.\n        indent (int): indicate how many spaces this element should be\n            indented\n        out (stream): a buffer where the formatted element is written.\n        xpath (string): The xpath of the parent of this element.\n        tag_no (int): the position of the element tag\n    \"\"\"\n    counter = {}\n    tag = element.tag.replace(\"{http://www.w3.org/1999/xhtml}\", \"\")\n\n    out.write(\" \" * (level * indent))\n    out.write(f\"&lt;{tag}\")\n\n    for att_tag, att_value in element.attrib.items():\n        out.write(\" \")\n        out.write(att_tag)\n        out.write('=\"')\n        out.write(att_value)\n        out.write('\"')\n\n    out.write(\"&gt;\")\n    if xpath and \"/body\" in xpath:\n        new_xpath = \"{}/{}\".format(xpath.replace(\"/html/\", \".//\"), tag)\n        if element_no &gt; 1:\n            new_xpath = f\"{new_xpath}[{element_no}]\"\n        out.write(\"\\t\")\n        out.write(new_xpath)\n        self.rangehandler.xpaths.append(new_xpath)\n\n    out.write(\"\\n\")\n\n    if element.text is not None and element.text.strip():\n        out.write(\" \" * ((level + 1) * indent))\n        out.write(element.text.strip())\n        out.write(\"\\n\")\n\n    for child in element:\n        if not counter.get(child.tag):\n            counter[child.tag] = 0\n        counter[child.tag] += 1\n        if element_no &gt; 1:\n            new_xpath = xpath + \"/\" + tag + \"[\" + str(element_no) + \"]\"\n        else:\n            new_xpath = xpath + \"/\" + tag\n        self.print_xpath(\n            child,\n            level + 1,\n            indent,\n            out,\n            xpath=new_xpath,\n            element_no=counter[child.tag],\n        )\n\n    out.write(\" \" * (level * indent))\n    out.write(f\"&lt;/{tag}&gt;\\n\")\n\n    if level &gt; 0 and element.tail is not None and element.tail.strip():\n        for _ in range(0, (level - 1) * indent):\n            out.write(\" \")\n        out.write(element.tail.strip())\n        out.write(\"\\n\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.EpubPresenter.save","title":"<code>save()</code>","text":"<p>Save metadata.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def save(self):\n\"\"\"Save metadata.\"\"\"\n    self.metadata.set_variable(\"skip_elements\", self.rangehandler.ranges)\n    self.metadata.write_file()\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.RangeHandler","title":"<code>RangeHandler</code>","text":"<p>Handle skip_elements ranges.</p> <p>Attributes:</p> Name Type Description <code>xpaths</code> <code>list of str</code> <p>the xpaths of the remaining html document after unwanted chapters have been removed.</p> <code>ranges</code> <code>set of tuple of int</code> <p>Each tuple has a pair of ints pointing to places in the xpaths list.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>class RangeHandler:\n\"\"\"Handle skip_elements ranges.\n\n    Attributes:\n        xpaths (list of str): the xpaths of the remaining html document\n            after unwanted chapters have been removed.\n        ranges (set of tuple of int):  Each tuple has a pair of ints\n            pointing to places in the xpaths list.\n    \"\"\"\n\n    xpaths = []\n    _ranges = set()\n\n    def clear_ranges(self):\n\"\"\"Clear the _ranges set.\"\"\"\n        self._ranges.clear()\n\n    def as_text(self, pair):\n\"\"\"Return a range as text.\n\n        Args:\n            pair (tuple): pairs of indexes to elements in self.xpaths.\n                The second part of the tuple may be empty.\n\n        Returns:\n            str\n        \"\"\"\n        if pair[1]:\n            return f\"{self.xpaths[pair[0]]};{self.xpaths[pair[1]]}\"\n        else:\n            return f\"{self.xpaths[pair[0]]};\"\n\n    @property\n    def ranges(self):\n\"\"\"Return the textual version of the range.\"\"\"\n        return \",\".join(\n            [self.as_text(pair) for pair in sorted(self._ranges, reverse=True)]\n        )\n\n    def check_range(self, xpath_pair):\n\"\"\"Check that the xpath_pair is a valid range.\n\n        Args:\n            xpath_pair (tuple of str): a pair of xpaths\n\n        Raises:\n            KeyError if invalid content is found.\n        \"\"\"\n        if not xpath_pair[0]:\n            raise KeyError(\"First xpath is empty.\")\n        if xpath_pair[0] not in self.xpaths:\n            raise KeyError(f\"{xpath_pair[0]} does not exist in this context\")\n        if xpath_pair[1] and xpath_pair[1] not in self.xpaths:\n            raise KeyError(f\"{xpath_pair[1]} does not exist in this context\")\n\n    def check_overlap(self, xpath_pair):\n\"\"\"Check if xpath_pair overlaps any of the existing ranges.\n\n        Args:\n            xpath_pair (tuple of str): a pair of xpaths\n        \"\"\"\n        for xpath in xpath_pair:\n            if xpath:\n                for pair in self._ranges:\n                    if pair[1] and pair[0] &lt; self.xpaths.index(xpath) &lt; pair[1] + 1:\n                        raise IndexError(\n                            \"{} &lt; {} &lt; {}\".format(\n                                self.xpaths[pair[0]], xpath, self.xpaths[pair[1]]\n                            )\n                        )\n                    if pair[0] == self.xpaths.index(xpath):\n                        raise IndexError(f\"{self.xpaths[pair[0]]} == {xpath}\")\n                    if pair[1] == self.xpaths.index(xpath):\n                        raise IndexError(f\"{self.xpaths[pair[1]]} == {xpath}\")\n\n    def add_range(self, xpath_pair):\n\"\"\"Add a new range.\n\n        Args:\n            xpath_pair (tuple of str): a pair of xpaths.\n        \"\"\"\n        self.check_range(xpath_pair)\n        self.check_overlap(xpath_pair)\n\n        if not xpath_pair[1]:\n            self._ranges.add((self.xpaths.index(xpath_pair[0]), \"\"))\n        else:\n            self._ranges.add(\n                tuple(\n                    sorted(\n                        (\n                            self.xpaths.index(xpath_pair[0]),\n                            self.xpaths.index(xpath_pair[1]),\n                        )\n                    )\n                )\n            )\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.RangeHandler.ranges","title":"<code>ranges</code>  <code>property</code>","text":"<p>Return the textual version of the range.</p>"},{"location":"reference/epubchooser/#corpustools.epubchooser.RangeHandler.add_range","title":"<code>add_range(xpath_pair)</code>","text":"<p>Add a new range.</p> <p>Parameters:</p> Name Type Description Default <code>xpath_pair</code> <code>tuple of str</code> <p>a pair of xpaths.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def add_range(self, xpath_pair):\n\"\"\"Add a new range.\n\n    Args:\n        xpath_pair (tuple of str): a pair of xpaths.\n    \"\"\"\n    self.check_range(xpath_pair)\n    self.check_overlap(xpath_pair)\n\n    if not xpath_pair[1]:\n        self._ranges.add((self.xpaths.index(xpath_pair[0]), \"\"))\n    else:\n        self._ranges.add(\n            tuple(\n                sorted(\n                    (\n                        self.xpaths.index(xpath_pair[0]),\n                        self.xpaths.index(xpath_pair[1]),\n                    )\n                )\n            )\n        )\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.RangeHandler.as_text","title":"<code>as_text(pair)</code>","text":"<p>Return a range as text.</p> <p>Parameters:</p> Name Type Description Default <code>pair</code> <code>tuple</code> <p>pairs of indexes to elements in self.xpaths. The second part of the tuple may be empty.</p> required <p>Returns:</p> Type Description <p>str</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def as_text(self, pair):\n\"\"\"Return a range as text.\n\n    Args:\n        pair (tuple): pairs of indexes to elements in self.xpaths.\n            The second part of the tuple may be empty.\n\n    Returns:\n        str\n    \"\"\"\n    if pair[1]:\n        return f\"{self.xpaths[pair[0]]};{self.xpaths[pair[1]]}\"\n    else:\n        return f\"{self.xpaths[pair[0]]};\"\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.RangeHandler.check_overlap","title":"<code>check_overlap(xpath_pair)</code>","text":"<p>Check if xpath_pair overlaps any of the existing ranges.</p> <p>Parameters:</p> Name Type Description Default <code>xpath_pair</code> <code>tuple of str</code> <p>a pair of xpaths</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def check_overlap(self, xpath_pair):\n\"\"\"Check if xpath_pair overlaps any of the existing ranges.\n\n    Args:\n        xpath_pair (tuple of str): a pair of xpaths\n    \"\"\"\n    for xpath in xpath_pair:\n        if xpath:\n            for pair in self._ranges:\n                if pair[1] and pair[0] &lt; self.xpaths.index(xpath) &lt; pair[1] + 1:\n                    raise IndexError(\n                        \"{} &lt; {} &lt; {}\".format(\n                            self.xpaths[pair[0]], xpath, self.xpaths[pair[1]]\n                        )\n                    )\n                if pair[0] == self.xpaths.index(xpath):\n                    raise IndexError(f\"{self.xpaths[pair[0]]} == {xpath}\")\n                if pair[1] == self.xpaths.index(xpath):\n                    raise IndexError(f\"{self.xpaths[pair[1]]} == {xpath}\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.RangeHandler.check_range","title":"<code>check_range(xpath_pair)</code>","text":"<p>Check that the xpath_pair is a valid range.</p> <p>Parameters:</p> Name Type Description Default <code>xpath_pair</code> <code>tuple of str</code> <p>a pair of xpaths</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def check_range(self, xpath_pair):\n\"\"\"Check that the xpath_pair is a valid range.\n\n    Args:\n        xpath_pair (tuple of str): a pair of xpaths\n\n    Raises:\n        KeyError if invalid content is found.\n    \"\"\"\n    if not xpath_pair[0]:\n        raise KeyError(\"First xpath is empty.\")\n    if xpath_pair[0] not in self.xpaths:\n        raise KeyError(f\"{xpath_pair[0]} does not exist in this context\")\n    if xpath_pair[1] and xpath_pair[1] not in self.xpaths:\n        raise KeyError(f\"{xpath_pair[1]} does not exist in this context\")\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.RangeHandler.clear_ranges","title":"<code>clear_ranges()</code>","text":"<p>Clear the _ranges set.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def clear_ranges(self):\n\"\"\"Clear the _ranges set.\"\"\"\n    self._ranges.clear()\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.main","title":"<code>main()</code>","text":"<p>Set which parts of an epub should be omitted.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def main():\n\"\"\"Set which parts of an epub should be omitted.\"\"\"\n    args = parse_options()\n\n    chooser = EpubChooser(args.epubfile)\n    chooser.exclude_chapters()\n    chooser.exclude_tags()\n</code></pre>"},{"location":"reference/epubchooser/#corpustools.epubchooser.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubchooser.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Choose which chapters and html ranges \"\n        \"should be omitted from an epub file.\",\n    )\n\n    parser.add_argument(\"epubfile\", help=\"Path to an epub file\")\n\n    args = parser.parse_args()\n\n    return args\n</code></pre>"},{"location":"reference/epubconverter/","title":"epubconverter","text":"<p>Convert epub documents to the Giella xml format.</p> <p>Epub files are zip files that contain text in xhtml files. This class reads all xhtml files found in this archive. The body element of these files are converted to div elements, and appended inside a new body element.</p> <p>It is possible to filter away ranges of elements from this new xhtml file. These ranges consist pairs of xpath paths, specified inside the metadata file that belongs to this epub file.</p>"},{"location":"reference/epubconverter/#corpustools.epubconverter.chapters","title":"<code>chapters(book, metadata)</code>","text":"<p>Get the all linear chapters of the epub book.</p> <p>Parameters:</p> Name Type Description Default <code>book</code> <code>epub.Book</code> <p>The epub book element</p> required <p>Yields:</p> Type Description <p>etree._Element: The body of an xhtml file found in the epub file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def chapters(book, metadata):\n\"\"\"Get the all linear chapters of the epub book.\n\n    Args:\n        book (epub.Book): The epub book element\n\n    Yields:\n        etree._Element: The body of an xhtml file found in the epub file.\n    \"\"\"\n    excluded = metadata.epub_excluded_chapters\n    for index, chapter in enumerate(book.chapters):\n        if index not in excluded:\n            chapterbody = read_chapter(chapter).find(\n                \"{http://www.w3.org/1999/xhtml}body\"\n            )\n            chapterbody.tag = \"{http://www.w3.org/1999/xhtml}div\"\n            yield chapterbody\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.extract_content","title":"<code>extract_content(filename, metadata)</code>","text":"<p>Extract content from the epub file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the document</p> required <p>Returns:</p> Type Description <p>etree.Element: the content of the epub file wrapped in html element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def extract_content(filename, metadata):\n\"\"\"Extract content from the epub file.\n\n    Args:\n        filename (str): path to the document\n\n    Returns:\n        etree.Element: the content of the epub file wrapped in html\n            element\n    \"\"\"\n    mainbody = etree.Element(\"{http://www.w3.org/1999/xhtml}body\")\n    html = etree.Element(\"{http://www.w3.org/1999/xhtml}html\")\n    html.append(etree.Element(\"{http://www.w3.org/1999/xhtml}head\"))\n    html.append(mainbody)\n\n    book = epub.Book(epub.open_epub(filename))\n\n    for chapterbody in chapters(book, metadata):\n        mainbody.append(chapterbody)\n\n    return html\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.read_chapter","title":"<code>read_chapter(chapter)</code>","text":"<p>Read the contents of a epub_file chapter.</p> <p>Parameters:</p> Name Type Description Default <code>chapter</code> <code>epub.BookChapter</code> <p>the chapter of an epub file</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The contents of a chapter</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def read_chapter(chapter):\n\"\"\"Read the contents of a epub_file chapter.\n\n    Args:\n        chapter (epub.BookChapter): the chapter of an epub file\n\n    Returns:\n        str: The contents of a chapter\n\n    Raises:\n        ConversionException\n    \"\"\"\n    try:\n        return etree.fromstring(chapter.read())\n    except KeyError as error:\n        raise util.ConversionError(error)\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.remove_first_element","title":"<code>remove_first_element(path1, content)</code>","text":"<p>Remove the first element in the range.</p> <p>Parameters:</p> Name Type Description Default <code>path1</code> <code>str</code> <p>path to the first element to remove.</p> required <code>content</code> <code>etree._Element</code> <p>the xhtml document that should be altered.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def remove_first_element(path1, content):\n\"\"\"Remove the first element in the range.\n\n    Args:\n        path1 (str): path to the first element to remove.\n        content (etree._Element): the xhtml document that should\n            be altered.\n    \"\"\"\n    first_start = content.find(\n        path1, namespaces={\"html\": \"http://www.w3.org/1999/xhtml\"}\n    )\n    first_start.getparent().remove(first_start)\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.remove_range","title":"<code>remove_range(path1, path2, content)</code>","text":"<p>Remove a range of elements from an xhtml document.</p> <p>Parameters:</p> Name Type Description Default <code>path1</code> <code>str</code> <p>path to first element</p> required <code>path2</code> <code>str</code> <p>path to second element</p> required <code>content</code> <code>etree._Element</code> <p>xhtml document</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def remove_range(path1, path2, content):\n\"\"\"Remove a range of elements from an xhtml document.\n\n    Args:\n        path1 (str): path to first element\n        path2 (str): path to second element\n        content (etree._Element): xhtml document\n    \"\"\"\n    if path2:\n        starts, ends = remove_trees_1(path1, path2, content)\n        remove_trees_2(starts, ends, content)\n        remove_first_element(path1, content)\n    else:\n        found = content.find(path1, namespaces={\"html\": \"http://www.w3.org/1999/xhtml\"})\n        found.getparent().remove(found)\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.remove_ranges","title":"<code>remove_ranges(metadata, html)</code>","text":"<p>Remove ranges of html elements.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the document</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def remove_ranges(metadata, html):\n\"\"\"Remove ranges of html elements.\n\n    Args:\n        filename (str): path to the document\n    \"\"\"\n    if metadata.skip_elements:\n        for pairs in metadata.skip_elements:\n            remove_range(pairs[0], pairs[1], html)\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.remove_siblings_shorten_path","title":"<code>remove_siblings_shorten_path(parts, content, preceding=False)</code>","text":"<p>Remove all siblings before or after an element.</p> <p>Parameters:</p> Name Type Description Default <code>parts</code> <code>list of str</code> <p>a xpath path split on /</p> required <code>content</code> <code>etree._Element</code> <p>an xhtml document</p> required <code>preceding</code> <code>bool</code> <p>When True, iterate through the preceding siblings of the found element, otherwise iterate throughe the following siblings.</p> <code>False</code> <p>Returns:</p> Type Description <p>list of str: the path to the parent of parts.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def remove_siblings_shorten_path(parts, content, preceding=False):\n\"\"\"Remove all siblings before or after an element.\n\n    Args:\n        parts (list of str): a xpath path split on /\n        content (etree._Element): an xhtml document\n        preceding (bool): When True, iterate through the preceding siblings\n            of the found element, otherwise iterate throughe the following\n            siblings.\n\n    Returns:\n        list of str: the path to the parent of parts.\n    \"\"\"\n    path = \"/\".join(parts)\n    found = content.find(path, namespaces={\"html\": \"http://www.w3.org/1999/xhtml\"})\n    parent = found.getparent()\n    for sibling in found.itersiblings(preceding=preceding):\n        parent.remove(sibling)\n\n    return parts[:-1]\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.remove_trees_1","title":"<code>remove_trees_1(path1, path2, content)</code>","text":"<p>Remove tree nodes that do not have the same parents.</p> <p>While the parents in starts and ends are unequal (that means that starts and ends belong in different trees), remove elements following starts and preceding ends. Shorten the path to the parents of starts and ends and remove more elements if needed. starts and ends are of equal length.</p> <p>Parameters:</p> Name Type Description Default <code>path1</code> <code>str</code> <p>path to first element</p> required <code>path2</code> <code>str</code> <p>path to second element</p> required <code>content</code> <code>etree._Element</code> <p>xhtml document, where elements are removed.</p> required <p>Returns:</p> Type Description <p>tuple of list of str: paths to the new start and end element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def remove_trees_1(path1, path2, content):\n\"\"\"Remove tree nodes that do not have the same parents.\n\n    While the parents in starts and ends are unequal (that means that\n    starts and ends belong in different trees), remove elements\n    following starts and preceding ends. Shorten the path to the parents\n    of starts and ends and remove more elements if needed. starts and\n    ends are of equal length.\n\n    Args:\n        path1 (str): path to first element\n        path2 (str): path to second element\n        content (etree._Element): xhtml document, where elements are\n            removed.\n\n    Returns:\n        tuple of list of str: paths to the new start and end element.\n    \"\"\"\n    starts, ends = shorten_longest_path(path1, path2, content)\n\n    while starts[:-1] != ends[:-1]:\n        starts = remove_siblings_shorten_path(starts, content)\n        ends = remove_siblings_shorten_path(ends, content, preceding=True)\n\n    return starts, ends\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.remove_trees_2","title":"<code>remove_trees_2(starts, ends, content)</code>","text":"<p>Remove tree nodes that have the same parents.</p> <p>Now that the parents of starts and ends are equal, remove the last trees of nodes between starts and ends (if necessary).</p> <p>Parameters:</p> Name Type Description Default <code>starts</code> <code>list of str</code> <p>path to first element</p> required <code>ends</code> <code>list of str</code> <p>path to second element</p> required <code>content</code> <code>etree._Element</code> <p>xhtml document, where elements are removed.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def remove_trees_2(starts, ends, content):\n\"\"\"Remove tree nodes that have the same parents.\n\n    Now that the parents of starts and ends are equal, remove the last\n    trees of nodes between starts and ends (if necessary).\n\n    Args:\n        starts (list of str): path to first element\n        ends (list of str): path to second element\n        content (etree._Element): xhtml document, where elements are\n            removed.\n    \"\"\"\n    deepest_start = content.find(\n        \"/\".join(starts), namespaces={\"html\": \"http://www.w3.org/1999/xhtml\"}\n    )\n    deepest_end = content.find(\n        \"/\".join(ends), namespaces={\"html\": \"http://www.w3.org/1999/xhtml\"}\n    )\n    parent = deepest_start.getparent()\n    for sibling in deepest_start.itersiblings():\n        if sibling == deepest_end:\n            break\n        else:\n            parent.remove(sibling)\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.shorten_longest_path","title":"<code>shorten_longest_path(path1, path2, content)</code>","text":"<p>Remove elements from the longest path.</p> <p>If starts is longer than ends, remove the siblings following starts, shorten starts with one step (going to the parent). If starts still is longer than ends, remove the siblings following the parent. This is done untill starts and ends are of equal length.</p> <p>If on the other hand ends is longer than starts, remove the siblings preceding ends, then shorten ends (going to its parent).</p> <p>Parameters:</p> Name Type Description Default <code>path1</code> <code>str</code> <p>path to first element</p> required <code>path2</code> <code>str</code> <p>path to second element</p> required <code>content</code> <code>etree._Element</code> <p>xhtml document, where elements are removed.</p> required <p>Returns:</p> Type Description <p>tuple of list of str: paths to the new start and end element, now with the same length.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def shorten_longest_path(path1, path2, content):\n\"\"\"Remove elements from the longest path.\n\n    If starts is longer than ends, remove the siblings following starts,\n    shorten starts with one step (going to the parent). If starts still is\n    longer than ends, remove the siblings following the parent. This is\n    done untill starts and ends are of equal length.\n\n    If on the other hand ends is longer than starts, remove the siblings\n    preceding ends, then shorten ends (going to its parent).\n\n    Args:\n        path1 (str): path to first element\n        path2 (str): path to second element\n        content (etree._Element): xhtml document, where elements are\n            removed.\n\n    Returns:\n        tuple of list of str: paths to the new start and end element, now\n            with the same length.\n    \"\"\"\n    starts, ends = path1.split(\"/\"), path2.split(\"/\")\n\n    while len(starts) &gt; len(ends):\n        starts = remove_siblings_shorten_path(starts, content)\n\n    while len(ends) &gt; len(starts):\n        ends = remove_siblings_shorten_path(ends, content, preceding=True)\n\n    return starts, ends\n</code></pre>"},{"location":"reference/epubconverter/#corpustools.epubconverter.to_html_elt","title":"<code>to_html_elt(filename)</code>","text":"<p>Append all chapter bodies as divs to an html file.</p> <p>Returns:</p> Type Description <p>An etree.Element containing the content of all xhtml files</p> <p>found in the epub file as one xhtml document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/epubconverter.py</code> <pre><code>def to_html_elt(filename):\n\"\"\"Append all chapter bodies as divs to an html file.\n\n    Returns:\n        An etree.Element containing the content of all xhtml files\n        found in the epub file as one xhtml document.\n    \"\"\"\n    metadata = xslsetter.MetadataHandler(filename + \".xsl\", create=True)\n    html = extract_content(filename, metadata)\n    try:\n        remove_ranges(metadata, html)\n    except AttributeError:\n        raise util.ConversionError(\n            \"Check that skip_elements in the \"\n            \"metadata file has the correct format\".format(filename)\n        )\n\n    return html\n</code></pre>"},{"location":"reference/errormarkup/","title":"errormarkup","text":"<p>Classes and functions to convert errormarkup to xml.</p>"},{"location":"reference/errormarkup/#corpustools.errormarkup.ErrorMarkupError","title":"<code>ErrorMarkupError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>This is raised for errors in this module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>class ErrorMarkupError(Exception):\n\"\"\"This is raised for errors in this module.\"\"\"\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.add_error_markup","title":"<code>add_error_markup(element)</code>","text":"<p>Convert error markup to xml in this element and its children.</p> <p>This is the starting point for doing markup.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>etree._Element</code> <p>The element where error markup should be converted to xml.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def add_error_markup(element):\n\"\"\"Convert error markup to xml in this element and its children.\n\n    This is the starting point for doing markup.\n\n    Args:\n        element (etree._Element): The element where error markup should\n            be converted to xml.\n    \"\"\"\n    errors = [message for message in validate_markup(element)]\n\n    if errors:\n        raise ErrorMarkupError(\"{}\".format(\"\\n\".join(errors)))\n\n    for child in element:\n        convert_to_errormarkupxml(child)\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.convert_to_errormarkupxml","title":"<code>convert_to_errormarkupxml(element)</code>","text":"<p>Convert errormarkup found in the element to xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def convert_to_errormarkupxml(element):\n\"\"\"Convert errormarkup found in the element to xml.\"\"\"\n    if element.text:\n        fix_text(element)\n\n    if element.tail:\n        fix_tail(element)\n\n    for child in element:\n        convert_to_errormarkupxml(child)\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.errormarkup_to_xml","title":"<code>errormarkup_to_xml(text, last_correction)</code>","text":"<p>Turn the errormarkup into error xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def errormarkup_to_xml(text, last_correction):\n\"\"\"Turn the errormarkup into error xml.\"\"\"\n    tail = text[last_correction.end() :]\n    text, error = scan_for_error(text[: last_correction.start()])\n    error_element = make_error_element(\n        error,\n        ERROR_TYPES[last_correction.group(\"correction\")[0]],\n        last_correction.group(\"correction\")[2:-1],\n    )\n    error_element.tail = tail\n    fix_text(error_element)\n\n    return text, error_element\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.fix_tail","title":"<code>fix_tail(element)</code>","text":"<p>Replace error markup with error xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def fix_tail(element):\n\"\"\"Replace error markup with error xml.\"\"\"\n    parent = element.getparent()\n    position = parent.index(element)\n    if element.tail:\n        text = element.tail\n        last_correction = LAST_CORRECTION_REGEX.search(text)\n        while last_correction:\n            position += 1\n            text, error_element = errormarkup_to_xml(text, last_correction)\n            element.tail = text\n            parent.insert(position, error_element)\n            last_correction = LAST_CORRECTION_REGEX.search(text)\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.fix_text","title":"<code>fix_text(element)</code>","text":"<p>Replace error markup with error xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def fix_text(element):\n\"\"\"Replace error markup with error xml.\"\"\"\n    if element.text:\n        text = element.text\n        last_correction = LAST_CORRECTION_REGEX.search(text)\n        while last_correction:\n            text, error_element = errormarkup_to_xml(text, last_correction)\n            element.text = text\n            element.insert(0, error_element)\n            last_correction = LAST_CORRECTION_REGEX.search(text)\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.has_not_valid_pairs","title":"<code>has_not_valid_pairs(text)</code>","text":"<p>Check if the text has valid pairs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def has_not_valid_pairs(text):\n\"\"\"Check if the text has valid pairs.\"\"\"\n    old = text\n    correction = CORRECTION_REGEX.search(old)\n    while correction:\n        no_simple = remove_simple_errors(old)\n        correction = CORRECTION_REGEX.search(no_simple)\n\n        if old == no_simple and correction:\n            return correction.group(\"correction\")\n\n        old = no_simple\n\n    return \"\"\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.invalid_corrections","title":"<code>invalid_corrections(text)</code>","text":"<p>Check if all corrections are valid.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def invalid_corrections(text):\n\"\"\"Check if all corrections are valid.\"\"\"\n    return [\n        correction\n        for match in CORRECTION_REGEX.finditer(text)\n        for correction in match.group(\"correction\").split(\"///\")\n        if not correction.count(\"|\") &lt; 2\n    ]\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.look_for_extended_attributes","title":"<code>look_for_extended_attributes(correction)</code>","text":"<p>Extract attributes and correction from a correctionstring.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def look_for_extended_attributes(correction):\n\"\"\"Extract attributes and correction from a correctionstring.\"\"\"\n    details = correction.split(\"|\")\n\n    if len(details) == 1:\n        return (details[0], None)\n\n    return (details[1], details[0])\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.make_correction_element","title":"<code>make_correction_element(correction_content)</code>","text":"<p>Make correction elements.</p> <p>Parameters:</p> Name Type Description Default <code>correction_content</code> <p>string containing the correction(s)</p> required <p>Yields:</p> Type Description <p>A correction element for each correction</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def make_correction_element(correction_content):\n\"\"\"Make correction elements.\n\n    Args:\n        correction_content: string containing the correction(s)\n\n    Yields:\n        A correction element for each correction\n    \"\"\"\n    for correction in correction_content.split(\"///\"):\n        correction_text, att_list = look_for_extended_attributes(correction)\n\n        correct_element = etree.Element(\"correct\")\n        correct_element.text = correction_text\n\n        if att_list is not None:\n            correct_element.set(\"errorinfo\", att_list)\n\n        yield correct_element\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.make_error_element","title":"<code>make_error_element(error_text, error_name, correction)</code>","text":"<p>Make an error xml element.</p> <p>Parameters:</p> Name Type Description Default <code>error_text</code> <p>the text of the error element</p> required <code>error_name</code> <p>the tag of the error element</p> required <code>correction</code> <p>the correction(s) for the error</p> required <p>Returns:</p> Type Description <p>An etree._Element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def make_error_element(error_text, error_name, correction):\n\"\"\"Make an error xml element.\n\n    Args:\n        error_text: the text of the error element\n        error_name: the tag of the error element\n        correction: the correction(s) for the error\n\n    Returns:\n        An etree._Element\n    \"\"\"\n    error_element = etree.Element(error_name)\n    error_element.text = error_text\n\n    for correction_element in make_correction_element(correction):\n        error_element.append(correction_element)\n\n    return error_element\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.remove_simple_errors","title":"<code>remove_simple_errors(text)</code>","text":"<p>Remove non nested errors from the text.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def remove_simple_errors(text):\n\"\"\"Remove non nested errors from the text.\"\"\"\n    result = []\n    previous = 0\n    for match in SIMPLE_ERROR_REGEX.finditer(text):\n        result.append(text[previous : match.start()])\n        previous = match.end()\n\n    if previous &lt; len(text):\n        result.append(text[previous:])\n\n    return \"\".join(result)\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.scan_for_error","title":"<code>scan_for_error(text)</code>","text":"<p>Scan for error markup in the given text.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def scan_for_error(text):\n\"\"\"Scan for error markup in the given text.\"\"\"\n    level = 0\n    index = len(text) - 1\n\n    while index &gt; 0:\n        if text[index] == \"}\":\n            level += 1\n        if text[index] == \"{\":\n            level -= 1\n        if level == 0:\n            break\n        index -= 1\n\n    if index:\n        return text[:index], text[index + 1 : -1]\n\n    return \"\", text[index + 1 : -1]\n</code></pre>"},{"location":"reference/errormarkup/#corpustools.errormarkup.validate_markup","title":"<code>validate_markup(element)</code>","text":"<p>Check if the markup is valid.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/errormarkup.py</code> <pre><code>def validate_markup(element):\n\"\"\"Check if the markup is valid.\"\"\"\n    for child in element:\n        child_as_text = etree.tostring(child, encoding=\"unicode\")\n        for invalid_correction in invalid_corrections(child_as_text):\n            yield f\"Too many \u00ab|\u00bb in {invalid_correction}\"\n        invalid_pair = has_not_valid_pairs(child_as_text)\n        if invalid_pair:\n            yield f\"In text starting with\\n\\t{child_as_text[len(child.tag)+2:50]}\"\n            yield f\"\\tError in front of\\n\\t\\t{invalid_pair}\"\n</code></pre>"},{"location":"reference/finder/","title":"finder","text":"<p>Manage corpus files in various ways.</p>"},{"location":"reference/finder/#corpustools.finder.move_twenty_percent_to_goldcorpus","title":"<code>move_twenty_percent_to_goldcorpus()</code>","text":"<p>Move twenty percent of the files to the goldcorpus</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/finder.py</code> <pre><code>def move_twenty_percent_to_goldcorpus():\n\"\"\"Move twenty percent of the files to the goldcorpus\"\"\"\n    directories = [\n        \"orig/sme/admin/sd/cealkamusat_fi\",\n        \"orig/sme/admin/sd/davviriikkalas_samekonvensuvdna_fi\",\n        \"orig/sme/admin/sd/inaugurations_fi\",\n        \"orig/sme/admin/sd/ohcan_lahkai_fi\",\n        \"orig/sme/admin/sd/sami_parlamentarals_raddi_fi\",\n        \"orig/sme/admin/sd/www.samediggi.fi\",\n        \"orig/sme/facta/samediggi.fi/\",\n    ]\n\n    fluff = collections.defaultdict(list)\n    for dir in directories:\n        for root, dirs, files in os.walk(os.path.join(os.getenv(\"GTFREE\"), dir)):\n            for f in files:\n                if f.endswith(\".xsl\"):\n                    name = os.path.join(root, f[:-4])\n                    size = os.path.getsize(name)\n                    fluff[size].append(name)\n\n    i = 0\n    for size in sorted(list(fluff.keys()), reverse=True):\n        for f in fluff[size]:\n            if i == 4:\n                move_files.mover(f, f.replace(\"orig/\", \"goldstandard/orig/\"))\n                i = 0\n            i += 1\n</code></pre>"},{"location":"reference/finder/#corpustools.finder.remove_files_with_duplicate_content","title":"<code>remove_files_with_duplicate_content()</code>","text":"<p>To replace: 123, , 339, 340</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/finder.py</code> <pre><code>def remove_files_with_duplicate_content():\n\"\"\"To replace: 123, , 339, 340\"\"\"\n    ufflangs = {\n        \"fin\": \"finnish\",\n        \"eng\": \"english\",\n        \"sme\": \"davvi\",\n        \"smn\": \"anaras\",\n        \"sms\": \"nuortta\",\n    }\n\n    this_lang = \"sms\"\n\n    foundcount = 0\n    notfoundcount = 0\n    fingetter = adder.AddToCorpus(\n        str(os.getenv(\"GTFREE\")), \"fin\", \"admin/sd/www.samediggi.fi\"\n    )\n    smsgetter = adder.AddToCorpus(\n        str(os.getenv(\"GTFREE\")), this_lang, \"admin/sd/www.samediggi.fi\"\n    )\n    for root, dirs, files in os.walk(\n        os.path.join(\n            os.getenv(\"GTFREE\"), \"orig\", this_lang, \"admin/sd/www.samediggi.fi\"\n        )\n    ):\n        print(root)\n        for f in files:\n            if f.endswith(\".xsl\") and \"itemid=256\" in f:\n                path = os.path.join(root, f)\n                mdh = xslsetter.MetadataHandler(path)\n                filename = mdh.get_variable(\"filename\")\n\n                parallellfile = path.replace(\"/\" + this_lang + \"/\", \"/fin/\")\n                parallellfile = parallellfile.replace(\".xsl\", \"\")\n                parallellfile = parallellfile.replace(\n                    \"lang=\" + ufflangs[this_lang], \"lang=finnish\"\n                )\n                parallellfile = parallellfile.replace(\"itemid=256\", \"itemid=195\")\n\n                if not os.path.exists(parallellfile):\n                    if this_lang != \"fin\":\n                        fingetter.copy_url_to_corpus(\n                            filename.replace(\"Itemid=256\", \"Itemid=195\").replace(\n                                \"lang=\" + ufflangs[this_lang], \"lang=finnish\"\n                            )\n                        )\n\n                smsgetter.copy_url_to_corpus(\n                    filename.replace(\"Itemid=256\", \"Itemid=195\"),\n                    parallelpath=parallellfile,\n                )\n                move_files.mover(path.replace(\".xsl\", \"\"), \"\")\n\n    smsgetter.add_files_to_working_copy()\n    fingetter.add_files_to_working_copy()\n</code></pre>"},{"location":"reference/generate_anchor_list/","title":"generate_anchor_list","text":"<p>Generate an anchor file needed by the java aligner.</p>"},{"location":"reference/generate_anchor_list/#corpustools.generate_anchor_list.GenerateAnchorList","title":"<code>GenerateAnchorList</code>","text":"<p>Generate anchor list used by tca2.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/generate_anchor_list.py</code> <pre><code>class GenerateAnchorList:\n\"\"\"Generate anchor list used by tca2.\"\"\"\n\n    def __init__(self, lang1, lang2, columns, input_file):\n\"\"\"Initialise the GenerateAnchorList class.\n\n        Args:\n            lang1: the main lang\n            lang2: the translated lang\n            columns (list of str): contains all the possible langs\n                found in the main anchor file.\n            path (str): path of the existing anchor file.\n        \"\"\"\n        self.lang1 = lang1\n        self.lang2 = lang2\n        self.lang1_index = columns.index(lang1)\n        self.lang2_index = columns.index(lang2)\n        self.columns = columns\n        self.input_file = input_file\n\n    def words_of_line(self, lineno, line):\n\"\"\"Either a word-pair or None, if no word-pair on that line.\"\"\"\n        line = line.strip()\n        if not line.startswith(\"#\") or not line.startswith(\"&amp;\"):\n            words = line.split(\"/\")\n            if len(words) == len(self.columns):\n                word1 = words[self.lang1_index].strip()\n                word2 = words[self.lang2_index].strip()\n                if word1 and word2:\n                    return word1, word2\n            else:\n                print(\n                    f\"Invalid line at {lineno} in {self.input_file}\",\n                    file=sys.stderr,\n                )\n\n    def read_anchors(self, quiet=False):\n\"\"\"List of word-pairs in infiles, empty/bad lines skipped.\"\"\"\n        with codecs.open(self.input_file, encoding=\"utf8\") as f:\n            out = [self.words_of_line(i, l) for i, l in enumerate(f.readlines())]\n            out = [_f for _f in out if _f]\n            if not quiet:\n                util.note(f\"Read {len(out)} anchors from {self.input_file}\")\n            return out\n\n    def generate_file(self, outpath, quiet=False):\n\"\"\"infiles is a list of file paths.\"\"\"\n        anchors = self.read_anchors(quiet)\n\n        with codecs.open(outpath, \"w\", encoding=\"utf8\") as outfile:\n            if not quiet:\n                util.note(f\"Generating anchor word list to {outpath}\")\n            out = \"\\n\".join(f\"{w1} / {w2}\" for w1, w2 in anchors)\n            outfile.write(out)\n            outfile.write(\"\\n\")\n</code></pre>"},{"location":"reference/generate_anchor_list/#corpustools.generate_anchor_list.GenerateAnchorList.__init__","title":"<code>__init__(lang1, lang2, columns, input_file)</code>","text":"<p>Initialise the GenerateAnchorList class.</p> <p>Parameters:</p> Name Type Description Default <code>lang1</code> <p>the main lang</p> required <code>lang2</code> <p>the translated lang</p> required <code>columns</code> <code>list of str</code> <p>contains all the possible langs found in the main anchor file.</p> required <code>path</code> <code>str</code> <p>path of the existing anchor file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/generate_anchor_list.py</code> <pre><code>def __init__(self, lang1, lang2, columns, input_file):\n\"\"\"Initialise the GenerateAnchorList class.\n\n    Args:\n        lang1: the main lang\n        lang2: the translated lang\n        columns (list of str): contains all the possible langs\n            found in the main anchor file.\n        path (str): path of the existing anchor file.\n    \"\"\"\n    self.lang1 = lang1\n    self.lang2 = lang2\n    self.lang1_index = columns.index(lang1)\n    self.lang2_index = columns.index(lang2)\n    self.columns = columns\n    self.input_file = input_file\n</code></pre>"},{"location":"reference/generate_anchor_list/#corpustools.generate_anchor_list.GenerateAnchorList.generate_file","title":"<code>generate_file(outpath, quiet=False)</code>","text":"<p>infiles is a list of file paths.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/generate_anchor_list.py</code> <pre><code>def generate_file(self, outpath, quiet=False):\n\"\"\"infiles is a list of file paths.\"\"\"\n    anchors = self.read_anchors(quiet)\n\n    with codecs.open(outpath, \"w\", encoding=\"utf8\") as outfile:\n        if not quiet:\n            util.note(f\"Generating anchor word list to {outpath}\")\n        out = \"\\n\".join(f\"{w1} / {w2}\" for w1, w2 in anchors)\n        outfile.write(out)\n        outfile.write(\"\\n\")\n</code></pre>"},{"location":"reference/generate_anchor_list/#corpustools.generate_anchor_list.GenerateAnchorList.read_anchors","title":"<code>read_anchors(quiet=False)</code>","text":"<p>List of word-pairs in infiles, empty/bad lines skipped.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/generate_anchor_list.py</code> <pre><code>def read_anchors(self, quiet=False):\n\"\"\"List of word-pairs in infiles, empty/bad lines skipped.\"\"\"\n    with codecs.open(self.input_file, encoding=\"utf8\") as f:\n        out = [self.words_of_line(i, l) for i, l in enumerate(f.readlines())]\n        out = [_f for _f in out if _f]\n        if not quiet:\n            util.note(f\"Read {len(out)} anchors from {self.input_file}\")\n        return out\n</code></pre>"},{"location":"reference/generate_anchor_list/#corpustools.generate_anchor_list.GenerateAnchorList.words_of_line","title":"<code>words_of_line(lineno, line)</code>","text":"<p>Either a word-pair or None, if no word-pair on that line.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/generate_anchor_list.py</code> <pre><code>def words_of_line(self, lineno, line):\n\"\"\"Either a word-pair or None, if no word-pair on that line.\"\"\"\n    line = line.strip()\n    if not line.startswith(\"#\") or not line.startswith(\"&amp;\"):\n        words = line.split(\"/\")\n        if len(words) == len(self.columns):\n            word1 = words[self.lang1_index].strip()\n            word2 = words[self.lang2_index].strip()\n            if word1 and word2:\n                return word1, word2\n        else:\n            print(\n                f\"Invalid line at {lineno} in {self.input_file}\",\n                file=sys.stderr,\n            )\n</code></pre>"},{"location":"reference/html_cleaner/","title":"html_cleaner","text":"<p>Script to write a nicely indented html doc.</p> <p>Mainly used to debug the input to the converter.HTMLContentConverter.</p>"},{"location":"reference/html_cleaner/#corpustools.html_cleaner.main","title":"<code>main()</code>","text":"<p>Convert an html file, and print the result to outfile.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/html_cleaner.py</code> <pre><code>def main():\n\"\"\"Convert an html file, and print the result to outfile.\"\"\"\n    args = parse_args()\n\n    c = htmlconverter.to_html_elt(args.inhtml)\n    with open(args.outhtml, \"w\") as outfile:\n        util.print_element(c, 0, 4, outfile)\n</code></pre>"},{"location":"reference/html_cleaner/#corpustools.html_cleaner.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/html_cleaner.py</code> <pre><code>def parse_args():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Program to print out a nicely indented html document. \"\n        \"This makes it easier to see the structure of it. This eases \"\n        \"debugging the conversion of html documents.\",\n    )\n\n    parser.add_argument(\"inhtml\", help=\"The path of the html to indent.\")\n    parser.add_argument(\n        \"outhtml\", help=\"The place where the indented html doc is written\"\n    )\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/htmlcontentconverter/","title":"htmlcontentconverter","text":"<p>Convert html content to the Giella xml format.</p>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier","title":"<code>HTMLBeautifier</code>","text":"<p>Convert html documents to the Giella xml format.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>class HTMLBeautifier:\n\"\"\"Convert html documents to the Giella xml format.\"\"\"\n\n    def __init__(self, html_elt):\n        for elt in html_elt.iter(\"script\"):\n            elt.getparent().remove(elt)\n\n        c_clean = self.superclean(etree.tostring(html_elt, encoding=\"unicode\"))\n        self.soup = html.document_fromstring(c_clean)\n\n    def superclean(self, content):\n\"\"\"Remove unwanted elements from an html document.\n\n        Args:\n            content is a string containing an html document.\n\n        Returns:\n            a string containing the cleaned up html document.\n        \"\"\"\n        cleaner = clean.Cleaner(\n            page_structure=False,\n            scripts=True,\n            javascript=True,\n            comments=True,\n            style=True,\n            processing_instructions=True,\n            remove_unknown_tags=True,\n            embedded=True,\n            kill_tags=[\n                \"img\",\n                \"area\",\n                \"address\",\n                \"hr\",\n                \"cite\",\n                \"footer\",\n                \"figcaption\",\n                \"aside\",\n                \"time\",\n                \"figure\",\n                \"nav\",\n                \"noscript\",\n                \"map\",\n                \"ins\",\n                \"s\",\n                \"colgroup\",\n            ],\n        )\n\n        return cleaner.clean_html(self.remove_cruft(content))\n\n    @staticmethod\n    def remove_cruft(content):\n\"\"\"Remove cruft from svenskakyrkan.se documents.\n\n        Args:\n            content (str): the content of a document.\n\n        Returns:\n            str: The content of the document without the cruft.\n        \"\"\"\n        replacements = [(\"//&lt;script\", \"&lt;script\"), (\"&amp;nbsp;\", \" \"), (\"\u00a0\", \" \")]\n        return util.replace_all(replacements, content)\n\n    def simplify_tags(self):\n\"\"\"Turn tags to divs.\n\n        We don't care about the difference between &lt;fieldsets&gt;, &lt;legend&gt;\n        etc. \u2013 treat them all as &lt;div&gt;'s for xhtml2corpus\n        \"\"\"\n        superfluously_named_tags = self.soup.xpath(\n            \"//fieldset | //legend | //article | //hgroup \"\n            \"| //section | //dl | //dd | //dt\"\n            \"| //menu\"\n        )\n        for elt in superfluously_named_tags:\n            elt.tag = \"div\"\n\n    def fix_spans_as_divs(self):\n\"\"\"Turn div like elements into div.\n\n        XHTML doesn't allow (and xhtml2corpus doesn't handle) span-like\n        elements with div-like elements inside them; fix this and\n        similar issues by turning them into divs.\n        \"\"\"\n        spans_as_divs = self.soup.xpath(\n            \"//*[( descendant::div or descendant::p\"\n            \"      or descendant::h1 or descendant::h2\"\n            \"      or descendant::h3 or descendant::h4\"\n            \"      or descendant::h5 or descendant::h6 ) \"\n            \"and ( self::span or self::b or self::i\"\n            \"      or self::em or self::strong \"\n            \"      or self::a )\"\n            \"    ]\"\n        )\n        for elt in spans_as_divs:\n            elt.tag = \"div\"\n\n        ps_as_divs = self.soup.xpath(\"//p[descendant::div]\")\n        for elt in ps_as_divs:\n            elt.tag = \"div\"\n\n        lists_as_divs = self.soup.xpath(\n            \"//*[( child::ul or child::ol ) \" \"and ( self::ul or self::ol )\" \"    ]\"\n        )\n        for elt in lists_as_divs:\n            elt.tag = \"div\"\n\n    def remove_empty_p(self):\n\"\"\"Remove empty p elements.\"\"\"\n        paragraphs = self.soup.xpath(\"//p\")\n\n        for elt in paragraphs:\n            if elt.text is None and elt.tail is None and not len(elt):\n                elt.getparent().remove(elt)\n\n    def remove_empty_class(self):\n\"\"\"Delete empty class attributes.\"\"\"\n        for element in self.soup.xpath('.//*[@class=\"\"]'):\n            del element.attrib[\"class\"]\n\n    def remove_elements(self):\n\"\"\"Remove unwanted tags from a html document.\n\n        The point with this exercise is to remove all but the main content of\n        the document.\n        \"\"\"\n        unwanted_classes_ids = {\n            \"div\": {\n                \"class\": [\n                    \"skiplinks\",  # yle.fi\n                    \"AddThis\",  # lansstyrelsen.se\n                    \"InnholdForfatter\",  # unginordland\n                    \"NavigationLeft\",  # lansstyrelsen.se\n                    \"QuickNav\",\n                    \"ad\",\n                    \"andrenyheter\",  # tysfjord.kommune.no\n                    \"art-layout-cell art-sidebar2\",  # gaaltije.se\n                    \"art-postheadericons art-metadata-icons\",  # gaaltije.se\n                    \"article-ad\",\n                    \"article-bottom-element\",\n                    \"article-column\",\n                    (\n                        \"article-dateline article-dateline-footer \"\n                        \"meta-widget-content\"\n                    ),  # nrk.no\n                    (\n                        \"article-dateline article-footer \" \"container-widget-content cf\"\n                    ),  # nrk.no\n                    \"article-heading-wrapper\",  # 1177.se\n                    \"article-info\",  # regjeringen.no\n                    \"article-related\",\n                    \"article-toolbar__tool\",  # umo.se\n                    \"article-universe-teaser container-widget-content\",\n                    \"articleImageRig\",\n                    \"articlegooglemap\",  # tysfjord.kommune.no\n                    \"articleTags\",  # nord-salten.no\n                    \"attribute-related_object\",  # samediggi.no\n                    \"authors\",\n                    \"authors ui-helper-clearfix\",  # nord-salten.no\n                    \"back_button\",\n                    \"banner-element\",\n                    \"bl_linktext\",\n                    \"bottom-center\",\n                    \"breadcrumbs \",\n                    \"breadcrumbs\",\n                    \"breadcrums span-12\",\n                    \"btm_menu\",\n                    \"byline\",  # arran.no\n                    \"c1\",  # jll.se\n                    \"art-bar art-nav\",  # gaaltije.se\n                    \"art-layout-cell art-sidebar1\",  # gaaltije.se\n                    \"clearfix breadcrumbsAndSocial noindex\",  # udir.no\n                    \"complexDocumentBottom\",  # regjeringen.no\n                    \"container-widget-content\",  # nrk.no\n                    \"container_full\",\n                    \"content-body attribute-vnd.openxmlformats-\"\n                    \"officedocument.spreadsheetml.sheet\",  # samediggi.no\n                    \"content-language-links\",  # metsa.fi\n                    \"content-wrapper\",  # siida.fi\n                    \"control-group field-wrapper tiedotteet-period\",  # metsa.fi\n                    \"control-group form-inline\",  # metsa.fi\n                    \"date\",  # samediggi.no, 2019 -&gt;\n                    \"documentInfoEm\",\n                    \"documentPaging\",\n                    \"documentPaging PagingBtm\",  # regjeringen.no\n                    \"documentTop\",  # regjeringen.no\n                    \"dotList\",  # nord-salten.no\n                    \"dropmenudiv\",  # calliidlagadus.org\n                    \"embedFile\",  # samediggi.no -&gt; 2019\n                    \"embedded-breadcrumbs\",\n                    \"egavpi\",  # calliidlagadus.org\n                    \"egavpi_fiskes\",  # calliidlagadus.org\n                    \"esite_footer\",\n                    \"esite_header\",\n                    \"expandable\",\n                    \"feedbackContainer noindex\",  # udir.no\n                    \"file\",  # samediggi.no\n                    \"fixed-header\",\n                    \"g100 col fc s18 sg6 sg9 sg12 menu-reference\",  # nrk.no\n                    \"g100 col fc s18 sg6 sg9 sg12 flow-reference\",  # nrk.no\n                    \"g11 col fl s2 sl6 sl9 sl12 sl18\",  # nrk.no\n                    \"g22 col fl s4 sl6 sl9 sl12 sl18 \"\n                    \"article-header-sidebar\",  # nrk.no\n                    \"g94 col fl s17 sl18 sg6 sg9 sg12 meta-widget\",  # nrk.no\n                    \"globmenu\",  # visitstetind.no\n                    \"grid cf\",  # nrk.no\n                    \"help closed hidden-xs\",\n                    \"historic-info\",  # regjeringen.no\n                    \"historic-label\",  # regjeringen.no\n                    \"imagecontainer\",\n                    \"innholdsfortegenlse-child\",\n                    \"inside\",  # samas.no\n                    \"latestnews_uutisarkisto\",\n                    \"ld-navbar\",\n                    \"listArticleLink\",  # samediggi.no -&gt; 2019\n                    \"logo-links\",  # metsa.fi\n                    \"meta\",\n                    \"meta ui-helper-clearfix\",  # nord-salten.no\n                    \"authors ui-helper-clearfix\",  # nord-salten.no\n                    \"menu\",  # visitstetind.no\n                    \"metaWrapper\",\n                    \"mini-frontpage\",  # yle.fi\n                    \"moduletable_oikopolut\",\n                    \"moduletable_etulinkki\",  # www.samediggi.fi\n                    \"navigation\",  # latex2html docs\n                    \"nav-menu nav-menu-style-dots\",  # metsa.fi\n                    \"naviHlp\",  # visitstetind.no\n                    \"noindex\",  # ntfk\n                    \"nrk-globalfooter\",  # nrk.no\n                    \"nrk-globalfooter-dk lp_globalfooter\",  # nrk.no\n                    \"nrk-globalnavigation\",  # nrk.no\n                    \"nrkno-share bulletin-share\",  # nrk.no\n                    \"outer-column\",\n                    \"page-inner\",  # samas.no\n                    \"person_info\",  # samediggi.no\n                    \"plug-teaser\",  # nrk.no\n                    \"post-footer\",\n                    \"printbutton-wrapper\",  # 1177.se\n                    \"printContact\",\n                    \"right\",  # ntfk\n                    \"rightverticalgradient\",  # udir.no\n                    \"sharebutton-wrapper\",  # 1177.se\n                    \"sharing\",\n                    \"sidebar\",\n                    \"spalte300\",  # osko.no\n                    \"span12 tiedotteet-show\",\n                    \"subpage-bottom\",\n                    \"subfooter\",  # visitstetind.no\n                    \"subnavigation\",  # oikeusministeri\u00f6\n                    \"tabbedmenu\",\n                    \"tipformcontainer\",  # tysfjord.kommune.no\n                    \"tipsarad mt6 selfClear\",\n                    \"titlepage\",\n                    \"toc-placeholder\",  # 1177.se\n                    \"toc\",\n                    \"tools\",  # arran.no\n                    \"trail\",  # siida.fi\n                    \"translations\",  # siida.fi\n                    \"upperheader\",\n                ],\n                \"id\": [\n                    \"oikea_palsta\",  # yle.fi\n                    \"ylefifooter\",  # yle.fi\n                    \"print-logo-wrapper\",  # 1177.se\n                    \"AreaLeft\",\n                    \"AreaLeftNav\",\n                    \"AreaRight\",\n                    \"AreaTopRight\",\n                    \"AreaTopSiteNav\",\n                    \"NAVbreadcrumbContainer\",\n                    \"NAVfooterContainer\",\n                    \"NAVheaderContainer\",\n                    \"NAVrelevantContentContainer\",\n                    \"NAVsubmenuContainer\",\n                    \"PageFooter\",\n                    \"PageLanguageInfo\",  # regjeringen.no\n                    \"PrintDocHead\",\n                    \"SamiDisclaimer\",\n                    \"ShareArticle\",\n                    \"WIPSELEMENT_CALENDAR\",  # learoevierhtieh.no\n                    \"WIPSELEMENT_HEADING\",  # learoevierhtieh.no\n                    \"WIPSELEMENT_MENU\",  # learoevierhtieh.no\n                    \"WIPSELEMENT_MENURIGHT\",  # learoevierhtieh.no\n                    \"WIPSELEMENT_NEWS\",  # learoevierhtieh.no\n                    \"WebPartZone1\",  # lansstyrelsen.se\n                    \"aa\",\n                    \"andrenyheter\",  # tysfjord.kommune.no\n                    \"article_footer\",\n                    \"attached\",  # tysfjord.kommune.no\n                    \"blog-pager\",\n                    \"bottom\",  # samas.no\n                    \"breadcrumbs-bottom\",\n                    \"bunninformasjon\",  # unginordland\n                    \"chatBox\",\n                    \"chromemenu\",  # calliidlagadus.org\n                    \"crumbs\",  # visitstetind.no\n                    \"ctl00_AccesskeyShortcuts\",  # lansstyrelsen.se\n                    \"ctl00_ctl00_ArticleFormContentRegion_\"\n                    \"ArticleBodyContentRegion_ctl00_\"\n                    \"PageToolWrapper\",  # 1177.se\n                    \"ctl00_ctl00_ArticleFormContentRegion_\"\n                    \"ArticleBodyContentRegion_ctl03_\"\n                    \"PageToolWrapper\",  # 1177.se\n                    \"ctl00_Cookies\",  # lansstyrelsen.se\n                    \"ctl00_FullRegion_CenterAndRightRegion_HitsControl_\"\n                    \"ctl00_FullRegion_CenterAndRightRegion_Sorting_sortByDiv\",\n                    \"ctl00_LSTPlaceHolderFeedback_\"\n                    \"editmodepanel31\",  # lansstyrelsen.se\n                    \"ctl00_LSTPlaceHolderSearch_\"\n                    \"SearchBoxControl\",  # lansstyrelsen.se\n                    \"ctl00_MidtSone_ucArtikkel_ctl00_ctl00_ctl01_divRessurser\",\n                    \"ctl00_MidtSone_ucArtikkel_ctl00_divNavigasjon\",\n                    \"ctl00_PlaceHolderMain_EditModePanel1\",  # lansstyrelsen.se\n                    \"ctl00_PlaceHolderTitleBreadcrumb_\"\n                    \"DefaultBreadcrumb\",  # lansstyrelsen.se\n                    \"ctl00_TopLinks\",  # lansstyrelsen.se\n                    \"deleModal\",\n                    \"document-header\",\n                    \"errorMessageContainer\",  # nord-salten.no\n                    \"final-footer-wrapper\",  # 1177.se\n                    \"flu-vaccination\",  # 1177.se\n                    \"footer\",  # forrest, too, tysfjord.kommune.no\n                    \"footer-wrapper\",\n                    \"frontgallery\",  # visitstetind.no\n                    \"header\",\n                    \"headerBar\",\n                    \"headWrapper\",  # osko.no\n                    \"hoyre\",  # unginordland\n                    \"innholdsfortegnelse\",  # regjeringen.no\n                    \"leftMenu\",\n                    \"leftPanel\",\n                    \"leftbar\",  # forrest (divvun and giellatekno sites)\n                    \"leftcol\",  # new samediggi.no\n                    \"leftmenu\",\n                    \"main_navi_main\",  # www.samediggi.fi\n                    \"mainContentBookmark\",  # udir.no\n                    \"mainsidebar\",  # arran.no\n                    \"menu\",\n                    \"mobile-header\",\n                    \"mobile-subnavigation\",\n                    \"murupolku\",  # www.samediggi.fi\n                    \"nav-content\",\n                    \"navbar\",  # tysfjord.kommune.no\n                    \"ncFooter\",  # visitstetind.no\n                    \"ntfkFooter\",  # ntfk\n                    \"ntfkHeader\",  # ntfk\n                    \"ntfkNavBreadcrumb\",  # ntfk\n                    \"ntfkNavMain\",  # ntfk\n                    \"pageFooter\",\n                    \"path\",  # new samediggi.no, tysfjord.kommune.no\n                    \"phone-bar\",  # 1177.se\n                    \"publishinfo\",  # 1177.se\n                    \"readspeaker_button1\",\n                    \"right-wrapper\",  # ndla\n                    \"rightAds\",\n                    \"rightCol\",\n                    \"rightside\",\n                    \"s4-leftpanel\",  # ntfk\n                    \"searchBox\",\n                    \"searchHitSummary\",\n                    \"sendReminder\",\n                    \"share-article\",\n                    \"sidebar\",  # finlex.fi, too\n                    \"sidebar-wrapper\",\n                    \"sitemap\",\n                    \"skipLinks\",  # udir.no\n                    \"skiplink\",  # tysfjord.kommune.no\n                    \"spraakvelger\",  # osko.no\n                    \"subfoote\",  # visitstetind.no\n                    \"submenu\",  # nord-salten.no\n                    \"svid10_49531bad1412ceb82564aea\",  # ostersund.se\n                    \"svid10_6ba9fa711d2575a2a7800024318\",  # jll.se\n                    \"svid10_6c1eb18a13ec7d9b5b82ee7\",  # ostersund.se\n                    \"svid10_b0dabad141b6aeaf101229\",  # ostersund.se\n                    \"svid10_49531bad1412ceb82564af3\",  # ostersund.se\n                    \"svid10_6ba9fa711d2575a2a7800032145\",  # jll.se\n                    \"svid10_6ba9fa711d2575a2a7800032151\",  # jll.se\n                    \"svid10_6ba9fa711d2575a2a7800024344\",  # jll.se\n                    \"svid10_6ba9fa711d2575a2a7800032135\",  # jll.se\n                    \"svid10_6c1eb18a13ec7d9b5b82ee3\",  # ostersund.se\n                    \"svid10_6c1eb18a13ec7d9b5b82edf\",  # ostersund.se\n                    \"svid10_6c1eb18a13ec7d9b5b82edd\",  # ostersund.se\n                    \"svid10_6c1eb18a13ec7d9b5b82eda\",  # ostersund.se\n                    \"svid10_6c1eb18a13ec7d9b5b82ed5\",  # ostersund.se\n                    \"svid12_6ba9fa711d2575a2a7800032140\",  # jll.se\n                    \"theme-area-label-wrapper\",  # 1177.se\n                    \"tipafriend\",\n                    \"tools\",  # arran.no\n                    \"topHeader\",  # nord-salten.no\n                    \"topMenu\",\n                    \"topUserMenu\",\n                    \"top\",  # arran.no\n                    \"topnav\",  # tysfjord.kommune.no\n                    \"toppsone\",  # unginordland\n                    \"vedleggogregistre\",  # regjeringen.no\n                    \"venstre\",  # unginordland\n                    \"static-menu-inner\",  # arran.no\n                ],\n            },\n            \"p\": {\n                \"class\": [\n                    \"WebPartReadMoreParagraph\",\n                    \"breadcrumbs\",\n                    \"langs\",  # oahpa.no\n                    \"art-page-footer\",  # gaaltije.se\n                ],\n                \"id\": [\"skip-link\"],  # samas.no\n            },\n            \"ul\": {\n                \"id\": [\n                    \"AreaTopLanguageNav\",\n                    \"AreaTopPrintMeny\",\n                    \"skiplinks\",  # umo.se\n                    \"mainmenu\",  # admin/tysfjord\n                ],\n                \"class\": [\n                    \"QuickNav\",\n                    \"article-tools\",\n                    \"article-universe-list\",  # nrk.no\n                    \"byline\",\n                    \"chapter-index\",  # lovdata.no\n                    \"footer-nav\",  # lovdata.no\n                    \"hidden\",  # unginordland\n                    \"mainmenu menu menulevel0\",  # admin/tysfjord\n                ],\n            },\n            \"span\": {\n                \"id\": [\"skiplinks\"],\n                \"class\": [\n                    \"K-NOTE-FOTNOTE\",\n                    \"graytext\",  # svenskakyrkan.se\n                    \"breadcrumbs pathway\",  # gaaltije.se\n                    \"meta\",  # yle.fi\n                ],\n            },\n            \"a\": {\n                \"id\": [\"ctl00_IdWelcome_ExplicitLogin\", \"leftPanelTab\"],  # ntfk\n                \"class\": [\n                    \"addthis_button_print\",  # ntfk\n                    \"mainlevel\",\n                    \"share-paragraf\",  # lovdata.no\n                    \"mainlevel_alavalikko\",  # www.samediggi.fi\n                    \"sublevel_alavalikko\",  # www.samediggi.fi\n                    \"skip-link\",  # 1177.se\n                    \"toggle-link expanded\",  # 1177.se\n                ],\n                \"name\": [\"footnote-ref\"],  # footnotes in running text\n            },\n            \"td\": {\n                \"id\": [\n                    \"hakulomake\",  # www.samediggi.fi\n                    \"paavalikko_linkit\",  # www.samediggi.fi\n                    \"sg_oikea\",  # www.samediggi.fi\n                    \"sg_vasen\",  # www.samediggi.fi\n                ],\n                \"class\": [\"modifydate\"],\n            },\n            \"tr\": {\"id\": [\"sg_ylaosa1\", \"sg_ylaosa2\"]},\n            \"header\": {\n                \"id\": [\"header\"],  # umo.se\n                \"class\": [\n                    \"nrk-masthead-content cf\",  # nrk.no\n                    \"pageHeader \",  # regjeringen.no\n                    \"singleton widget rich nrk-masthead lp_masthead\",  # nrk.no\n                ],\n            },\n            \"section\": {\n                \"class\": [\n                    \"recents-on-this-topic\",  # yle.fi\n                    \"section-theme-sub-nav\",  # 1177.se\n                    \"span3\",  # samernas.se\n                    \"tree-menu current\",  # umo.se\n                    \"tree-menu\",  # umo.se\n                ]\n            },\n            \"table\": {\"id\": [\"Table_01\"]},\n        }\n\n        namespace = {\"html\": \"http://www.w3.org/1999/xhtml\"}\n        for tag, attribs in unwanted_classes_ids.items():\n            for key, values in attribs.items():\n                for value in values:\n                    search = f'.//{tag}[@{key}=\"{value}\"]'\n                    for unwanted in self.soup.xpath(search, namespaces=namespace):\n                        unwanted.getparent().remove(unwanted)\n\n    def add_p_around_text(self):\n\"\"\"Add p around text after an hX element.\"\"\"\n        stop_tags = [\"p\", \"h3\", \"h2\", \"div\", \"table\"]\n        for tag in self.soup.xpath(\".//body/*\"):\n            if tag.tail is not None and tag.tail.strip() != \"\":\n                paragraph = etree.Element(\"p\")\n                paragraph.text = tag.tail\n                tag.tail = None\n                for next_element in iter(tag.getnext, None):\n                    if next_element.tag in stop_tags:\n                        break\n                    paragraph.append(next_element)\n\n                tag_parent = tag.getparent()\n                tag_parent.insert(tag_parent.index(tag) + 1, paragraph)\n\n        # br's are not allowed right under body in XHTML:\n        for elt in self.soup.xpath(\".//body/br\"):\n            elt.tag = \"p\"\n            elt.text = \" \"\n\n    def center2div(self):\n\"\"\"Convert center to div in tidy style.\"\"\"\n        for center in self.soup.xpath(\".//center\"):\n            center.tag = \"div\"\n            center.set(\"class\", \"c1\")\n\n    def body_i(self):\n\"\"\"Wrap bare elements inside a p element.\"\"\"\n        for tag in [\"a\", \"i\", \"em\", \"u\", \"strong\", \"span\"]:\n            for body_tag in self.soup.xpath(f\".//body/{tag}\"):\n                paragraph = etree.Element(\"p\")\n                bi_parent = body_tag.getparent()\n                bi_parent.insert(bi_parent.index(body_tag), paragraph)\n                paragraph.append(body_tag)\n\n    @staticmethod\n    def handle_font_text(font_elt):\n\"\"\"Incorporate font.text into correct element.\n\n        Args:\n            font_elt (etree.Element): a font element.\n        \"\"\"\n        font_parent = font_elt.getparent()\n        font_index = font_parent.index(font_elt)\n\n        if font_elt.text is not None:\n            if font_index &gt; 0:\n                previous_element = font_parent[font_index - 1]\n                if previous_element.tail is not None:\n                    previous_element.tail += font_elt.text\n                else:\n                    previous_element.tail = font_elt.text\n            else:\n                if font_elt.text is not None:\n                    if font_parent.text is not None:\n                        font_parent.text += font_elt.text\n                    else:\n                        font_parent.text = font_elt.text\n\n    @staticmethod\n    def handle_font_children(font_elt):\n\"\"\"Incorporate font children into correct element.\n\n        Args:\n            font_elt (etree.Element): a font element.\n        \"\"\"\n        font_parent = font_elt.getparent()\n        font_index = font_parent.index(font_elt)\n\n        for position, font_child in enumerate(font_elt, start=font_index):\n            if font_elt.tail is not None:\n                if font_elt[-1].tail is not None:\n                    font_elt[-1].tail += font_elt.tail\n                else:\n                    font_elt[-1].tail = font_elt.tail\n            font_parent.insert(position, font_child)\n\n    @staticmethod\n    def handle_font_tail(font_elt):\n\"\"\"Incorporate font.tail into correct element.\n\n        Args:\n            font_elt (etree.Element): a font element.\n        \"\"\"\n        font_parent = font_elt.getparent()\n        font_index = font_parent.index(font_elt)\n        previous_element = font_parent[font_index - 1]\n\n        if font_elt.tail is not None:\n            if font_index &gt; 0:\n                if previous_element.tail is not None:\n                    previous_element.tail += font_elt.tail\n                else:\n                    previous_element.tail = font_elt.tail\n            else:\n                if font_parent.text is not None:\n                    font_parent.text += font_elt.tail\n                else:\n                    font_parent.text = font_elt.tail\n\n    def remove_font(self):\n\"\"\"Remove font elements, incorporate content into it's parent.\"\"\"\n        for font_elt in reversed(list(self.soup.iter(\"{*}font\"))):\n            self.handle_font_text(font_elt)\n\n            if len(font_elt) &gt; 0:\n                self.handle_font_children(font_elt)\n            else:\n                self.handle_font_tail(font_elt)\n\n            font_elt.getparent().remove(font_elt)\n\n    def body_text(self):\n\"\"\"Wrap bare text inside a p element.\"\"\"\n        body = self.soup.find(\".//body\")\n\n        if body.text is not None:\n            paragraph = etree.Element(\"p\")\n            paragraph.text = body.text\n            body.text = None\n            body.insert(0, paragraph)\n\n    def beautify(self):\n\"\"\"Clean up the html document.\n\n        Destructively modifies self.soup, trying\n        to create strict xhtml for xhtml2corpus.xsl\n        \"\"\"\n        self.remove_empty_class()\n        self.remove_empty_p()\n        self.remove_elements()\n        self.remove_font()\n        self.add_p_around_text()\n        self.center2div()\n        self.body_i()\n        self.body_text()\n        self.simplify_tags()\n        self.fix_spans_as_divs()\n\n        return self.soup\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.add_p_around_text","title":"<code>add_p_around_text()</code>","text":"<p>Add p around text after an hX element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def add_p_around_text(self):\n\"\"\"Add p around text after an hX element.\"\"\"\n    stop_tags = [\"p\", \"h3\", \"h2\", \"div\", \"table\"]\n    for tag in self.soup.xpath(\".//body/*\"):\n        if tag.tail is not None and tag.tail.strip() != \"\":\n            paragraph = etree.Element(\"p\")\n            paragraph.text = tag.tail\n            tag.tail = None\n            for next_element in iter(tag.getnext, None):\n                if next_element.tag in stop_tags:\n                    break\n                paragraph.append(next_element)\n\n            tag_parent = tag.getparent()\n            tag_parent.insert(tag_parent.index(tag) + 1, paragraph)\n\n    # br's are not allowed right under body in XHTML:\n    for elt in self.soup.xpath(\".//body/br\"):\n        elt.tag = \"p\"\n        elt.text = \" \"\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.beautify","title":"<code>beautify()</code>","text":"<p>Clean up the html document.</p> <p>Destructively modifies self.soup, trying to create strict xhtml for xhtml2corpus.xsl</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def beautify(self):\n\"\"\"Clean up the html document.\n\n    Destructively modifies self.soup, trying\n    to create strict xhtml for xhtml2corpus.xsl\n    \"\"\"\n    self.remove_empty_class()\n    self.remove_empty_p()\n    self.remove_elements()\n    self.remove_font()\n    self.add_p_around_text()\n    self.center2div()\n    self.body_i()\n    self.body_text()\n    self.simplify_tags()\n    self.fix_spans_as_divs()\n\n    return self.soup\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.body_i","title":"<code>body_i()</code>","text":"<p>Wrap bare elements inside a p element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def body_i(self):\n\"\"\"Wrap bare elements inside a p element.\"\"\"\n    for tag in [\"a\", \"i\", \"em\", \"u\", \"strong\", \"span\"]:\n        for body_tag in self.soup.xpath(f\".//body/{tag}\"):\n            paragraph = etree.Element(\"p\")\n            bi_parent = body_tag.getparent()\n            bi_parent.insert(bi_parent.index(body_tag), paragraph)\n            paragraph.append(body_tag)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.body_text","title":"<code>body_text()</code>","text":"<p>Wrap bare text inside a p element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def body_text(self):\n\"\"\"Wrap bare text inside a p element.\"\"\"\n    body = self.soup.find(\".//body\")\n\n    if body.text is not None:\n        paragraph = etree.Element(\"p\")\n        paragraph.text = body.text\n        body.text = None\n        body.insert(0, paragraph)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.center2div","title":"<code>center2div()</code>","text":"<p>Convert center to div in tidy style.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def center2div(self):\n\"\"\"Convert center to div in tidy style.\"\"\"\n    for center in self.soup.xpath(\".//center\"):\n        center.tag = \"div\"\n        center.set(\"class\", \"c1\")\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.fix_spans_as_divs","title":"<code>fix_spans_as_divs()</code>","text":"<p>Turn div like elements into div.</p> <p>XHTML doesn't allow (and xhtml2corpus doesn't handle) span-like elements with div-like elements inside them; fix this and similar issues by turning them into divs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def fix_spans_as_divs(self):\n\"\"\"Turn div like elements into div.\n\n    XHTML doesn't allow (and xhtml2corpus doesn't handle) span-like\n    elements with div-like elements inside them; fix this and\n    similar issues by turning them into divs.\n    \"\"\"\n    spans_as_divs = self.soup.xpath(\n        \"//*[( descendant::div or descendant::p\"\n        \"      or descendant::h1 or descendant::h2\"\n        \"      or descendant::h3 or descendant::h4\"\n        \"      or descendant::h5 or descendant::h6 ) \"\n        \"and ( self::span or self::b or self::i\"\n        \"      or self::em or self::strong \"\n        \"      or self::a )\"\n        \"    ]\"\n    )\n    for elt in spans_as_divs:\n        elt.tag = \"div\"\n\n    ps_as_divs = self.soup.xpath(\"//p[descendant::div]\")\n    for elt in ps_as_divs:\n        elt.tag = \"div\"\n\n    lists_as_divs = self.soup.xpath(\n        \"//*[( child::ul or child::ol ) \" \"and ( self::ul or self::ol )\" \"    ]\"\n    )\n    for elt in lists_as_divs:\n        elt.tag = \"div\"\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.handle_font_children","title":"<code>handle_font_children(font_elt)</code>  <code>staticmethod</code>","text":"<p>Incorporate font children into correct element.</p> <p>Parameters:</p> Name Type Description Default <code>font_elt</code> <code>etree.Element</code> <p>a font element.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>@staticmethod\ndef handle_font_children(font_elt):\n\"\"\"Incorporate font children into correct element.\n\n    Args:\n        font_elt (etree.Element): a font element.\n    \"\"\"\n    font_parent = font_elt.getparent()\n    font_index = font_parent.index(font_elt)\n\n    for position, font_child in enumerate(font_elt, start=font_index):\n        if font_elt.tail is not None:\n            if font_elt[-1].tail is not None:\n                font_elt[-1].tail += font_elt.tail\n            else:\n                font_elt[-1].tail = font_elt.tail\n        font_parent.insert(position, font_child)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.handle_font_tail","title":"<code>handle_font_tail(font_elt)</code>  <code>staticmethod</code>","text":"<p>Incorporate font.tail into correct element.</p> <p>Parameters:</p> Name Type Description Default <code>font_elt</code> <code>etree.Element</code> <p>a font element.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>@staticmethod\ndef handle_font_tail(font_elt):\n\"\"\"Incorporate font.tail into correct element.\n\n    Args:\n        font_elt (etree.Element): a font element.\n    \"\"\"\n    font_parent = font_elt.getparent()\n    font_index = font_parent.index(font_elt)\n    previous_element = font_parent[font_index - 1]\n\n    if font_elt.tail is not None:\n        if font_index &gt; 0:\n            if previous_element.tail is not None:\n                previous_element.tail += font_elt.tail\n            else:\n                previous_element.tail = font_elt.tail\n        else:\n            if font_parent.text is not None:\n                font_parent.text += font_elt.tail\n            else:\n                font_parent.text = font_elt.tail\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.handle_font_text","title":"<code>handle_font_text(font_elt)</code>  <code>staticmethod</code>","text":"<p>Incorporate font.text into correct element.</p> <p>Parameters:</p> Name Type Description Default <code>font_elt</code> <code>etree.Element</code> <p>a font element.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>@staticmethod\ndef handle_font_text(font_elt):\n\"\"\"Incorporate font.text into correct element.\n\n    Args:\n        font_elt (etree.Element): a font element.\n    \"\"\"\n    font_parent = font_elt.getparent()\n    font_index = font_parent.index(font_elt)\n\n    if font_elt.text is not None:\n        if font_index &gt; 0:\n            previous_element = font_parent[font_index - 1]\n            if previous_element.tail is not None:\n                previous_element.tail += font_elt.text\n            else:\n                previous_element.tail = font_elt.text\n        else:\n            if font_elt.text is not None:\n                if font_parent.text is not None:\n                    font_parent.text += font_elt.text\n                else:\n                    font_parent.text = font_elt.text\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.remove_cruft","title":"<code>remove_cruft(content)</code>  <code>staticmethod</code>","text":"<p>Remove cruft from svenskakyrkan.se documents.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>the content of a document.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The content of the document without the cruft.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>@staticmethod\ndef remove_cruft(content):\n\"\"\"Remove cruft from svenskakyrkan.se documents.\n\n    Args:\n        content (str): the content of a document.\n\n    Returns:\n        str: The content of the document without the cruft.\n    \"\"\"\n    replacements = [(\"//&lt;script\", \"&lt;script\"), (\"&amp;nbsp;\", \" \"), (\"\u00a0\", \" \")]\n    return util.replace_all(replacements, content)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.remove_elements","title":"<code>remove_elements()</code>","text":"<p>Remove unwanted tags from a html document.</p> <p>The point with this exercise is to remove all but the main content of the document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def remove_elements(self):\n\"\"\"Remove unwanted tags from a html document.\n\n    The point with this exercise is to remove all but the main content of\n    the document.\n    \"\"\"\n    unwanted_classes_ids = {\n        \"div\": {\n            \"class\": [\n                \"skiplinks\",  # yle.fi\n                \"AddThis\",  # lansstyrelsen.se\n                \"InnholdForfatter\",  # unginordland\n                \"NavigationLeft\",  # lansstyrelsen.se\n                \"QuickNav\",\n                \"ad\",\n                \"andrenyheter\",  # tysfjord.kommune.no\n                \"art-layout-cell art-sidebar2\",  # gaaltije.se\n                \"art-postheadericons art-metadata-icons\",  # gaaltije.se\n                \"article-ad\",\n                \"article-bottom-element\",\n                \"article-column\",\n                (\n                    \"article-dateline article-dateline-footer \"\n                    \"meta-widget-content\"\n                ),  # nrk.no\n                (\n                    \"article-dateline article-footer \" \"container-widget-content cf\"\n                ),  # nrk.no\n                \"article-heading-wrapper\",  # 1177.se\n                \"article-info\",  # regjeringen.no\n                \"article-related\",\n                \"article-toolbar__tool\",  # umo.se\n                \"article-universe-teaser container-widget-content\",\n                \"articleImageRig\",\n                \"articlegooglemap\",  # tysfjord.kommune.no\n                \"articleTags\",  # nord-salten.no\n                \"attribute-related_object\",  # samediggi.no\n                \"authors\",\n                \"authors ui-helper-clearfix\",  # nord-salten.no\n                \"back_button\",\n                \"banner-element\",\n                \"bl_linktext\",\n                \"bottom-center\",\n                \"breadcrumbs \",\n                \"breadcrumbs\",\n                \"breadcrums span-12\",\n                \"btm_menu\",\n                \"byline\",  # arran.no\n                \"c1\",  # jll.se\n                \"art-bar art-nav\",  # gaaltije.se\n                \"art-layout-cell art-sidebar1\",  # gaaltije.se\n                \"clearfix breadcrumbsAndSocial noindex\",  # udir.no\n                \"complexDocumentBottom\",  # regjeringen.no\n                \"container-widget-content\",  # nrk.no\n                \"container_full\",\n                \"content-body attribute-vnd.openxmlformats-\"\n                \"officedocument.spreadsheetml.sheet\",  # samediggi.no\n                \"content-language-links\",  # metsa.fi\n                \"content-wrapper\",  # siida.fi\n                \"control-group field-wrapper tiedotteet-period\",  # metsa.fi\n                \"control-group form-inline\",  # metsa.fi\n                \"date\",  # samediggi.no, 2019 -&gt;\n                \"documentInfoEm\",\n                \"documentPaging\",\n                \"documentPaging PagingBtm\",  # regjeringen.no\n                \"documentTop\",  # regjeringen.no\n                \"dotList\",  # nord-salten.no\n                \"dropmenudiv\",  # calliidlagadus.org\n                \"embedFile\",  # samediggi.no -&gt; 2019\n                \"embedded-breadcrumbs\",\n                \"egavpi\",  # calliidlagadus.org\n                \"egavpi_fiskes\",  # calliidlagadus.org\n                \"esite_footer\",\n                \"esite_header\",\n                \"expandable\",\n                \"feedbackContainer noindex\",  # udir.no\n                \"file\",  # samediggi.no\n                \"fixed-header\",\n                \"g100 col fc s18 sg6 sg9 sg12 menu-reference\",  # nrk.no\n                \"g100 col fc s18 sg6 sg9 sg12 flow-reference\",  # nrk.no\n                \"g11 col fl s2 sl6 sl9 sl12 sl18\",  # nrk.no\n                \"g22 col fl s4 sl6 sl9 sl12 sl18 \"\n                \"article-header-sidebar\",  # nrk.no\n                \"g94 col fl s17 sl18 sg6 sg9 sg12 meta-widget\",  # nrk.no\n                \"globmenu\",  # visitstetind.no\n                \"grid cf\",  # nrk.no\n                \"help closed hidden-xs\",\n                \"historic-info\",  # regjeringen.no\n                \"historic-label\",  # regjeringen.no\n                \"imagecontainer\",\n                \"innholdsfortegenlse-child\",\n                \"inside\",  # samas.no\n                \"latestnews_uutisarkisto\",\n                \"ld-navbar\",\n                \"listArticleLink\",  # samediggi.no -&gt; 2019\n                \"logo-links\",  # metsa.fi\n                \"meta\",\n                \"meta ui-helper-clearfix\",  # nord-salten.no\n                \"authors ui-helper-clearfix\",  # nord-salten.no\n                \"menu\",  # visitstetind.no\n                \"metaWrapper\",\n                \"mini-frontpage\",  # yle.fi\n                \"moduletable_oikopolut\",\n                \"moduletable_etulinkki\",  # www.samediggi.fi\n                \"navigation\",  # latex2html docs\n                \"nav-menu nav-menu-style-dots\",  # metsa.fi\n                \"naviHlp\",  # visitstetind.no\n                \"noindex\",  # ntfk\n                \"nrk-globalfooter\",  # nrk.no\n                \"nrk-globalfooter-dk lp_globalfooter\",  # nrk.no\n                \"nrk-globalnavigation\",  # nrk.no\n                \"nrkno-share bulletin-share\",  # nrk.no\n                \"outer-column\",\n                \"page-inner\",  # samas.no\n                \"person_info\",  # samediggi.no\n                \"plug-teaser\",  # nrk.no\n                \"post-footer\",\n                \"printbutton-wrapper\",  # 1177.se\n                \"printContact\",\n                \"right\",  # ntfk\n                \"rightverticalgradient\",  # udir.no\n                \"sharebutton-wrapper\",  # 1177.se\n                \"sharing\",\n                \"sidebar\",\n                \"spalte300\",  # osko.no\n                \"span12 tiedotteet-show\",\n                \"subpage-bottom\",\n                \"subfooter\",  # visitstetind.no\n                \"subnavigation\",  # oikeusministeri\u00f6\n                \"tabbedmenu\",\n                \"tipformcontainer\",  # tysfjord.kommune.no\n                \"tipsarad mt6 selfClear\",\n                \"titlepage\",\n                \"toc-placeholder\",  # 1177.se\n                \"toc\",\n                \"tools\",  # arran.no\n                \"trail\",  # siida.fi\n                \"translations\",  # siida.fi\n                \"upperheader\",\n            ],\n            \"id\": [\n                \"oikea_palsta\",  # yle.fi\n                \"ylefifooter\",  # yle.fi\n                \"print-logo-wrapper\",  # 1177.se\n                \"AreaLeft\",\n                \"AreaLeftNav\",\n                \"AreaRight\",\n                \"AreaTopRight\",\n                \"AreaTopSiteNav\",\n                \"NAVbreadcrumbContainer\",\n                \"NAVfooterContainer\",\n                \"NAVheaderContainer\",\n                \"NAVrelevantContentContainer\",\n                \"NAVsubmenuContainer\",\n                \"PageFooter\",\n                \"PageLanguageInfo\",  # regjeringen.no\n                \"PrintDocHead\",\n                \"SamiDisclaimer\",\n                \"ShareArticle\",\n                \"WIPSELEMENT_CALENDAR\",  # learoevierhtieh.no\n                \"WIPSELEMENT_HEADING\",  # learoevierhtieh.no\n                \"WIPSELEMENT_MENU\",  # learoevierhtieh.no\n                \"WIPSELEMENT_MENURIGHT\",  # learoevierhtieh.no\n                \"WIPSELEMENT_NEWS\",  # learoevierhtieh.no\n                \"WebPartZone1\",  # lansstyrelsen.se\n                \"aa\",\n                \"andrenyheter\",  # tysfjord.kommune.no\n                \"article_footer\",\n                \"attached\",  # tysfjord.kommune.no\n                \"blog-pager\",\n                \"bottom\",  # samas.no\n                \"breadcrumbs-bottom\",\n                \"bunninformasjon\",  # unginordland\n                \"chatBox\",\n                \"chromemenu\",  # calliidlagadus.org\n                \"crumbs\",  # visitstetind.no\n                \"ctl00_AccesskeyShortcuts\",  # lansstyrelsen.se\n                \"ctl00_ctl00_ArticleFormContentRegion_\"\n                \"ArticleBodyContentRegion_ctl00_\"\n                \"PageToolWrapper\",  # 1177.se\n                \"ctl00_ctl00_ArticleFormContentRegion_\"\n                \"ArticleBodyContentRegion_ctl03_\"\n                \"PageToolWrapper\",  # 1177.se\n                \"ctl00_Cookies\",  # lansstyrelsen.se\n                \"ctl00_FullRegion_CenterAndRightRegion_HitsControl_\"\n                \"ctl00_FullRegion_CenterAndRightRegion_Sorting_sortByDiv\",\n                \"ctl00_LSTPlaceHolderFeedback_\"\n                \"editmodepanel31\",  # lansstyrelsen.se\n                \"ctl00_LSTPlaceHolderSearch_\"\n                \"SearchBoxControl\",  # lansstyrelsen.se\n                \"ctl00_MidtSone_ucArtikkel_ctl00_ctl00_ctl01_divRessurser\",\n                \"ctl00_MidtSone_ucArtikkel_ctl00_divNavigasjon\",\n                \"ctl00_PlaceHolderMain_EditModePanel1\",  # lansstyrelsen.se\n                \"ctl00_PlaceHolderTitleBreadcrumb_\"\n                \"DefaultBreadcrumb\",  # lansstyrelsen.se\n                \"ctl00_TopLinks\",  # lansstyrelsen.se\n                \"deleModal\",\n                \"document-header\",\n                \"errorMessageContainer\",  # nord-salten.no\n                \"final-footer-wrapper\",  # 1177.se\n                \"flu-vaccination\",  # 1177.se\n                \"footer\",  # forrest, too, tysfjord.kommune.no\n                \"footer-wrapper\",\n                \"frontgallery\",  # visitstetind.no\n                \"header\",\n                \"headerBar\",\n                \"headWrapper\",  # osko.no\n                \"hoyre\",  # unginordland\n                \"innholdsfortegnelse\",  # regjeringen.no\n                \"leftMenu\",\n                \"leftPanel\",\n                \"leftbar\",  # forrest (divvun and giellatekno sites)\n                \"leftcol\",  # new samediggi.no\n                \"leftmenu\",\n                \"main_navi_main\",  # www.samediggi.fi\n                \"mainContentBookmark\",  # udir.no\n                \"mainsidebar\",  # arran.no\n                \"menu\",\n                \"mobile-header\",\n                \"mobile-subnavigation\",\n                \"murupolku\",  # www.samediggi.fi\n                \"nav-content\",\n                \"navbar\",  # tysfjord.kommune.no\n                \"ncFooter\",  # visitstetind.no\n                \"ntfkFooter\",  # ntfk\n                \"ntfkHeader\",  # ntfk\n                \"ntfkNavBreadcrumb\",  # ntfk\n                \"ntfkNavMain\",  # ntfk\n                \"pageFooter\",\n                \"path\",  # new samediggi.no, tysfjord.kommune.no\n                \"phone-bar\",  # 1177.se\n                \"publishinfo\",  # 1177.se\n                \"readspeaker_button1\",\n                \"right-wrapper\",  # ndla\n                \"rightAds\",\n                \"rightCol\",\n                \"rightside\",\n                \"s4-leftpanel\",  # ntfk\n                \"searchBox\",\n                \"searchHitSummary\",\n                \"sendReminder\",\n                \"share-article\",\n                \"sidebar\",  # finlex.fi, too\n                \"sidebar-wrapper\",\n                \"sitemap\",\n                \"skipLinks\",  # udir.no\n                \"skiplink\",  # tysfjord.kommune.no\n                \"spraakvelger\",  # osko.no\n                \"subfoote\",  # visitstetind.no\n                \"submenu\",  # nord-salten.no\n                \"svid10_49531bad1412ceb82564aea\",  # ostersund.se\n                \"svid10_6ba9fa711d2575a2a7800024318\",  # jll.se\n                \"svid10_6c1eb18a13ec7d9b5b82ee7\",  # ostersund.se\n                \"svid10_b0dabad141b6aeaf101229\",  # ostersund.se\n                \"svid10_49531bad1412ceb82564af3\",  # ostersund.se\n                \"svid10_6ba9fa711d2575a2a7800032145\",  # jll.se\n                \"svid10_6ba9fa711d2575a2a7800032151\",  # jll.se\n                \"svid10_6ba9fa711d2575a2a7800024344\",  # jll.se\n                \"svid10_6ba9fa711d2575a2a7800032135\",  # jll.se\n                \"svid10_6c1eb18a13ec7d9b5b82ee3\",  # ostersund.se\n                \"svid10_6c1eb18a13ec7d9b5b82edf\",  # ostersund.se\n                \"svid10_6c1eb18a13ec7d9b5b82edd\",  # ostersund.se\n                \"svid10_6c1eb18a13ec7d9b5b82eda\",  # ostersund.se\n                \"svid10_6c1eb18a13ec7d9b5b82ed5\",  # ostersund.se\n                \"svid12_6ba9fa711d2575a2a7800032140\",  # jll.se\n                \"theme-area-label-wrapper\",  # 1177.se\n                \"tipafriend\",\n                \"tools\",  # arran.no\n                \"topHeader\",  # nord-salten.no\n                \"topMenu\",\n                \"topUserMenu\",\n                \"top\",  # arran.no\n                \"topnav\",  # tysfjord.kommune.no\n                \"toppsone\",  # unginordland\n                \"vedleggogregistre\",  # regjeringen.no\n                \"venstre\",  # unginordland\n                \"static-menu-inner\",  # arran.no\n            ],\n        },\n        \"p\": {\n            \"class\": [\n                \"WebPartReadMoreParagraph\",\n                \"breadcrumbs\",\n                \"langs\",  # oahpa.no\n                \"art-page-footer\",  # gaaltije.se\n            ],\n            \"id\": [\"skip-link\"],  # samas.no\n        },\n        \"ul\": {\n            \"id\": [\n                \"AreaTopLanguageNav\",\n                \"AreaTopPrintMeny\",\n                \"skiplinks\",  # umo.se\n                \"mainmenu\",  # admin/tysfjord\n            ],\n            \"class\": [\n                \"QuickNav\",\n                \"article-tools\",\n                \"article-universe-list\",  # nrk.no\n                \"byline\",\n                \"chapter-index\",  # lovdata.no\n                \"footer-nav\",  # lovdata.no\n                \"hidden\",  # unginordland\n                \"mainmenu menu menulevel0\",  # admin/tysfjord\n            ],\n        },\n        \"span\": {\n            \"id\": [\"skiplinks\"],\n            \"class\": [\n                \"K-NOTE-FOTNOTE\",\n                \"graytext\",  # svenskakyrkan.se\n                \"breadcrumbs pathway\",  # gaaltije.se\n                \"meta\",  # yle.fi\n            ],\n        },\n        \"a\": {\n            \"id\": [\"ctl00_IdWelcome_ExplicitLogin\", \"leftPanelTab\"],  # ntfk\n            \"class\": [\n                \"addthis_button_print\",  # ntfk\n                \"mainlevel\",\n                \"share-paragraf\",  # lovdata.no\n                \"mainlevel_alavalikko\",  # www.samediggi.fi\n                \"sublevel_alavalikko\",  # www.samediggi.fi\n                \"skip-link\",  # 1177.se\n                \"toggle-link expanded\",  # 1177.se\n            ],\n            \"name\": [\"footnote-ref\"],  # footnotes in running text\n        },\n        \"td\": {\n            \"id\": [\n                \"hakulomake\",  # www.samediggi.fi\n                \"paavalikko_linkit\",  # www.samediggi.fi\n                \"sg_oikea\",  # www.samediggi.fi\n                \"sg_vasen\",  # www.samediggi.fi\n            ],\n            \"class\": [\"modifydate\"],\n        },\n        \"tr\": {\"id\": [\"sg_ylaosa1\", \"sg_ylaosa2\"]},\n        \"header\": {\n            \"id\": [\"header\"],  # umo.se\n            \"class\": [\n                \"nrk-masthead-content cf\",  # nrk.no\n                \"pageHeader \",  # regjeringen.no\n                \"singleton widget rich nrk-masthead lp_masthead\",  # nrk.no\n            ],\n        },\n        \"section\": {\n            \"class\": [\n                \"recents-on-this-topic\",  # yle.fi\n                \"section-theme-sub-nav\",  # 1177.se\n                \"span3\",  # samernas.se\n                \"tree-menu current\",  # umo.se\n                \"tree-menu\",  # umo.se\n            ]\n        },\n        \"table\": {\"id\": [\"Table_01\"]},\n    }\n\n    namespace = {\"html\": \"http://www.w3.org/1999/xhtml\"}\n    for tag, attribs in unwanted_classes_ids.items():\n        for key, values in attribs.items():\n            for value in values:\n                search = f'.//{tag}[@{key}=\"{value}\"]'\n                for unwanted in self.soup.xpath(search, namespaces=namespace):\n                    unwanted.getparent().remove(unwanted)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.remove_empty_class","title":"<code>remove_empty_class()</code>","text":"<p>Delete empty class attributes.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def remove_empty_class(self):\n\"\"\"Delete empty class attributes.\"\"\"\n    for element in self.soup.xpath('.//*[@class=\"\"]'):\n        del element.attrib[\"class\"]\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.remove_empty_p","title":"<code>remove_empty_p()</code>","text":"<p>Remove empty p elements.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def remove_empty_p(self):\n\"\"\"Remove empty p elements.\"\"\"\n    paragraphs = self.soup.xpath(\"//p\")\n\n    for elt in paragraphs:\n        if elt.text is None and elt.tail is None and not len(elt):\n            elt.getparent().remove(elt)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.remove_font","title":"<code>remove_font()</code>","text":"<p>Remove font elements, incorporate content into it's parent.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def remove_font(self):\n\"\"\"Remove font elements, incorporate content into it's parent.\"\"\"\n    for font_elt in reversed(list(self.soup.iter(\"{*}font\"))):\n        self.handle_font_text(font_elt)\n\n        if len(font_elt) &gt; 0:\n            self.handle_font_children(font_elt)\n        else:\n            self.handle_font_tail(font_elt)\n\n        font_elt.getparent().remove(font_elt)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.simplify_tags","title":"<code>simplify_tags()</code>","text":"<p>Turn tags to divs.</p> <p>We don't care about the difference between ,  etc. \u2013 treat them all as 's for xhtml2corpus Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def simplify_tags(self):\n\"\"\"Turn tags to divs.\n\n    We don't care about the difference between &lt;fieldsets&gt;, &lt;legend&gt;\n    etc. \u2013 treat them all as &lt;div&gt;'s for xhtml2corpus\n    \"\"\"\n    superfluously_named_tags = self.soup.xpath(\n        \"//fieldset | //legend | //article | //hgroup \"\n        \"| //section | //dl | //dd | //dt\"\n        \"| //menu\"\n    )\n    for elt in superfluously_named_tags:\n        elt.tag = \"div\"\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.HTMLBeautifier.superclean","title":"<code>superclean(content)</code>","text":"<p>Remove unwanted elements from an html document.</p> <p>Returns:</p> Type Description <p>a string containing the cleaned up html document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def superclean(self, content):\n\"\"\"Remove unwanted elements from an html document.\n\n    Args:\n        content is a string containing an html document.\n\n    Returns:\n        a string containing the cleaned up html document.\n    \"\"\"\n    cleaner = clean.Cleaner(\n        page_structure=False,\n        scripts=True,\n        javascript=True,\n        comments=True,\n        style=True,\n        processing_instructions=True,\n        remove_unknown_tags=True,\n        embedded=True,\n        kill_tags=[\n            \"img\",\n            \"area\",\n            \"address\",\n            \"hr\",\n            \"cite\",\n            \"footer\",\n            \"figcaption\",\n            \"aside\",\n            \"time\",\n            \"figure\",\n            \"nav\",\n            \"noscript\",\n            \"map\",\n            \"ins\",\n            \"s\",\n            \"colgroup\",\n        ],\n    )\n\n    return cleaner.clean_html(self.remove_cruft(content))\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.add_p_instead_of_tail","title":"<code>add_p_instead_of_tail(intermediate)</code>","text":"<p>Convert tail in list and p to a p element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def add_p_instead_of_tail(intermediate):\n\"\"\"Convert tail in list and p to a p element.\"\"\"\n    for element in [\"list\", \"p\"]:\n        for found_element in intermediate.findall(\".//\" + element):\n            if found_element.tail is not None and found_element.tail.strip() != \"\":\n                new_p = etree.Element(\"p\")\n                new_p.text = found_element.tail\n                found_element.tail = None\n                found_element.addnext(new_p)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.convert2intermediate","title":"<code>convert2intermediate(filename)</code>","text":"<p>Convert a webpage to Giella xml.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of the file</p> required <p>Returns:</p> Type Description <p>etree.Element: the root element of the Giella xml document</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def convert2intermediate(filename):\n\"\"\"Convert a webpage to Giella xml.\n\n    Args:\n        filename (str): name of the file\n\n    Returns:\n        etree.Element: the root element of the Giella xml document\n    \"\"\"\n    return xhtml2intermediate(to_html_elt(filename))\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.replace_bare_text","title":"<code>replace_bare_text(body)</code>","text":"<p>Replace bare text in body with a p element.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>etree.Element</code> <p>the body element of the html document</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def replace_bare_text(body):\n\"\"\"Replace bare text in body with a p element.\n\n    Args:\n        body (etree.Element): the body element of the html document\n    \"\"\"\n    if body.text is not None and body.text.strip() != \"\":\n        new_p = etree.Element(\"p\")\n        new_p.text = body.text\n        body.text = None\n        body.insert(0, new_p)\n</code></pre>"},{"location":"reference/htmlcontentconverter/#corpustools.htmlcontentconverter.xhtml2intermediate","title":"<code>xhtml2intermediate(content_xml)</code>","text":"<p>Convert xhtml to Giella xml.</p> <p>Parameters:</p> Name Type Description Default <code>xhtml</code> <code>etree.Element</code> <p>the result of convert2xhtml</p> required <p>Returns:</p> Type Description <p>etree.Element: the root element of the Giella xml document</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlcontentconverter.py</code> <pre><code>def xhtml2intermediate(content_xml):\n\"\"\"Convert xhtml to Giella xml.\n\n    Args:\n        xhtml (etree.Element): the result of convert2xhtml\n\n    Returns:\n        etree.Element: the root element of the Giella xml document\n    \"\"\"\n    converter_xsl = os.path.join(HERE, \"xslt/xhtml2corpus.xsl\")\n\n    html_xslt_root = etree.parse(converter_xsl)\n    transform = etree.XSLT(html_xslt_root)\n\n    intermediate = transform(HTMLBeautifier(content_xml).beautify())\n    beautify_intermediate(intermediate)\n\n    return intermediate.getroot()\n</code></pre>"},{"location":"reference/htmlconverter/","title":"htmlconverter","text":"<p>Convert html files to the Giella xml format.</p>"},{"location":"reference/htmlconverter/#corpustools.htmlconverter.HTMLError","title":"<code>HTMLError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raise this error in this module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlconverter.py</code> <pre><code>class HTMLError(Exception):\n\"\"\"Raise this error in this module.\"\"\"\n</code></pre>"},{"location":"reference/htmlconverter/#corpustools.htmlconverter.remove_declared_encoding","title":"<code>remove_declared_encoding(content)</code>","text":"<p>Remove declared decoding.</p> <p>lxml explodes if we send a decoded Unicode string with an xml-declared encoding http://lxml.de/parsing.html#python-unicode-strings</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>the contents of a html document</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>content sans the declared decoding</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlconverter.py</code> <pre><code>def remove_declared_encoding(content):\n\"\"\"Remove declared decoding.\n\n    lxml explodes if we send a decoded Unicode string with an\n    xml-declared encoding\n    http://lxml.de/parsing.html#python-unicode-strings\n\n    Args:\n        content (str): the contents of a html document\n\n    Returns:\n        str: content sans the declared decoding\n    \"\"\"\n    xml_encoding_declaration_re = re.compile(\n        r\"^&lt;\\?xml [^&gt;]*encoding=[\\\"']([^\\\"']+)[^&gt;]*\\?&gt;[ \\r\\n]*\", re.IGNORECASE\n    )\n\n    return re.sub(xml_encoding_declaration_re, \"\", content)\n</code></pre>"},{"location":"reference/htmlconverter/#corpustools.htmlconverter.to_html_elt","title":"<code>to_html_elt(filename)</code>","text":"<p>Return the content of the html doc as a string.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the webpage</p> required <p>Returns:</p> Type Description <p>etree.Element: the content of the webpage sent through the lxml.html5parser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/htmlconverter.py</code> <pre><code>def to_html_elt(filename):\n\"\"\"Return the content of the html doc as a string.\n\n    Args:\n        filename (str): path to the webpage\n\n    Returns:\n        etree.Element: the content of the webpage sent through the\n            lxml.html5parser.\n    \"\"\"\n    for encoding in [\"utf-8\", \"windows-1252\", \"latin1\"]:\n        try:\n            with codecs.open(filename, encoding=encoding) as file_:\n                parser = etree.HTMLParser(remove_comments=True)\n                return html.document_fromstring(\n                    remove_declared_encoding(file_.read()), parser=parser\n                )\n        except UnicodeDecodeError:\n            pass\n\n    raise HTMLError(f\"{filename}: encoding trouble\")\n</code></pre>"},{"location":"reference/iso_ir_197/","title":"iso_ir_197","text":"<p>Python Character Mapping Codec for iso-ir-197.</p>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.Codec","title":"<code>Codec</code>","text":"<p>         Bases: <code>codecs.Codec</code></p> <p>Implement the interface for stateless encoders/decoders.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>class Codec(codecs.Codec):\n\"\"\"Implement the interface for stateless encoders/decoders.\"\"\"\n\n    def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n                'backslashreplace'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_encode(instring, errors, encoding_table)\n\n    def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace' or 'ignore'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.Codec.decode","title":"<code>decode(instring, errors='strict')</code>","text":"<p>Decode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace' or 'ignore'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace' or 'ignore'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.Codec.encode","title":"<code>encode(instring, errors='strict')</code>","text":"<p>Encode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace', 'ignore',  'xmlcharrefreplace' or 'backslashreplace'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n            'backslashreplace'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_encode(instring, errors, encoding_table)\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.IncrementalDecoder","title":"<code>IncrementalDecoder</code>","text":"<p>         Bases: <code>codecs.IncrementalDecoder</code></p> <p>Implement an IncrementalDecoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>class IncrementalDecoder(codecs.IncrementalDecoder):\n\"\"\"Implement an IncrementalDecoder.\"\"\"\n\n    def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.IncrementalDecoder.decode","title":"<code>decode(instring, final=False)</code>","text":"<p>Decode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.IncrementalEncoder","title":"<code>IncrementalEncoder</code>","text":"<p>         Bases: <code>codecs.IncrementalEncoder</code></p> <p>Implement an IncrementalEncoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>class IncrementalEncoder(codecs.IncrementalEncoder):\n\"\"\"Implement an IncrementalEncoder.\"\"\"\n\n    def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.IncrementalEncoder.encode","title":"<code>encode(instring, final=False)</code>","text":"<p>Encode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.getregentry","title":"<code>getregentry()</code>","text":"<p>Get the info for this encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>def getregentry():\n\"\"\"Get the info for this encoding.\"\"\"\n    return codecs.CodecInfo(\n        name=\"ir197\",\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=codecs.StreamReader,\n        streamwriter=codecs.StreamWriter,\n    )\n</code></pre>"},{"location":"reference/iso_ir_197/#corpustools.iso_ir_197.lookup","title":"<code>lookup(encoding)</code>","text":"<p>Lookup the name of the encoding.</p> <p>Parameters:</p> Name Type Description Default <code>encoding</code> <code>str</code> <p>name of the encoding</p> required <p>Returns:</p> Type Description <p>Codecs.CodecInfo if encoding is the name of the encoding of this file, None otherwise.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_197.py</code> <pre><code>def lookup(encoding):\n\"\"\"Lookup the name of the encoding.\n\n    Args:\n        encoding (str): name of the encoding\n\n    Returns:\n        Codecs.CodecInfo if encoding is the name of the encoding of\n            this file, None otherwise.\n    \"\"\"\n    if encoding == \"ir197\":\n        return getregentry()\n    return None\n</code></pre>"},{"location":"reference/iso_ir_209/","title":"iso_ir_209","text":"<p>Python Character Mapping Codec for iso-ir-209.</p>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.Codec","title":"<code>Codec</code>","text":"<p>         Bases: <code>codecs.Codec</code></p> <p>Implement the interface for stateless encoders/decoders.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>class Codec(codecs.Codec):\n\"\"\"Implement the interface for stateless encoders/decoders.\"\"\"\n\n    def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n                'backslashreplace'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_encode(instring, errors, encoding_table)\n\n    def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace' or 'ignore'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.Codec.decode","title":"<code>decode(instring, errors='strict')</code>","text":"<p>Decode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace' or 'ignore'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace' or 'ignore'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.Codec.encode","title":"<code>encode(instring, errors='strict')</code>","text":"<p>Encode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace', 'ignore',  'xmlcharrefreplace' or 'backslashreplace'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n            'backslashreplace'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_encode(instring, errors, encoding_table)\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.IncrementalDecoder","title":"<code>IncrementalDecoder</code>","text":"<p>         Bases: <code>codecs.IncrementalDecoder</code></p> <p>Implement an IncrementalDecoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>class IncrementalDecoder(codecs.IncrementalDecoder):\n\"\"\"Implement an IncrementalDecoder.\"\"\"\n\n    def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.IncrementalDecoder.decode","title":"<code>decode(instring, final=False)</code>","text":"<p>Decode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.IncrementalEncoder","title":"<code>IncrementalEncoder</code>","text":"<p>         Bases: <code>codecs.IncrementalEncoder</code></p> <p>Implement an IncrementalEncoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>class IncrementalEncoder(codecs.IncrementalEncoder):\n\"\"\"Implement an IncrementalEncoder.\"\"\"\n\n    def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.IncrementalEncoder.encode","title":"<code>encode(instring, final=False)</code>","text":"<p>Encode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.getregentry","title":"<code>getregentry()</code>","text":"<p>Get the info for this encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>def getregentry():\n\"\"\"Get the info for this encoding.\"\"\"\n    return codecs.CodecInfo(\n        name=\"ir209\",\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=codecs.StreamReader,\n        streamwriter=codecs.StreamWriter,\n    )\n</code></pre>"},{"location":"reference/iso_ir_209/#corpustools.iso_ir_209.lookup","title":"<code>lookup(encoding)</code>","text":"<p>Lookup the name of the encoding.</p> <p>Parameters:</p> Name Type Description Default <code>encoding</code> <code>str</code> <p>name of the encoding</p> required <p>Returns:</p> Type Description <p>Codecs.CodecInfo if encoding is the name of the encoding of this file, None otherwise.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/iso_ir_209.py</code> <pre><code>def lookup(encoding):\n\"\"\"Lookup the name of the encoding.\n\n    Args:\n        encoding (str): name of the encoding\n\n    Returns:\n        Codecs.CodecInfo if encoding is the name of the encoding of\n            this file, None otherwise.\n    \"\"\"\n    if encoding == \"ir209\":\n        return getregentry()\n    return None\n</code></pre>"},{"location":"reference/korp_mono/","title":"korp_mono","text":"<p>Turn analysed files into Korp files.</p>"},{"location":"reference/korp_mono/#corpustools.korp_mono.extract_original_analysis","title":"<code>extract_original_analysis(used_analysis, language)</code>","text":"<p>Filter all Err- and Sem-tags from the string.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def extract_original_analysis(used_analysis, language):\n\"\"\"Filter all Err- and Sem-tags from the string.\"\"\"\n    # lang-nob produces:\n    # Use/Circ Use/SpellNoSugg\"CWD\" N Prop Sem/Org ACR Dyn Err/Orth Msc Sg Indef\n    # make a space in front of the first \"\"\n    for strange_use in [\"Circ\", \"SpellNoSugg\"]:\n        used_analysis = used_analysis.replace(\n            f'Use/{strange_use}\"', f'Use/{strange_use} \"'\n        )\n    if language == \"sme\":\n        used_analysis = group_sem(used_analysis)\n    else:\n        used_analysis = re.sub(r\"Sem/[^\\s]+\\s\", \"\", used_analysis)\n\n    for regex in [\n        r\"Use/[^\\s]+\\s\",\n        r\"Gram/[^\\s]+\\s\",\n        r\"OLang/[^\\s]+\\s\",\n        r\"Dial/[^\\s]+\\s\",\n        r\"CmpN/[^\\s]+\\s\",\n        r\"CmpNP/[^\\s]+\\s\",\n        r\"G3+\\s\",\n        r\"v9+\\s\",\n        r\"Err/[^\\s]+\\s\",\n    ]:\n        used_analysis = re.sub(regex, \"\", used_analysis)\n\n    return used_analysis\n</code></pre>"},{"location":"reference/korp_mono/#corpustools.korp_mono.lemma_generation","title":"<code>lemma_generation(original_analysis, pos, _current_lang)</code>","text":"<p>Generate lemma.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def lemma_generation(original_analysis, pos, _current_lang):\n\"\"\"Generate lemma.\"\"\"\n    if \"Ex/\" in original_analysis or \"_\u2122_\" in original_analysis:\n        lemma_generation_string = get_generation_string(\n            original_analysis, pos, _current_lang\n        )\n\n        if lemma_generation_string:\n            return generate_lemma(lemma_generation_string, _current_lang)\n\n    return \"\"\n</code></pre>"},{"location":"reference/korp_mono/#corpustools.korp_mono.make_morpho_syntactic_description","title":"<code>make_morpho_syntactic_description(rest)</code>","text":"<p>Extract morpho_syntactic_description</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def make_morpho_syntactic_description(rest):\n\"\"\"Extract morpho_syntactic_description\"\"\"\n    ex_in_r = rest.find(\"_\u00a9_\")\n    tm_in_r = rest.find(\"_\u2122_\")\n\n    # split derivation/composition string from the rest of MSD\n    # and put it in and extra tuple at the end of the tuple list,\n    # otherwise add a default tuple '___'\n    # no derivation, no composition\n    if ex_in_r == -1 and tm_in_r == -1:\n        return rest\n        ###logging.info('_msd_cds_1_|'+str(msd)+'|_|'+str(dcs)+'|_')\n    # no derivation, but composition\n    elif (ex_in_r == -1 and not tm_in_r == -1) or (\n        not ex_in_r == -1 and not tm_in_r == -1 and tm_in_r &lt; ex_in_r\n    ):\n        return re.compile(\"_\u2122_\").split(rest, 1)[0]\n    # derivation, but no composition\n    elif (not ex_in_r == -1 and tm_in_r == -1) or (\n        not ex_in_r == -1 and not tm_in_r == -1 and ex_in_r &lt; tm_in_r\n    ):\n        return re.compile(\"_\u00a9_\").split(rest, 1)[0]\n    # covered all relevant combinations?\n    else:\n        return \"\"\n</code></pre>"},{"location":"reference/korp_mono/#corpustools.korp_mono.make_sentences","title":"<code>make_sentences(sentences, current_lang)</code>","text":"<p>Make sentences from the current analysis.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def make_sentences(sentences, current_lang):\n\"\"\"Make sentences from the current analysis.\"\"\"\n    return [\n        make_sentence(current_sentence, current_lang) for current_sentence in sentences\n    ]\n</code></pre>"},{"location":"reference/korp_mono/#corpustools.korp_mono.make_vrt_xml","title":"<code>make_vrt_xml(current_file, lang)</code>","text":"<p>Convert analysis of a file into a vrt file</p> <p>Converting the analysis output into a suitable xml format for vrt transformation (vrt is the cwb input format)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def make_vrt_xml(current_file, lang):\n\"\"\"Convert analysis of a file into a vrt file\n\n    Converting the analysis output into a suitable xml format for vrt\n    transformation (vrt is the cwb input format)\n    \"\"\"\n    p = etree.XMLParser(encoding=\"utf-8\", huge_tree=True)\n    xml_tree = etree.parse(current_file, parser=p)\n    old_root = xml_tree.getroot()\n\n    f_root = make_root_element(old_root)\n    for s_id, sentence in enumerate(\n        make_sentences(valid_sentences(old_root.find(\".//body/dependency\").text), lang)\n    ):\n        current_sentence = etree.SubElement(f_root, \"sentence\")\n        current_sentence.set(\"id\", str(s_id + 1))\n        current_sentence.text = sentence\n\n    pad_elements(f_root)\n\n    return f_root\n</code></pre>"},{"location":"reference/korp_mono/#corpustools.korp_mono.pad_elements","title":"<code>pad_elements(elem)</code>","text":"<p>Make sure empty text or tail is padded with newline.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def pad_elements(elem):\n\"\"\"Make sure empty text or tail is padded with newline.\"\"\"\n    padding = \"\\n\"\n    if len(elem):\n        if not elem.text or not elem.text.strip():\n            elem.text = padding\n        for child in elem:\n            pad_elements(child)\n    if not elem.tail or not elem.tail.strip():\n        elem.tail = padding\n</code></pre>"},{"location":"reference/korp_mono/#corpustools.korp_mono.process_file","title":"<code>process_file(current_file, lang)</code>","text":"<p>Convert analysed file into vrt format file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def process_file(current_file, lang):\n\"\"\"Convert analysed file into vrt format file.\"\"\"\n    print(f\"... processing {current_file}\")\n    analysed_file = corpuspath.CorpusPath(current_file)\n    path = analysed_file.korp\n    print(f\"path={path}\")\n\n    with util.ignored(OSError):\n        os.makedirs(os.path.dirname(path))\n\n    with open(path, \"wb\") as newfile_stream:\n        newfile_stream.write(\n            etree.tostring(\n                make_vrt_xml(current_file, lang),\n                xml_declaration=False,\n                encoding=\"utf-8\",\n            )\n        )\n    print(\"DONE \", path, \"\\n\\n\")\n</code></pre>"},{"location":"reference/korp_mono/#corpustools.korp_mono.process_in_parallel","title":"<code>process_in_parallel(lang, files_list)</code>","text":"<p>Process file in parallel.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_mono.py</code> <pre><code>def process_in_parallel(lang, files_list):\n\"\"\"Process file in parallel.\"\"\"\n\n    pool_size = multiprocessing.cpu_count() * 2\n    pool = multiprocessing.Pool(processes=pool_size)\n    pool.map(partial(process_file, lang=lang), files_list)\n    pool.close()  # no more tasks\n    pool.join()  # wrap up current tasks\n    return\n</code></pre>"},{"location":"reference/korp_para/","title":"korp_para","text":""},{"location":"reference/korp_para/#corpustools.korp_para.process_in_parallel","title":"<code>process_in_parallel(files_list)</code>","text":"<p>Process file in parallel.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/korp_para.py</code> <pre><code>def process_in_parallel(files_list):\n\"\"\"Process file in parallel.\"\"\"\n\n    pool_size = multiprocessing.cpu_count() * 2\n    pool = multiprocessing.Pool(processes=pool_size)\n    pool.map(process_file, files_list)\n    pool.close()  # no more tasks\n    pool.join()  # wrap up current tasks\n    return\n</code></pre>"},{"location":"reference/languagedetector/","title":"languagedetector","text":"<p>This file contains classes fix converted documents.</p>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector","title":"<code>LanguageDetector</code>","text":"<p>Detect and set the languages of a document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/languagedetector.py</code> <pre><code>class LanguageDetector:\n\"\"\"Detect and set the languages of a document.\"\"\"\n\n    def __init__(self, document, language_guesser):\n\"\"\"Initialise the LanguageDetector class.\n\n        Args:\n            document: an etree element.\n            languageGuesser: a text_cat.Classifier.\n        \"\"\"\n        self.document = document\n        self.language_guesser = language_guesser\n\n    @property\n    def inlangs(self):\n\"\"\"Return the predifined possible languages of the document.\"\"\"\n        inlangs = [\n            language.get(\"{http://www.w3.org/XML/1998/namespace}\" \"lang\")\n            for language in self.document.findall(\"header/multilingual/language\")\n        ]\n        if inlangs:\n            inlangs.append(self.mainlang)\n\n        return inlangs\n\n    @property\n    def mainlang(self):\n\"\"\"Get the mainlang of the file.\"\"\"\n        return self.document.attrib[\"{http://www.w3.org/XML/1998/namespace}lang\"]\n\n    def set_paragraph_language(self, paragraph):\n\"\"\"Set xml:lang of paragraph.\n\n        Extract the text outside the quotes, use this text to set\n        language of the paragraph.\n        Set the language of the quotes in the paragraph.\n        \"\"\"\n        if paragraph.get(\"{http://www.w3.org/XML/1998/namespace}lang\") is None:\n            paragraph_text = self.remove_quote(paragraph)\n            if self.language_guesser is not None and self.language_guesser.get_langs(\n                self.inlangs\n            ):\n                lang = self.language_guesser.classify(\n                    paragraph_text, langs=self.inlangs\n                )\n                if lang != self.mainlang:\n                    paragraph.set(\"{http://www.w3.org/XML/1998/namespace}lang\", lang)\n\n                self.set_span_language(paragraph)\n\n        return paragraph\n\n    def set_span_language(self, paragraph):\n\"\"\"Set xml:lang of span element.\"\"\"\n        for element in paragraph.iter(\"span\"):\n            if element.get(\"type\") == \"quote\":\n                if element.text is not None:\n                    lang = self.language_guesser.classify(\n                        element.text, langs=self.inlangs\n                    )\n                    if lang != self.mainlang:\n                        element.set(\"{http://www.w3.org/XML/1998/namespace}lang\", lang)\n\n    @staticmethod\n    def remove_quote(paragraph):\n\"\"\"Extract all text except the one inside &lt;span type='quote'&gt;.\"\"\"\n        text = \"\"\n        for element in paragraph.iter():\n            if (\n                element.tag == \"span\"\n                and element.get(\"type\") == \"quote\"\n                and element.tail is not None\n            ):\n                text = text + element.tail\n            else:\n                if element.text is not None:\n                    text = text + element.text\n                if element.tail is not None:\n                    text = text + element.tail\n\n        return text\n\n    def detect_language(self):\n\"\"\"Detect language in all the paragraphs in self.document.\"\"\"\n        if self.document.find(\"header/multilingual\") is not None:\n            for paragraph in self.document.iter(\"p\"):\n                self.set_paragraph_language(paragraph)\n</code></pre>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector.inlangs","title":"<code>inlangs</code>  <code>property</code>","text":"<p>Return the predifined possible languages of the document.</p>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector.mainlang","title":"<code>mainlang</code>  <code>property</code>","text":"<p>Get the mainlang of the file.</p>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector.__init__","title":"<code>__init__(document, language_guesser)</code>","text":"<p>Initialise the LanguageDetector class.</p> <p>Parameters:</p> Name Type Description Default <code>document</code> <p>an etree element.</p> required <code>languageGuesser</code> <p>a text_cat.Classifier.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/languagedetector.py</code> <pre><code>def __init__(self, document, language_guesser):\n\"\"\"Initialise the LanguageDetector class.\n\n    Args:\n        document: an etree element.\n        languageGuesser: a text_cat.Classifier.\n    \"\"\"\n    self.document = document\n    self.language_guesser = language_guesser\n</code></pre>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector.detect_language","title":"<code>detect_language()</code>","text":"<p>Detect language in all the paragraphs in self.document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/languagedetector.py</code> <pre><code>def detect_language(self):\n\"\"\"Detect language in all the paragraphs in self.document.\"\"\"\n    if self.document.find(\"header/multilingual\") is not None:\n        for paragraph in self.document.iter(\"p\"):\n            self.set_paragraph_language(paragraph)\n</code></pre>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector.remove_quote","title":"<code>remove_quote(paragraph)</code>  <code>staticmethod</code>","text":"<p>Extract all text except the one inside . Source code in <code>/home/anders/projects/CorpusTools/corpustools/languagedetector.py</code> <pre><code>@staticmethod\ndef remove_quote(paragraph):\n\"\"\"Extract all text except the one inside &lt;span type='quote'&gt;.\"\"\"\n    text = \"\"\n    for element in paragraph.iter():\n        if (\n            element.tag == \"span\"\n            and element.get(\"type\") == \"quote\"\n            and element.tail is not None\n        ):\n            text = text + element.tail\n        else:\n            if element.text is not None:\n                text = text + element.text\n            if element.tail is not None:\n                text = text + element.tail\n\n    return text\n</code></pre>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector.set_paragraph_language","title":"<code>set_paragraph_language(paragraph)</code>","text":"<p>Set xml:lang of paragraph.</p> <p>Extract the text outside the quotes, use this text to set language of the paragraph. Set the language of the quotes in the paragraph.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/languagedetector.py</code> <pre><code>def set_paragraph_language(self, paragraph):\n\"\"\"Set xml:lang of paragraph.\n\n    Extract the text outside the quotes, use this text to set\n    language of the paragraph.\n    Set the language of the quotes in the paragraph.\n    \"\"\"\n    if paragraph.get(\"{http://www.w3.org/XML/1998/namespace}lang\") is None:\n        paragraph_text = self.remove_quote(paragraph)\n        if self.language_guesser is not None and self.language_guesser.get_langs(\n            self.inlangs\n        ):\n            lang = self.language_guesser.classify(\n                paragraph_text, langs=self.inlangs\n            )\n            if lang != self.mainlang:\n                paragraph.set(\"{http://www.w3.org/XML/1998/namespace}lang\", lang)\n\n            self.set_span_language(paragraph)\n\n    return paragraph\n</code></pre>"},{"location":"reference/languagedetector/#corpustools.languagedetector.LanguageDetector.set_span_language","title":"<code>set_span_language(paragraph)</code>","text":"<p>Set xml:lang of span element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/languagedetector.py</code> <pre><code>def set_span_language(self, paragraph):\n\"\"\"Set xml:lang of span element.\"\"\"\n    for element in paragraph.iter(\"span\"):\n        if element.get(\"type\") == \"quote\":\n            if element.text is not None:\n                lang = self.language_guesser.classify(\n                    element.text, langs=self.inlangs\n                )\n                if lang != self.mainlang:\n                    element.set(\"{http://www.w3.org/XML/1998/namespace}lang\", lang)\n</code></pre>"},{"location":"reference/macsami/","title":"macsami","text":"<p>Python Character Mapping Codec for macsami.</p>"},{"location":"reference/macsami/#corpustools.macsami.Codec","title":"<code>Codec</code>","text":"<p>         Bases: <code>codecs.Codec</code></p> <p>Implement the interface for stateless encoders/decoders.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>class Codec(codecs.Codec):\n\"\"\"Implement the interface for stateless encoders/decoders.\"\"\"\n\n    def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object input.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n                'backslashreplace'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_encode(instring, errors, encoding_table)\n\n    def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object input.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace' or 'ignore'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.Codec.decode","title":"<code>decode(instring, errors='strict')</code>","text":"<p>Decode the object input.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace' or 'ignore'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object input.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace' or 'ignore'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.Codec.encode","title":"<code>encode(instring, errors='strict')</code>","text":"<p>Encode the object input.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace', 'ignore',  'xmlcharrefreplace' or 'backslashreplace'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object input.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n            'backslashreplace'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_encode(instring, errors, encoding_table)\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.IncrementalDecoder","title":"<code>IncrementalDecoder</code>","text":"<p>         Bases: <code>codecs.IncrementalDecoder</code></p> <p>Implement an IncrementalDecoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>class IncrementalDecoder(codecs.IncrementalDecoder):\n\"\"\"Implement an IncrementalDecoder.\"\"\"\n\n    def decode(self, instring, final=False):\n\"\"\"Decode input.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.IncrementalDecoder.decode","title":"<code>decode(instring, final=False)</code>","text":"<p>Decode input.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>def decode(self, instring, final=False):\n\"\"\"Decode input.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.IncrementalEncoder","title":"<code>IncrementalEncoder</code>","text":"<p>         Bases: <code>codecs.IncrementalEncoder</code></p> <p>Implement an IncrementalEncoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>class IncrementalEncoder(codecs.IncrementalEncoder):\n\"\"\"Implement an IncrementalEncoder.\"\"\"\n\n    def encode(self, instring, final=False):\n\"\"\"Encode input.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.IncrementalEncoder.encode","title":"<code>encode(instring, final=False)</code>","text":"<p>Encode input.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>def encode(self, instring, final=False):\n\"\"\"Encode input.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.getregentry","title":"<code>getregentry()</code>","text":"<p>Get the info for this encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>def getregentry():\n\"\"\"Get the info for this encoding.\"\"\"\n    return codecs.CodecInfo(\n        name=\"macsami\",\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=codecs.StreamReader,\n        streamwriter=codecs.StreamWriter,\n    )\n</code></pre>"},{"location":"reference/macsami/#corpustools.macsami.lookup","title":"<code>lookup(encoding)</code>","text":"<p>Lookup the name of the encoding.</p> <p>Parameters:</p> Name Type Description Default <code>encoding</code> <code>str</code> <p>name of the encoding</p> required <p>Returns:</p> Type Description <p>Codecs.CodecInfo if encoding is the name of the encoding of this file, None otherwise.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/macsami.py</code> <pre><code>def lookup(encoding):\n\"\"\"Lookup the name of the encoding.\n\n    Args:\n        encoding (str): name of the encoding\n\n    Returns:\n        Codecs.CodecInfo if encoding is the name of the encoding of\n            this file, None otherwise.\n    \"\"\"\n    if encoding == \"macsami\":\n        return getregentry()\n    return None\n</code></pre>"},{"location":"reference/mari/","title":"mari","text":"<p>Python Character Mapping Codec cp1251 generated from 'MAPPINGS/VENDORS/MICSFT/WINDOWS/CP1251.TXT' with gencodec.py.</p>"},{"location":"reference/mari/#corpustools.mari.Codec","title":"<code>Codec</code>","text":"<p>         Bases: <code>codecs.Codec</code></p> <p>Implement the interface for stateless encoders/decoders.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>class Codec(codecs.Codec):\n\"\"\"Implement the interface for stateless encoders/decoders.\"\"\"\n\n    def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n                'backslashreplace'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_encode(instring, errors, encoding_table)\n\n    def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace' or 'ignore'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.Codec.decode","title":"<code>decode(instring, errors='strict')</code>","text":"<p>Decode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace' or 'ignore'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace' or 'ignore'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.Codec.encode","title":"<code>encode(instring, errors='strict')</code>","text":"<p>Encode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace', 'ignore',  'xmlcharrefreplace' or 'backslashreplace'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n            'backslashreplace'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_encode(instring, errors, encoding_table)\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.IncrementalDecoder","title":"<code>IncrementalDecoder</code>","text":"<p>         Bases: <code>codecs.IncrementalDecoder</code></p> <p>Implement an IncrementalDecoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>class IncrementalDecoder(codecs.IncrementalDecoder):\n\"\"\"Implement an IncrementalDecoder.\"\"\"\n\n    def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.IncrementalDecoder.decode","title":"<code>decode(instring, final=False)</code>","text":"<p>Decode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.IncrementalEncoder","title":"<code>IncrementalEncoder</code>","text":"<p>         Bases: <code>codecs.IncrementalEncoder</code></p> <p>Implement an IncrementalEncoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>class IncrementalEncoder(codecs.IncrementalEncoder):\n\"\"\"Implement an IncrementalEncoder.\"\"\"\n\n    def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.IncrementalEncoder.encode","title":"<code>encode(instring, final=False)</code>","text":"<p>Encode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.getregentry","title":"<code>getregentry()</code>","text":"<p>Get the info for this encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>def getregentry():\n\"\"\"Get the info for this encoding.\"\"\"\n    return codecs.CodecInfo(\n        name=\"meadowmari\",\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=codecs.StreamReader,\n        streamwriter=codecs.StreamWriter,\n    )\n</code></pre>"},{"location":"reference/mari/#corpustools.mari.lookup","title":"<code>lookup(encoding)</code>","text":"<p>Lookup the name of the encoding.</p> <p>Parameters:</p> Name Type Description Default <code>encoding</code> <code>str</code> <p>name of the encoding</p> required <p>Returns:</p> Type Description <p>Codecs.CodecInfo if encoding is the name of the encoding of this file, None otherwise.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/mari.py</code> <pre><code>def lookup(encoding):\n\"\"\"Lookup the name of the encoding.\n\n    Args:\n        encoding (str): name of the encoding\n\n    Returns:\n        Codecs.CodecInfo if encoding is the name of the encoding of\n            this file, None otherwise.\n    \"\"\"\n    if encoding == \"meadowmari\":\n        return getregentry()\n    return None\n</code></pre>"},{"location":"reference/modes/","title":"modes","text":"<p>Classes and functions to handle apertium modes.xml files.</p>"},{"location":"reference/modes/#corpustools.modes.Pipeline","title":"<code>Pipeline</code>","text":"<p>Make a pipeline out of modes.xml file.</p> <p>Attributes:</p> Name Type Description <code>modename</code> <code>str</code> <p>a mode element from a modes.xml file.</p> <code>giella_prefix</code> <code>str</code> <p>Set this variable if the installed giella files are not found in the standard places.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>class Pipeline:\n\"\"\"Make a pipeline out of modes.xml file.\n\n    Attributes:\n        modename (str): a mode element from a modes.xml file.\n        giella_prefix (str): Set this variable if the installed giella files\n            are not found in the standard places.\n    \"\"\"\n\n    def __init__(self, modename, lang, giella_prefix=None):\n\"\"\"Initialise the Pipeline class.\n\n        Args:\n            modename (str): name of a mode that is expected to be found\n                in the modes.xml file.\n            giella_prefix (str): directory where the filenames given in the\n                modes.xml file exist.\n        \"\"\"\n        modefile = etree.parse(os.path.join(os.path.dirname(__file__), \"xml/modes.xml\"))\n        self.mode = modefile.find(f'.//mode[@name=\"{modename}\"]')\n        self.giella_prefix = self.valid_path(giella_prefix, lang)\n        self.sanity_check()\n\n    @staticmethod\n    def valid_path(giella_prefix, lang):\n\"\"\"Check if resources needed by modes exists.\n\n        Args:\n            giella_prefix (str): user provided directory where resources exist.\n            lang (str): the language that modes is asked to serve.\n\n        Returns:\n            A directory where resources for the given language exist.\n\n        Raises:\n            utils.ArgumentError if no resources are found.\n        \"\"\"\n        if giella_prefix is not None:\n            return os.path.join(giella_prefix, \"share/giella\", lang)\n        else:\n            for prefix in [\n                os.path.join(os.getenv(\"HOME\"), \".local\"),\n                \"/usr/local\",\n                \"/usr\",\n            ]:\n                path = os.path.join(prefix, \"share/giella\", lang)\n                if os.path.isdir(path) and os.listdir(path):\n                    return path\n\n        raise (util.ArgumentError(f\"ERROR: found no resources for {lang}\"))\n\n    @staticmethod\n    def raise_unless_exists(filenames):\n\"\"\"Raise an ArgumentError if filename does not exist.\n\n        Args:\n            filenames (list of str): list of filenames harvested from the\n                mode element.\n\n        Raises:\n            util.ArgumentError if a filename does not exist.\n        \"\"\"\n        for filename in filenames:\n            if not os.path.exists(filename):\n                raise (util.ArgumentError(f\"ERROR: {filename} does not exist\"))\n\n    def sanity_check(self):\n\"\"\"Check that programs and files found in a program element exist.\"\"\"\n        util.sanity_check(\n            [program.get(\"name\") for program in self.mode.iter(\"program\")]\n        )\n        self.raise_unless_exists(\n            [\n                os.path.join(self.giella_prefix, file_elem.get(\"name\"))\n                for file_elem in self.mode.iter(\"file\")\n            ]\n        )\n\n    def run_external_command(self, command, instring):\n\"\"\"Run the command with input using subprocess.\n\n        Args:\n            command (list of str): a subprocess compatible command.\n            instring (bytes): the input to the command.\n\n        Returns:\n            bytes: the output of the command\n        \"\"\"\n        runner = util.ExternalCommandRunner()\n        runner.run(command, to_stdin=instring)\n        self.check_error(command, runner.stderr)\n\n        return runner.stdout\n\n    @staticmethod\n    def check_error(command, error):\n\"\"\"Print errors.\"\"\"\n        if error:\n            print(\n                \"{} failed:\\n{}\".format(\" \".join(command), error.decode(\"utf8\")),\n                file=sys.stderr,\n            )\n\n    def tag2commandpart(self, element):\n\"\"\"Turn program elements to a command part.\n\n        Args:\n            element (lxml.Element): a program subelement\n\n        Returns:\n            str: a program, a program option or a path to a file\n        \"\"\"\n        if element.tag == \"file\":\n            return os.path.join(self.giella_prefix, element.get(\"name\"))\n\n        return element.get(\"name\")\n\n    def program2command(self, program):\n\"\"\"Turn a program element to a subprocess compatible command.\n\n        Args:\n            program (str): a program element\n\n        Returns:\n            list of str: a subprocess compatible command\n        \"\"\"\n        return [self.tag2commandpart(element) for element in program.iter()]\n\n    @property\n    def commands(self):\n\"\"\"Make a list of subprocess compatible commands.\n\n        Returns:\n            list of list: a list of subprocess compatible commands.\n        \"\"\"\n        return [self.program2command(program) for program in self.mode.iter(\"program\")]\n\n    def run(self, instring):\n\"\"\"Run the pipeline using input.\n\n        Args:\n            instring (bytes): utf-8 encoded input to the pipeline\n\n        Returns:\n            str: output of the pipeline\n        \"\"\"\n        for command in self.commands:\n            instring = self.run_external_command(command, instring)\n\n        return instring.decode(\"utf8\")\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.commands","title":"<code>commands</code>  <code>property</code>","text":"<p>Make a list of subprocess compatible commands.</p> <p>Returns:</p> Type Description <p>list of list: a list of subprocess compatible commands.</p>"},{"location":"reference/modes/#corpustools.modes.Pipeline.__init__","title":"<code>__init__(modename, lang, giella_prefix=None)</code>","text":"<p>Initialise the Pipeline class.</p> <p>Parameters:</p> Name Type Description Default <code>modename</code> <code>str</code> <p>name of a mode that is expected to be found in the modes.xml file.</p> required <code>giella_prefix</code> <code>str</code> <p>directory where the filenames given in the modes.xml file exist.</p> <code>None</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>def __init__(self, modename, lang, giella_prefix=None):\n\"\"\"Initialise the Pipeline class.\n\n    Args:\n        modename (str): name of a mode that is expected to be found\n            in the modes.xml file.\n        giella_prefix (str): directory where the filenames given in the\n            modes.xml file exist.\n    \"\"\"\n    modefile = etree.parse(os.path.join(os.path.dirname(__file__), \"xml/modes.xml\"))\n    self.mode = modefile.find(f'.//mode[@name=\"{modename}\"]')\n    self.giella_prefix = self.valid_path(giella_prefix, lang)\n    self.sanity_check()\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.check_error","title":"<code>check_error(command, error)</code>  <code>staticmethod</code>","text":"<p>Print errors.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>@staticmethod\ndef check_error(command, error):\n\"\"\"Print errors.\"\"\"\n    if error:\n        print(\n            \"{} failed:\\n{}\".format(\" \".join(command), error.decode(\"utf8\")),\n            file=sys.stderr,\n        )\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.program2command","title":"<code>program2command(program)</code>","text":"<p>Turn a program element to a subprocess compatible command.</p> <p>Parameters:</p> Name Type Description Default <code>program</code> <code>str</code> <p>a program element</p> required <p>Returns:</p> Type Description <p>list of str: a subprocess compatible command</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>def program2command(self, program):\n\"\"\"Turn a program element to a subprocess compatible command.\n\n    Args:\n        program (str): a program element\n\n    Returns:\n        list of str: a subprocess compatible command\n    \"\"\"\n    return [self.tag2commandpart(element) for element in program.iter()]\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.raise_unless_exists","title":"<code>raise_unless_exists(filenames)</code>  <code>staticmethod</code>","text":"<p>Raise an ArgumentError if filename does not exist.</p> <p>Parameters:</p> Name Type Description Default <code>filenames</code> <code>list of str</code> <p>list of filenames harvested from the mode element.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>@staticmethod\ndef raise_unless_exists(filenames):\n\"\"\"Raise an ArgumentError if filename does not exist.\n\n    Args:\n        filenames (list of str): list of filenames harvested from the\n            mode element.\n\n    Raises:\n        util.ArgumentError if a filename does not exist.\n    \"\"\"\n    for filename in filenames:\n        if not os.path.exists(filename):\n            raise (util.ArgumentError(f\"ERROR: {filename} does not exist\"))\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.run","title":"<code>run(instring)</code>","text":"<p>Run the pipeline using input.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>bytes</code> <p>utf-8 encoded input to the pipeline</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>output of the pipeline</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>def run(self, instring):\n\"\"\"Run the pipeline using input.\n\n    Args:\n        instring (bytes): utf-8 encoded input to the pipeline\n\n    Returns:\n        str: output of the pipeline\n    \"\"\"\n    for command in self.commands:\n        instring = self.run_external_command(command, instring)\n\n    return instring.decode(\"utf8\")\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.run_external_command","title":"<code>run_external_command(command, instring)</code>","text":"<p>Run the command with input using subprocess.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>list of str</code> <p>a subprocess compatible command.</p> required <code>instring</code> <code>bytes</code> <p>the input to the command.</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <p>the output of the command</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>def run_external_command(self, command, instring):\n\"\"\"Run the command with input using subprocess.\n\n    Args:\n        command (list of str): a subprocess compatible command.\n        instring (bytes): the input to the command.\n\n    Returns:\n        bytes: the output of the command\n    \"\"\"\n    runner = util.ExternalCommandRunner()\n    runner.run(command, to_stdin=instring)\n    self.check_error(command, runner.stderr)\n\n    return runner.stdout\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.sanity_check","title":"<code>sanity_check()</code>","text":"<p>Check that programs and files found in a program element exist.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>def sanity_check(self):\n\"\"\"Check that programs and files found in a program element exist.\"\"\"\n    util.sanity_check(\n        [program.get(\"name\") for program in self.mode.iter(\"program\")]\n    )\n    self.raise_unless_exists(\n        [\n            os.path.join(self.giella_prefix, file_elem.get(\"name\"))\n            for file_elem in self.mode.iter(\"file\")\n        ]\n    )\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.tag2commandpart","title":"<code>tag2commandpart(element)</code>","text":"<p>Turn program elements to a command part.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>lxml.Element</code> <p>a program subelement</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>a program, a program option or a path to a file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>def tag2commandpart(self, element):\n\"\"\"Turn program elements to a command part.\n\n    Args:\n        element (lxml.Element): a program subelement\n\n    Returns:\n        str: a program, a program option or a path to a file\n    \"\"\"\n    if element.tag == \"file\":\n        return os.path.join(self.giella_prefix, element.get(\"name\"))\n\n    return element.get(\"name\")\n</code></pre>"},{"location":"reference/modes/#corpustools.modes.Pipeline.valid_path","title":"<code>valid_path(giella_prefix, lang)</code>  <code>staticmethod</code>","text":"<p>Check if resources needed by modes exists.</p> <p>Parameters:</p> Name Type Description Default <code>giella_prefix</code> <code>str</code> <p>user provided directory where resources exist.</p> required <code>lang</code> <code>str</code> <p>the language that modes is asked to serve.</p> required <p>Returns:</p> Type Description <p>A directory where resources for the given language exist.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/modes.py</code> <pre><code>@staticmethod\ndef valid_path(giella_prefix, lang):\n\"\"\"Check if resources needed by modes exists.\n\n    Args:\n        giella_prefix (str): user provided directory where resources exist.\n        lang (str): the language that modes is asked to serve.\n\n    Returns:\n        A directory where resources for the given language exist.\n\n    Raises:\n        utils.ArgumentError if no resources are found.\n    \"\"\"\n    if giella_prefix is not None:\n        return os.path.join(giella_prefix, \"share/giella\", lang)\n    else:\n        for prefix in [\n            os.path.join(os.getenv(\"HOME\"), \".local\"),\n            \"/usr/local\",\n            \"/usr\",\n        ]:\n            path = os.path.join(prefix, \"share/giella\", lang)\n            if os.path.isdir(path) and os.listdir(path):\n                return path\n\n    raise (util.ArgumentError(f\"ERROR: found no resources for {lang}\"))\n</code></pre>"},{"location":"reference/move_files/","title":"move_files","text":"<p>Move a corpus file from oldpath to newpath.</p>"},{"location":"reference/move_files/#corpustools.move_files.main","title":"<code>main()</code>","text":"<p>Move a file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/move_files.py</code> <pre><code>def main():\n\"\"\"Move a file.\"\"\"\n    args = mover_parse_args()\n    if args.oldpath == args.newpath:\n        print(\n            f\"{args.oldpath} and {args.newpath} are the same file\",\n            file=sys.stderr,\n        )\n    else:\n        oldpath = args.oldpath\n        newpath = args.newpath\n        try:\n            mover(os.path.abspath(oldpath), os.path.abspath(newpath))\n        except UserWarning as e:\n            print(\"Can not move file:\", str(e), file=sys.stderr)\n</code></pre>"},{"location":"reference/move_files/#corpustools.move_files.mover","title":"<code>mover(oldpath, newpath)</code>","text":"<p>Move a file from oldpath to newpath.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/move_files.py</code> <pre><code>def mover(oldpath, newpath):\n\"\"\"Move a file from oldpath to newpath.\"\"\"\n    if os.path.isfile(oldpath):\n        if oldpath.endswith(\".xsl\"):\n            oldpath = oldpath[:-4]\n    else:\n        raise UserWarning(f\"{oldpath} is not a file\")\n\n    if newpath.endswith(\".xsl\"):\n        newpath = newpath[:-4]\n    elif os.path.isdir(newpath):\n        newpath = os.path.join(newpath, os.path.basename(oldpath))\n\n    cfmu = namechanger.CorpusFilesetMoverAndUpdater(oldpath, newpath)\n    filepair = cfmu.move_computer.filepairs[0]\n    if filepair.newpath:\n        print(f\"\\tmoving {filepair.oldpath} -&gt; {filepair.newpath}\")\n    else:\n        print(f\"\\tremoving {filepair.oldpath}\")\n    cfmu.move_files()\n    cfmu.update_own_metadata()\n    cfmu.update_parallel_files_metadata()\n</code></pre>"},{"location":"reference/move_files/#corpustools.move_files.mover_parse_args","title":"<code>mover_parse_args()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/move_files.py</code> <pre><code>def mover_parse_args():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Program to move or rename a file inside the corpus.\",\n    )\n\n    parser.add_argument(\"oldpath\", help=\"The path of the old file.\")\n    parser.add_argument(\n        \"newpath\",\n        help=\"The place to move the file to. newpath can \"\n        \"be either a filename or a directory\",\n    )\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/move_files/#corpustools.move_files.remove_main","title":"<code>remove_main()</code>","text":"<p>Remove a file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/move_files.py</code> <pre><code>def remove_main():\n\"\"\"Remove a file.\"\"\"\n    args = remover_parse_args()\n    try:\n        mover(os.path.abspath(args.oldpath), \"\")\n    except UserWarning as e:\n        print(\"Can not remove file:\", str(e), file=sys.stderr)\n</code></pre>"},{"location":"reference/move_files/#corpustools.move_files.remover_parse_args","title":"<code>remover_parse_args()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/move_files.py</code> <pre><code>def remover_parse_args():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Program to remove a file from the corpus.\",\n    )\n\n    parser.add_argument(\"oldpath\", help=\"The path of the old file.\")\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/namechanger/","title":"namechanger","text":"<p>Classes and functions change names of corpus files.</p>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFileMover","title":"<code>CorpusFileMover</code>","text":"<p>Move an original file and all its derived files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>class CorpusFileMover:\n\"\"\"Move an original file and all its derived files.\"\"\"\n\n    def __init__(self, oldpath, newpath):\n\"\"\"Class to move corpus files.\n\n        Args:\n            oldpath (unicode): the old path of the original file.\n            newpath (unicode): the new path of tht original file.\n        \"\"\"\n        self.old_corpus_path = corpuspath.CorpusPath(oldpath)\n        p = Path(oldpath)\n        if not p.exists():\n            raise SystemExit(f\"{oldpath} does not exist!\")\n        self.new_corpus_path = corpuspath.CorpusPath(newpath)\n        self.new_corpus_path.metadata = self.old_corpus_path.metadata\n        self.orig_vcs = versioncontrol.vcs(self.old_corpus_path.orig_corpus_dir)\n        self.conv_vcs = versioncontrol.vcs(self.old_corpus_path.converted_corpus_dir)\n\n    def move_files(self):\n\"\"\"Move all files that are under version control.\"\"\"\n        p = Path(self.new_corpus_path.orig)\n        if not p.parent.exists():\n            p.parent.mkdir(parents=True)\n\n        self.orig_vcs.move(self.old_corpus_path.orig, self.new_corpus_path.orig)\n        self.orig_vcs.move(self.old_corpus_path.xsl, self.new_corpus_path.xsl)\n\n        if os.path.exists(self.old_corpus_path.converted):\n            p = Path(self.new_corpus_path.converted)\n            if not p.parent.exists():\n                p.parent.mkdir(parents=True)\n            self.conv_vcs.move(\n                self.old_corpus_path.converted, self.new_corpus_path.converted\n            )\n        if not self.old_corpus_path.metadata.get_variable(\"translated_from\"):\n            for lang in self.old_corpus_path.metadata.get_parallel_texts():\n                if os.path.exists(self.old_corpus_path.tmx(lang)):\n                    p = Path(self.new_corpus_path.tmx(lang))\n                    if not p.parent.exists():\n                        p.parent.mkdir(parents=True)\n                    self.conv_vcs.move(\n                        self.old_corpus_path.tmx(lang), self.new_corpus_path.tmx(lang)\n                    )\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFileMover.__init__","title":"<code>__init__(oldpath, newpath)</code>","text":"<p>Class to move corpus files.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>unicode</code> <p>the old path of the original file.</p> required <code>newpath</code> <code>unicode</code> <p>the new path of tht original file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def __init__(self, oldpath, newpath):\n\"\"\"Class to move corpus files.\n\n    Args:\n        oldpath (unicode): the old path of the original file.\n        newpath (unicode): the new path of tht original file.\n    \"\"\"\n    self.old_corpus_path = corpuspath.CorpusPath(oldpath)\n    p = Path(oldpath)\n    if not p.exists():\n        raise SystemExit(f\"{oldpath} does not exist!\")\n    self.new_corpus_path = corpuspath.CorpusPath(newpath)\n    self.new_corpus_path.metadata = self.old_corpus_path.metadata\n    self.orig_vcs = versioncontrol.vcs(self.old_corpus_path.orig_corpus_dir)\n    self.conv_vcs = versioncontrol.vcs(self.old_corpus_path.converted_corpus_dir)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFileMover.move_files","title":"<code>move_files()</code>","text":"<p>Move all files that are under version control.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def move_files(self):\n\"\"\"Move all files that are under version control.\"\"\"\n    p = Path(self.new_corpus_path.orig)\n    if not p.parent.exists():\n        p.parent.mkdir(parents=True)\n\n    self.orig_vcs.move(self.old_corpus_path.orig, self.new_corpus_path.orig)\n    self.orig_vcs.move(self.old_corpus_path.xsl, self.new_corpus_path.xsl)\n\n    if os.path.exists(self.old_corpus_path.converted):\n        p = Path(self.new_corpus_path.converted)\n        if not p.parent.exists():\n            p.parent.mkdir(parents=True)\n        self.conv_vcs.move(\n            self.old_corpus_path.converted, self.new_corpus_path.converted\n        )\n    if not self.old_corpus_path.metadata.get_variable(\"translated_from\"):\n        for lang in self.old_corpus_path.metadata.get_parallel_texts():\n            if os.path.exists(self.old_corpus_path.tmx(lang)):\n                p = Path(self.new_corpus_path.tmx(lang))\n                if not p.parent.exists():\n                    p.parent.mkdir(parents=True)\n                self.conv_vcs.move(\n                    self.old_corpus_path.tmx(lang), self.new_corpus_path.tmx(lang)\n                )\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFileRemover","title":"<code>CorpusFileRemover</code>","text":"<p>Remove an original file and all its derived files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>class CorpusFileRemover:\n\"\"\"Remove an original file and all its derived files.\"\"\"\n\n    def __init__(self, oldpath):\n\"\"\"Class to remove corpus files.\n\n        Args:\n            oldpath (unicode): the old path\n        \"\"\"\n        self.old_corpus_path = corpuspath.CorpusPath(oldpath)\n        p = Path(oldpath)\n        if not p.exists():\n            raise SystemExit(f\"{oldpath} does not exist!\")\n        self.orig_vcs = versioncontrol.vcs(self.old_corpus_path.orig_corpus_dir)\n        self.conv_vcs = versioncontrol.vcs(self.old_corpus_path.converted_corpus_dir)\n\n    def remove_files(self):\n\"\"\"Remove all the files that are under version control.\"\"\"\n        self.orig_vcs.remove(self.old_corpus_path.orig)\n        self.orig_vcs.remove(self.old_corpus_path.xsl)\n        self.conv_vcs.remove(self.old_corpus_path.converted)\n        for lang in self.old_corpus_path.metadata.get_parallel_texts():\n            if os.path.exists(self.old_corpus_path.tmx(lang)):\n                self.conv_vcs.remove(self.old_corpus_path.tmx(lang))\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFileRemover.__init__","title":"<code>__init__(oldpath)</code>","text":"<p>Class to remove corpus files.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>unicode</code> <p>the old path</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def __init__(self, oldpath):\n\"\"\"Class to remove corpus files.\n\n    Args:\n        oldpath (unicode): the old path\n    \"\"\"\n    self.old_corpus_path = corpuspath.CorpusPath(oldpath)\n    p = Path(oldpath)\n    if not p.exists():\n        raise SystemExit(f\"{oldpath} does not exist!\")\n    self.orig_vcs = versioncontrol.vcs(self.old_corpus_path.orig_corpus_dir)\n    self.conv_vcs = versioncontrol.vcs(self.old_corpus_path.converted_corpus_dir)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFileRemover.remove_files","title":"<code>remove_files()</code>","text":"<p>Remove all the files that are under version control.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def remove_files(self):\n\"\"\"Remove all the files that are under version control.\"\"\"\n    self.orig_vcs.remove(self.old_corpus_path.orig)\n    self.orig_vcs.remove(self.old_corpus_path.xsl)\n    self.conv_vcs.remove(self.old_corpus_path.converted)\n    for lang in self.old_corpus_path.metadata.get_parallel_texts():\n        if os.path.exists(self.old_corpus_path.tmx(lang)):\n            self.conv_vcs.remove(self.old_corpus_path.tmx(lang))\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFilesetMoverAndUpdater","title":"<code>CorpusFilesetMoverAndUpdater</code>","text":"<p>Move or remove a file within a repository.</p> <p>When moving a file inside the same directory: * move the original file * move the metadata file * move the prestable/converted file * move the prestable/toktmx file * move the prestable/tmx file * change the metadata in the metadata file, if needed * change the reference to the file name in the parallel files'   metadata, if needed * if the parallel files need name normalisation, move them the same way the   original file is handled</p> <p>Removal is signaled by an empty string for the newpath argument. When removing a file. : * remove the original file * remove the metadata file * remove the prestable/converted file * remove the prestable/toktmx file * remove the prestable/tmx file * change the reference to the file name in the parallel files' metadata * if the parallel files need name normalisation, move them the same way the   original file is handled</p> <p>When moving a file from one subdirectory to another: * move the original file * move the metadata file * move the prestable/converted file * move the prestable/toktmx file * move the prestable/tmx file * change the metadata in the metadata file, if needed * change the reference to the file name in the parallel files'   metadata, if needed * change the reference to the file name in the parallel files'   metadata if needed * move the parallel files the same way the original file has been moved.</p> <p>When moving a file to a new genre: * the subdirectory move operations + * change the genre reference in the metadata files</p> <p>When moving a file to a new language: * move the original file * move the metadata file * move the prestable/converted file * move the prestable/toktmx file * move the prestable/tmx file * change the language of the file in the parallel files' metadata * if the parallel files need name normalisation, move them the same way the   original file is handled</p> <p>Normalise a file name: Replace non-ascii char with ascii ones and remove unwanted characters.</p> <p>When doing these operations, detect name clashes for the original files.</p> <p>If a name clash is found, check if the files are duplicates. If they are duplicates, raise an exception, otherwise suggest a new name.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>class CorpusFilesetMoverAndUpdater:\n\"\"\"Move or remove a file within a repository.\n\n    When moving a file inside the same directory:\n    * move the original file\n    * move the metadata file\n    * move the prestable/converted file\n    * move the prestable/toktmx file\n    * move the prestable/tmx file\n    * change the metadata in the metadata file, if needed\n    * change the reference to the file name in the parallel files'\n      metadata, if needed\n    * if the parallel files need name normalisation, move them the same way the\n      original file is handled\n\n    Removal is signaled by an empty string for the newpath argument.\n    When removing a file. :\n    * remove the original file\n    * remove the metadata file\n    * remove the prestable/converted file\n    * remove the prestable/toktmx file\n    * remove the prestable/tmx file\n    * change the reference to the file name in the parallel files' metadata\n    * if the parallel files need name normalisation, move them the same way the\n      original file is handled\n\n    When moving a file from one subdirectory to another:\n    * move the original file\n    * move the metadata file\n    * move the prestable/converted file\n    * move the prestable/toktmx file\n    * move the prestable/tmx file\n    * change the metadata in the metadata file, if needed\n    * change the reference to the file name in the parallel files'\n      metadata, if needed\n    * change the reference to the file name in the parallel files'\n      metadata if needed\n    * move the parallel files the same way the original file has been moved.\n\n    When moving a file to a new genre:\n    * the subdirectory move operations +\n    * change the genre reference in the metadata files\n\n    When moving a file to a new language:\n    * move the original file\n    * move the metadata file\n    * move the prestable/converted file\n    * move the prestable/toktmx file\n    * move the prestable/tmx file\n    * change the language of the file in the parallel files' metadata\n    * if the parallel files need name normalisation, move them the same way the\n      original file is handled\n\n    Normalise a file name: Replace non-ascii char with ascii ones and remove\n    unwanted characters.\n\n    When doing these operations, detect name clashes for the original files.\n\n    If a name clash is found, check if the files are duplicates. If they are\n    duplicates, raise an exception, otherwise suggest a new name.\n    \"\"\"\n\n    def __init__(self, oldpath, newpath):\n\"\"\"Initialise the CorpusFilesetMoverAndUpdater class.\n\n        oldpath (str): path to the file that should be renamed.\n        newpath (str): path to the new name of the file.\n        \"\"\"\n        orig_corpus_path = corpuspath.CorpusPath(oldpath)\n        orig_corpus_path.metadata.set_lang_genre_xsl()\n        orig_corpus_path.metadata.write_file()\n\n        self.old_components = orig_corpus_path.pathcomponents\n        self.vcs = versioncontrol.vcs(\n            os.path.join(\n                orig_corpus_path.pathcomponents.root,\n                f\"corpus-{orig_corpus_path.pathcomponents.lang}{orig_corpus_path.pathcomponents.dirsuffix}\",\n            )\n        )\n        # self.vcs.add(orig_corpus_path.xsl)\n\n        self.move_computer = MovepairComputer()\n        self.move_computer.compute_all_movepairs(oldpath, newpath)\n\n    def move_files(self):\n\"\"\"Move all files under version control that belong to the original.\"\"\"\n        for filepair in self.move_computer.filepairs:\n            if not filepair.newpath:\n                cfr = CorpusFileRemover(filepair.oldpath)\n                cfr.remove_files()\n            elif filepair.oldpath != filepair.newpath:\n                cfm = CorpusFileMover(filepair.oldpath, filepair.newpath)\n                cfm.move_files()\n\n    def update_own_metadata(self):\n\"\"\"Update metadata.\"\"\"\n        for filepair in self.move_computer.filepairs:\n            if filepair.newpath:\n                old_components = corpuspath.CorpusPath(filepair.oldpath).pathcomponents\n                new_components = corpuspath.CorpusPath(filepair.newpath).pathcomponents\n\n                metadataname = filepair.newpath + \".xsl\"\n                if os.path.isfile(metadataname):\n                    metadatafile = xslsetter.MetadataHandler(metadataname)\n                    if old_components.genre != new_components.genre:\n                        metadatafile.set_variable(\"genre\", new_components.genre)\n                    if old_components.lang != new_components.lang:\n                        metadatafile.set_variable(\"mainlang\", new_components.lang)\n                    metadatafile.write_file()\n                    self.vcs.add(metadataname)\n\n    def update_parallel_file_metadata(self, old_components, newpath, parallel_name):\n\"\"\"Update metadata in a metadata file.\n\n        Args:\n            old_components (util.PathComponents): A named tuple\n                representing the path to the old name of the file\n            newpath (str): path to the new file\n            parallel_name (str) : name of the parallel file\n        \"\"\"\n        parallel_metadatafile = xslsetter.MetadataHandler(parallel_name)\n\n        if newpath:\n            new_components = corpuspath.CorpusPath(newpath).pathcomponents\n            if old_components.lang != new_components.lang:\n                parallel_metadatafile.set_parallel_text(old_components.lang, \"\")\n                parallel_metadatafile.set_parallel_text(\n                    new_components.lang, new_components.basename\n                )\n            elif old_components.basename != new_components.basename:\n                parallel_metadatafile.set_parallel_text(\n                    new_components.lang, new_components.basename\n                )\n\n        else:\n            parallel_metadatafile.set_parallel_text(old_components.lang, \"\")\n\n        parallel_metadatafile.write_file()\n        self.vcs.add(parallel_name)\n\n    def update_parallel_files_metadata(self):\n\"\"\"Update the info in the parallel files.\"\"\"\n        for filepair in self.move_computer.filepairs:\n            parallel_filepairs = list(self.move_computer.filepairs)\n            parallel_filepairs.remove(filepair)\n            old_components = corpuspath.CorpusPath(filepair.oldpath).pathcomponents\n\n            for parallel_filepair in parallel_filepairs:\n                parallel_name = parallel_filepair.newpath + \".xsl\"\n                if os.path.isfile(parallel_name):\n                    self.update_parallel_file_metadata(\n                        old_components, filepair.newpath, parallel_name\n                    )\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFilesetMoverAndUpdater.__init__","title":"<code>__init__(oldpath, newpath)</code>","text":"<p>Initialise the CorpusFilesetMoverAndUpdater class.</p> <p>oldpath (str): path to the file that should be renamed. newpath (str): path to the new name of the file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def __init__(self, oldpath, newpath):\n\"\"\"Initialise the CorpusFilesetMoverAndUpdater class.\n\n    oldpath (str): path to the file that should be renamed.\n    newpath (str): path to the new name of the file.\n    \"\"\"\n    orig_corpus_path = corpuspath.CorpusPath(oldpath)\n    orig_corpus_path.metadata.set_lang_genre_xsl()\n    orig_corpus_path.metadata.write_file()\n\n    self.old_components = orig_corpus_path.pathcomponents\n    self.vcs = versioncontrol.vcs(\n        os.path.join(\n            orig_corpus_path.pathcomponents.root,\n            f\"corpus-{orig_corpus_path.pathcomponents.lang}{orig_corpus_path.pathcomponents.dirsuffix}\",\n        )\n    )\n    # self.vcs.add(orig_corpus_path.xsl)\n\n    self.move_computer = MovepairComputer()\n    self.move_computer.compute_all_movepairs(oldpath, newpath)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFilesetMoverAndUpdater.move_files","title":"<code>move_files()</code>","text":"<p>Move all files under version control that belong to the original.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def move_files(self):\n\"\"\"Move all files under version control that belong to the original.\"\"\"\n    for filepair in self.move_computer.filepairs:\n        if not filepair.newpath:\n            cfr = CorpusFileRemover(filepair.oldpath)\n            cfr.remove_files()\n        elif filepair.oldpath != filepair.newpath:\n            cfm = CorpusFileMover(filepair.oldpath, filepair.newpath)\n            cfm.move_files()\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFilesetMoverAndUpdater.update_own_metadata","title":"<code>update_own_metadata()</code>","text":"<p>Update metadata.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def update_own_metadata(self):\n\"\"\"Update metadata.\"\"\"\n    for filepair in self.move_computer.filepairs:\n        if filepair.newpath:\n            old_components = corpuspath.CorpusPath(filepair.oldpath).pathcomponents\n            new_components = corpuspath.CorpusPath(filepair.newpath).pathcomponents\n\n            metadataname = filepair.newpath + \".xsl\"\n            if os.path.isfile(metadataname):\n                metadatafile = xslsetter.MetadataHandler(metadataname)\n                if old_components.genre != new_components.genre:\n                    metadatafile.set_variable(\"genre\", new_components.genre)\n                if old_components.lang != new_components.lang:\n                    metadatafile.set_variable(\"mainlang\", new_components.lang)\n                metadatafile.write_file()\n                self.vcs.add(metadataname)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFilesetMoverAndUpdater.update_parallel_file_metadata","title":"<code>update_parallel_file_metadata(old_components, newpath, parallel_name)</code>","text":"<p>Update metadata in a metadata file.</p> <p>Parameters:</p> Name Type Description Default <code>old_components</code> <code>util.PathComponents</code> <p>A named tuple representing the path to the old name of the file</p> required <code>newpath</code> <code>str</code> <p>path to the new file</p> required <code>parallel_name</code> <code>str) </code> <p>name of the parallel file</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def update_parallel_file_metadata(self, old_components, newpath, parallel_name):\n\"\"\"Update metadata in a metadata file.\n\n    Args:\n        old_components (util.PathComponents): A named tuple\n            representing the path to the old name of the file\n        newpath (str): path to the new file\n        parallel_name (str) : name of the parallel file\n    \"\"\"\n    parallel_metadatafile = xslsetter.MetadataHandler(parallel_name)\n\n    if newpath:\n        new_components = corpuspath.CorpusPath(newpath).pathcomponents\n        if old_components.lang != new_components.lang:\n            parallel_metadatafile.set_parallel_text(old_components.lang, \"\")\n            parallel_metadatafile.set_parallel_text(\n                new_components.lang, new_components.basename\n            )\n        elif old_components.basename != new_components.basename:\n            parallel_metadatafile.set_parallel_text(\n                new_components.lang, new_components.basename\n            )\n\n    else:\n        parallel_metadatafile.set_parallel_text(old_components.lang, \"\")\n\n    parallel_metadatafile.write_file()\n    self.vcs.add(parallel_name)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.CorpusFilesetMoverAndUpdater.update_parallel_files_metadata","title":"<code>update_parallel_files_metadata()</code>","text":"<p>Update the info in the parallel files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def update_parallel_files_metadata(self):\n\"\"\"Update the info in the parallel files.\"\"\"\n    for filepair in self.move_computer.filepairs:\n        parallel_filepairs = list(self.move_computer.filepairs)\n        parallel_filepairs.remove(filepair)\n        old_components = corpuspath.CorpusPath(filepair.oldpath).pathcomponents\n\n        for parallel_filepair in parallel_filepairs:\n            parallel_name = parallel_filepair.newpath + \".xsl\"\n            if os.path.isfile(parallel_name):\n                self.update_parallel_file_metadata(\n                    old_components, filepair.newpath, parallel_name\n                )\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.MovepairComputer","title":"<code>MovepairComputer</code>","text":"<p>Compute oldname, newname pairs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>class MovepairComputer:\n\"\"\"Compute oldname, newname pairs.\"\"\"\n\n    def __init__(self):\n\"\"\"Initialise the MovepairComputer.\n\n        filepairs (list of PathPairs): List of filepairs that should be moved.\n        \"\"\"\n        self.filepairs = []\n\n    def compute_orig_movepair(self, oldpath, newpath, nochange=False):\n\"\"\"Add the oldpath and the new goalpath to filepairs.\n\n        Args:\n            oldpath (unicode): the old path to an original file\n            newpath (unicode): the new path of an original file\n        \"\"\"\n        if not newpath:\n            self.filepairs.append(PathPair(oldpath, \"\"))\n        else:\n            normalisedpath = os.path.join(\n                os.path.dirname(newpath), normalise_filename(os.path.basename(newpath))\n            )\n            if normalisedpath == newpath and nochange:\n                non_dupe_path = newpath\n            else:\n                non_dupe_path = compute_new_basename(oldpath, normalisedpath)\n\n            self.filepairs.append(PathPair(oldpath, non_dupe_path))\n\n    def compute_parallel_movepairs(self, oldpath, newpath):\n\"\"\"Add the parallel files of oldpath to filepairs.\n\n        Args:\n            oldpath (unicode): the old path\n            newpath (unicode): the new path\n        \"\"\"\n        old_corpus_path = corpuspath.CorpusPath(oldpath)\n        if not newpath:\n            newpath = oldpath\n\n        for parallel_name in old_corpus_path.parallels():\n            old_parallel_corpus_path = corpuspath.CorpusPath(parallel_name)\n            new_corpus_path = corpuspath.CorpusPath(newpath)\n            new_parallel_name = old_parallel_corpus_path.move_orig(\n                genre=new_corpus_path.pathcomponents.genre,\n                subdirs=new_corpus_path.pathcomponents.subdirs,\n            )\n            self.compute_orig_movepair(parallel_name, new_parallel_name)\n\n    def compute_all_movepairs(self, oldpath, newpath):\n\"\"\"Compute all the potential name pairs that should be moved.\n\n        Args:\n            oldpath (str): path to the original file.\n            newpath (str): path to the new file.\n        \"\"\"\n        self.compute_orig_movepair(oldpath, newpath)\n        self.compute_parallel_movepairs(oldpath, newpath)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.MovepairComputer.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the MovepairComputer.</p> <p>filepairs (list of PathPairs): List of filepairs that should be moved.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the MovepairComputer.\n\n    filepairs (list of PathPairs): List of filepairs that should be moved.\n    \"\"\"\n    self.filepairs = []\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.MovepairComputer.compute_all_movepairs","title":"<code>compute_all_movepairs(oldpath, newpath)</code>","text":"<p>Compute all the potential name pairs that should be moved.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>str</code> <p>path to the original file.</p> required <code>newpath</code> <code>str</code> <p>path to the new file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def compute_all_movepairs(self, oldpath, newpath):\n\"\"\"Compute all the potential name pairs that should be moved.\n\n    Args:\n        oldpath (str): path to the original file.\n        newpath (str): path to the new file.\n    \"\"\"\n    self.compute_orig_movepair(oldpath, newpath)\n    self.compute_parallel_movepairs(oldpath, newpath)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.MovepairComputer.compute_orig_movepair","title":"<code>compute_orig_movepair(oldpath, newpath, nochange=False)</code>","text":"<p>Add the oldpath and the new goalpath to filepairs.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>unicode</code> <p>the old path to an original file</p> required <code>newpath</code> <code>unicode</code> <p>the new path of an original file</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def compute_orig_movepair(self, oldpath, newpath, nochange=False):\n\"\"\"Add the oldpath and the new goalpath to filepairs.\n\n    Args:\n        oldpath (unicode): the old path to an original file\n        newpath (unicode): the new path of an original file\n    \"\"\"\n    if not newpath:\n        self.filepairs.append(PathPair(oldpath, \"\"))\n    else:\n        normalisedpath = os.path.join(\n            os.path.dirname(newpath), normalise_filename(os.path.basename(newpath))\n        )\n        if normalisedpath == newpath and nochange:\n            non_dupe_path = newpath\n        else:\n            non_dupe_path = compute_new_basename(oldpath, normalisedpath)\n\n        self.filepairs.append(PathPair(oldpath, non_dupe_path))\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.MovepairComputer.compute_parallel_movepairs","title":"<code>compute_parallel_movepairs(oldpath, newpath)</code>","text":"<p>Add the parallel files of oldpath to filepairs.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>unicode</code> <p>the old path</p> required <code>newpath</code> <code>unicode</code> <p>the new path</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def compute_parallel_movepairs(self, oldpath, newpath):\n\"\"\"Add the parallel files of oldpath to filepairs.\n\n    Args:\n        oldpath (unicode): the old path\n        newpath (unicode): the new path\n    \"\"\"\n    old_corpus_path = corpuspath.CorpusPath(oldpath)\n    if not newpath:\n        newpath = oldpath\n\n    for parallel_name in old_corpus_path.parallels():\n        old_parallel_corpus_path = corpuspath.CorpusPath(parallel_name)\n        new_corpus_path = corpuspath.CorpusPath(newpath)\n        new_parallel_name = old_parallel_corpus_path.move_orig(\n            genre=new_corpus_path.pathcomponents.genre,\n            subdirs=new_corpus_path.pathcomponents.subdirs,\n        )\n        self.compute_orig_movepair(parallel_name, new_parallel_name)\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.NamechangerError","title":"<code>NamechangerError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>This exception is raised when errors occurs in this module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>class NamechangerError(Exception):\n\"\"\"This exception is raised when errors occurs in this module.\"\"\"\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.are_duplicates","title":"<code>are_duplicates(oldpath, newpath)</code>","text":"<p>Check if oldpath and newpath are duplicates of each other.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>unicode</code> <p>old path of the file</p> required <code>newpath</code> <code>unicode</code> <p>the wanted, new path of the file</p> required <p>Returns:</p> Type Description <p>a boolean indicating if the two files are duplicates</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def are_duplicates(oldpath, newpath):\n\"\"\"Check if oldpath and newpath are duplicates of each other.\n\n    Args:\n        oldpath (unicode): old path of the file\n        newpath (unicode): the wanted, new path of the file\n\n    Returns:\n        a boolean indicating if the two files are duplicates\n    \"\"\"\n    if os.path.isfile(oldpath) and os.path.isfile(newpath):\n        with open(oldpath, \"rb\") as oldcontent, open(newpath, \"rb\") as newcontent:\n            return compute_hexdigest(oldcontent) == compute_hexdigest(newcontent)\n    else:\n        return False\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.compute_hexdigest","title":"<code>compute_hexdigest(afile, blocksize=65536)</code>","text":"<p>Compute the hexdigest of the file in path.</p> <p>Parameters:</p> Name Type Description Default <code>afile</code> <p>a file like object</p> required <p>Returns:</p> Type Description <p>a hexdigest of the file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def compute_hexdigest(afile, blocksize=65536):\n\"\"\"Compute the hexdigest of the file in path.\n\n    Args:\n        afile: a file like object\n\n    Returns:\n        a hexdigest of the file\n    \"\"\"\n    hasher = hashlib.md5()\n    buf = afile.read(blocksize)\n    while buf:\n        hasher.update(buf)\n        buf = afile.read(blocksize)\n\n    return hasher.hexdigest()\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.compute_new_basename","title":"<code>compute_new_basename(oldpath, wanted_path)</code>","text":"<p>Compute the new path.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>unicode</code> <p>path to the old file</p> required <code>wanted_path</code> <code>unicode</code> <p>the path that one wants to move the file to</p> required <p>Returns:</p> Type Description <p>a unicode string pointing to the new path</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def compute_new_basename(oldpath, wanted_path):\n\"\"\"Compute the new path.\n\n    Args:\n        oldpath (unicode): path to the old file\n        wanted_path (unicode): the path that one wants to move the file to\n\n    Returns:\n        a unicode string pointing to the new path\n    \"\"\"\n    wanted_basename = os.path.basename(wanted_path)\n    new_basename = os.path.basename(wanted_path)\n    newpath = os.path.join(os.path.dirname(wanted_path), new_basename)\n    index = 1\n\n    while os.path.exists(newpath):\n        if are_duplicates(oldpath, newpath):\n            raise UserWarning(f\"{oldpath} and {newpath} are duplicates. \")\n        else:\n            if \".\" in wanted_basename:\n                dot = wanted_basename.rfind(\".\")\n                extension = wanted_basename[dot:]\n                pre_extension = wanted_basename[:dot]\n                new_basename = pre_extension + \"_\" + str(index) + extension\n            else:\n                new_basename = wanted_basename + str(index)\n            newpath = os.path.join(os.path.dirname(wanted_path), new_basename)\n            index += 1\n\n    return newpath\n</code></pre>"},{"location":"reference/namechanger/#corpustools.namechanger.normalise_filename","title":"<code>normalise_filename(filename)</code>","text":"<p>Normalise filename to ascii only.</p> <p>Downcase filename, replace non-ascii characters with ascii ones and remove or replace unwanted characters.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of the file</p> required <p>Returns:</p> Type Description <p>a downcased string containing only ascii chars</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/namechanger.py</code> <pre><code>def normalise_filename(filename):\n\"\"\"Normalise filename to ascii only.\n\n    Downcase filename, replace non-ascii characters with ascii ones and\n    remove or replace unwanted characters.\n\n    Args:\n        filename (str): name of the file\n\n    Returns:\n        a downcased string containing only ascii chars\n    \"\"\"\n    if os.sep in filename:\n        raise NamechangerError(\n            \"Invalid filename {}.\\n\"\n            \"Filename is not allowed to contain {}\".format(filename, os.sep)\n        )\n\n    # unicode.decode wants a unicode string\n    if not isinstance(filename, str):\n        filename = filename.decode(\"utf8\")\n\n    # unidecode.unidecode makes ascii only\n    # urllib.unquote replaces %xx escapes by their single-character equivalent.\n    asciiname = unidecode.unidecode(unquote(filename))\n\n    while asciiname.startswith((\"-\", \"_\")):\n        asciiname = asciiname[1:]\n\n    unwanted = re.compile(\"[+ ()'\u2013?,!,&lt;&gt;\\\"&amp;;&amp;#\\\\|$]+\")\n\n    return unwanted.sub(\"_\", asciiname).lower()\n</code></pre>"},{"location":"reference/normalise_filenames/","title":"normalise_filenames","text":"<p>Normalise the files in the given directory.</p>"},{"location":"reference/normalise_filenames/#corpustools.normalise_filenames.main","title":"<code>main()</code>","text":"<p>Normalise filenames.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/normalise_filenames.py</code> <pre><code>def main():\n\"\"\"Normalise filenames.\"\"\"\n    for target_dir in normalise_parse_args().target_dirs:\n        normalise(target_dir)\n</code></pre>"},{"location":"reference/normalise_filenames/#corpustools.normalise_filenames.normalise","title":"<code>normalise(target_dir)</code>","text":"<p>Normalise the filenames in the corpuses.</p> <p>Parameters:</p> Name Type Description Default <code>target_dir</code> <code>str</code> <p>directory where filenames should be normalised</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/normalise_filenames.py</code> <pre><code>def normalise(target_dir):\n\"\"\"Normalise the filenames in the corpuses.\n\n    Args:\n        target_dir (str): directory where filenames should be normalised\n    \"\"\"\n    print(f\"Normalising names in {target_dir}\")\n    for root, dirs, files in os.walk(os.path.join(target_dir)):\n        for f in files:\n            if not f.endswith(\".xsl\"):\n                try:\n                    orig_path = os.path.join(root, f)\n\n                    cfmu = namechanger.CorpusFilesetMoverAndUpdater(\n                        orig_path, orig_path\n                    )\n                    filepair = cfmu.move_computer.filepairs[0]\n                    print(f\"\\t\\tmove {filepair.oldpath} -&gt; {filepair.newpath}\")\n                    cfmu.move_files()\n                    cfmu.update_own_metadata()\n                    cfmu.update_parallel_files_metadata()\n                except UserWarning:\n                    pass\n</code></pre>"},{"location":"reference/normalise_filenames/#corpustools.normalise_filenames.normalise_parse_args","title":"<code>normalise_parse_args()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/normalise_filenames.py</code> <pre><code>def normalise_parse_args():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Program to normalise names in given directories. \"\n        \"The filenames are downcased, non ascii characters are replaced \"\n        \"by ascii ones and some unwanted characters are removed.\",\n    )\n    parser.add_argument(\n        \"target_dirs\",\n        nargs=\"+\",\n        help=\"The directory/ies where filenames should be normalised.\",\n    )\n\n    args = parser.parse_args()\n\n    return args\n</code></pre>"},{"location":"reference/nrk_no_crawler/","title":"nrk_no_crawler","text":"<p>This file contains routines to crawl nrk.no containing saami text.</p>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler","title":"<code>NrkSmeCrawler</code>","text":"<p>Collect Northern Saami pages from nrk.no.</p> <p>Attributes:</p> Name Type Description <code>language_guesser</code> <code>text_cat.Classifier</code> <p>guess language from a given string</p> <code>goaldir</code> <code>str</code> <p>the directory where the working copy of the corpus is</p> <code>corpus_adder</code> <code>adder.AddToCorpus</code> <p>the working horse, adds urls to the corpus</p> <code>tags</code> <code>dict of str to str</code> <p>numerical tags that point to a specific topic on nrk.no</p> <code>invalid_links</code> <code>set of str</code> <p>all links containing 'gammelsystem'</p> <code>counter</code> <code>collections.defaultdict of int</code> <p>collect interesting statistics, such number of links visited and fetched links within a tag</p> <code>fetched_links</code> <code>set of str</code> <p>links to articles that have already been fetched</p> <code>authors</code> <code>set of str</code> <p>authors of articles</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>class NrkSmeCrawler:\n\"\"\"Collect Northern Saami pages from nrk.no.\n\n    Attributes:\n        language_guesser (text_cat.Classifier): guess language from a given\n            string\n        goaldir (str): the directory where the working copy of the corpus is\n        corpus_adder (adder.AddToCorpus): the working horse, adds urls to\n            the corpus\n        tags (dict of str to str): numerical tags that point to a specific\n            topic on nrk.no\n        invalid_links (set of str): all links containing 'gammelsystem'\n        counter (collections.defaultdict of int): collect interesting\n            statistics, such number of links visited and fetched links within\n            a tag\n        fetched_links (set of str): links to articles that have already been\n            fetched\n        authors (set of str): authors of articles\n    \"\"\"\n\n    language_guesser = text_cat.Classifier(None)\n    goaldir = str(os.getenv(\"GTBOUND\"))\n    corpus_adder = adder.AddToCorpus(goaldir, \"sme\", \"news/nrk.no\")\n    tags = defaultdict(str)\n    invalid_links = set()\n    counter = defaultdict(int)\n    authors = set()\n\n    def __init__(self):\n\"\"\"Initialise the NrkSmeCrawler class.\"\"\"\n        self.fetched_ids = self.get_fetched_links(self.corpus_adder.goaldir)\n        # Ids containing norwegian text\n        self.fetched_ids |= {\n            \"1.11060139\",\n            \"1.11205504\",\n            \"1.11518300\",\n            \"1.11526579\",\n            \"1.11876027\",\n            \"1.11909062\",\n            \"1.12274706\",\n            \"1.13050654\",\n            \"1.13077542\",\n            \"1.13599435\",\n            \"1.13683886\",\n            \"1.13683979\",\n            \"1.13684081\",\n            \"1.2265333\",\n            \"1.4708759\",\n            \"1.4837038\",\n            \"1.5174999\",\n            \"1.6129908\",\n            \"1.6431307\",\n            \"1.6439563\",\n            \"1.6468432\",\n            \"1.6469363\",\n            \"1.6538125\",\n            \"1.6563405\",\n            \"1.6776103\",\n            \"1.6784213\",\n            \"1.6857178\",\n            \"1.7066094\",\n            \"1.7222473\",\n            \"1.7391316\",\n            \"1.7397359\",\n            \"1.7826351\",\n            \"1.7971308\",\n            \"1.7990373\",\n            \"1.8065147\",\n            \"1.8231915\",\n            \"1.8239588\",\n            \"1.8836268\",\n            \"1.4178483\",\n            \"1.6474023\",\n            \"1.7096768\",\n            \"1.12593187\",\n            \"1.6479890\",\n            \"1.6136593\",\n            \"1.6602458\",\n        }\n\n    def guess_lang(self, address):\n\"\"\"Guess the language of the address element.\n\n        Args:\n            address (html.Element): An element where interesting text is found\n\n        Returns:\n            str containing the language of the text\n        \"\"\"\n        # This bytes hoopla is done because the text\n        # comes out as utf8 encoded as latin1 \u2026\n        try:\n            text = bytes(\n                address.find('.//p[@class=\"plug-preamble\"]').text, encoding=\"latin1\"\n            )\n        except AttributeError:\n            text = bytes(address.find('.//h2[@class=\"title\"]').text, encoding=\"latin1\")\n        lang = self.language_guesser.classify(text)\n        if lang == \"sme\":\n            util.print_frame(text)\n\n        return lang\n\n    def get_tag_page_trees(self, tag):\n\"\"\"Fetch topic pages containing links to articles.\n\n        By using the page_links_template, one can fetch `quantity` number of\n        links to articles within `tag` at a time.\n\n        Attributes:\n            page_links_template: a url to a specific topic in nrk.no.\n            quantity (int): the number of links to fetch a time\n            limit (int): max number of links that one tries to fetch\n\n        Args:\n            tag (str): a numerical tag, pointing to a specific topic on nrk.no\n\n        Yields:\n            lxml.html.HtmlElement: a parsed html document.\n        \"\"\"\n        page_links_template = (\n            \"https://www.nrk.no/serum/api/render/{tag}?\"\n            \"size=18&amp;perspective=BRIEF&amp;alignment=AUTO&amp;\"\n            \"classes=surrogate-content&amp;\"\n            \"display=false&amp;arrangement.offset={offset}&amp;\"\n            \"arrangement.quantity={quantity}&amp;\"\n            \"arrangement.repetition=PATTERN&amp;\"\n            \"arrangement.view[0].perspective=BRIEF&amp;\"\n            \"arrangement.view[0].size=6&amp;\"\n            \"arrangement.view[0].alignment=LEFT&amp;\"\n            \"paged=SIMPLE\"\n        )\n        quantity = 10\n        limit = 10000\n\n        for offset in range(0, limit, quantity):\n            print(\".\", end=\"\")\n            sys.stdout.flush()\n            try:\n                result = requests.get(\n                    page_links_template.format(\n                        tag=tag, offset=offset, quantity=quantity\n                    )\n                )\n            except requests.exceptions.ConnectionError:\n                util.note(f\"Connection error when fetching {tag}\")\n                break\n            else:\n                try:\n                    yield html.document_fromstring(result.content)\n                except etree.ParserError:\n                    util.note(f\"No more articles in tag: \u00ab{self.tags[tag]}\u00bb\")\n                    break\n\n    def interesting_links(self, tag):\n\"\"\"Find interesting pages inside a topic.\n\n        Args:\n            tag (str): a numerical tag pointing to a specific topic.\n\n        Yields:\n            str: a url to an nrk.no article\n        \"\"\"\n        for tree in self.get_tag_page_trees(tag):\n            for address in tree.xpath('//a[@class=\"autonomous lp_plug\"]'):\n                self.counter[tag + \"_total\"] += 1\n                href = address.get(\"href\")\n                article_id = href.strip().split(\"-\")[-1]\n                if \"systemtest\" in href:\n                    self.invalid_links.add(href)\n                if (\n                    \"systemtest\" not in href\n                    and article_id not in self.fetched_ids\n                    and self.guess_lang(address) == \"sme\"\n                ):\n                    self.counter[tag + \"_fetched\"] += 1\n                    yield href\n\n    @staticmethod\n    def pick_tags(path):\n\"\"\"Find tags in an nrk.no article.\n\n        Tags potientially contain more Northern S\u00e1mi articles.\n\n        Args:\n            path (str): path to an nrk.no article\n\n        Yields:\n            tuple of str: a numerical tag, used internally by nrk.no to point\n                to a specific topic and a short description of the topic.\n        \"\"\"\n        article = html.parse(path)\n\n        for address in article.xpath(\n            '//a[@class=\"universe widget reference article-universe-link '\n            'universe-teaser skin-border skin-text lp_universe_link\"]'\n        ):\n            href = address.get(\"href\")\n            yield href[href.rfind(\"-\") + 1 :], address[0].tail.strip()\n\n    def crawl_tag(self, tag, tagname):\n\"\"\"Look for articles in nrk.no tags.\n\n        Args:\n            tag (str): an internal nrk.no tag\n        \"\"\"\n        if tag not in self.tags:\n            util.note(f\"Fetching articles from \u00ab{tagname}\u00bb\")\n            self.tags[tag] = tagname\n            for href in self.interesting_links(tag):\n                self.add_nrk_article(href)\n\n            self.counter[\"total\"] += self.counter[tag + \"_total\"]\n            self.counter[\"fetched\"] += self.counter[tag + \"_fetched\"]\n\n    def add_nrk_article(self, href):\n\"\"\"Copy an article to the working copy.\n\n        Args:\n            href (str): a url to an nrk article.\n        \"\"\"\n        self.fetched_ids.add(href.split(\"-\")[-1])\n        try:\n            path = self.corpus_adder.copy_url_to_corpus(href)\n            self.add_metadata(path)\n        except (\n            requests.exceptions.TooManyRedirects,\n            adder.AdderError,\n            UserWarning,\n        ) as error:\n            util.note(href)\n            util.note(error)\n\n    def crawl_site(self):\n\"\"\"Fetch Northern Saami pages from nrk.no.\"\"\"\n        self.crawl_oanehaccat()\n        self.crawl_existing_tags()\n        # self.crawl_authors()\n        # self.corpus_adder.add_files_to_working_copy()\n        self.report()\n\n    def find_nrk_files(self):\n\"\"\"Find all nrk.no files.\"\"\"\n        for root, _, files in os.walk(self.corpus_adder.goaldir):\n            for file_ in files:\n                if file_.endswith(\".html\"):\n                    yield os.path.join(root, file_)\n\n    def crawl_existing_tags(self):\n\"\"\"Crawl all tags found in nrk.no documents.\"\"\"\n        for nrk_file in self.find_nrk_files():\n            for additional_tag, tag_name in self.pick_tags(nrk_file):\n                self.crawl_tag(additional_tag, tag_name)\n\n    def crawl_oanehaccat(self):\n\"\"\"Crawl short news, provided by a json dict.\n\n        This feed only contains Northern S\u00e1mi articles.\n        \"\"\"\n        util.note(\"Fetching articles from {}\".format(\"oaneha\u010d\u010dat\"))\n        self.tags[\"oaneha\u010d\u010dat\"] = \"oaneha\u010d\u010dat\"\n        oanehaccat = requests.get(\n            \"https://www.nrk.no/serum/api/content/json/\"\n            \"1.13572949?v=2&amp;limit=1000&amp;context=items\"\n        )\n        for relation in oanehaccat.json()[\"relations\"]:\n            self.counter[\"oaneha\u010d\u010dat_total\"] += 1\n            if relation[\"id\"] not in self.fetched_ids:\n                self.counter[\"oaneha\u010d\u010dat_fetched\"] += 1\n                self.add_nrk_article(\n                    \"https://www.nrk.no/sapmi/{}\".format(relation[\"id\"])\n                )\n\n        self.counter[\"total\"] += self.counter[\"oaneha\u010d\u010dat_total\"]\n        self.counter[\"fetched\"] += self.counter[\"oaneha\u010d\u010dat_fetched\"]\n\n    def handle_search_hits(self, hits):\n\"\"\"Decide whether articles found in search results should be saved.\"\"\"\n        for hit in hits:\n            if hit[\"url\"].split(\"-\")[-1] not in self.fetched_ids and hit.get(\n                \"description\"\n            ):\n                lang = self.language_guesser.classify(hit[\"description\"])\n                if lang == \"sme\":\n                    util.print_frame(len(hit[\"description\"]), hit[\"description\"], \"\\n\")\n                    if len(hit[\"description\"]) &gt; 15:\n                        self.counter[\"authors_fetched\"] += 1\n                        self.add_nrk_article(hit[\"url\"])\n\n    def crawl_authors(self):\n\"\"\"Search for authors on nrk.no.\n\n        Not all articles have are represented under the tags found, so\n        a search on author names is also done.\n        \"\"\"\n        self.tags[\"authors\"] = \"authors\"\n        for nrk_file in self.find_nrk_files():\n            self.counter[\"nrk_file\"] += 1\n            article = html.parse(nrk_file)\n            for author_body in article.xpath('.//div[@class=\"author__body\"]'):\n                self.counter[\"author__body\"] += 1\n                author_name = author_body.find('./a[@class=\"author__name\"]')\n                if author_name is not None and author_name.text is not None:\n                    self.authors.add(author_name.text.strip().split()[-1].lower())\n                    self.counter[\"name\"] += 1\n\n        for author_parts in self.authors:\n            util.print_frame(author_parts, \"\\n\")\n            index = 0\n            total = 100001\n            while True:\n                hits = self.get_search_page(\n                    \"https://www.nrk.no/sok/?format=json&amp;scope=nrkno\"\n                    \"&amp;filter=nrkno&amp;q={}&amp;from={}\".format(author_parts, str(index))\n                )\n                if not hits:\n                    util.print_frame(\"empty hits, should break\")\n                    break\n                if int(hits[\"total\"]) &lt; total:\n                    total = int(hits[\"total\"])\n                self.handle_search_hits(hits[\"hits\"])\n                if index &gt; total:\n                    break\n                index += 20\n\n        self.counter[\"fetched\"] += self.counter[\"authors_fetched\"]\n\n    @staticmethod\n    def get_search_page(search_link):\n\"\"\"Get search pages, containing links to author search.\n\n        Args:\n            search_link (str): query string to nrk.no\n\n        Returns:\n            dict containing search results from search\n        \"\"\"\n        result = requests.get(search_link)\n        content = result.content.decode(\"utf8\")\n\n        try:\n            return json.loads(content)\n        except json.decoder.JSONDecodeError:\n            util.print_frame(search_link)\n            util.print_frame(result)\n            util.print_frame(content)\n\n            if content:\n                return {\"hits\": [], \"from\": \"-1\", \"total\": \"100000\"}\n            else:\n                return content\n\n    def report(self):\n\"\"\"Print a report on what was found.\"\"\"\n        print(f\"{len(self.invalid_links)} invalid links.\")\n        for invalid_link in self.invalid_links:\n            print(invalid_link)\n        print()\n        print(f\"Searched through {len(self.tags)} tags\")\n        print(f\"Searched through {len(self.authors)} authors\")\n        print(\"Fetched {fetched} pages\".format(**self.counter))\n        for tag in self.tags:\n            if self.counter[tag + \"_fetched\"]:\n                print(\n                    \"Fetched {} articles from category {} from nrk.no\".format(\n                        self.counter[tag + \"_fetched\"], self.tags[tag]\n                    )\n                )\n\n    @staticmethod\n    def valid_authors(article):\n\"\"\"Find authors with the correct roles.\n\n        Args:\n            article (etree.Element): The parsed html document.\n\n        Yields:\n            tuple of str\n        \"\"\"\n        for author_role in article.xpath('.//span[@class=\"author__role\"]'):\n            text = author_role.text.strip()\n            if text is not None and (\n                text.startswith(\"Journ\")\n                or text.startswith(\"Komm\")\n                or text.startswith(\"Arti\")\n            ):\n                parts = author_role.getprevious().text.strip().split()\n\n                yield parts\n\n    def add_metadata(self, path):\n\"\"\"Get metadata from the nrk.no article.\n\n        Args:\n            path (str): path to the nrk.no article\n        \"\"\"\n        article = html.parse(path)\n        metadata = xslsetter.MetadataHandler(path + \".xsl\")\n\n        for count, author_parts in enumerate(self.valid_authors(article), start=1):\n            metadata.set_variable(\"author\" + str(count) + \"_ln\", author_parts[-1])\n            metadata.set_variable(\n                \"author\" + str(count) + \"_fn\", \" \".join(author_parts[:-1])\n            )\n\n        time = article.find('//time[@itemprop=\"datePublished\"]')\n        if time is None:\n            time = article.find('//time[@class=\"relative bulletin-time\"]')\n        date = dateutil.parser.parse(time.get(\"datetime\"))\n        metadata.set_variable(\"year\", date.year)\n\n        metadata.set_variable(\"publisher\", \"NRK\")\n        metadata.set_variable(\"license_type\", \"standard\")\n        metadata.write_file()\n\n    @staticmethod\n    def get_fetched_links(path):\n\"\"\"Find fetched links.\n\n        Args:\n            path (str): path to the directory where nrk articles are found.\n\n        Returns:\n            set of strings, where the strings are ids to the article.\n        \"\"\"\n        return {\n            xslsetter.MetadataHandler(os.path.join(root, file_))\n            .get_variable(\"filename\")\n            .split(\"-\")[-1]\n            for root, _, files in os.walk(path)\n            for file_ in files\n            if file_.endswith(\".xsl\")\n        }\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the NrkSmeCrawler class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the NrkSmeCrawler class.\"\"\"\n    self.fetched_ids = self.get_fetched_links(self.corpus_adder.goaldir)\n    # Ids containing norwegian text\n    self.fetched_ids |= {\n        \"1.11060139\",\n        \"1.11205504\",\n        \"1.11518300\",\n        \"1.11526579\",\n        \"1.11876027\",\n        \"1.11909062\",\n        \"1.12274706\",\n        \"1.13050654\",\n        \"1.13077542\",\n        \"1.13599435\",\n        \"1.13683886\",\n        \"1.13683979\",\n        \"1.13684081\",\n        \"1.2265333\",\n        \"1.4708759\",\n        \"1.4837038\",\n        \"1.5174999\",\n        \"1.6129908\",\n        \"1.6431307\",\n        \"1.6439563\",\n        \"1.6468432\",\n        \"1.6469363\",\n        \"1.6538125\",\n        \"1.6563405\",\n        \"1.6776103\",\n        \"1.6784213\",\n        \"1.6857178\",\n        \"1.7066094\",\n        \"1.7222473\",\n        \"1.7391316\",\n        \"1.7397359\",\n        \"1.7826351\",\n        \"1.7971308\",\n        \"1.7990373\",\n        \"1.8065147\",\n        \"1.8231915\",\n        \"1.8239588\",\n        \"1.8836268\",\n        \"1.4178483\",\n        \"1.6474023\",\n        \"1.7096768\",\n        \"1.12593187\",\n        \"1.6479890\",\n        \"1.6136593\",\n        \"1.6602458\",\n    }\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.add_metadata","title":"<code>add_metadata(path)</code>","text":"<p>Get metadata from the nrk.no article.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path to the nrk.no article</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def add_metadata(self, path):\n\"\"\"Get metadata from the nrk.no article.\n\n    Args:\n        path (str): path to the nrk.no article\n    \"\"\"\n    article = html.parse(path)\n    metadata = xslsetter.MetadataHandler(path + \".xsl\")\n\n    for count, author_parts in enumerate(self.valid_authors(article), start=1):\n        metadata.set_variable(\"author\" + str(count) + \"_ln\", author_parts[-1])\n        metadata.set_variable(\n            \"author\" + str(count) + \"_fn\", \" \".join(author_parts[:-1])\n        )\n\n    time = article.find('//time[@itemprop=\"datePublished\"]')\n    if time is None:\n        time = article.find('//time[@class=\"relative bulletin-time\"]')\n    date = dateutil.parser.parse(time.get(\"datetime\"))\n    metadata.set_variable(\"year\", date.year)\n\n    metadata.set_variable(\"publisher\", \"NRK\")\n    metadata.set_variable(\"license_type\", \"standard\")\n    metadata.write_file()\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.add_nrk_article","title":"<code>add_nrk_article(href)</code>","text":"<p>Copy an article to the working copy.</p> <p>Parameters:</p> Name Type Description Default <code>href</code> <code>str</code> <p>a url to an nrk article.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def add_nrk_article(self, href):\n\"\"\"Copy an article to the working copy.\n\n    Args:\n        href (str): a url to an nrk article.\n    \"\"\"\n    self.fetched_ids.add(href.split(\"-\")[-1])\n    try:\n        path = self.corpus_adder.copy_url_to_corpus(href)\n        self.add_metadata(path)\n    except (\n        requests.exceptions.TooManyRedirects,\n        adder.AdderError,\n        UserWarning,\n    ) as error:\n        util.note(href)\n        util.note(error)\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.crawl_authors","title":"<code>crawl_authors()</code>","text":"<p>Search for authors on nrk.no.</p> <p>Not all articles have are represented under the tags found, so a search on author names is also done.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def crawl_authors(self):\n\"\"\"Search for authors on nrk.no.\n\n    Not all articles have are represented under the tags found, so\n    a search on author names is also done.\n    \"\"\"\n    self.tags[\"authors\"] = \"authors\"\n    for nrk_file in self.find_nrk_files():\n        self.counter[\"nrk_file\"] += 1\n        article = html.parse(nrk_file)\n        for author_body in article.xpath('.//div[@class=\"author__body\"]'):\n            self.counter[\"author__body\"] += 1\n            author_name = author_body.find('./a[@class=\"author__name\"]')\n            if author_name is not None and author_name.text is not None:\n                self.authors.add(author_name.text.strip().split()[-1].lower())\n                self.counter[\"name\"] += 1\n\n    for author_parts in self.authors:\n        util.print_frame(author_parts, \"\\n\")\n        index = 0\n        total = 100001\n        while True:\n            hits = self.get_search_page(\n                \"https://www.nrk.no/sok/?format=json&amp;scope=nrkno\"\n                \"&amp;filter=nrkno&amp;q={}&amp;from={}\".format(author_parts, str(index))\n            )\n            if not hits:\n                util.print_frame(\"empty hits, should break\")\n                break\n            if int(hits[\"total\"]) &lt; total:\n                total = int(hits[\"total\"])\n            self.handle_search_hits(hits[\"hits\"])\n            if index &gt; total:\n                break\n            index += 20\n\n    self.counter[\"fetched\"] += self.counter[\"authors_fetched\"]\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.crawl_existing_tags","title":"<code>crawl_existing_tags()</code>","text":"<p>Crawl all tags found in nrk.no documents.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def crawl_existing_tags(self):\n\"\"\"Crawl all tags found in nrk.no documents.\"\"\"\n    for nrk_file in self.find_nrk_files():\n        for additional_tag, tag_name in self.pick_tags(nrk_file):\n            self.crawl_tag(additional_tag, tag_name)\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.crawl_oanehaccat","title":"<code>crawl_oanehaccat()</code>","text":"<p>Crawl short news, provided by a json dict.</p> <p>This feed only contains Northern S\u00e1mi articles.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def crawl_oanehaccat(self):\n\"\"\"Crawl short news, provided by a json dict.\n\n    This feed only contains Northern S\u00e1mi articles.\n    \"\"\"\n    util.note(\"Fetching articles from {}\".format(\"oaneha\u010d\u010dat\"))\n    self.tags[\"oaneha\u010d\u010dat\"] = \"oaneha\u010d\u010dat\"\n    oanehaccat = requests.get(\n        \"https://www.nrk.no/serum/api/content/json/\"\n        \"1.13572949?v=2&amp;limit=1000&amp;context=items\"\n    )\n    for relation in oanehaccat.json()[\"relations\"]:\n        self.counter[\"oaneha\u010d\u010dat_total\"] += 1\n        if relation[\"id\"] not in self.fetched_ids:\n            self.counter[\"oaneha\u010d\u010dat_fetched\"] += 1\n            self.add_nrk_article(\n                \"https://www.nrk.no/sapmi/{}\".format(relation[\"id\"])\n            )\n\n    self.counter[\"total\"] += self.counter[\"oaneha\u010d\u010dat_total\"]\n    self.counter[\"fetched\"] += self.counter[\"oaneha\u010d\u010dat_fetched\"]\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.crawl_site","title":"<code>crawl_site()</code>","text":"<p>Fetch Northern Saami pages from nrk.no.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def crawl_site(self):\n\"\"\"Fetch Northern Saami pages from nrk.no.\"\"\"\n    self.crawl_oanehaccat()\n    self.crawl_existing_tags()\n    # self.crawl_authors()\n    # self.corpus_adder.add_files_to_working_copy()\n    self.report()\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.crawl_tag","title":"<code>crawl_tag(tag, tagname)</code>","text":"<p>Look for articles in nrk.no tags.</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>an internal nrk.no tag</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def crawl_tag(self, tag, tagname):\n\"\"\"Look for articles in nrk.no tags.\n\n    Args:\n        tag (str): an internal nrk.no tag\n    \"\"\"\n    if tag not in self.tags:\n        util.note(f\"Fetching articles from \u00ab{tagname}\u00bb\")\n        self.tags[tag] = tagname\n        for href in self.interesting_links(tag):\n            self.add_nrk_article(href)\n\n        self.counter[\"total\"] += self.counter[tag + \"_total\"]\n        self.counter[\"fetched\"] += self.counter[tag + \"_fetched\"]\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.find_nrk_files","title":"<code>find_nrk_files()</code>","text":"<p>Find all nrk.no files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def find_nrk_files(self):\n\"\"\"Find all nrk.no files.\"\"\"\n    for root, _, files in os.walk(self.corpus_adder.goaldir):\n        for file_ in files:\n            if file_.endswith(\".html\"):\n                yield os.path.join(root, file_)\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.get_fetched_links","title":"<code>get_fetched_links(path)</code>  <code>staticmethod</code>","text":"<p>Find fetched links.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path to the directory where nrk articles are found.</p> required <p>Returns:</p> Type Description <p>set of strings, where the strings are ids to the article.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>@staticmethod\ndef get_fetched_links(path):\n\"\"\"Find fetched links.\n\n    Args:\n        path (str): path to the directory where nrk articles are found.\n\n    Returns:\n        set of strings, where the strings are ids to the article.\n    \"\"\"\n    return {\n        xslsetter.MetadataHandler(os.path.join(root, file_))\n        .get_variable(\"filename\")\n        .split(\"-\")[-1]\n        for root, _, files in os.walk(path)\n        for file_ in files\n        if file_.endswith(\".xsl\")\n    }\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.get_search_page","title":"<code>get_search_page(search_link)</code>  <code>staticmethod</code>","text":"<p>Get search pages, containing links to author search.</p> <p>Parameters:</p> Name Type Description Default <code>search_link</code> <code>str</code> <p>query string to nrk.no</p> required <p>Returns:</p> Type Description <p>dict containing search results from search</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>@staticmethod\ndef get_search_page(search_link):\n\"\"\"Get search pages, containing links to author search.\n\n    Args:\n        search_link (str): query string to nrk.no\n\n    Returns:\n        dict containing search results from search\n    \"\"\"\n    result = requests.get(search_link)\n    content = result.content.decode(\"utf8\")\n\n    try:\n        return json.loads(content)\n    except json.decoder.JSONDecodeError:\n        util.print_frame(search_link)\n        util.print_frame(result)\n        util.print_frame(content)\n\n        if content:\n            return {\"hits\": [], \"from\": \"-1\", \"total\": \"100000\"}\n        else:\n            return content\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.get_tag_page_trees","title":"<code>get_tag_page_trees(tag)</code>","text":"<p>Fetch topic pages containing links to articles.</p> <p>By using the page_links_template, one can fetch <code>quantity</code> number of links to articles within <code>tag</code> at a time.</p> <p>Attributes:</p> Name Type Description <code>page_links_template</code> <p>a url to a specific topic in nrk.no.</p> <code>quantity</code> <code>int</code> <p>the number of links to fetch a time</p> <code>limit</code> <code>int</code> <p>max number of links that one tries to fetch</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>a numerical tag, pointing to a specific topic on nrk.no</p> required <p>Yields:</p> Type Description <p>lxml.html.HtmlElement: a parsed html document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def get_tag_page_trees(self, tag):\n\"\"\"Fetch topic pages containing links to articles.\n\n    By using the page_links_template, one can fetch `quantity` number of\n    links to articles within `tag` at a time.\n\n    Attributes:\n        page_links_template: a url to a specific topic in nrk.no.\n        quantity (int): the number of links to fetch a time\n        limit (int): max number of links that one tries to fetch\n\n    Args:\n        tag (str): a numerical tag, pointing to a specific topic on nrk.no\n\n    Yields:\n        lxml.html.HtmlElement: a parsed html document.\n    \"\"\"\n    page_links_template = (\n        \"https://www.nrk.no/serum/api/render/{tag}?\"\n        \"size=18&amp;perspective=BRIEF&amp;alignment=AUTO&amp;\"\n        \"classes=surrogate-content&amp;\"\n        \"display=false&amp;arrangement.offset={offset}&amp;\"\n        \"arrangement.quantity={quantity}&amp;\"\n        \"arrangement.repetition=PATTERN&amp;\"\n        \"arrangement.view[0].perspective=BRIEF&amp;\"\n        \"arrangement.view[0].size=6&amp;\"\n        \"arrangement.view[0].alignment=LEFT&amp;\"\n        \"paged=SIMPLE\"\n    )\n    quantity = 10\n    limit = 10000\n\n    for offset in range(0, limit, quantity):\n        print(\".\", end=\"\")\n        sys.stdout.flush()\n        try:\n            result = requests.get(\n                page_links_template.format(\n                    tag=tag, offset=offset, quantity=quantity\n                )\n            )\n        except requests.exceptions.ConnectionError:\n            util.note(f\"Connection error when fetching {tag}\")\n            break\n        else:\n            try:\n                yield html.document_fromstring(result.content)\n            except etree.ParserError:\n                util.note(f\"No more articles in tag: \u00ab{self.tags[tag]}\u00bb\")\n                break\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.guess_lang","title":"<code>guess_lang(address)</code>","text":"<p>Guess the language of the address element.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>html.Element</code> <p>An element where interesting text is found</p> required <p>Returns:</p> Type Description <p>str containing the language of the text</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def guess_lang(self, address):\n\"\"\"Guess the language of the address element.\n\n    Args:\n        address (html.Element): An element where interesting text is found\n\n    Returns:\n        str containing the language of the text\n    \"\"\"\n    # This bytes hoopla is done because the text\n    # comes out as utf8 encoded as latin1 \u2026\n    try:\n        text = bytes(\n            address.find('.//p[@class=\"plug-preamble\"]').text, encoding=\"latin1\"\n        )\n    except AttributeError:\n        text = bytes(address.find('.//h2[@class=\"title\"]').text, encoding=\"latin1\")\n    lang = self.language_guesser.classify(text)\n    if lang == \"sme\":\n        util.print_frame(text)\n\n    return lang\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.handle_search_hits","title":"<code>handle_search_hits(hits)</code>","text":"<p>Decide whether articles found in search results should be saved.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def handle_search_hits(self, hits):\n\"\"\"Decide whether articles found in search results should be saved.\"\"\"\n    for hit in hits:\n        if hit[\"url\"].split(\"-\")[-1] not in self.fetched_ids and hit.get(\n            \"description\"\n        ):\n            lang = self.language_guesser.classify(hit[\"description\"])\n            if lang == \"sme\":\n                util.print_frame(len(hit[\"description\"]), hit[\"description\"], \"\\n\")\n                if len(hit[\"description\"]) &gt; 15:\n                    self.counter[\"authors_fetched\"] += 1\n                    self.add_nrk_article(hit[\"url\"])\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.interesting_links","title":"<code>interesting_links(tag)</code>","text":"<p>Find interesting pages inside a topic.</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>a numerical tag pointing to a specific topic.</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>a url to an nrk.no article</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def interesting_links(self, tag):\n\"\"\"Find interesting pages inside a topic.\n\n    Args:\n        tag (str): a numerical tag pointing to a specific topic.\n\n    Yields:\n        str: a url to an nrk.no article\n    \"\"\"\n    for tree in self.get_tag_page_trees(tag):\n        for address in tree.xpath('//a[@class=\"autonomous lp_plug\"]'):\n            self.counter[tag + \"_total\"] += 1\n            href = address.get(\"href\")\n            article_id = href.strip().split(\"-\")[-1]\n            if \"systemtest\" in href:\n                self.invalid_links.add(href)\n            if (\n                \"systemtest\" not in href\n                and article_id not in self.fetched_ids\n                and self.guess_lang(address) == \"sme\"\n            ):\n                self.counter[tag + \"_fetched\"] += 1\n                yield href\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.pick_tags","title":"<code>pick_tags(path)</code>  <code>staticmethod</code>","text":"<p>Find tags in an nrk.no article.</p> <p>Tags potientially contain more Northern S\u00e1mi articles.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path to an nrk.no article</p> required <p>Yields:</p> Type Description <p>tuple of str: a numerical tag, used internally by nrk.no to point to a specific topic and a short description of the topic.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>@staticmethod\ndef pick_tags(path):\n\"\"\"Find tags in an nrk.no article.\n\n    Tags potientially contain more Northern S\u00e1mi articles.\n\n    Args:\n        path (str): path to an nrk.no article\n\n    Yields:\n        tuple of str: a numerical tag, used internally by nrk.no to point\n            to a specific topic and a short description of the topic.\n    \"\"\"\n    article = html.parse(path)\n\n    for address in article.xpath(\n        '//a[@class=\"universe widget reference article-universe-link '\n        'universe-teaser skin-border skin-text lp_universe_link\"]'\n    ):\n        href = address.get(\"href\")\n        yield href[href.rfind(\"-\") + 1 :], address[0].tail.strip()\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.report","title":"<code>report()</code>","text":"<p>Print a report on what was found.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>def report(self):\n\"\"\"Print a report on what was found.\"\"\"\n    print(f\"{len(self.invalid_links)} invalid links.\")\n    for invalid_link in self.invalid_links:\n        print(invalid_link)\n    print()\n    print(f\"Searched through {len(self.tags)} tags\")\n    print(f\"Searched through {len(self.authors)} authors\")\n    print(\"Fetched {fetched} pages\".format(**self.counter))\n    for tag in self.tags:\n        if self.counter[tag + \"_fetched\"]:\n            print(\n                \"Fetched {} articles from category {} from nrk.no\".format(\n                    self.counter[tag + \"_fetched\"], self.tags[tag]\n                )\n            )\n</code></pre>"},{"location":"reference/nrk_no_crawler/#corpustools.nrk_no_crawler.NrkSmeCrawler.valid_authors","title":"<code>valid_authors(article)</code>  <code>staticmethod</code>","text":"<p>Find authors with the correct roles.</p> <p>Parameters:</p> Name Type Description Default <code>article</code> <code>etree.Element</code> <p>The parsed html document.</p> required <p>Yields:</p> Type Description <p>tuple of str</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/nrk_no_crawler.py</code> <pre><code>@staticmethod\ndef valid_authors(article):\n\"\"\"Find authors with the correct roles.\n\n    Args:\n        article (etree.Element): The parsed html document.\n\n    Yields:\n        tuple of str\n    \"\"\"\n    for author_role in article.xpath('.//span[@class=\"author__role\"]'):\n        text = author_role.text.strip()\n        if text is not None and (\n            text.startswith(\"Journ\")\n            or text.startswith(\"Komm\")\n            or text.startswith(\"Arti\")\n        ):\n            parts = author_role.getprevious().text.strip().split()\n\n            yield parts\n</code></pre>"},{"location":"reference/one-off-functions/","title":"one-off-functions","text":"<p>One off funtions to set metadata.</p> <p>Might be useful in other contexts.</p>"},{"location":"reference/one-off-functions/#corpustools.one-off-functions.find_endings","title":"<code>find_endings(directories, suffix)</code>","text":"<p>Find all files in with suffix within directories.</p> <p>Parameters:</p> Name Type Description Default <code>directories</code> <code>list of str</code> <p>list of directories to walk</p> required <code>suffix</code> <code>str</code> <p>files suffixes to be searched for</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>path to file with suffix</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/one-off-functions.py</code> <pre><code>def find_endings(directories, suffix):\n\"\"\"Find all files in with suffix within directories.\n\n    Args:\n        directories (list of str): list of directories to walk\n        suffix (str): files suffixes to be searched for\n\n    Yields:\n        str: path to file with suffix\n    \"\"\"\n    for directory in directories:\n        for root, _, files in os.walk(directory):\n            for file_ in files:\n                if file_.endswith(suffix):\n                    yield os.path.join(root, file_)\n</code></pre>"},{"location":"reference/one-off-functions/#corpustools.one-off-functions.regjeringen_no","title":"<code>regjeringen_no(directories)</code>","text":"<p>Set metadata for regjeringen.no html files.</p> <p>Parameters:</p> Name Type Description Default <code>directories</code> <code>list of str</code> <p>list of directories to walk</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/one-off-functions.py</code> <pre><code>def regjeringen_no(directories):\n\"\"\"Set metadata for regjeringen.no html files.\n\n    Args:\n        directories (list of str): list of directories to walk\n    \"\"\"\n    for html_file in find_endings(directories, \".html\"):\n        conv = converter.HTMLConverter(html_file)\n        content = html.document_fromstring(conv.content)\n\n        should_write = False\n        author = content.find('.//meta[@name=\"AUTHOR\"]')\n        if author is not None:\n            should_write = True\n            conv.md.set_variable(\"author1_ln\", author.get(\"content\"))\n\n        creation_date = content.find('.//meta[@name=\"creation_date\"]')\n        if creation_date is not None:\n            should_write = True\n            conv.md.set_variable(\"year\", parse(creation_date.get(\"content\")).year)\n\n        publisher = content.find('.//meta[@name=\"DC.Publisher\"]')\n        if publisher is not None:\n            should_write = True\n            conv.md.set_variable(\"publisher\", publisher.get(\"content\"))\n\n        if should_write:\n            conv.md.write_file()\n</code></pre>"},{"location":"reference/one-off-functions/#corpustools.one-off-functions.skuvla_historja","title":"<code>skuvla_historja(directories)</code>","text":"<p>Find skuvlahistorja directories in paths, set year.</p> <p>Parameters:</p> Name Type Description Default <code>directories</code> <code>list of str</code> <p>list of directories to walk</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/one-off-functions.py</code> <pre><code>def skuvla_historja(directories):\n\"\"\"Find skuvlahistorja directories in paths, set year.\n\n    Args:\n        directories (list of str): list of directories to walk\n    \"\"\"\n    years = {\n        \"skuvlahistorja1\": \"2005\",\n        \"skuvlahistorja2\": \"2007\",\n        \"skuvlahistorja3\": \"2009\",\n        \"skuvlahistorja4\": \"2010\",\n        \"skuvlahistorja5\": \"2011\",\n        \"skuvlahistorja6\": \"2013\",\n    }\n\n    for file_ in find_endings(directories, \".xsl\"):\n        if \"skuvlahistorja\" in file_:\n            print(file_)\n            metadata = xslsetter.MetadataHandler(file_)\n            metadata.set_variable(\"year\", years[file_.split(\"/\")[-1]])\n            metadata.write_file()\n</code></pre>"},{"location":"reference/one-off-functions/#corpustools.one-off-functions.to_free","title":"<code>to_free(path)</code>","text":"<p>Set the lisence type.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/one-off-functions.py</code> <pre><code>def to_free(path):\n\"\"\"Set the lisence type.\"\"\"\n    conv_manager = converter.ConverterManager(False, False)\n    conv_manager.collect_files([path])\n\n    for file_ in conv_manager.FILES:\n        conv = conv_manager.converter(file_)\n        conv.md.set_variable(\"license_type\", \"free\")\n        conv.md.write_file()\n</code></pre>"},{"location":"reference/one-off-functions/#corpustools.one-off-functions.translated_from","title":"<code>translated_from(url_part, mainlang, directories)</code>","text":"<p>Set all docs from url_part to be translated from mainlang.</p> <p>Parameters:</p> Name Type Description Default <code>url_part</code> <code>str</code> <p>the defining part of the url</p> required <code>mainlang</code> <code>str</code> <p>three character long language code</p> required <code>directories</code> <code>list of str</code> <p>list of directories to walk</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/one-off-functions.py</code> <pre><code>def translated_from(url_part, mainlang, directories):\n\"\"\"Set all docs from url_part to be translated from mainlang.\n\n    Args:\n        url_part (str): the defining part of the url\n        mainlang (str): three character long language code\n        directories (list of str): list of directories to walk\n    \"\"\"\n    # Check if the arguments are valid\n    if \".\" not in url_part:\n        raise UserWarning(f\"{url_part} does not seem to part of a url\")\n    if len(mainlang) != 3 and not isinstance(mainlang, \"str\"):\n        raise UserWarning(\"{} does not seem to be a valid language code\")\n\n    counter = collections.defaultdict(int)\n    for file_ in find_endings(directories, \".xsl\"):\n        corpus_path = corpuspath.CorpusPath(file_)\n        if (\n            url_part in corpus_path.metadata.get_variable(\"filename\")\n            and corpus_path.metadata.get_variable(\"mainlang\") == mainlang\n        ):\n            counter[mainlang] += 1\n            for parallel in corpus_path.parallels():\n                counter[\"parallels\"] += 1\n                try:\n                    metadata = xslsetter.MetadataHandler(parallel + \".xsl\")\n                except util.ArgumentError as error:\n                    util.note(error)\n                    util.note(f\"Referenced from {file_}\")\n                finally:\n                    metadata.set_variable(\"translated_from\", mainlang)\n                    metadata.write_file()\n\n    print(counter)\n</code></pre>"},{"location":"reference/packagetmx/","title":"packagetmx","text":"<p>Add tmx files to a zipfile.</p>"},{"location":"reference/packagetmx/#corpustools.packagetmx.PackageTmx","title":"<code>PackageTmx</code>","text":"<p>A class to package tmx files into a zip file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>class PackageTmx:\n\"\"\"A class to package tmx files into a zip file.\"\"\"\n\n    def __init__(self, dirname):\n\"\"\"Set the counter on which filenames are based.\"\"\"\n        self.fileId = 1\n        self.date = time.strftime(\"%Y-%m-%d\", time.localtime())\n        self.dirname = dirname\n        self.zipname = self.dirname + \"-\" + self.date + \".zip\"\n        self.zipfile = zipfile.ZipFile(self.zipname, mode=\"w\")\n\n    def __del__(self):\n\"\"\"Close the zipfile.\"\"\"\n        print(\"All tmx files are in\", self.zipname)\n        self.zipfile.close()\n\n    def find_tmx_files(self):\n\"\"\"Find the tmx files in dirname, return them as a list.\"\"\"\n        filelist = []\n        for root, dirs, files in os.walk(\n            os.path.join(os.environ[\"GTFREE\"], \"prestable/tmx/\" + self.dirname)\n        ):\n            for f in files:\n                if f.endswith(\".tmx\"):\n                    filelist.append(os.path.join(root, f))\n\n        return filelist\n\n    def generate_filename(self):\n\"\"\"Generate a new file name. Return the new filename.\"\"\"\n        name = \"\".join([self.dirname, \"-\", self.date, f\"-{self.fileId:06d}\", \".tmx\"])\n        self.fileId += 1\n\n        return name\n\n    def write_new_file(self, tmxFile):\n\"\"\"Write the file to the zipfile with a new filename.\"\"\"\n        # print \"Writing\", self.tmxFile, 'as', self.generateFilename()\n        self.zipfile.write(\n            tmxFile,\n            arcname=self.generate_filename(),\n            compress_type=zipfile.ZIP_DEFLATED,\n        )\n</code></pre>"},{"location":"reference/packagetmx/#corpustools.packagetmx.PackageTmx.__del__","title":"<code>__del__()</code>","text":"<p>Close the zipfile.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>def __del__(self):\n\"\"\"Close the zipfile.\"\"\"\n    print(\"All tmx files are in\", self.zipname)\n    self.zipfile.close()\n</code></pre>"},{"location":"reference/packagetmx/#corpustools.packagetmx.PackageTmx.__init__","title":"<code>__init__(dirname)</code>","text":"<p>Set the counter on which filenames are based.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>def __init__(self, dirname):\n\"\"\"Set the counter on which filenames are based.\"\"\"\n    self.fileId = 1\n    self.date = time.strftime(\"%Y-%m-%d\", time.localtime())\n    self.dirname = dirname\n    self.zipname = self.dirname + \"-\" + self.date + \".zip\"\n    self.zipfile = zipfile.ZipFile(self.zipname, mode=\"w\")\n</code></pre>"},{"location":"reference/packagetmx/#corpustools.packagetmx.PackageTmx.find_tmx_files","title":"<code>find_tmx_files()</code>","text":"<p>Find the tmx files in dirname, return them as a list.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>def find_tmx_files(self):\n\"\"\"Find the tmx files in dirname, return them as a list.\"\"\"\n    filelist = []\n    for root, dirs, files in os.walk(\n        os.path.join(os.environ[\"GTFREE\"], \"prestable/tmx/\" + self.dirname)\n    ):\n        for f in files:\n            if f.endswith(\".tmx\"):\n                filelist.append(os.path.join(root, f))\n\n    return filelist\n</code></pre>"},{"location":"reference/packagetmx/#corpustools.packagetmx.PackageTmx.generate_filename","title":"<code>generate_filename()</code>","text":"<p>Generate a new file name. Return the new filename.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>def generate_filename(self):\n\"\"\"Generate a new file name. Return the new filename.\"\"\"\n    name = \"\".join([self.dirname, \"-\", self.date, f\"-{self.fileId:06d}\", \".tmx\"])\n    self.fileId += 1\n\n    return name\n</code></pre>"},{"location":"reference/packagetmx/#corpustools.packagetmx.PackageTmx.write_new_file","title":"<code>write_new_file(tmxFile)</code>","text":"<p>Write the file to the zipfile with a new filename.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>def write_new_file(self, tmxFile):\n\"\"\"Write the file to the zipfile with a new filename.\"\"\"\n    # print \"Writing\", self.tmxFile, 'as', self.generateFilename()\n    self.zipfile.write(\n        tmxFile,\n        arcname=self.generate_filename(),\n        compress_type=zipfile.ZIP_DEFLATED,\n    )\n</code></pre>"},{"location":"reference/packagetmx/#corpustools.packagetmx.main","title":"<code>main()</code>","text":"<p>Make a package containing the tmx files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>def main():\n\"\"\"Make a package containing the tmx files.\"\"\"\n    parse_options()\n\n    for dirname in [\"nob2sme\"]:\n        packagetmx = PackageTmx(dirname)\n        for filename in packagetmx.find_tmx_files():\n            packagetmx.write_new_file(filename)\n</code></pre>"},{"location":"reference/packagetmx/#corpustools.packagetmx.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the command line. No arguments expected.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/packagetmx.py</code> <pre><code>def parse_options():\n\"\"\"Parse the command line. No arguments expected.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Run this to add tmx \"\n        \"files to a zip archive. It depends on \"\n        \"tmx files to exist in \"\n        \"$GTFREE/prestable/tmx.\"\n    )\n\n    parser.parse_args()\n</code></pre>"},{"location":"reference/parallelize/","title":"parallelize","text":"<p>Classes and functions to sentence align two files.</p>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize","title":"<code>Parallelize</code>","text":"<p>A class to parallelize two files.</p> <p>Input is the xml file that should be parallellized and the language that it should be parallellized with. The language of the input file is found in the metadata of the input file. The other file is found via the metadata in the input file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>class Parallelize:\n\"\"\"A class to parallelize two files.\n\n    Input is the xml file that should be parallellized and the language that it\n    should be parallellized with.\n    The language of the input file is found in the metadata of the input file.\n    The other file is found via the metadata in the input file\n    \"\"\"\n\n    def __init__(\n        self, origfile1, lang2, anchor_file=None, quiet=False, giella_prefix=None\n    ):\n\"\"\"Initialise the Parallelize class.\n\n        Args:\n            origfile1 (str): path to one of the files that should be\n                sentence aligned.\n            lang2 (str): language of the other file that should be\n                sentence aligned.\n            anchor_file (str): path to the anchor file. Defaults to None.\n                A real file is only needed when using tca2 for sentence\n                alignment.\n            quiet (bool): If True, be verbose. Otherwise, be quiet.\n        \"\"\"\n        self.quiet = quiet\n        self.origfiles = []\n        self.giella_prefix = giella_prefix\n        self.origfiles.append(corpuspath.CorpusPath(os.path.abspath(origfile1)))\n\n        para_file = self.origfiles[0].parallel(lang2)\n        if para_file is not None:\n            self.origfiles.append(corpuspath.CorpusPath(para_file))\n        else:\n            raise OSError(f\"{origfile1} doesn't have a parallel file in {lang2}\")\n\n        # As stated in --help, we assume user-specified anchor file\n        # has columns based on input files, where --parallel_file is\n        # column two regardless of what file was translated from what,\n        # therefore we set this before reshuffling:\n        if self.is_translated_from_lang2():\n            (self.origfiles[1], self.origfiles[0]) = (\n                self.origfiles[0],\n                self.origfiles[1],\n            )\n\n        self.gal = self.setup_anchors(anchor_file)\n\n    def setup_anchors(self, path):\n\"\"\"Setup anchor file.\n\n        Args:\n            path (str): where the anchor file will be written.\n            cols (list of str): list of all the possible langs.\n\n        Returns:\n            generate_anchor_list.GenerateAnchorList\n        \"\"\"\n        if path is None:\n            path1 = os.path.join(\n                os.environ[\"GTHOME\"],\n                f\"gt/common/src/anchor-{self.lang1}-{self.lang2}.txt\",\n            )\n            path2 = os.path.join(\n                os.environ[\"GTHOME\"],\n                f\"gt/common/src/anchor-{self.lang2}-{self.lang1}.txt\",\n            )\n            if os.path.exists(path1):\n\n                return generate_anchor_list.GenerateAnchorList(\n                    self.lang1, self.lang2, [self.lang1, self.lang2], path1\n                )\n            elif os.path.exists(path2):\n                return generate_anchor_list.GenerateAnchorList(\n                    self.lang1, self.lang2, [self.lang2, self.lang1], path2\n                )\n            else:\n                if not self.quiet:\n                    util.note(\n                        \"No anchor file for the {}/{} combo. \"\n                        \"Making a fake anchor file\".format(self.lang1, self.lang2)\n                    )\n\n    @property\n    def outfile_name(self):\n\"\"\"Compute the name of the final tmx file.\"\"\"\n        return self.origfiles[0].prestable_tmx(self.lang2)\n\n    @property\n    def lang1(self):\n\"\"\"Get language 1.\"\"\"\n        return self.origfiles[0].pathcomponents.lang\n\n    @property\n    def lang2(self):\n\"\"\"Get language 2.\"\"\"\n        return self.origfiles[1].pathcomponents.lang\n\n    @property\n    def origfile1(self):\n\"\"\"Name of the original file 1.\"\"\"\n        return self.origfiles[0].orig\n\n    @property\n    def origfile2(self):\n\"\"\"Name of the original file 2.\"\"\"\n        return self.origfiles[1].orig\n\n    def is_translated_from_lang2(self):\n\"\"\"Find out if the given doc is translated from lang2.\"\"\"\n        translated_from = self.origfiles[0].metadata.get_variable(\"translated_from\")\n\n        if translated_from is not None:\n            return translated_from == self.lang2\n        else:\n            return False\n\n    def parallelize_files(self):\n\"\"\"Parallelize two files.\"\"\"\n        if not self.quiet:\n            util.note(\"Aligning files \u2026\")\n        return self.align()\n\n    def run_command(self, command):\n\"\"\"Run a parallelize command and return its output.\"\"\"\n        if not self.quiet:\n            util.note(\"Running {}\".format(\" \".join(command)))\n        subp = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        (output, error) = subp.communicate()\n\n        if subp.returncode != 0:\n            raise UserWarning(\n                \"Could not parallelize {} and {} into \"\n                \"sentences\\n{}\\n\\n{}\\n\".format(\n                    self.origfile1,\n                    self.origfile2,\n                    output.decode(\"utf8\"),\n                    error.decode(\"utf8\"),\n                )\n            )\n\n        return output, error\n\n    def align(self):\n\"\"\"Sentence align two corpus files.\"\"\"\n        raise NotImplementedError(\"You have to subclass and override align\")\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.lang1","title":"<code>lang1</code>  <code>property</code>","text":"<p>Get language 1.</p>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.lang2","title":"<code>lang2</code>  <code>property</code>","text":"<p>Get language 2.</p>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.origfile1","title":"<code>origfile1</code>  <code>property</code>","text":"<p>Name of the original file 1.</p>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.origfile2","title":"<code>origfile2</code>  <code>property</code>","text":"<p>Name of the original file 2.</p>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.outfile_name","title":"<code>outfile_name</code>  <code>property</code>","text":"<p>Compute the name of the final tmx file.</p>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.__init__","title":"<code>__init__(origfile1, lang2, anchor_file=None, quiet=False, giella_prefix=None)</code>","text":"<p>Initialise the Parallelize class.</p> <p>Parameters:</p> Name Type Description Default <code>origfile1</code> <code>str</code> <p>path to one of the files that should be sentence aligned.</p> required <code>lang2</code> <code>str</code> <p>language of the other file that should be sentence aligned.</p> required <code>anchor_file</code> <code>str</code> <p>path to the anchor file. Defaults to None. A real file is only needed when using tca2 for sentence alignment.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>If True, be verbose. Otherwise, be quiet.</p> <code>False</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def __init__(\n    self, origfile1, lang2, anchor_file=None, quiet=False, giella_prefix=None\n):\n\"\"\"Initialise the Parallelize class.\n\n    Args:\n        origfile1 (str): path to one of the files that should be\n            sentence aligned.\n        lang2 (str): language of the other file that should be\n            sentence aligned.\n        anchor_file (str): path to the anchor file. Defaults to None.\n            A real file is only needed when using tca2 for sentence\n            alignment.\n        quiet (bool): If True, be verbose. Otherwise, be quiet.\n    \"\"\"\n    self.quiet = quiet\n    self.origfiles = []\n    self.giella_prefix = giella_prefix\n    self.origfiles.append(corpuspath.CorpusPath(os.path.abspath(origfile1)))\n\n    para_file = self.origfiles[0].parallel(lang2)\n    if para_file is not None:\n        self.origfiles.append(corpuspath.CorpusPath(para_file))\n    else:\n        raise OSError(f\"{origfile1} doesn't have a parallel file in {lang2}\")\n\n    # As stated in --help, we assume user-specified anchor file\n    # has columns based on input files, where --parallel_file is\n    # column two regardless of what file was translated from what,\n    # therefore we set this before reshuffling:\n    if self.is_translated_from_lang2():\n        (self.origfiles[1], self.origfiles[0]) = (\n            self.origfiles[0],\n            self.origfiles[1],\n        )\n\n    self.gal = self.setup_anchors(anchor_file)\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.align","title":"<code>align()</code>","text":"<p>Sentence align two corpus files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def align(self):\n\"\"\"Sentence align two corpus files.\"\"\"\n    raise NotImplementedError(\"You have to subclass and override align\")\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.is_translated_from_lang2","title":"<code>is_translated_from_lang2()</code>","text":"<p>Find out if the given doc is translated from lang2.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def is_translated_from_lang2(self):\n\"\"\"Find out if the given doc is translated from lang2.\"\"\"\n    translated_from = self.origfiles[0].metadata.get_variable(\"translated_from\")\n\n    if translated_from is not None:\n        return translated_from == self.lang2\n    else:\n        return False\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.parallelize_files","title":"<code>parallelize_files()</code>","text":"<p>Parallelize two files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def parallelize_files(self):\n\"\"\"Parallelize two files.\"\"\"\n    if not self.quiet:\n        util.note(\"Aligning files \u2026\")\n    return self.align()\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.run_command","title":"<code>run_command(command)</code>","text":"<p>Run a parallelize command and return its output.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def run_command(self, command):\n\"\"\"Run a parallelize command and return its output.\"\"\"\n    if not self.quiet:\n        util.note(\"Running {}\".format(\" \".join(command)))\n    subp = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (output, error) = subp.communicate()\n\n    if subp.returncode != 0:\n        raise UserWarning(\n            \"Could not parallelize {} and {} into \"\n            \"sentences\\n{}\\n\\n{}\\n\".format(\n                self.origfile1,\n                self.origfile2,\n                output.decode(\"utf8\"),\n                error.decode(\"utf8\"),\n            )\n        )\n\n    return output, error\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Parallelize.setup_anchors","title":"<code>setup_anchors(path)</code>","text":"<p>Setup anchor file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>where the anchor file will be written.</p> required <code>cols</code> <code>list of str</code> <p>list of all the possible langs.</p> required <p>Returns:</p> Type Description <p>generate_anchor_list.GenerateAnchorList</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def setup_anchors(self, path):\n\"\"\"Setup anchor file.\n\n    Args:\n        path (str): where the anchor file will be written.\n        cols (list of str): list of all the possible langs.\n\n    Returns:\n        generate_anchor_list.GenerateAnchorList\n    \"\"\"\n    if path is None:\n        path1 = os.path.join(\n            os.environ[\"GTHOME\"],\n            f\"gt/common/src/anchor-{self.lang1}-{self.lang2}.txt\",\n        )\n        path2 = os.path.join(\n            os.environ[\"GTHOME\"],\n            f\"gt/common/src/anchor-{self.lang2}-{self.lang1}.txt\",\n        )\n        if os.path.exists(path1):\n\n            return generate_anchor_list.GenerateAnchorList(\n                self.lang1, self.lang2, [self.lang1, self.lang2], path1\n            )\n        elif os.path.exists(path2):\n            return generate_anchor_list.GenerateAnchorList(\n                self.lang1, self.lang2, [self.lang2, self.lang1], path2\n            )\n        else:\n            if not self.quiet:\n                util.note(\n                    \"No anchor file for the {}/{} combo. \"\n                    \"Making a fake anchor file\".format(self.lang1, self.lang2)\n                )\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeHunalign","title":"<code>ParallelizeHunalign</code>","text":"<p>         Bases: <code>Parallelize</code></p> <p>Use hunalign to parallelise two converted corpus files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>class ParallelizeHunalign(Parallelize):\n\"\"\"Use hunalign to parallelise two converted corpus files.\"\"\"\n\n    split_anchors_on = re.compile(r\" *, *\")\n\n    def anchor_to_dict(self, words_pairs):\n\"\"\"Turn anchorfile tuples into a dictionary.\"\"\"\n        # turn [(\"foo, bar\", \"fie\")] into [(\"foo\", \"fie\"), (\"bar\", \"fie\")]:\n        expanded_pairs = [\n            (w1, w2)\n            for w1s, w2s in words_pairs\n            for w1 in re.split(self.split_anchors_on, w1s)\n            for w2 in re.split(self.split_anchors_on, w2s)\n            if w1 and w2\n        ]\n        return expanded_pairs\n\n    def make_dict(self):\n\"\"\"Turn an anchorlist to a dictionary.\"\"\"\n        if self.gal is not None:\n            assert self.gal.lang1 == self.lang1\n            assert self.gal.lang2 == self.lang2\n            words_pairs = self.gal.read_anchors(quiet=self.quiet)\n            expanded_pairs = self.anchor_to_dict(words_pairs)\n            cleaned_pairs = [\n                (w1.replace(\"*\", \"\"), w2.replace(\"*\", \"\")) for w1, w2 in expanded_pairs\n            ]\n        else:\n            cleaned_pairs = [(self.lang1, self.lang2)]\n        # Hunalign expects the _reverse_ format for the dictionary!\n        # See Dictionary under http://mokk.bme.hu/resources/hunalign/\n        return \"\\n\".join([f\"{w2} @ {w1}\" for w1, w2 in cleaned_pairs]) + \"\\n\"\n\n    def to_sents(self, origfile):\n\"\"\"Divide the content of origfile to sentences.\"\"\"\n        divider = sentencedivider.SentenceDivider(\n            origfile.pathcomponents.lang, giella_prefix=self.giella_prefix\n        )\n        return \"\\n\".join(\n            divider.make_valid_sentences(\n                sentencedivider.to_plain_text(\n                    origfile.pathcomponents.lang, origfile.converted\n                )\n            )\n        )\n\n    def align(self):\n\"\"\"Parallelize two files using hunalign.\"\"\"\n\n        def tmp():\n\"\"\"Temporary filename.\n\n            Returns:\n                str: name of the temporary file\n            \"\"\"\n            return tempfile.NamedTemporaryFile(\"wb\")\n\n        with tmp() as dict_f, tmp() as sent0_f, tmp() as sent1_f:\n            dict_f.write(self.make_dict().encode(\"utf8\"))\n            sent0_f.write(self.to_sents(self.origfiles[0]).encode(\"utf8\"))\n            sent1_f.write(self.to_sents(self.origfiles[1]).encode(\"utf8\"))\n            dict_f.flush()\n            sent0_f.flush()\n            sent1_f.flush()\n\n            command = [\n                \"hunalign\",\n                \"-utf\",\n                \"-realign\",\n                \"-text\",\n                dict_f.name,\n                sent0_f.name,\n                sent1_f.name,\n            ]\n            output, _ = self.run_command(command)\n\n        translation_mem_ex = tmx.HunalignToTmx(self.origfiles, output.decode(\"utf-8\"))\n        return translation_mem_ex\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeHunalign.align","title":"<code>align()</code>","text":"<p>Parallelize two files using hunalign.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def align(self):\n\"\"\"Parallelize two files using hunalign.\"\"\"\n\n    def tmp():\n\"\"\"Temporary filename.\n\n        Returns:\n            str: name of the temporary file\n        \"\"\"\n        return tempfile.NamedTemporaryFile(\"wb\")\n\n    with tmp() as dict_f, tmp() as sent0_f, tmp() as sent1_f:\n        dict_f.write(self.make_dict().encode(\"utf8\"))\n        sent0_f.write(self.to_sents(self.origfiles[0]).encode(\"utf8\"))\n        sent1_f.write(self.to_sents(self.origfiles[1]).encode(\"utf8\"))\n        dict_f.flush()\n        sent0_f.flush()\n        sent1_f.flush()\n\n        command = [\n            \"hunalign\",\n            \"-utf\",\n            \"-realign\",\n            \"-text\",\n            dict_f.name,\n            sent0_f.name,\n            sent1_f.name,\n        ]\n        output, _ = self.run_command(command)\n\n    translation_mem_ex = tmx.HunalignToTmx(self.origfiles, output.decode(\"utf-8\"))\n    return translation_mem_ex\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeHunalign.anchor_to_dict","title":"<code>anchor_to_dict(words_pairs)</code>","text":"<p>Turn anchorfile tuples into a dictionary.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def anchor_to_dict(self, words_pairs):\n\"\"\"Turn anchorfile tuples into a dictionary.\"\"\"\n    # turn [(\"foo, bar\", \"fie\")] into [(\"foo\", \"fie\"), (\"bar\", \"fie\")]:\n    expanded_pairs = [\n        (w1, w2)\n        for w1s, w2s in words_pairs\n        for w1 in re.split(self.split_anchors_on, w1s)\n        for w2 in re.split(self.split_anchors_on, w2s)\n        if w1 and w2\n    ]\n    return expanded_pairs\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeHunalign.make_dict","title":"<code>make_dict()</code>","text":"<p>Turn an anchorlist to a dictionary.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def make_dict(self):\n\"\"\"Turn an anchorlist to a dictionary.\"\"\"\n    if self.gal is not None:\n        assert self.gal.lang1 == self.lang1\n        assert self.gal.lang2 == self.lang2\n        words_pairs = self.gal.read_anchors(quiet=self.quiet)\n        expanded_pairs = self.anchor_to_dict(words_pairs)\n        cleaned_pairs = [\n            (w1.replace(\"*\", \"\"), w2.replace(\"*\", \"\")) for w1, w2 in expanded_pairs\n        ]\n    else:\n        cleaned_pairs = [(self.lang1, self.lang2)]\n    # Hunalign expects the _reverse_ format for the dictionary!\n    # See Dictionary under http://mokk.bme.hu/resources/hunalign/\n    return \"\\n\".join([f\"{w2} @ {w1}\" for w1, w2 in cleaned_pairs]) + \"\\n\"\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeHunalign.to_sents","title":"<code>to_sents(origfile)</code>","text":"<p>Divide the content of origfile to sentences.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def to_sents(self, origfile):\n\"\"\"Divide the content of origfile to sentences.\"\"\"\n    divider = sentencedivider.SentenceDivider(\n        origfile.pathcomponents.lang, giella_prefix=self.giella_prefix\n    )\n    return \"\\n\".join(\n        divider.make_valid_sentences(\n            sentencedivider.to_plain_text(\n                origfile.pathcomponents.lang, origfile.converted\n            )\n        )\n    )\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeTCA2","title":"<code>ParallelizeTCA2</code>","text":"<p>         Bases: <code>Parallelize</code></p> <p>Use tca2 to parallelise two converted corpus files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>class ParallelizeTCA2(Parallelize):\n\"\"\"Use tca2 to parallelise two converted corpus files.\"\"\"\n\n    def generate_anchor_file(self, outpath):\n\"\"\"Generate an anchor file with lang1 and lang2.\"\"\"\n        if self.gal is not None:\n            assert self.gal.lang1 == self.lang1\n            assert self.gal.lang2 == self.lang2\n            self.gal.generate_file(outpath, quiet=self.quiet)\n        else:\n            with open(outpath, \"w\") as outfile:\n                print(f\"{self.lang1} / {self.lang2}\", file=outfile)\n\n    def divide_p_into_sentences(self):\n\"\"\"Tokenize the text in the given file and reassemble it again.\"\"\"\n        for pfile in self.origfiles:\n            divider = Tca2SentenceDivider()\n            divider.make_sentence_file(\n                pfile.pathcomponents.lang,\n                pfile.converted,\n                pfile.sent_filename,\n                self.giella_prefix,\n            )\n\n    @property\n    def sentfiles(self):\n\"\"\"Get files containing the sentences.\"\"\"\n        return [name.sent_filename for name in self.origfiles]\n\n    def align(self):\n\"\"\"Parallelize two files using tca2.\"\"\"\n        if not self.quiet:\n            util.note(\"Adding sentence structure for the aligner \u2026\")\n        self.divide_p_into_sentences()\n\n        tca2_jar = os.path.join(HERE, \"tca2/dist/lib/alignment.jar\")\n        # util.sanity_check([tca2_jar])\n\n        with tempfile.NamedTemporaryFile(\"w\") as anchor_file:\n            self.generate_anchor_file(anchor_file.name)\n            anchor_file.flush()\n            command = (\n                \"java -Xms512m -Xmx1024m -jar {} -cli-plain -anchor={} \"\n                \"-in1={} -in2={}\".format(\n                    tca2_jar,\n                    anchor_file.name,\n                    self.origfiles[0].sent_filename,\n                    self.origfiles[1].sent_filename,\n                )\n            )\n\n            self.run_command(command.split())\n\n        translation_mem_ex = tmx.Tca2ToTmx(self.origfiles, self.sentfiles)\n        return translation_mem_ex\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeTCA2.sentfiles","title":"<code>sentfiles</code>  <code>property</code>","text":"<p>Get files containing the sentences.</p>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeTCA2.align","title":"<code>align()</code>","text":"<p>Parallelize two files using tca2.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def align(self):\n\"\"\"Parallelize two files using tca2.\"\"\"\n    if not self.quiet:\n        util.note(\"Adding sentence structure for the aligner \u2026\")\n    self.divide_p_into_sentences()\n\n    tca2_jar = os.path.join(HERE, \"tca2/dist/lib/alignment.jar\")\n    # util.sanity_check([tca2_jar])\n\n    with tempfile.NamedTemporaryFile(\"w\") as anchor_file:\n        self.generate_anchor_file(anchor_file.name)\n        anchor_file.flush()\n        command = (\n            \"java -Xms512m -Xmx1024m -jar {} -cli-plain -anchor={} \"\n            \"-in1={} -in2={}\".format(\n                tca2_jar,\n                anchor_file.name,\n                self.origfiles[0].sent_filename,\n                self.origfiles[1].sent_filename,\n            )\n        )\n\n        self.run_command(command.split())\n\n    translation_mem_ex = tmx.Tca2ToTmx(self.origfiles, self.sentfiles)\n    return translation_mem_ex\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeTCA2.divide_p_into_sentences","title":"<code>divide_p_into_sentences()</code>","text":"<p>Tokenize the text in the given file and reassemble it again.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def divide_p_into_sentences(self):\n\"\"\"Tokenize the text in the given file and reassemble it again.\"\"\"\n    for pfile in self.origfiles:\n        divider = Tca2SentenceDivider()\n        divider.make_sentence_file(\n            pfile.pathcomponents.lang,\n            pfile.converted,\n            pfile.sent_filename,\n            self.giella_prefix,\n        )\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.ParallelizeTCA2.generate_anchor_file","title":"<code>generate_anchor_file(outpath)</code>","text":"<p>Generate an anchor file with lang1 and lang2.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def generate_anchor_file(self, outpath):\n\"\"\"Generate an anchor file with lang1 and lang2.\"\"\"\n    if self.gal is not None:\n        assert self.gal.lang1 == self.lang1\n        assert self.gal.lang2 == self.lang2\n        self.gal.generate_file(outpath, quiet=self.quiet)\n    else:\n        with open(outpath, \"w\") as outfile:\n            print(f\"{self.lang1} / {self.lang2}\", file=outfile)\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Tca2SentenceDivider","title":"<code>Tca2SentenceDivider</code>","text":"<p>Make tca2 compatible input files.</p> <p>It spits out an xml document that has divided the text into sentences. Each sentence is encased in an s tag, and has an id number</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>class Tca2SentenceDivider:\n\"\"\"Make tca2 compatible input files.\n\n    It spits out an xml document that has divided the text into sentences.\n    Each sentence is encased in an s tag, and has an id number\n    \"\"\"\n\n    @staticmethod\n    def make_sentence_xml(lang, xmlfile, giella_prefix):\n\"\"\"Make sentence xml that tca2 can use.\n\n        Args:\n            lang (str): three character name of main language of document.\n            filename (str): name of the xmlfile\n\n        Returns:\n            lxml.etree._Element: an xml element containing all sentences.\n        \"\"\"\n        document = etree.Element(\"document\")\n\n        divider = sentencedivider.SentenceDivider(lang, giella_prefix)\n        for index, sentence in enumerate(\n            divider.make_valid_sentences(sentencedivider.to_plain_text(lang, xmlfile))\n        ):\n            s_elem = etree.Element(\"s\")\n            s_elem.attrib[\"id\"] = str(index)\n            s_elem.text = sentence\n            document.append(s_elem)\n\n        return document\n\n    def make_sentence_file(self, lang, xmlfile, outfile, giella_prefix):\n\"\"\"Make input document for tca2.\n\n        Args:\n            lang (str): three character name for main language of document.\n            xmlfile (str): name of the xmlfile\n            outfile (str): name of the input file for tca2\n        \"\"\"\n        o_path, _ = os.path.split(outfile)\n        o_rel_path = o_path.replace(os.getcwd() + \"/\", \"\", 1)\n        with util.ignored(OSError):\n            os.makedirs(o_rel_path)\n        with open(outfile, \"wb\") as sentence_file:\n            tree = etree.ElementTree(\n                self.make_sentence_xml(lang, xmlfile, giella_prefix=giella_prefix)\n            )\n            tree.write(\n                sentence_file, pretty_print=True, encoding=\"utf8\", xml_declaration=True\n            )\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Tca2SentenceDivider.make_sentence_file","title":"<code>make_sentence_file(lang, xmlfile, outfile, giella_prefix)</code>","text":"<p>Make input document for tca2.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>three character name for main language of document.</p> required <code>xmlfile</code> <code>str</code> <p>name of the xmlfile</p> required <code>outfile</code> <code>str</code> <p>name of the input file for tca2</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def make_sentence_file(self, lang, xmlfile, outfile, giella_prefix):\n\"\"\"Make input document for tca2.\n\n    Args:\n        lang (str): three character name for main language of document.\n        xmlfile (str): name of the xmlfile\n        outfile (str): name of the input file for tca2\n    \"\"\"\n    o_path, _ = os.path.split(outfile)\n    o_rel_path = o_path.replace(os.getcwd() + \"/\", \"\", 1)\n    with util.ignored(OSError):\n        os.makedirs(o_rel_path)\n    with open(outfile, \"wb\") as sentence_file:\n        tree = etree.ElementTree(\n            self.make_sentence_xml(lang, xmlfile, giella_prefix=giella_prefix)\n        )\n        tree.write(\n            sentence_file, pretty_print=True, encoding=\"utf8\", xml_declaration=True\n        )\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.Tca2SentenceDivider.make_sentence_xml","title":"<code>make_sentence_xml(lang, xmlfile, giella_prefix)</code>  <code>staticmethod</code>","text":"<p>Make sentence xml that tca2 can use.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>three character name of main language of document.</p> required <code>filename</code> <code>str</code> <p>name of the xmlfile</p> required <p>Returns:</p> Type Description <p>lxml.etree._Element: an xml element containing all sentences.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>@staticmethod\ndef make_sentence_xml(lang, xmlfile, giella_prefix):\n\"\"\"Make sentence xml that tca2 can use.\n\n    Args:\n        lang (str): three character name of main language of document.\n        filename (str): name of the xmlfile\n\n    Returns:\n        lxml.etree._Element: an xml element containing all sentences.\n    \"\"\"\n    document = etree.Element(\"document\")\n\n    divider = sentencedivider.SentenceDivider(lang, giella_prefix)\n    for index, sentence in enumerate(\n        divider.make_valid_sentences(sentencedivider.to_plain_text(lang, xmlfile))\n    ):\n        s_elem = etree.Element(\"s\")\n        s_elem.attrib[\"id\"] = str(index)\n        s_elem.text = sentence\n        document.append(s_elem)\n\n    return document\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.main","title":"<code>main()</code>","text":"<p>Parallelise files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def main():\n\"\"\"Parallelise files.\"\"\"\n    args = parse_options()\n\n    # TODO: filter out those pairs that already exist in presteable/tmx\n    for source in args.sources:\n        try:\n            if os.path.isfile(source):\n                parallelise_file(\n                    source,\n                    args.lang2,\n                    args.dict,\n                    args.quiet,\n                    args.aligner,\n                    args.stdout,\n                    args.force,\n                )\n            elif os.path.isdir(source):\n                for root, _, files in os.walk(source):\n                    for converted in files:\n                        path = os.path.join(root, converted)\n                        try:\n                            parallelise_file(\n                                path,\n                                args.lang2,\n                                args.dict,\n                                args.quiet,\n                                args.aligner,\n                                args.stdout,\n                                args.force,\n                            )\n                        except UserWarning as error:\n                            print(str(error))\n        except util.ArgumentError as error:\n            raise SystemExit(error)\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.parallelise_file","title":"<code>parallelise_file(input_file, lang2, dictionary, quiet, aligner, stdout, force)</code>","text":"<p>Align sentences of two parallel files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def parallelise_file(input_file, lang2, dictionary, quiet, aligner, stdout, force):\n\"\"\"Align sentences of two parallel files.\"\"\"\n    try:\n        if aligner == \"hunalign\":\n            parallelizer = ParallelizeHunalign(\n                origfile1=input_file, lang2=lang2, anchor_file=dictionary, quiet=quiet\n            )\n        elif aligner == \"tca2\":\n            parallelizer = ParallelizeTCA2(\n                origfile1=input_file, lang2=lang2, anchor_file=dictionary, quiet=quiet\n            )\n    except OSError as error:\n        if not quiet:\n            util.note(error)\n    except NameError:  # parallel filename is empty\n        pass\n\n    else:\n\n        outfile = \"/dev/stdout\" if stdout else parallelizer.outfile_name\n\n        if (\n            outfile == \"/dev/stdout\"\n            or not os.path.exists(outfile)\n            or (os.path.exists(outfile) and force)\n        ):\n            if not quiet:\n                util.note(f\"Aligning {input_file} and its parallel file\")\n            translation_mem_ex = parallelizer.parallelize_files()\n            translation_mem_ex.clean_toktmx()\n            if not quiet:\n                util.note(f\"Generating the tmx file {outfile}\")\n            translation_mem_ex.write_tmx_file(outfile)\n            translation_mem_ex.tmx2html(parallelizer.outfile_name + \".html\")\n            if not quiet:\n                util.note(\"Wrote\\n\\t{}\\n\\t{}\\n\".format(outfile, outfile + \".html\"))\n\n            return outfile\n        else:\n            util.note(f\"{outfile} already exists, skipping \u2026\")\n</code></pre>"},{"location":"reference/parallelize/#corpustools.parallelize.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/parallelize.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser], description=\"Sentence align file pairs.\"\n    )\n\n    parser.add_argument(\n        \"sources\",\n        nargs=\"+\",\n        help=\"Files or directories to search for \" \"parallelisable files\",\n    )\n    parser.add_argument(\n        \"-s\",\n        \"--stdout\",\n        help=\"Whether output of the parallelisation \"\n        \"should be written to stdout or a files. \"\n        \"Defaults to \"\n        \"prestable/tmx/{lang1}2{lang2}/{GENRE}/.../{BASENAME}.tmx\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--force\",\n        help=\"Overwrite output file if it already exists.\" \"This is the default.\",\n        action=\"store_false\",\n    )\n    parser.add_argument(\n        \"-q\",\n        \"--quiet\",\n        help=\"Don't mention anything out of the ordinary.\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-a\",\n        \"--aligner\",\n        choices=[\"hunalign\", \"tca2\"],\n        default=\"tca2\",\n        help=\"Either hunalign or tca2 (the default).\",\n    )\n    parser.add_argument(\n        \"-d\",\n        \"--dict\",\n        default=None,\n        help=\"Use a different bilingual seed dictionary. \"\n        \"Must have two columns, with input_file language \"\n        \"first, and --parallel_language second, separated \"\n        \"by `/'. By default, \"\n        \"$GTHOME/gt/common/src/anchor.txt is used, but this \"\n        \"file only supports pairings between \"\n        \"sme/sma/smj/fin/eng/nob. \",\n    )\n    parser.add_argument(\n        \"-l2\",\n        \"--lang2\",\n        help=\"Indicate which language the given file should\" \"be parallelised with\",\n        required=True,\n    )\n\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"reference/pdfconverter/","title":"pdfconverter","text":"<p>Convert pdf files to the Giella xml format.</p>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter","title":"<code>PDF2XMLConverter</code>","text":"<p>         Bases: <code>basicconverter.BasicConverter</code></p> <p>Class to convert the xml output of pdftohtml to Giella xml.</p> <p>Attributes:</p> Name Type Description <code>extractor</code> <code>PDFTextExtractor</code> <p>class to extract text from the xml that pdftohtml produces.</p> <code>pdffontspecs</code> <code>PDFFontspecs</code> <p>class to store fontspecs found in the xml pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>class PDF2XMLConverter(basicconverter.BasicConverter):\n\"\"\"Class to convert the xml output of pdftohtml to Giella xml.\n\n    Attributes:\n        extractor (PDFTextExtractor): class to extract text from the xml that\n            pdftohtml produces.\n        pdffontspecs (PDFFontspecs): class to store fontspecs found in the xml\n            pages.\n    \"\"\"\n\n    def __init__(self, filename):\n\"\"\"Initialise the PDF2XMLConverte class.\n\n        Args:\n            filename (str): the path to the pdf file.\n            write_intermediate (boolean): indicate whether intermediate\n                versions of the converter document should be written to disk.\n        \"\"\"\n        super().__init__(filename)\n        self.pdffontspecs = PDFFontspecs()\n\n    @staticmethod\n    def strip_chars(content, extra=\"\"):\n\"\"\"Strip unwanted chars from the document.\n\n        Args:\n            content (str): the xml document that pdftohtml produces\n            extra (str): more character that should be removed\n\n        Returns:\n            str containing the modified version of the document.\n        \"\"\"\n        remove_re = re.compile(f\"[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F{extra}]\")\n        content, _ = remove_re.subn(\"\", content)\n\n        # Microsoft Word PDF's have Latin-1 file names in links; we\n        # don't actually need any link attributes:\n        content = re.sub(\"&lt;a [^&gt;]+&gt;\", \"&lt;a&gt;\", content)\n\n        return content\n\n    @staticmethod\n    def replace_ligatures(content):\n\"\"\"Replace unwanted strings with correct replacements.\n\n        Args:\n            content (str): content of an xml document.\n\n        Returns:\n            String containing the new content of the xml document.\n        \"\"\"\n        replacements = {\n            \"[dstrok]\": \"\u0111\",\n            \"[Dstrok]\": \"\u0110\",\n            \"[tstrok]\": \"\u0167\",\n            \"[Tstrok]\": \"\u0166\",\n            \"[scaron]\": \"\u0161\",\n            \"[Scaron]\": \"\u0160\",\n            \"[zcaron]\": \"\u017e\",\n            \"[Zcaron]\": \"\u017d\",\n            \"[ccaron]\": \"\u010d\",\n            \"[Ccaron]\": \"\u010c\",\n            \"[eng\": \"\u014b\",\n            \" ]\": \"\",\n            \"\u010e\": \"\u0111\",  # cough\n            \"\u010f\": \"\u0111\",  # cough\n            \"\ufb01\": \"fi\",\n            \"\ufb02\": \"fl\",\n            \"\ufb00\": \"ff\",\n            \"\ufb03\": \"ffi\",\n            \"\ufb04\": \"ffl\",\n            \"\ufb05\": \"ft\",\n        }\n\n        for key, value in replacements.items():\n            content = content.replace(key + \" \", value)\n            content = content.replace(key, value)\n\n        return content\n\n    def convert2intermediate(self):\n\"\"\"Convert from pdf to a corpus xml file.\n\n        Returns:\n            A corpus xml etree with the content of the pdf file, but without\n            most of the metadata.\n        \"\"\"\n        command = f\"pdftohtml -hidden -enc UTF-8 -stdout -nodrm -i -s {self.orig}\"\n        pdftohtmloutput = self.extract_text(command.split())\n        return self.pdftohtml2intermediate(pdftohtmloutput)\n\n    @staticmethod\n    def possibly_add_to_body(body, this_p):\n        if this_p.text or len(this_p):\n            body.append(this_p)\n\n    def pdftohtml2intermediate(self, pdftohtmloutput):\n\"\"\"Convert output of pdftohtml to a corpus xml file.\n\n        Returns:\n            A corpus xml etree with the content of the pdf file, but without\n            most of the metadata.\n        \"\"\"\n        pdf_content = self.split_by_br(\n            self.replace_ligatures(self.strip_chars(pdftohtmloutput))\n        )\n\n        document = etree.Element(\"html\")\n        body = etree.SubElement(document, \"body\")\n\n        try:\n            parser = etree.HTMLParser()\n            root_element = etree.fromstring(pdf_content.encode(\"utf8\"), parser=parser)\n        except etree.XMLSyntaxError as error:\n            self.handle_syntaxerror(error, util.lineno(), pdf_content)\n\n        this_p = etree.Element(\"p\")\n        for paragraph in self.parse_pages(root_element):\n            text = paragraph.xpath(\"string()\").strip()\n            if text:\n                if text[0] != text[0].lower():\n                    self.possibly_add_to_body(body, this_p)\n                    this_p = etree.Element(\"p\")\n                this_p = merge(this_p, paragraph)\n\n        self.possibly_add_to_body(body, this_p)\n\n        return document\n\n    def pdftohtml2html(self, pdftohtmloutput):\n\"\"\"Convert output of pdftohtml to html (applying our regular fixes)\n\n        Returns:\n            An html file as string with the content of the pdf file, but without\n            most of the metadata.\n        \"\"\"\n        doc = self.pdftohtml2intermediate(pdftohtmloutput)\n        meta = etree.Element(\"meta\")\n        meta.attrib[\"charset\"] = \"utf-8\"\n        doc.insert(0, meta)\n        list(map(doc.remove, doc.findall(\"header\")))\n        doc.tag = \"html\"\n        lang = self.metadata.get_variable(\"mainlang\")\n        if lang is None or lang == \"\":\n            lang = \"se\"\n        doc.attrib[\"lang\"] = lang\n        return etree.tostring(doc, encoding=\"utf8\", method=\"html\", pretty_print=True)\n\n    def parse_page(self, page):\n\"\"\"Parse the page element.\n\n        Args:\n            page: a pdf xml page element.\n        \"\"\"\n        try:\n            pdfpage = PDFPage(\n                page,\n                metadata_margins=self.metadata.margins,\n                metadata_inner_margins=self.metadata.inner_margins,\n                linespacing=self.metadata.linespacing,\n            )\n            if not pdfpage.is_skip_page(self.metadata.skip_pages):\n                # pdfpage.fix_font_id(self.pdffontspecs)\n                yield from pdfpage.pick_valid_text_elements()\n        except xslsetter.XsltError as error:\n            raise util.ConversionError(str(error))\n\n    def parse_pages(self, root_element):\n\"\"\"Parse the pages of the pdf xml document.\n\n        Args:\n            root_element: the root element of the pdf2xml document.\n        \"\"\"\n        return (\n            paragraph\n            for page in root_element.xpath('//div[starts-with(@id, \"page\")]')\n            for paragraph in self.parse_page(page)\n        )\n\n    def add_fontspecs(self, page):\n\"\"\"Extract font specs found in a pdf2xml page element.\n\n        Args:\n            page (etree.Element): a pdf page\n        \"\"\"\n        for xmlfontspec in page.iter(\"fontspec\"):\n            self.pdffontspecs.add_fontspec(xmlfontspec)\n\n    def split_by_br(self, text):\n        brs = text.replace(\"&amp;#160;\", \" \").split(\"&lt;br/&gt;\")\n\n        if len(brs) == 1:\n            return text\n\n        strings = [\n            handle_br(brs[index], current) for index, current in enumerate(brs[1:])\n        ]\n        strings.append(brs[-1])\n\n        return \"\".join(strings)\n\n    def extract_text(self, command):\n\"\"\"Extract the text from a document.\n\n        :command: a list containing the command and the arguments sent to\n        ExternalCommandRunner.\n        :returns: byte string containing the output of the program\n        \"\"\"\n        runner = util.ExternalCommandRunner()\n        runner.run(command, cwd=\"/tmp\")\n\n        if runner.returncode != 0:\n            with open(self.orig + \".log\", \"w\") as logfile:\n                print(f\"stdout\\n{runner.stdout}\\n\", file=logfile)\n                print(f\"stderr\\n{runner.stderr}\\n\", file=logfile)\n                raise util.ConversionError(\n                    \"{} failed. More info in the log file: {}\".format(\n                        command[0], self.orig + \".log\"\n                    )\n                )\n\n        return runner.stdout.decode(\"utf8\")\n\n    def handle_syntaxerror(self, error, lineno, invalid_input):\n\"\"\"Handle an xml syntax error.\n\n        Args:\n            error: an exception\n            lineno: the line number in this module where the error happened.\n            invalid_input: a string containing the invalid input.\n        \"\"\"\n        with open(self.orig + \".log\", \"w\") as logfile:\n            logfile.write(f\"Error at: {lineno}\")\n            for entry in error.error_log:\n                logfile.write(f\"\\n{str(entry.line)}: {str(entry.column)} \")\n                try:\n                    logfile.write(entry.message)\n                except ValueError:\n                    logfile.write(entry.message.encode(\"latin1\"))\n\n                logfile.write(\"\\n\")\n\n            logfile.write(invalid_input)\n\n        raise util.ConversionError(\n            \"{}: log is found in {}\".format(type(self).__name__, self.orig + \".log\")\n        )\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.__init__","title":"<code>__init__(filename)</code>","text":"<p>Initialise the PDF2XMLConverte class.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>the path to the pdf file.</p> required <code>write_intermediate</code> <code>boolean</code> <p>indicate whether intermediate versions of the converter document should be written to disk.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def __init__(self, filename):\n\"\"\"Initialise the PDF2XMLConverte class.\n\n    Args:\n        filename (str): the path to the pdf file.\n        write_intermediate (boolean): indicate whether intermediate\n            versions of the converter document should be written to disk.\n    \"\"\"\n    super().__init__(filename)\n    self.pdffontspecs = PDFFontspecs()\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.add_fontspecs","title":"<code>add_fontspecs(page)</code>","text":"<p>Extract font specs found in a pdf2xml page element.</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>etree.Element</code> <p>a pdf page</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def add_fontspecs(self, page):\n\"\"\"Extract font specs found in a pdf2xml page element.\n\n    Args:\n        page (etree.Element): a pdf page\n    \"\"\"\n    for xmlfontspec in page.iter(\"fontspec\"):\n        self.pdffontspecs.add_fontspec(xmlfontspec)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.convert2intermediate","title":"<code>convert2intermediate()</code>","text":"<p>Convert from pdf to a corpus xml file.</p> <p>Returns:</p> Type Description <p>A corpus xml etree with the content of the pdf file, but without</p> <p>most of the metadata.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def convert2intermediate(self):\n\"\"\"Convert from pdf to a corpus xml file.\n\n    Returns:\n        A corpus xml etree with the content of the pdf file, but without\n        most of the metadata.\n    \"\"\"\n    command = f\"pdftohtml -hidden -enc UTF-8 -stdout -nodrm -i -s {self.orig}\"\n    pdftohtmloutput = self.extract_text(command.split())\n    return self.pdftohtml2intermediate(pdftohtmloutput)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.extract_text","title":"<code>extract_text(command)</code>","text":"<p>Extract the text from a document.</p> <p>:command: a list containing the command and the arguments sent to ExternalCommandRunner. :returns: byte string containing the output of the program</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def extract_text(self, command):\n\"\"\"Extract the text from a document.\n\n    :command: a list containing the command and the arguments sent to\n    ExternalCommandRunner.\n    :returns: byte string containing the output of the program\n    \"\"\"\n    runner = util.ExternalCommandRunner()\n    runner.run(command, cwd=\"/tmp\")\n\n    if runner.returncode != 0:\n        with open(self.orig + \".log\", \"w\") as logfile:\n            print(f\"stdout\\n{runner.stdout}\\n\", file=logfile)\n            print(f\"stderr\\n{runner.stderr}\\n\", file=logfile)\n            raise util.ConversionError(\n                \"{} failed. More info in the log file: {}\".format(\n                    command[0], self.orig + \".log\"\n                )\n            )\n\n    return runner.stdout.decode(\"utf8\")\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.handle_syntaxerror","title":"<code>handle_syntaxerror(error, lineno, invalid_input)</code>","text":"<p>Handle an xml syntax error.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <p>an exception</p> required <code>lineno</code> <p>the line number in this module where the error happened.</p> required <code>invalid_input</code> <p>a string containing the invalid input.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def handle_syntaxerror(self, error, lineno, invalid_input):\n\"\"\"Handle an xml syntax error.\n\n    Args:\n        error: an exception\n        lineno: the line number in this module where the error happened.\n        invalid_input: a string containing the invalid input.\n    \"\"\"\n    with open(self.orig + \".log\", \"w\") as logfile:\n        logfile.write(f\"Error at: {lineno}\")\n        for entry in error.error_log:\n            logfile.write(f\"\\n{str(entry.line)}: {str(entry.column)} \")\n            try:\n                logfile.write(entry.message)\n            except ValueError:\n                logfile.write(entry.message.encode(\"latin1\"))\n\n            logfile.write(\"\\n\")\n\n        logfile.write(invalid_input)\n\n    raise util.ConversionError(\n        \"{}: log is found in {}\".format(type(self).__name__, self.orig + \".log\")\n    )\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.parse_page","title":"<code>parse_page(page)</code>","text":"<p>Parse the page element.</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <p>a pdf xml page element.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def parse_page(self, page):\n\"\"\"Parse the page element.\n\n    Args:\n        page: a pdf xml page element.\n    \"\"\"\n    try:\n        pdfpage = PDFPage(\n            page,\n            metadata_margins=self.metadata.margins,\n            metadata_inner_margins=self.metadata.inner_margins,\n            linespacing=self.metadata.linespacing,\n        )\n        if not pdfpage.is_skip_page(self.metadata.skip_pages):\n            # pdfpage.fix_font_id(self.pdffontspecs)\n            yield from pdfpage.pick_valid_text_elements()\n    except xslsetter.XsltError as error:\n        raise util.ConversionError(str(error))\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.parse_pages","title":"<code>parse_pages(root_element)</code>","text":"<p>Parse the pages of the pdf xml document.</p> <p>Parameters:</p> Name Type Description Default <code>root_element</code> <p>the root element of the pdf2xml document.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def parse_pages(self, root_element):\n\"\"\"Parse the pages of the pdf xml document.\n\n    Args:\n        root_element: the root element of the pdf2xml document.\n    \"\"\"\n    return (\n        paragraph\n        for page in root_element.xpath('//div[starts-with(@id, \"page\")]')\n        for paragraph in self.parse_page(page)\n    )\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.pdftohtml2html","title":"<code>pdftohtml2html(pdftohtmloutput)</code>","text":"<p>Convert output of pdftohtml to html (applying our regular fixes)</p> <p>Returns:</p> Type Description <p>An html file as string with the content of the pdf file, but without</p> <p>most of the metadata.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def pdftohtml2html(self, pdftohtmloutput):\n\"\"\"Convert output of pdftohtml to html (applying our regular fixes)\n\n    Returns:\n        An html file as string with the content of the pdf file, but without\n        most of the metadata.\n    \"\"\"\n    doc = self.pdftohtml2intermediate(pdftohtmloutput)\n    meta = etree.Element(\"meta\")\n    meta.attrib[\"charset\"] = \"utf-8\"\n    doc.insert(0, meta)\n    list(map(doc.remove, doc.findall(\"header\")))\n    doc.tag = \"html\"\n    lang = self.metadata.get_variable(\"mainlang\")\n    if lang is None or lang == \"\":\n        lang = \"se\"\n    doc.attrib[\"lang\"] = lang\n    return etree.tostring(doc, encoding=\"utf8\", method=\"html\", pretty_print=True)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.pdftohtml2intermediate","title":"<code>pdftohtml2intermediate(pdftohtmloutput)</code>","text":"<p>Convert output of pdftohtml to a corpus xml file.</p> <p>Returns:</p> Type Description <p>A corpus xml etree with the content of the pdf file, but without</p> <p>most of the metadata.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def pdftohtml2intermediate(self, pdftohtmloutput):\n\"\"\"Convert output of pdftohtml to a corpus xml file.\n\n    Returns:\n        A corpus xml etree with the content of the pdf file, but without\n        most of the metadata.\n    \"\"\"\n    pdf_content = self.split_by_br(\n        self.replace_ligatures(self.strip_chars(pdftohtmloutput))\n    )\n\n    document = etree.Element(\"html\")\n    body = etree.SubElement(document, \"body\")\n\n    try:\n        parser = etree.HTMLParser()\n        root_element = etree.fromstring(pdf_content.encode(\"utf8\"), parser=parser)\n    except etree.XMLSyntaxError as error:\n        self.handle_syntaxerror(error, util.lineno(), pdf_content)\n\n    this_p = etree.Element(\"p\")\n    for paragraph in self.parse_pages(root_element):\n        text = paragraph.xpath(\"string()\").strip()\n        if text:\n            if text[0] != text[0].lower():\n                self.possibly_add_to_body(body, this_p)\n                this_p = etree.Element(\"p\")\n            this_p = merge(this_p, paragraph)\n\n    self.possibly_add_to_body(body, this_p)\n\n    return document\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.replace_ligatures","title":"<code>replace_ligatures(content)</code>  <code>staticmethod</code>","text":"<p>Replace unwanted strings with correct replacements.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>content of an xml document.</p> required <p>Returns:</p> Type Description <p>String containing the new content of the xml document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>@staticmethod\ndef replace_ligatures(content):\n\"\"\"Replace unwanted strings with correct replacements.\n\n    Args:\n        content (str): content of an xml document.\n\n    Returns:\n        String containing the new content of the xml document.\n    \"\"\"\n    replacements = {\n        \"[dstrok]\": \"\u0111\",\n        \"[Dstrok]\": \"\u0110\",\n        \"[tstrok]\": \"\u0167\",\n        \"[Tstrok]\": \"\u0166\",\n        \"[scaron]\": \"\u0161\",\n        \"[Scaron]\": \"\u0160\",\n        \"[zcaron]\": \"\u017e\",\n        \"[Zcaron]\": \"\u017d\",\n        \"[ccaron]\": \"\u010d\",\n        \"[Ccaron]\": \"\u010c\",\n        \"[eng\": \"\u014b\",\n        \" ]\": \"\",\n        \"\u010e\": \"\u0111\",  # cough\n        \"\u010f\": \"\u0111\",  # cough\n        \"\ufb01\": \"fi\",\n        \"\ufb02\": \"fl\",\n        \"\ufb00\": \"ff\",\n        \"\ufb03\": \"ffi\",\n        \"\ufb04\": \"ffl\",\n        \"\ufb05\": \"ft\",\n    }\n\n    for key, value in replacements.items():\n        content = content.replace(key + \" \", value)\n        content = content.replace(key, value)\n\n    return content\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDF2XMLConverter.strip_chars","title":"<code>strip_chars(content, extra='')</code>  <code>staticmethod</code>","text":"<p>Strip unwanted chars from the document.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>the xml document that pdftohtml produces</p> required <code>extra</code> <code>str</code> <p>more character that should be removed</p> <code>''</code> <p>Returns:</p> Type Description <p>str containing the modified version of the document.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>@staticmethod\ndef strip_chars(content, extra=\"\"):\n\"\"\"Strip unwanted chars from the document.\n\n    Args:\n        content (str): the xml document that pdftohtml produces\n        extra (str): more character that should be removed\n\n    Returns:\n        str containing the modified version of the document.\n    \"\"\"\n    remove_re = re.compile(f\"[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F{extra}]\")\n    content, _ = remove_re.subn(\"\", content)\n\n    # Microsoft Word PDF's have Latin-1 file names in links; we\n    # don't actually need any link attributes:\n    content = re.sub(\"&lt;a [^&gt;]+&gt;\", \"&lt;a&gt;\", content)\n\n    return content\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFEmptyPageError","title":"<code>PDFEmptyPageError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raise this exception if a pdf page is empty.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>class PDFEmptyPageError(Exception):\n\"\"\"Raise this exception if a pdf page is empty.\"\"\"\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFFontspecs","title":"<code>PDFFontspecs</code>","text":"<p>Add font specs found in a pdf page to this class.</p> <p>Attributes:</p> Name Type Description <code>pdffontspecs</code> <code>dict{PDFFontspec</code> <p>int}): map fontspecs to fontspec ids.</p> <code>duplicates</code> <code>dict{str</code> <p>str}): map ids of duplicate fontspecs to the id of the first instance of this fontspec.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>class PDFFontspecs:\n\"\"\"Add font specs found in a pdf page to this class.\n\n    Attributes:\n        pdffontspecs (dict{PDFFontspec:int}): map fontspecs to fontspec ids.\n        duplicates (dict{str:str}): map ids of duplicate fontspecs to the\n            id of the first instance of this fontspec.\n    \"\"\"\n\n    def __init__(self):\n\"\"\"Initialise the PDFFontspecs class.\"\"\"\n        self.pdffontspecs = {}\n        self.duplicates = {}\n\n    def add_fontspec(self, xmlfontspec):\n\"\"\"Add a pdf2xml fontspec to this class.\n\n        Args:\n            xmlfontspec (etree.Element): a PDF2XML fontspec element found in a\n                PDF2XML page element.\n        \"\"\"\n        this_id = xmlfontspec.get(\"id\")\n        this_fontspec = PDFFontspec(\n            size=xmlfontspec.get(\"size\"),\n            family=xmlfontspec.get(\"family\"),\n            color=xmlfontspec.get(\"color\"),\n        )\n\n        for fontspec in list(self.pdffontspecs.keys()):\n            if fontspec == this_fontspec:\n                self.duplicates[this_id] = self.pdffontspecs[fontspec]\n                break\n        else:\n            self.pdffontspecs[this_fontspec] = this_id\n\n    def corrected_id(self, font_id):\n\"\"\"Return a corrected id of a fontspec.\n\n        Some xmlfontspecs have different id's for an identical font.\n        This function makes sure identical fonts have identical id's.\n\n        Args:\n            font_id: an integer that is the id of the fontspec.\n\n        Returns:\n            an integer that is the corrected id of the fontspec.\n        \"\"\"\n        if font_id in self.duplicates:\n            return self.duplicates[font_id]\n        else:\n            return font_id\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFFontspecs.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the PDFFontspecs class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the PDFFontspecs class.\"\"\"\n    self.pdffontspecs = {}\n    self.duplicates = {}\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFFontspecs.add_fontspec","title":"<code>add_fontspec(xmlfontspec)</code>","text":"<p>Add a pdf2xml fontspec to this class.</p> <p>Parameters:</p> Name Type Description Default <code>xmlfontspec</code> <code>etree.Element</code> <p>a PDF2XML fontspec element found in a PDF2XML page element.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def add_fontspec(self, xmlfontspec):\n\"\"\"Add a pdf2xml fontspec to this class.\n\n    Args:\n        xmlfontspec (etree.Element): a PDF2XML fontspec element found in a\n            PDF2XML page element.\n    \"\"\"\n    this_id = xmlfontspec.get(\"id\")\n    this_fontspec = PDFFontspec(\n        size=xmlfontspec.get(\"size\"),\n        family=xmlfontspec.get(\"family\"),\n        color=xmlfontspec.get(\"color\"),\n    )\n\n    for fontspec in list(self.pdffontspecs.keys()):\n        if fontspec == this_fontspec:\n            self.duplicates[this_id] = self.pdffontspecs[fontspec]\n            break\n    else:\n        self.pdffontspecs[this_fontspec] = this_id\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFFontspecs.corrected_id","title":"<code>corrected_id(font_id)</code>","text":"<p>Return a corrected id of a fontspec.</p> <p>Some xmlfontspecs have different id's for an identical font. This function makes sure identical fonts have identical id's.</p> <p>Parameters:</p> Name Type Description Default <code>font_id</code> <p>an integer that is the id of the fontspec.</p> required <p>Returns:</p> Type Description <p>an integer that is the corrected id of the fontspec.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def corrected_id(self, font_id):\n\"\"\"Return a corrected id of a fontspec.\n\n    Some xmlfontspecs have different id's for an identical font.\n    This function makes sure identical fonts have identical id's.\n\n    Args:\n        font_id: an integer that is the id of the fontspec.\n\n    Returns:\n        an integer that is the corrected id of the fontspec.\n    \"\"\"\n    if font_id in self.duplicates:\n        return self.duplicates[font_id]\n    else:\n        return font_id\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage","title":"<code>PDFPage</code>","text":"<p>Reads a page element.</p> <p>Attributes:</p> Name Type Description <code>textelements</code> <code>list of PDFTextElements</code> <p>contains the text of the page</p> <code>pdf_pagemetadata</code> <code>PDFPageMetadata</code> <p>contains the metadata of the page</p> <p>The textelements are manipulated in several ways, then ordered in the way they appear on the page and finally sent to PDFTextExtractor</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>class PDFPage:\n\"\"\"Reads a page element.\n\n    Attributes:\n        textelements (list of PDFTextElements): contains the text of the page\n        pdf_pagemetadata (PDFPageMetadata): contains the metadata of the page\n\n    The textelements are manipulated in several ways,\n    then ordered in the way they appear on the page and\n    finally sent to PDFTextExtractor\n    \"\"\"\n\n    def __init__(\n        self,\n        page_element,\n        metadata_margins=None,\n        metadata_inner_margins=None,\n        linespacing=None,\n    ):\n\"\"\"Initialise the PDFPage class.\n\n        Args:\n            page_element: an etree element representing a pdf page\n            metadata_margins: a dict containing margins read from the metadata\n            file.\n            metadata_inner_margins: a dict containing inner_margins read from\n            the metadata file.\n        \"\"\"\n        self.page_element = page_element\n        self.pdf_pagemetadata = PDFPageMetadata(\n            page_id=page_element.get(\"id\"),\n            page_style=page_element.get(\"style\"),\n            metadata_margins=metadata_margins,\n            metadata_inner_margins=metadata_inner_margins,\n        )\n\n    def is_skip_page(self, skip_pages):\n\"\"\"Found out if this page should be skipped.\n\n        Args:\n            skip_pages (list of mixed): list of the pages that should be\n                skipped.\n\n        Returns:\n            boolean: True if this page should be skipped, otherwise false.\n        \"\"\"\n        return (\n            (\"odd\" in skip_pages and (self.pdf_pagemetadata.page_number % 2) == 1)\n            or (\"even\" in skip_pages and (self.pdf_pagemetadata.page_number % 2) == 0)\n            or self.pdf_pagemetadata.page_number in skip_pages\n        )\n\n    @property\n    def linespacing(self):\n\"\"\"Return linespacing.\"\"\"\n        if self.linespacing_dict.get(\"all\"):\n            return self.linespacing_dict[\"all\"]\n        elif self.linespacing_dict.get(\"even\") and (\n            (self.pdf_pagemetadata.page_number % 2) == 0\n        ):\n            return self.linespacing_dict[\"even\"]\n        elif self.linespacing_dict.get(\"odd\") and (\n            (self.pdf_pagemetadata.page_number % 2) == 1\n        ):\n            return self.linespacing_dict[\"odd\"]\n        elif self.linespacing_dict.get(self.pdf_pagemetadata.page_number):\n            return self.linespacing_dict[self.pdf_pagemetadata.page_number]\n        else:\n            return 1.5\n\n    def fix_font_id(self, pdffontspecs):\n\"\"\"Fix font id in text elements.\n\n        Sometimes the same font has different ID's. Correct that ID\n        if necessary.\n\n        Args:\n            pdffontspecs (PDFFontspecs): a PDFFontspecs instance.\n        \"\"\"\n        for textelement in self.textelements:\n            correct = pdffontspecs.corrected_id(textelement.font)\n            textelement.text_elt.set(\"font\", correct)\n\n    def remove_elements_outside_margin(self):\n\"\"\"Remove PDFTextElements from textelements if needed.\"\"\"\n        margins = self.pdf_pagemetadata.compute_margins()\n        inner_margins = self.pdf_pagemetadata.compute_inner_margins()\n\n        self.textelements[:] = [\n            t for t in self.textelements if self.is_inside_margins(t, margins)\n        ]\n        if inner_margins:\n            self.textelements[:] = [\n                t\n                for t in self.textelements\n                if not self.is_inside_inner_margins(t, inner_margins)\n            ]\n\n    @staticmethod\n    def is_inside_margins(text, margins):\n\"\"\"Check if t is inside the given margins.\n\n        t is a text element\n        \"\"\"\n        if not margins:\n            return False\n\n        style = styles(text.get(\"style\"))\n        top = int(style.get(\"top\"))\n        left = int(style.get(\"left\"))\n\n        return (\n            margins[\"top_margin\"] &lt; top &lt; margins[\"bottom_margin\"]\n            and margins[\"left_margin\"] &lt; left &lt; margins[\"right_margin\"]\n        )\n\n    def pick_valid_text_elements(self):\n\"\"\"Pick the wanted text elements from a page.\n\n        This is the main function of this class\n        \"\"\"\n        margins = self.pdf_pagemetadata.compute_margins()\n        inner_margins = self.pdf_pagemetadata.compute_inner_margins()\n        for paragraph in self.page_element.iter(\"p\"):\n            if self.is_inside_margins(\n                paragraph, margins\n            ) and not self.is_inside_margins(paragraph, inner_margins):\n                yield deepcopy(paragraph)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage.linespacing","title":"<code>linespacing</code>  <code>property</code>","text":"<p>Return linespacing.</p>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage.__init__","title":"<code>__init__(page_element, metadata_margins=None, metadata_inner_margins=None, linespacing=None)</code>","text":"<p>Initialise the PDFPage class.</p> <p>Parameters:</p> Name Type Description Default <code>page_element</code> <p>an etree element representing a pdf page</p> required <code>metadata_margins</code> <p>a dict containing margins read from the metadata</p> <code>None</code> <code>metadata_inner_margins</code> <p>a dict containing inner_margins read from</p> <code>None</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def __init__(\n    self,\n    page_element,\n    metadata_margins=None,\n    metadata_inner_margins=None,\n    linespacing=None,\n):\n\"\"\"Initialise the PDFPage class.\n\n    Args:\n        page_element: an etree element representing a pdf page\n        metadata_margins: a dict containing margins read from the metadata\n        file.\n        metadata_inner_margins: a dict containing inner_margins read from\n        the metadata file.\n    \"\"\"\n    self.page_element = page_element\n    self.pdf_pagemetadata = PDFPageMetadata(\n        page_id=page_element.get(\"id\"),\n        page_style=page_element.get(\"style\"),\n        metadata_margins=metadata_margins,\n        metadata_inner_margins=metadata_inner_margins,\n    )\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage.fix_font_id","title":"<code>fix_font_id(pdffontspecs)</code>","text":"<p>Fix font id in text elements.</p> <p>Sometimes the same font has different ID's. Correct that ID if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>pdffontspecs</code> <code>PDFFontspecs</code> <p>a PDFFontspecs instance.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def fix_font_id(self, pdffontspecs):\n\"\"\"Fix font id in text elements.\n\n    Sometimes the same font has different ID's. Correct that ID\n    if necessary.\n\n    Args:\n        pdffontspecs (PDFFontspecs): a PDFFontspecs instance.\n    \"\"\"\n    for textelement in self.textelements:\n        correct = pdffontspecs.corrected_id(textelement.font)\n        textelement.text_elt.set(\"font\", correct)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage.is_inside_margins","title":"<code>is_inside_margins(text, margins)</code>  <code>staticmethod</code>","text":"<p>Check if t is inside the given margins.</p> <p>t is a text element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>@staticmethod\ndef is_inside_margins(text, margins):\n\"\"\"Check if t is inside the given margins.\n\n    t is a text element\n    \"\"\"\n    if not margins:\n        return False\n\n    style = styles(text.get(\"style\"))\n    top = int(style.get(\"top\"))\n    left = int(style.get(\"left\"))\n\n    return (\n        margins[\"top_margin\"] &lt; top &lt; margins[\"bottom_margin\"]\n        and margins[\"left_margin\"] &lt; left &lt; margins[\"right_margin\"]\n    )\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage.is_skip_page","title":"<code>is_skip_page(skip_pages)</code>","text":"<p>Found out if this page should be skipped.</p> <p>Parameters:</p> Name Type Description Default <code>skip_pages</code> <code>list of mixed</code> <p>list of the pages that should be skipped.</p> required <p>Returns:</p> Name Type Description <code>boolean</code> <p>True if this page should be skipped, otherwise false.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def is_skip_page(self, skip_pages):\n\"\"\"Found out if this page should be skipped.\n\n    Args:\n        skip_pages (list of mixed): list of the pages that should be\n            skipped.\n\n    Returns:\n        boolean: True if this page should be skipped, otherwise false.\n    \"\"\"\n    return (\n        (\"odd\" in skip_pages and (self.pdf_pagemetadata.page_number % 2) == 1)\n        or (\"even\" in skip_pages and (self.pdf_pagemetadata.page_number % 2) == 0)\n        or self.pdf_pagemetadata.page_number in skip_pages\n    )\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage.pick_valid_text_elements","title":"<code>pick_valid_text_elements()</code>","text":"<p>Pick the wanted text elements from a page.</p> <p>This is the main function of this class</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def pick_valid_text_elements(self):\n\"\"\"Pick the wanted text elements from a page.\n\n    This is the main function of this class\n    \"\"\"\n    margins = self.pdf_pagemetadata.compute_margins()\n    inner_margins = self.pdf_pagemetadata.compute_inner_margins()\n    for paragraph in self.page_element.iter(\"p\"):\n        if self.is_inside_margins(\n            paragraph, margins\n        ) and not self.is_inside_margins(paragraph, inner_margins):\n            yield deepcopy(paragraph)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPage.remove_elements_outside_margin","title":"<code>remove_elements_outside_margin()</code>","text":"<p>Remove PDFTextElements from textelements if needed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def remove_elements_outside_margin(self):\n\"\"\"Remove PDFTextElements from textelements if needed.\"\"\"\n    margins = self.pdf_pagemetadata.compute_margins()\n    inner_margins = self.pdf_pagemetadata.compute_inner_margins()\n\n    self.textelements[:] = [\n        t for t in self.textelements if self.is_inside_margins(t, margins)\n    ]\n    if inner_margins:\n        self.textelements[:] = [\n            t\n            for t in self.textelements\n            if not self.is_inside_inner_margins(t, inner_margins)\n        ]\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata","title":"<code>PDFPageMetadata</code>","text":"<p>Read pdf metadata from the metadata file into this class.</p> <p>Compute metadata needed by the conversion from the data contained in this class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>class PDFPageMetadata:\n\"\"\"Read pdf metadata from the metadata file into this class.\n\n    Compute metadata needed by the conversion from the data contained in\n    this class.\n    \"\"\"\n\n    def __init__(\n        self, page_id, page_style, metadata_margins=None, metadata_inner_margins=None\n    ):\n\"\"\"Initialise the PDFPageMetadata class.\n\n        Args:\n            page_number: integer\n            page_height: integer\n            page_width: integer\n            metadata_margins: a dict containing margins read from the metadata\n            file.\n            metadata_inner_margins: a dict containing inner_margins read from\n            the metadata file.\n        \"\"\"\n        self.page_number = int(page_id.replace(\"page\", \"\").replace(\"-div\", \"\"))\n        style = styles(page_style)\n        self.page_height = int(style.get(\"height\"))\n        self.page_width = int(style.get(\"width\"))\n        self.metadata_margins = metadata_margins or {}\n        self.metadata_inner_margins = metadata_inner_margins or {}\n\n    def compute_margins(self):\n\"\"\"Compute the margins of a page in pixels.\n\n        :returns: a dict containing the four margins in pixels\n        \"\"\"\n        margins = {\n            margin: self.compute_margin(margin)\n            for margin in [\"right_margin\", \"left_margin\", \"top_margin\", \"bottom_margin\"]\n        }\n\n        return margins\n\n    def compute_margin(self, margin):\n\"\"\"Compute a margin in pixels.\n\n        :param margin: the name of the  margin\n\n        :return: an int telling where the margin is on the page.\n        \"\"\"\n        coefficient = self.get_coefficient(margin)\n\n        if margin == \"left_margin\":\n            return int(coefficient * self.page_width / 100.0)\n        if margin == \"right_margin\":\n            return int(self.page_width - coefficient * self.page_width / 100.0)\n        if margin == \"top_margin\":\n            return int(coefficient * self.page_height / 100.0)\n        if margin == \"bottom_margin\":\n            return int(self.page_height - coefficient * self.page_height / 100.0)\n\n    def get_coefficient(self, margin):\n\"\"\"Get the width of the margin in percent.\"\"\"\n        coefficient = 7\n        if margin in list(self.metadata_margins.keys()):\n            margin_data = self.metadata_margins[margin]\n            if margin_data.get(str(self.page_number)) is not None:\n                coefficient = margin_data[str(self.page_number)]\n            elif margin_data.get(\"all\") is not None:\n                coefficient = margin_data[\"all\"]\n            elif self.page_number % 2 == 0 and margin_data.get(\"even\") is not None:\n                coefficient = margin_data[\"even\"]\n            elif self.page_number % 2 == 1 and margin_data.get(\"odd\") is not None:\n                coefficient = margin_data[\"odd\"]\n\n        return coefficient\n\n    def compute_inner_margins(self):\n\"\"\"Compute inner margins of the document.\n\n        Returns:\n            A dict where the key is the name of the margin and the value\n            is an integer indicating where the margin is on the page.\n        \"\"\"\n        margins = {\n            margin.replace(\"inner_\", \"\"): self.compute_inner_margin(margin)\n            for margin in [\n                \"inner_right_margin\",\n                \"inner_left_margin\",\n                \"inner_top_margin\",\n                \"inner_bottom_margin\",\n            ]\n        }\n\n        if (\n            margins[\"bottom_margin\"] == self.page_height\n            and margins[\"top_margin\"] == 0\n            and margins[\"left_margin\"] == 0\n            and margins[\"right_margin\"] == self.page_width\n        ):\n            margins = {}\n\n        return margins\n\n    def compute_inner_margin(self, margin):\n\"\"\"Compute a margin in pixels.\n\n        :param margin: the name of the margin\n\n        :return: an int telling where the margin is on the page.\n        \"\"\"\n        coefficient = self.get_inner_coefficient(margin)\n\n        if margin == \"inner_left_margin\":\n            return int(coefficient * self.page_width / 100.0)\n        if margin == \"inner_right_margin\":\n            return int(self.page_width - coefficient * self.page_width / 100.0)\n        if margin == \"inner_top_margin\":\n            return int(coefficient * self.page_height / 100.0)\n        if margin == \"inner_bottom_margin\":\n            return int(self.page_height - coefficient * self.page_height / 100.0)\n\n    def get_inner_coefficient(self, margin):\n\"\"\"Get the width of the margin in percent.\"\"\"\n        coefficient = 0\n        if margin in list(self.metadata_inner_margins.keys()):\n            margin_data = self.metadata_inner_margins[margin]\n            if margin_data.get(str(self.page_number)) is not None:\n                coefficient = margin_data[str(self.page_number)]\n            elif margin_data.get(\"all\") is not None:\n                coefficient = margin_data[\"all\"]\n            elif self.page_number % 2 == 0 and margin_data.get(\"even\") is not None:\n                coefficient = margin_data[\"even\"]\n            elif self.page_number % 2 == 1 and margin_data.get(\"odd\") is not None:\n                coefficient = margin_data[\"odd\"]\n\n        return coefficient\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata.__init__","title":"<code>__init__(page_id, page_style, metadata_margins=None, metadata_inner_margins=None)</code>","text":"<p>Initialise the PDFPageMetadata class.</p> <p>Parameters:</p> Name Type Description Default <code>page_number</code> <p>integer</p> required <code>page_height</code> <p>integer</p> required <code>page_width</code> <p>integer</p> required <code>metadata_margins</code> <p>a dict containing margins read from the metadata</p> <code>None</code> <code>metadata_inner_margins</code> <p>a dict containing inner_margins read from</p> <code>None</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def __init__(\n    self, page_id, page_style, metadata_margins=None, metadata_inner_margins=None\n):\n\"\"\"Initialise the PDFPageMetadata class.\n\n    Args:\n        page_number: integer\n        page_height: integer\n        page_width: integer\n        metadata_margins: a dict containing margins read from the metadata\n        file.\n        metadata_inner_margins: a dict containing inner_margins read from\n        the metadata file.\n    \"\"\"\n    self.page_number = int(page_id.replace(\"page\", \"\").replace(\"-div\", \"\"))\n    style = styles(page_style)\n    self.page_height = int(style.get(\"height\"))\n    self.page_width = int(style.get(\"width\"))\n    self.metadata_margins = metadata_margins or {}\n    self.metadata_inner_margins = metadata_inner_margins or {}\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata.compute_inner_margin","title":"<code>compute_inner_margin(margin)</code>","text":"<p>Compute a margin in pixels.</p> <p>:param margin: the name of the margin</p> <p>:return: an int telling where the margin is on the page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def compute_inner_margin(self, margin):\n\"\"\"Compute a margin in pixels.\n\n    :param margin: the name of the margin\n\n    :return: an int telling where the margin is on the page.\n    \"\"\"\n    coefficient = self.get_inner_coefficient(margin)\n\n    if margin == \"inner_left_margin\":\n        return int(coefficient * self.page_width / 100.0)\n    if margin == \"inner_right_margin\":\n        return int(self.page_width - coefficient * self.page_width / 100.0)\n    if margin == \"inner_top_margin\":\n        return int(coefficient * self.page_height / 100.0)\n    if margin == \"inner_bottom_margin\":\n        return int(self.page_height - coefficient * self.page_height / 100.0)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata.compute_inner_margins","title":"<code>compute_inner_margins()</code>","text":"<p>Compute inner margins of the document.</p> <p>Returns:</p> Type Description <p>A dict where the key is the name of the margin and the value</p> <p>is an integer indicating where the margin is on the page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def compute_inner_margins(self):\n\"\"\"Compute inner margins of the document.\n\n    Returns:\n        A dict where the key is the name of the margin and the value\n        is an integer indicating where the margin is on the page.\n    \"\"\"\n    margins = {\n        margin.replace(\"inner_\", \"\"): self.compute_inner_margin(margin)\n        for margin in [\n            \"inner_right_margin\",\n            \"inner_left_margin\",\n            \"inner_top_margin\",\n            \"inner_bottom_margin\",\n        ]\n    }\n\n    if (\n        margins[\"bottom_margin\"] == self.page_height\n        and margins[\"top_margin\"] == 0\n        and margins[\"left_margin\"] == 0\n        and margins[\"right_margin\"] == self.page_width\n    ):\n        margins = {}\n\n    return margins\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata.compute_margin","title":"<code>compute_margin(margin)</code>","text":"<p>Compute a margin in pixels.</p> <p>:param margin: the name of the  margin</p> <p>:return: an int telling where the margin is on the page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def compute_margin(self, margin):\n\"\"\"Compute a margin in pixels.\n\n    :param margin: the name of the  margin\n\n    :return: an int telling where the margin is on the page.\n    \"\"\"\n    coefficient = self.get_coefficient(margin)\n\n    if margin == \"left_margin\":\n        return int(coefficient * self.page_width / 100.0)\n    if margin == \"right_margin\":\n        return int(self.page_width - coefficient * self.page_width / 100.0)\n    if margin == \"top_margin\":\n        return int(coefficient * self.page_height / 100.0)\n    if margin == \"bottom_margin\":\n        return int(self.page_height - coefficient * self.page_height / 100.0)\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata.compute_margins","title":"<code>compute_margins()</code>","text":"<p>Compute the margins of a page in pixels.</p> <p>:returns: a dict containing the four margins in pixels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def compute_margins(self):\n\"\"\"Compute the margins of a page in pixels.\n\n    :returns: a dict containing the four margins in pixels\n    \"\"\"\n    margins = {\n        margin: self.compute_margin(margin)\n        for margin in [\"right_margin\", \"left_margin\", \"top_margin\", \"bottom_margin\"]\n    }\n\n    return margins\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata.get_coefficient","title":"<code>get_coefficient(margin)</code>","text":"<p>Get the width of the margin in percent.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def get_coefficient(self, margin):\n\"\"\"Get the width of the margin in percent.\"\"\"\n    coefficient = 7\n    if margin in list(self.metadata_margins.keys()):\n        margin_data = self.metadata_margins[margin]\n        if margin_data.get(str(self.page_number)) is not None:\n            coefficient = margin_data[str(self.page_number)]\n        elif margin_data.get(\"all\") is not None:\n            coefficient = margin_data[\"all\"]\n        elif self.page_number % 2 == 0 and margin_data.get(\"even\") is not None:\n            coefficient = margin_data[\"even\"]\n        elif self.page_number % 2 == 1 and margin_data.get(\"odd\") is not None:\n            coefficient = margin_data[\"odd\"]\n\n    return coefficient\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.PDFPageMetadata.get_inner_coefficient","title":"<code>get_inner_coefficient(margin)</code>","text":"<p>Get the width of the margin in percent.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def get_inner_coefficient(self, margin):\n\"\"\"Get the width of the margin in percent.\"\"\"\n    coefficient = 0\n    if margin in list(self.metadata_inner_margins.keys()):\n        margin_data = self.metadata_inner_margins[margin]\n        if margin_data.get(str(self.page_number)) is not None:\n            coefficient = margin_data[str(self.page_number)]\n        elif margin_data.get(\"all\") is not None:\n            coefficient = margin_data[\"all\"]\n        elif self.page_number % 2 == 0 and margin_data.get(\"even\") is not None:\n            coefficient = margin_data[\"even\"]\n        elif self.page_number % 2 == 1 and margin_data.get(\"odd\") is not None:\n            coefficient = margin_data[\"odd\"]\n\n    return coefficient\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.handle_br","title":"<code>handle_br(previous, current)</code>","text":"<p>Handle br tags in p elements.</p> <p>Parameters:</p> Name Type Description Default <code>previous</code> <p>the previous string in front of a particular br tag</p> required <code>current</code> <p>the current string following a particular br tag</p> required <p>Returns:</p> Type Description <p>A possibly modified version of previous</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def handle_br(previous, current):\n\"\"\"Handle br tags in p elements.\n\n    Args:\n        previous: the previous string in front of a particular br tag\n        current:  the current string following a particular br tag\n\n    Returns:\n        A possibly modified version of previous\n    \"\"\"\n    # Remove hyphen\n    if is_probably_hyphenated(previous, current):\n        return previous[:-1]\n\n    # Preserve hyphen\n    if previous and previous[-1] == \"-\":\n        return previous\n\n    # Turn br tag into space\n    return f\"{previous} \"\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.is_probably_hyphenated","title":"<code>is_probably_hyphenated(previous, current)</code>","text":"<p>Find out if previous is part of a hyphenated word.</p> <p>Parameters:</p> Name Type Description Default <code>previous</code> <p>the previous string in front of a particular br tag</p> required <code>current</code> <p>the current string following a particular br tag</p> required <p>Returns:</p> Type Description <p>True if previous is part of a hyphenated word, False otherwise</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def is_probably_hyphenated(previous, current):\n\"\"\"Find out if previous is part of a hyphenated word.\n\n    Args:\n        previous: the previous string in front of a particular br tag\n        current:  the current string following a particular br tag\n\n    Returns:\n        True if previous is part of a hyphenated word, False otherwise\n    \"\"\"\n    previous1 = previous[-2:]\n    current1 = current[:2]\n\n    return (\n        LETTER_HYPHEN_AT_END.match(previous1)\n        and LETTER_AT_START.match(current1)\n        and current[0] == current[0].lower()\n    )\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.merge","title":"<code>merge(first, second)</code>","text":"<p>Merge two paragraph elements into one.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def merge(first, second):\n\"\"\"Merge two paragraph elements into one.\"\"\"\n    if len(first):\n        if second.text:\n            if first[-1].tail:\n                first[-1].tail = f\"{first[-1].tail}{second.text}\"\n            else:\n                first[-1].tail = second.text\n    else:\n        if second.text:\n            if first.text:\n                first.text = f\"{first.text}{second.text}\"\n            else:\n                first.text = second.text\n\n    for child in second:\n        first.append(child)\n\n    return first\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.styles","title":"<code>styles(page_style)</code>","text":"<p>Turn inline css styles into a dict.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def styles(page_style):\n\"\"\"Turn inline css styles into a dict.\"\"\"\n    styles = {}\n    for style_pair in page_style.split(\";\"):\n        if style_pair:\n            values = style_pair.split(\":\")\n            styles[values[0]] = values[1].replace(\"px\", \"\")\n\n    return styles\n</code></pre>"},{"location":"reference/pdfconverter/#corpustools.pdfconverter.to_html_elt","title":"<code>to_html_elt(path)</code>","text":"<p>Convert a pdf document to the Giella xml format.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the document</p> required <p>Returns:</p> Type Description <p>etree.Element: the root element of the Giella xml document</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pdfconverter.py</code> <pre><code>def to_html_elt(path):\n\"\"\"Convert a pdf document to the Giella xml format.\n\n    Args:\n        filename (str): path to the document\n\n    Returns:\n        etree.Element: the root element of the Giella xml document\n    \"\"\"\n    converter = PDF2XMLConverter(path)\n    return converter.convert2intermediate()\n</code></pre>"},{"location":"reference/pick_parallel_docs/","title":"pick_parallel_docs","text":"<p>Pick out parallel files to prestable/converted inside a corpus directory.</p>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker","title":"<code>ParallelPicker</code>","text":"<p>Pick valid parallel files from converted xml files.</p> <p>Attributes:</p> Name Type Description <code>vcs</code> <code>versioncontrol.vcs</code> <p>version control client for the corpus directory</p> <code>language1_dir</code> <code>str</code> <p>the directory where converted files of language1 are found</p> <code>parallel_language</code> <code>str</code> <p>three character long language code</p> <code>minratio</code> <code>float</code> <p>the lowest diff in percent between wordcount in the language1 and parallel document that is accepted</p> <code>maxratio</code> <code>float</code> <p>the highest diff in percent between wordcount in the language1 and parallel document that is accepted</p> <code>poor_ratio</code> <code>list of tuple</code> <p>each tuple contains a pair of filename paths and the word count ratio of this pair.</p> <code>counter</code> <code>defaultdict(int</code> <p>count various things.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>class ParallelPicker:\n\"\"\"Pick valid parallel files from converted xml files.\n\n    Attributes:\n        vcs (versioncontrol.vcs): version control client for the corpus\n            directory\n        language1_dir (str): the directory where converted files of language1\n            are found\n        parallel_language (str): three character long language code\n        minratio (float): the lowest diff in percent between wordcount in the\n            language1 and parallel document that is accepted\n        maxratio (float): the highest diff in percent between wordcount in the\n            language1 and parallel document that is accepted\n        poor_ratio (list of tuple): each tuple contains a pair of filename\n            paths and the word count ratio of this pair.\n        counter (defaultdict(int)): count various things.\n    \"\"\"\n\n    def __init__(self, language1_dir, parallel_language, minratio, maxratio):\n\"\"\"Initialise the ParallelPicker class.\n\n        Args:\n            language1_dir (str): the directory where the lang1 files exist.\n            parallel_language (str): the parallel language where the lang2\n                files exist.\n            minratio (int): the minimum acceptable ratio of sentences\n                between two parallel documents\n            maxratio (int): the maximum acceptable ratio of sentences\n                between two parallel documents\n        \"\"\"\n        self.vcs = versioncontrol.vcs(language1_dir[: language1_dir.find(\"converted/\")])\n        self.language1_dir = language1_dir\n        self.calculate_language1(language1_dir)\n        self.parallel_language = parallel_language\n        self.minratio = float(minratio)\n        self.maxratio = float(maxratio)\n        self.poor_ratio = []\n        self.counter = defaultdict(int)\n\n    def calculate_language1(self, language1_dir):\n\"\"\"The language is the part after 'converted/'.\"\"\"\n        converted_pos = language1_dir.find(\"converted/\")\n        part_after_converted = language1_dir[converted_pos + len(\"converted/\") :]\n\n        if part_after_converted.find(\"/\") == -1:\n            self.language1 = part_after_converted\n        else:\n            self.language1 = part_after_converted[: part_after_converted.find(\"/\")]\n\n    def find_lang1_files(self):\n\"\"\"Find the language1 files.\n\n        Yields:\n            corpusxmlfile.CorpusXMLFile\n        \"\"\"\n        for root, _, files in os.walk(self.language1_dir):\n            for lang1_file in files:\n                if lang1_file.endswith(\".xml\"):\n                    yield corpusxmlfile.CorpusXMLFile(os.path.join(root, lang1_file))\n\n    def has_parallel(self, language1_file):\n\"\"\"Check if the given file has a parallel file.\n\n        Args:\n            language1_file (corpusxmlfile.CorpusXMLFile): The first file of a\n                parallel pair.\n\n        Returns:\n            boolean\n        \"\"\"\n        parallel_name = language1_file.get_parallel_filename(self.parallel_language)\n        return parallel_name is not None and os.path.isfile(parallel_name)\n\n    @staticmethod\n    def has_sufficient_words(file1, file2):\n\"\"\"Check if the given file contains more words than the threshold.\n\n        Args:\n            file1 (corpusxmlfile.CorpusXMLFile): The first file of a parallel\n                pair.\n            file2 (corpusxmlfile.CorpusXMLFile): The second file of a parallel\n                pair.\n\n        Returns:\n            boolean\n        \"\"\"\n        threshold = 30\n        return (\n            file1.word_count is not None\n            and int(file1.word_count) &gt; threshold\n            and file2.word_count is not None\n            and int(file2.word_count) &gt; threshold\n        )\n\n    def has_sufficient_ratio(self, file1, file2):\n\"\"\"See if the ratio of words is good enough.\n\n        Args:\n            file1 (corpusxmlfile.CorpusXMLFile): The first file of a parallel\n                pair.\n            file2 (corpusxmlfile.CorpusXMLFile): The second file of a parallel\n                pair.\n\n        Returns:\n            boolean\n        \"\"\"\n        ratio = float(file1.word_count) / float(file2.word_count) * 100\n        if self.minratio &lt; ratio &lt; self.maxratio:\n            return True\n        else:\n            self.poor_ratio.append(\n                (file1.name, file1.word_count, file2.name, file2.word_count, ratio)\n            )\n\n    def copy_file(self, xml_file):\n\"\"\"Copy xml_file to prestable/converted.\n\n        Args:\n            xml_file (corpusxmlfile.CorpusXMLFile): the file that should be\n                copied to prestable/converted.\n        \"\"\"\n        prestable_dir = xml_file.dirname.replace(\"converted\", \"prestable/converted\")\n\n        if not os.path.isdir(prestable_dir):\n            with util.ignored(OSError):\n                os.makedirs(prestable_dir)\n\n        prestable_name = os.path.join(prestable_dir, xml_file.basename)\n        shutil.copy(xml_file.name, prestable_dir)\n        self.vcs.add(prestable_name)\n\n        return prestable_name\n\n    def is_valid_pair(self, file1, file2):\n\"\"\"Check if file1 and file2 is a valid parallel pair.\n\n        Args:\n            file1 (corpusxmlfile.CorpusXMLFile): The first file of a parallel\n                pair.\n            file2 (corpusxmlfile.CorpusXMLFile): The second file of a parallel\n                pair.\n\n        Returns:\n            bool\n        \"\"\"\n        return self.has_sufficient_words(file1, file2) and self.has_sufficient_ratio(\n            file1, file2\n        )\n\n    def valid_parallels(self):\n\"\"\"Pick valid parallel file pairs.\n\n        Yields:\n            tuple of corpusxmlfile.CorpusXMLFile\n        \"\"\"\n        for language1_file in self.find_lang1_files():\n            if self.has_parallel(language1_file):\n                self.counter[\"has_parallel\"] += 1\n                parallel_file = corpusxmlfile.CorpusXMLFile(\n                    language1_file.get_parallel_filename(self.parallel_language)\n                )\n                if self.is_valid_pair(language1_file, parallel_file):\n                    self.counter[\"good_parallel\"] += 1\n                    yield (language1_file, parallel_file)\n\n    def copy_valid_parallels(self):\n\"\"\"Copy valid parallel files from converted to prestable/converted.\"\"\"\n        for file1, file2 in self.valid_parallels():\n            prestable_name = self.copy_file(file1)\n            self.copy_file(file2)\n            outfile = parallelize.parallelise_file(\n                prestable_name,\n                file2.lang,\n                dictionary=None,\n                quiet=True,\n                aligner=\"tca2\",\n                stdout=False,\n                force=True,\n            )\n\n            self.vcs.add(outfile)\n            self.vcs.add(outfile + \".html\")\n\n    def print_report(self):\n        for poor_ratio in self.poor_ratio:\n            print(\"{}: {}\\n{}: {}\\nratio: {}\\n\".format(*poor_ratio))\n\n        for key, value in self.counter.items():\n            print(key, value)\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.__init__","title":"<code>__init__(language1_dir, parallel_language, minratio, maxratio)</code>","text":"<p>Initialise the ParallelPicker class.</p> <p>Parameters:</p> Name Type Description Default <code>language1_dir</code> <code>str</code> <p>the directory where the lang1 files exist.</p> required <code>parallel_language</code> <code>str</code> <p>the parallel language where the lang2 files exist.</p> required <code>minratio</code> <code>int</code> <p>the minimum acceptable ratio of sentences between two parallel documents</p> required <code>maxratio</code> <code>int</code> <p>the maximum acceptable ratio of sentences between two parallel documents</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def __init__(self, language1_dir, parallel_language, minratio, maxratio):\n\"\"\"Initialise the ParallelPicker class.\n\n    Args:\n        language1_dir (str): the directory where the lang1 files exist.\n        parallel_language (str): the parallel language where the lang2\n            files exist.\n        minratio (int): the minimum acceptable ratio of sentences\n            between two parallel documents\n        maxratio (int): the maximum acceptable ratio of sentences\n            between two parallel documents\n    \"\"\"\n    self.vcs = versioncontrol.vcs(language1_dir[: language1_dir.find(\"converted/\")])\n    self.language1_dir = language1_dir\n    self.calculate_language1(language1_dir)\n    self.parallel_language = parallel_language\n    self.minratio = float(minratio)\n    self.maxratio = float(maxratio)\n    self.poor_ratio = []\n    self.counter = defaultdict(int)\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.calculate_language1","title":"<code>calculate_language1(language1_dir)</code>","text":"<p>The language is the part after 'converted/'.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def calculate_language1(self, language1_dir):\n\"\"\"The language is the part after 'converted/'.\"\"\"\n    converted_pos = language1_dir.find(\"converted/\")\n    part_after_converted = language1_dir[converted_pos + len(\"converted/\") :]\n\n    if part_after_converted.find(\"/\") == -1:\n        self.language1 = part_after_converted\n    else:\n        self.language1 = part_after_converted[: part_after_converted.find(\"/\")]\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.copy_file","title":"<code>copy_file(xml_file)</code>","text":"<p>Copy xml_file to prestable/converted.</p> <p>Parameters:</p> Name Type Description Default <code>xml_file</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>the file that should be copied to prestable/converted.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def copy_file(self, xml_file):\n\"\"\"Copy xml_file to prestable/converted.\n\n    Args:\n        xml_file (corpusxmlfile.CorpusXMLFile): the file that should be\n            copied to prestable/converted.\n    \"\"\"\n    prestable_dir = xml_file.dirname.replace(\"converted\", \"prestable/converted\")\n\n    if not os.path.isdir(prestable_dir):\n        with util.ignored(OSError):\n            os.makedirs(prestable_dir)\n\n    prestable_name = os.path.join(prestable_dir, xml_file.basename)\n    shutil.copy(xml_file.name, prestable_dir)\n    self.vcs.add(prestable_name)\n\n    return prestable_name\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.copy_valid_parallels","title":"<code>copy_valid_parallels()</code>","text":"<p>Copy valid parallel files from converted to prestable/converted.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def copy_valid_parallels(self):\n\"\"\"Copy valid parallel files from converted to prestable/converted.\"\"\"\n    for file1, file2 in self.valid_parallels():\n        prestable_name = self.copy_file(file1)\n        self.copy_file(file2)\n        outfile = parallelize.parallelise_file(\n            prestable_name,\n            file2.lang,\n            dictionary=None,\n            quiet=True,\n            aligner=\"tca2\",\n            stdout=False,\n            force=True,\n        )\n\n        self.vcs.add(outfile)\n        self.vcs.add(outfile + \".html\")\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.find_lang1_files","title":"<code>find_lang1_files()</code>","text":"<p>Find the language1 files.</p> <p>Yields:</p> Type Description <p>corpusxmlfile.CorpusXMLFile</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def find_lang1_files(self):\n\"\"\"Find the language1 files.\n\n    Yields:\n        corpusxmlfile.CorpusXMLFile\n    \"\"\"\n    for root, _, files in os.walk(self.language1_dir):\n        for lang1_file in files:\n            if lang1_file.endswith(\".xml\"):\n                yield corpusxmlfile.CorpusXMLFile(os.path.join(root, lang1_file))\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.has_parallel","title":"<code>has_parallel(language1_file)</code>","text":"<p>Check if the given file has a parallel file.</p> <p>Parameters:</p> Name Type Description Default <code>language1_file</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>The first file of a parallel pair.</p> required <p>Returns:</p> Type Description <p>boolean</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def has_parallel(self, language1_file):\n\"\"\"Check if the given file has a parallel file.\n\n    Args:\n        language1_file (corpusxmlfile.CorpusXMLFile): The first file of a\n            parallel pair.\n\n    Returns:\n        boolean\n    \"\"\"\n    parallel_name = language1_file.get_parallel_filename(self.parallel_language)\n    return parallel_name is not None and os.path.isfile(parallel_name)\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.has_sufficient_ratio","title":"<code>has_sufficient_ratio(file1, file2)</code>","text":"<p>See if the ratio of words is good enough.</p> <p>Parameters:</p> Name Type Description Default <code>file1</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>The first file of a parallel pair.</p> required <code>file2</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>The second file of a parallel pair.</p> required <p>Returns:</p> Type Description <p>boolean</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def has_sufficient_ratio(self, file1, file2):\n\"\"\"See if the ratio of words is good enough.\n\n    Args:\n        file1 (corpusxmlfile.CorpusXMLFile): The first file of a parallel\n            pair.\n        file2 (corpusxmlfile.CorpusXMLFile): The second file of a parallel\n            pair.\n\n    Returns:\n        boolean\n    \"\"\"\n    ratio = float(file1.word_count) / float(file2.word_count) * 100\n    if self.minratio &lt; ratio &lt; self.maxratio:\n        return True\n    else:\n        self.poor_ratio.append(\n            (file1.name, file1.word_count, file2.name, file2.word_count, ratio)\n        )\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.has_sufficient_words","title":"<code>has_sufficient_words(file1, file2)</code>  <code>staticmethod</code>","text":"<p>Check if the given file contains more words than the threshold.</p> <p>Parameters:</p> Name Type Description Default <code>file1</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>The first file of a parallel pair.</p> required <code>file2</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>The second file of a parallel pair.</p> required <p>Returns:</p> Type Description <p>boolean</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>@staticmethod\ndef has_sufficient_words(file1, file2):\n\"\"\"Check if the given file contains more words than the threshold.\n\n    Args:\n        file1 (corpusxmlfile.CorpusXMLFile): The first file of a parallel\n            pair.\n        file2 (corpusxmlfile.CorpusXMLFile): The second file of a parallel\n            pair.\n\n    Returns:\n        boolean\n    \"\"\"\n    threshold = 30\n    return (\n        file1.word_count is not None\n        and int(file1.word_count) &gt; threshold\n        and file2.word_count is not None\n        and int(file2.word_count) &gt; threshold\n    )\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.is_valid_pair","title":"<code>is_valid_pair(file1, file2)</code>","text":"<p>Check if file1 and file2 is a valid parallel pair.</p> <p>Parameters:</p> Name Type Description Default <code>file1</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>The first file of a parallel pair.</p> required <code>file2</code> <code>corpusxmlfile.CorpusXMLFile</code> <p>The second file of a parallel pair.</p> required <p>Returns:</p> Type Description <p>bool</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def is_valid_pair(self, file1, file2):\n\"\"\"Check if file1 and file2 is a valid parallel pair.\n\n    Args:\n        file1 (corpusxmlfile.CorpusXMLFile): The first file of a parallel\n            pair.\n        file2 (corpusxmlfile.CorpusXMLFile): The second file of a parallel\n            pair.\n\n    Returns:\n        bool\n    \"\"\"\n    return self.has_sufficient_words(file1, file2) and self.has_sufficient_ratio(\n        file1, file2\n    )\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.ParallelPicker.valid_parallels","title":"<code>valid_parallels()</code>","text":"<p>Pick valid parallel file pairs.</p> <p>Yields:</p> Type Description <p>tuple of corpusxmlfile.CorpusXMLFile</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def valid_parallels(self):\n\"\"\"Pick valid parallel file pairs.\n\n    Yields:\n        tuple of corpusxmlfile.CorpusXMLFile\n    \"\"\"\n    for language1_file in self.find_lang1_files():\n        if self.has_parallel(language1_file):\n            self.counter[\"has_parallel\"] += 1\n            parallel_file = corpusxmlfile.CorpusXMLFile(\n                language1_file.get_parallel_filename(self.parallel_language)\n            )\n            if self.is_valid_pair(language1_file, parallel_file):\n                self.counter[\"good_parallel\"] += 1\n                yield (language1_file, parallel_file)\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.main","title":"<code>main()</code>","text":"<p>Copy valid parallel pairs from converted to prestable/converted.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def main():\n\"\"\"Copy valid parallel pairs from converted to prestable/converted.\"\"\"\n    args = parse_options()\n\n    picker = ParallelPicker(\n        args.language1_dir, args.parallel_language, args.minratio, args.maxratio\n    )\n    picker.copy_valid_parallels()\n    picker.print_report()\n</code></pre>"},{"location":"reference/pick_parallel_docs/#corpustools.pick_parallel_docs.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_parallel_docs.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Pick out parallel files from converted to \" \"prestable/converted.\",\n    )\n\n    parser.add_argument(\n        \"language1_dir\", help=\"directory where the files of language1 exist\"\n    )\n    parser.add_argument(\n        \"-p\",\n        \"--parallel_language\",\n        dest=\"parallel_language\",\n        help=\"The language where we would like to find \" \"parallel documents\",\n        required=True,\n    )\n    parser.add_argument(\n        \"--minratio\", dest=\"minratio\", help=\"The minimum ratio\", required=True\n    )\n    parser.add_argument(\n        \"--maxratio\", dest=\"maxratio\", help=\"The maximum ratio\", required=True\n    )\n\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"reference/pick_samediggi_se_docs/","title":"pick_samediggi_se_docs","text":"<p>Program to pick out documents to be saved to the corpus from samediggi.se.</p> <p>The documents have been fetched using wget.</p>"},{"location":"reference/pick_samediggi_se_docs/#corpustools.pick_samediggi_se_docs.DocumentPicker","title":"<code>DocumentPicker</code>","text":"<p>Pick documents from samediggi.se to be added to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_samediggi_se_docs.py</code> <pre><code>class DocumentPicker:\n\"\"\"Pick documents from samediggi.se to be added to the corpus.\"\"\"\n\n    def __init__(self, source_dir):\n        self.freecorpus = os.getenv(\"GTFREE\")\n        self.source_dir = source_dir\n        self.file_dict = {}\n        self.file_dict.setdefault(\"sma\", [])\n        self.file_dict.setdefault(\"sme\", [])\n        self.file_dict.setdefault(\"smj\", [])\n        self.file_dict.setdefault(\"swe\", [])\n        self.file_dict.setdefault(\"none\", [])\n        self.parallel_dict = {}\n        self.total_file = 0\n\n    def classify_files(self):\n\"\"\"Iterate through all files, classify them according to language\"\"\"\n        for root, dirs, files in os.walk(self.source_dir):\n            for f in files:\n                if f.endswith(\".html\"):\n                    self.total_file += 1\n                    self.classify_file(os.path.join(root, f))\n\n    def get_parallel_name(self, file_, a):\n        dirname = os.path.dirname(file_)\n        href = a.get(\"href\").replace(\"http://www.samediggi.se/\", \"\")\n\n        if \"..\" in href:\n            dirname_parts = dirname.split(\"/\")\n            href_parts = href.split(\"/\")\n            dirname = \"/\".join(dirname_parts[:-1])\n            href = \"/\".join(href_parts[1:])\n\n        return os.path.join(dirname, href)\n\n    def append_parallel(self, file_, a):\n        if os.path.exists(self.get_parallel_name(file_, a)):\n            self.parallel_dict[file_].append(self.get_parallel_name(file_, a))\n        else:\n            print(\n                util.lineno(),\n                self.get_parallel_name(file_, a),\n                \"does not exist\",\n                a.get(\"title\"),\n                file_,\n                file=sys.stderr,\n            )\n\n    def get_parallels(self, a, file_):\n        self.parallel_dict.setdefault(file_, [])\n\n        prev = a.getprevious()\n        next_ = a.getnext()\n\n        while prev is not None:\n            if prev != a:\n                self.append_parallel(file_, prev)\n            prev = prev.getprevious()\n\n        while next_ is not None:\n            if next_ != a:\n                self.append_parallel(file_, next_)\n            next_ = next_.getnext()\n\n    def append_file(self, language, file_):\n        self.file_dict[language].append(file_)\n        self.file_dict[\"none\"].remove(file_)\n\n    def classify_file(self, file_):\n\"\"\"Identify the language of the file\"\"\"\n        parser = etree.HTMLParser()\n        html = etree.parse(file_, parser)\n        self.file_dict[\"none\"].append(file_)\n\n        for img in html.iter(\"img\"):\n            if img.get(\"src\") is not None and \"icon_flag_sme_dim.gif\" in img.get(\"src\"):\n                self.append_file(\"sme\", file_)\n                self.get_parallels(img.getparent(), file_)\n            elif img.get(\"src\") is not None and \"icon_flag_smj_dim.gif\" in img.get(\n                \"src\"\n            ):\n                self.append_file(\"smj\", file_)\n                self.get_parallels(img.getparent(), file_)\n            elif img.get(\"src\") is not None and \"icon_flag_sma_dim.gif\" in img.get(\n                \"src\"\n            ):\n                self.append_file(\"sma\", file_)\n                self.get_parallels(img.getparent(), file_)\n            elif img.get(\"src\") is not None and \"icon_flag_swe_dim.gif\" in img.get(\n                \"src\"\n            ):\n                self.append_file(\"swe\", file_)\n                self.get_parallels(img.getparent(), file_)\n\n    def conclude(self):\n        total = 0\n        for key, value in self.file_dict.items():\n            total += len(self.file_dict[key])\n            print(key, len(self.file_dict[key]))\n        print(total, self.total_file)\n\n    def check_consistency(self):\n\"\"\"Check if all files that claim to have parallels actually exist\n\n        Remove the parallel file from the list of parallels\n        \"\"\"\n        for file_ in self.parallel_dict:\n            for parallel_file in self.parallel_dict[file_]:\n                try:\n                    self.parallel_dict[parallel_file]\n                    if file_ not in self.parallel_dict[parallel_file]:\n                        self.parallel_dict[file_].remove(parallel_file)\n                except KeyError:\n                    self.parallel_dict[file_].remove(parallel_file)\n\n    def get_goal_name(self, file_, lang):\n        filename = os.path.basename(file_)\n        goalfile = os.path.join(\n            self.freecorpus, \"orig\", lang, \"admin\", \"sd\", \"www.samediggi.se\", filename\n        )\n\n        return goalfile\n\n    def set_metadata(self, file_, lang):\n        mh = xslsetter.MetadataHandler(\n            self.get_goal_name(file_, lang) + \".xsl\", create=True\n        )\n        for key, value in self.set_variables(file_, lang).items():\n            mh.set_variable(key, value)\n        mh.write_file()\n\n    def set_variables(self, file_, lang):\n        variables = {}\n        variables[\"filename\"] = \"http://\" + file_.replace(\".html\", \"\")\n        variables[\"license_type\"] = \"free\"\n        variables[\"sub_name\"] = \"B\u00f8rre Gaup\"\n        variables[\"sub_email\"] = \"borre.gaup@uit.no\"\n        variables[\"mainlang\"] = lang\n        variables[\"monolingual\"] = \"1\"\n\n        if lang != \"swe\":\n            variables[\"translated_from\"] = \"swe\"\n\n        if self.parallel_dict[file_]:\n            variables[\"parallel_texts\"] = \"1\"\n            para_langs = [\"sma\", \"sme\", \"smj\", \"swe\"]\n            para_langs.remove(lang)\n            for parallel_file in self.parallel_dict[file_]:\n                for para_lang in para_langs:\n                    if parallel_file in self.file_dict[para_lang]:\n                        variables[\"para_\" + para_lang] = os.path.basename(parallel_file)\n\n        return variables\n\n    def move_swe_file(self, file_):\n        for candidate in self.parallel_dict[file_]:\n            if candidate in self.file_dict[\"swe\"]:\n                shutil.copy(candidate, self.get_goal_name(candidate, \"swe\"))\n                self.set_metadata(candidate, \"swe\")\n\n    def move_files_set_metadata(self):\n        for lang in [\"sma\", \"smj\", \"sme\"]:\n            for file_ in self.file_dict[lang]:\n                shutil.copy(file_, self.get_goal_name(file_, lang))\n                self.move_swe_file(file_)\n                self.set_metadata(file_, lang)\n</code></pre>"},{"location":"reference/pick_samediggi_se_docs/#corpustools.pick_samediggi_se_docs.DocumentPicker.check_consistency","title":"<code>check_consistency()</code>","text":"<p>Check if all files that claim to have parallels actually exist</p> <p>Remove the parallel file from the list of parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_samediggi_se_docs.py</code> <pre><code>def check_consistency(self):\n\"\"\"Check if all files that claim to have parallels actually exist\n\n    Remove the parallel file from the list of parallels\n    \"\"\"\n    for file_ in self.parallel_dict:\n        for parallel_file in self.parallel_dict[file_]:\n            try:\n                self.parallel_dict[parallel_file]\n                if file_ not in self.parallel_dict[parallel_file]:\n                    self.parallel_dict[file_].remove(parallel_file)\n            except KeyError:\n                self.parallel_dict[file_].remove(parallel_file)\n</code></pre>"},{"location":"reference/pick_samediggi_se_docs/#corpustools.pick_samediggi_se_docs.DocumentPicker.classify_file","title":"<code>classify_file(file_)</code>","text":"<p>Identify the language of the file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_samediggi_se_docs.py</code> <pre><code>def classify_file(self, file_):\n\"\"\"Identify the language of the file\"\"\"\n    parser = etree.HTMLParser()\n    html = etree.parse(file_, parser)\n    self.file_dict[\"none\"].append(file_)\n\n    for img in html.iter(\"img\"):\n        if img.get(\"src\") is not None and \"icon_flag_sme_dim.gif\" in img.get(\"src\"):\n            self.append_file(\"sme\", file_)\n            self.get_parallels(img.getparent(), file_)\n        elif img.get(\"src\") is not None and \"icon_flag_smj_dim.gif\" in img.get(\n            \"src\"\n        ):\n            self.append_file(\"smj\", file_)\n            self.get_parallels(img.getparent(), file_)\n        elif img.get(\"src\") is not None and \"icon_flag_sma_dim.gif\" in img.get(\n            \"src\"\n        ):\n            self.append_file(\"sma\", file_)\n            self.get_parallels(img.getparent(), file_)\n        elif img.get(\"src\") is not None and \"icon_flag_swe_dim.gif\" in img.get(\n            \"src\"\n        ):\n            self.append_file(\"swe\", file_)\n            self.get_parallels(img.getparent(), file_)\n</code></pre>"},{"location":"reference/pick_samediggi_se_docs/#corpustools.pick_samediggi_se_docs.DocumentPicker.classify_files","title":"<code>classify_files()</code>","text":"<p>Iterate through all files, classify them according to language</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_samediggi_se_docs.py</code> <pre><code>def classify_files(self):\n\"\"\"Iterate through all files, classify them according to language\"\"\"\n    for root, dirs, files in os.walk(self.source_dir):\n        for f in files:\n            if f.endswith(\".html\"):\n                self.total_file += 1\n                self.classify_file(os.path.join(root, f))\n</code></pre>"},{"location":"reference/pick_titles/","title":"pick_titles","text":"<p>Program to pick out documents to be saved to the corpus from samediggi.se.</p> <p>The documents have been fetched using wget.</p>"},{"location":"reference/pick_titles/#corpustools.pick_titles.DocumentPicker","title":"<code>DocumentPicker</code>","text":"<p>Pick documents from samediggi.se to be added to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_titles.py</code> <pre><code>class DocumentPicker:\n\"\"\"Pick documents from samediggi.se to be added to the corpus.\"\"\"\n\n    def __init__(self, source_dir):\n        self.freecorpus = os.getenv(\"GTFREE\")\n        self.source_dir = source_dir\n        self.file_dict = {}\n        self.file_dict.setdefault(\"sma\", [])\n        self.file_dict.setdefault(\"sme\", [])\n        self.file_dict.setdefault(\"smj\", [])\n        self.file_dict.setdefault(\"swe\", [])\n        self.file_dict.setdefault(\"none\", [])\n        self.parallel_dict = {}\n        self.total_file = 0\n\n    def classify_files(self):\n\"\"\"Iterate through all files, classify them according to language\"\"\"\n        for root, dirs, files in os.walk(self.source_dir):\n            for f in files:\n                if f.endswith(\".xsl\"):\n                    self.total_file += 1\n                    self.classify_file(os.path.join(root, f))\n\n    def classify_file(self, file_):\n\"\"\"Identify the language of the file\"\"\"\n        mh = xslsetter.MetadataHandler(file_, create=True)\n        url = mh.get_variable(\"filename\")\n        if (\n            \"regjeringen.no\" in url\n            and \"regjeringen.no\" not in file_\n            and \".pdf\" not in file_\n        ):\n            try:\n                remote = urllib2.urlopen(urllib2.Request(url.encode(\"utf8\")))\n                self.copyfile(remote, file_)\n            except urllib2.HTTPError:\n                print(\n                    util.lineno(),\n                    \"Could not fetch\",\n                    file_.replace(\".xsl\", \"\"),\n                    file=sys.stderr,\n                )\n            except UnicodeEncodeError:\n                print(util.lineno(), \"Unicode error in url\", url, file=sys.stderr)\n            print(util.lineno(), \"sleeping \u2026\")\n            time.sleep(2)\n\n    def copyfile(self, remote, file_):\n        try:\n            with open(file_.replace(\".xsl\", \"\"), \"wb\") as f:\n                print(util.lineno(), \"Fetching\", file_.replace(\".xsl\", \"\"))\n                shutil.copyfileobj(remote, f)\n        finally:\n            remote.close()\n</code></pre>"},{"location":"reference/pick_titles/#corpustools.pick_titles.DocumentPicker.classify_file","title":"<code>classify_file(file_)</code>","text":"<p>Identify the language of the file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_titles.py</code> <pre><code>def classify_file(self, file_):\n\"\"\"Identify the language of the file\"\"\"\n    mh = xslsetter.MetadataHandler(file_, create=True)\n    url = mh.get_variable(\"filename\")\n    if (\n        \"regjeringen.no\" in url\n        and \"regjeringen.no\" not in file_\n        and \".pdf\" not in file_\n    ):\n        try:\n            remote = urllib2.urlopen(urllib2.Request(url.encode(\"utf8\")))\n            self.copyfile(remote, file_)\n        except urllib2.HTTPError:\n            print(\n                util.lineno(),\n                \"Could not fetch\",\n                file_.replace(\".xsl\", \"\"),\n                file=sys.stderr,\n            )\n        except UnicodeEncodeError:\n            print(util.lineno(), \"Unicode error in url\", url, file=sys.stderr)\n        print(util.lineno(), \"sleeping \u2026\")\n        time.sleep(2)\n</code></pre>"},{"location":"reference/pick_titles/#corpustools.pick_titles.DocumentPicker.classify_files","title":"<code>classify_files()</code>","text":"<p>Iterate through all files, classify them according to language</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/pick_titles.py</code> <pre><code>def classify_files(self):\n\"\"\"Iterate through all files, classify them according to language\"\"\"\n    for root, dirs, files in os.walk(self.source_dir):\n        for f in files:\n            if f.endswith(\".xsl\"):\n                self.total_file += 1\n                self.classify_file(os.path.join(root, f))\n</code></pre>"},{"location":"reference/plaintextconverter/","title":"plaintextconverter","text":"<p>Convert plaintext files to the Giella xml format.</p>"},{"location":"reference/plaintextconverter/#corpustools.plaintextconverter.PlaintextConverter","title":"<code>PlaintextConverter</code>","text":"<p>         Bases: <code>basicconverter.BasicConverter</code></p> <p>Convert plain text files to the Giella xml format.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/plaintextconverter.py</code> <pre><code>class PlaintextConverter(basicconverter.BasicConverter):\n\"\"\"Convert plain text files to the Giella xml format.\"\"\"\n\n    def to_unicode(self):\n\"\"\"Read a file into a unicode string.\n\n        If the content of the file is not utf-8, pretend the encoding is\n        latin1. The real encoding will be detected later.\n\n        Returns:\n            str\n        \"\"\"\n        try:\n            content = codecs.open(self.orig, encoding=\"utf8\").read()\n        except ValueError:\n            content = codecs.open(self.orig, encoding=\"latin1\").read()\n\n        content = self.strip_chars(content.replace(\"\\r\\n\", \"\\n\"))\n\n        return content\n\n    @staticmethod\n    def strip_chars(content, extra=\"\"):\n\"\"\"Remove the characters found in plaintext_oddities from content.\n\n        Args:\n            content: a string containing the content of a document.\n            extra: a string containg even more characters to remove\n            from content.\n\n        Returns:\n            A string containing the content sans unwanted characters.\n        \"\"\"\n        plaintext_oddities = [\n            (\"\u00ca\u00ca\", \"\\n\"),\n            (r\"&lt;\\!q&gt;\", \"\"),\n            (r\"&lt;\\!h&gt;\", \"\"),\n            (\"&lt;*B&gt;\", \"\"),\n            (\"&lt;*P&gt;\", \"\"),\n            (\"&lt;*I&gt;\", \"\"),\n            (\"\\r\", \"\\n\"),\n            (\"&lt;ASCII-MAC&gt;\", \"\"),\n            (\"&lt;vsn:3.000000&gt;\", \"\"),\n            (\"&lt;0x010C&gt;\", \"\u010c\"),\n            (\"&lt;0x010D&gt;\", \"\u010d\"),\n            (\"&lt;0x0110&gt;\", \"\u0110\"),\n            (\"&lt;0x0111&gt;\", \"\u0111\"),\n            (\"&lt;0x014A&gt;\", \"\u014a\"),\n            (\"&lt;0x014B&gt;\", \"\u014b\"),\n            (\"&lt;0x0160&gt;\", \"\u0160\"),\n            (\"&lt;0x0161&gt;\", \"\u0161\"),\n            (\"&lt;0x0166&gt;\", \"\u0166\"),\n            (\"&lt;0x0167&gt;\", \"\u0167\"),\n            (\"&lt;0x017D&gt;\", \"\u017d\"),\n            (\"&lt;0x017E&gt;\", \"\u017e\"),\n            (\"&lt;0x2003&gt;\", \" \"),\n            (\n                \"========================================================\"\n                \"========================\",\n                \"\\n\",\n            ),\n        ]\n        content = util.replace_all(plaintext_oddities, content)\n        remove_re = re.compile(f\"[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F{extra}]\")\n        content, _ = remove_re.subn(\"\", content)\n\n        return content\n\n    @staticmethod\n    def make_element(element_name, text):\n\"\"\"Make an xml element.\n\n        Args:\n            element_name (str): Name of the xml element\n            text (str): The text the xml should contain\n            attributes (dict): The attributes the element should have\n\n        :returns: lxml.etree.Element\n        \"\"\"\n        element = etree.Element(element_name)\n\n        hyph_parts = text.split(\"&lt;hyph/&gt;\")\n        if len(hyph_parts) &gt; 1:\n            element.text = hyph_parts[0]\n            for hyph_part in hyph_parts[1:]:\n                hyph = etree.Element(\"hyph\")\n                hyph.tail = hyph_part\n                element.append(hyph)\n        else:\n            element.text = text\n\n        return element\n\n    def content2xml(self, content):\n\"\"\"Transform plaintext to an intermediate xml document.\n\n        Args:\n            content (str): the content of the plaintext document.\n\n        Returns:\n            An etree element.\n        \"\"\"\n        document = etree.Element(\"document\")\n        header = etree.Element(\"header\")\n        body = etree.Element(\"body\")\n\n        ptext = \"\"\n\n        for line_no, line in enumerate(content, start=1):\n            if line_no not in self.metadata.skip_lines:\n                if line.strip() == \"\":\n                    if ptext.strip() != \"\":\n                        body.append(self.make_element(\"p\", ptext))\n                    ptext = \"\"\n                else:\n                    ptext = ptext + line\n\n        if ptext != \"\":\n            body.append(self.make_element(\"p\", ptext))\n\n        document.append(header)\n        document.append(body)\n\n        return document\n</code></pre>"},{"location":"reference/plaintextconverter/#corpustools.plaintextconverter.PlaintextConverter.content2xml","title":"<code>content2xml(content)</code>","text":"<p>Transform plaintext to an intermediate xml document.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>the content of the plaintext document.</p> required <p>Returns:</p> Type Description <p>An etree element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/plaintextconverter.py</code> <pre><code>def content2xml(self, content):\n\"\"\"Transform plaintext to an intermediate xml document.\n\n    Args:\n        content (str): the content of the plaintext document.\n\n    Returns:\n        An etree element.\n    \"\"\"\n    document = etree.Element(\"document\")\n    header = etree.Element(\"header\")\n    body = etree.Element(\"body\")\n\n    ptext = \"\"\n\n    for line_no, line in enumerate(content, start=1):\n        if line_no not in self.metadata.skip_lines:\n            if line.strip() == \"\":\n                if ptext.strip() != \"\":\n                    body.append(self.make_element(\"p\", ptext))\n                ptext = \"\"\n            else:\n                ptext = ptext + line\n\n    if ptext != \"\":\n        body.append(self.make_element(\"p\", ptext))\n\n    document.append(header)\n    document.append(body)\n\n    return document\n</code></pre>"},{"location":"reference/plaintextconverter/#corpustools.plaintextconverter.PlaintextConverter.make_element","title":"<code>make_element(element_name, text)</code>  <code>staticmethod</code>","text":"<p>Make an xml element.</p> <p>Parameters:</p> Name Type Description Default <code>element_name</code> <code>str</code> <p>Name of the xml element</p> required <code>text</code> <code>str</code> <p>The text the xml should contain</p> required <code>attributes</code> <code>dict</code> <p>The attributes the element should have</p> required <p>:returns: lxml.etree.Element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/plaintextconverter.py</code> <pre><code>@staticmethod\ndef make_element(element_name, text):\n\"\"\"Make an xml element.\n\n    Args:\n        element_name (str): Name of the xml element\n        text (str): The text the xml should contain\n        attributes (dict): The attributes the element should have\n\n    :returns: lxml.etree.Element\n    \"\"\"\n    element = etree.Element(element_name)\n\n    hyph_parts = text.split(\"&lt;hyph/&gt;\")\n    if len(hyph_parts) &gt; 1:\n        element.text = hyph_parts[0]\n        for hyph_part in hyph_parts[1:]:\n            hyph = etree.Element(\"hyph\")\n            hyph.tail = hyph_part\n            element.append(hyph)\n    else:\n        element.text = text\n\n    return element\n</code></pre>"},{"location":"reference/plaintextconverter/#corpustools.plaintextconverter.PlaintextConverter.strip_chars","title":"<code>strip_chars(content, extra='')</code>  <code>staticmethod</code>","text":"<p>Remove the characters found in plaintext_oddities from content.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <p>a string containing the content of a document.</p> required <code>extra</code> <p>a string containg even more characters to remove</p> <code>''</code> <p>Returns:</p> Type Description <p>A string containing the content sans unwanted characters.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/plaintextconverter.py</code> <pre><code>@staticmethod\ndef strip_chars(content, extra=\"\"):\n\"\"\"Remove the characters found in plaintext_oddities from content.\n\n    Args:\n        content: a string containing the content of a document.\n        extra: a string containg even more characters to remove\n        from content.\n\n    Returns:\n        A string containing the content sans unwanted characters.\n    \"\"\"\n    plaintext_oddities = [\n        (\"\u00ca\u00ca\", \"\\n\"),\n        (r\"&lt;\\!q&gt;\", \"\"),\n        (r\"&lt;\\!h&gt;\", \"\"),\n        (\"&lt;*B&gt;\", \"\"),\n        (\"&lt;*P&gt;\", \"\"),\n        (\"&lt;*I&gt;\", \"\"),\n        (\"\\r\", \"\\n\"),\n        (\"&lt;ASCII-MAC&gt;\", \"\"),\n        (\"&lt;vsn:3.000000&gt;\", \"\"),\n        (\"&lt;0x010C&gt;\", \"\u010c\"),\n        (\"&lt;0x010D&gt;\", \"\u010d\"),\n        (\"&lt;0x0110&gt;\", \"\u0110\"),\n        (\"&lt;0x0111&gt;\", \"\u0111\"),\n        (\"&lt;0x014A&gt;\", \"\u014a\"),\n        (\"&lt;0x014B&gt;\", \"\u014b\"),\n        (\"&lt;0x0160&gt;\", \"\u0160\"),\n        (\"&lt;0x0161&gt;\", \"\u0161\"),\n        (\"&lt;0x0166&gt;\", \"\u0166\"),\n        (\"&lt;0x0167&gt;\", \"\u0167\"),\n        (\"&lt;0x017D&gt;\", \"\u017d\"),\n        (\"&lt;0x017E&gt;\", \"\u017e\"),\n        (\"&lt;0x2003&gt;\", \" \"),\n        (\n            \"========================================================\"\n            \"========================\",\n            \"\\n\",\n        ),\n    ]\n    content = util.replace_all(plaintext_oddities, content)\n    remove_re = re.compile(f\"[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F{extra}]\")\n    content, _ = remove_re.subn(\"\", content)\n\n    return content\n</code></pre>"},{"location":"reference/plaintextconverter/#corpustools.plaintextconverter.PlaintextConverter.to_unicode","title":"<code>to_unicode()</code>","text":"<p>Read a file into a unicode string.</p> <p>If the content of the file is not utf-8, pretend the encoding is latin1. The real encoding will be detected later.</p> <p>Returns:</p> Type Description <p>str</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/plaintextconverter.py</code> <pre><code>def to_unicode(self):\n\"\"\"Read a file into a unicode string.\n\n    If the content of the file is not utf-8, pretend the encoding is\n    latin1. The real encoding will be detected later.\n\n    Returns:\n        str\n    \"\"\"\n    try:\n        content = codecs.open(self.orig, encoding=\"utf8\").read()\n    except ValueError:\n        content = codecs.open(self.orig, encoding=\"latin1\").read()\n\n    content = self.strip_chars(content.replace(\"\\r\\n\", \"\\n\"))\n\n    return content\n</code></pre>"},{"location":"reference/plaintextconverter/#corpustools.plaintextconverter.convert2intermediate","title":"<code>convert2intermediate(filename)</code>","text":"<p>Transform plaintext to an intermediate xml document.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of the file that should be converted</p> required <p>Returns:</p> Type Description <p>An etree element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/plaintextconverter.py</code> <pre><code>def convert2intermediate(filename):\n\"\"\"Transform plaintext to an intermediate xml document.\n\n    Args:\n        filename (str): name of the file that should be converted\n\n    Returns:\n        An etree element.\n    \"\"\"\n    converter = PlaintextConverter(filename)\n\n    return converter.content2xml(io.StringIO(converter.to_unicode()))\n</code></pre>"},{"location":"reference/realign/","title":"realign","text":"<p>Sentence align a given file anew.</p>"},{"location":"reference/realign/#corpustools.realign.calculate_paths","title":"<code>calculate_paths(tmxhtml)</code>","text":"<p>Calculate paths, given a file from the command line.</p> <p>Parameters:</p> Name Type Description Default <code>tmxhtml</code> <code>str</code> <p>path to a .tmx or a .tmx.html file</p> required <p>Returns:</p> Type Description <p>tuple of corpuspath.CorpusPath</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/realign.py</code> <pre><code>def calculate_paths(tmxhtml):\n\"\"\"Calculate paths, given a file from the command line.\n\n    Args:\n        tmxhtml (str): path to a .tmx or a .tmx.html file\n\n    Returns:\n        tuple of corpuspath.CorpusPath\n    \"\"\"\n    path = tmxhtml[:-5] if tmxhtml.endswith(\".tmx.html\") else tmxhtml\n    corpus_path1 = corpuspath.CorpusPath(path)\n    lang2 = corpus_path1.split_on_module(path)[2].split(\"/\")[0].split(\"2\")[1]\n    corpus_path2 = corpuspath.CorpusPath(corpus_path1.parallel(lang2))\n\n    return corpus_path1, corpus_path2\n</code></pre>"},{"location":"reference/realign/#corpustools.realign.convert_and_copy","title":"<code>convert_and_copy(corpus_path1, corpus_path2)</code>","text":"<p>Reconvert and copy files to prestable/converted.</p> <p>Parameters:</p> Name Type Description Default <code>corpus_path1</code> <code>corpuspath.CorpusPath</code> <p>A CorpusPath representing the lang1 file that should be reconverted.</p> required <code>corpus_path2</code> <code>corpuspath.CorpusPath</code> <p>A CorpusPath representing the lang2 file that should be reconverted.</p> required <code>prestable</code> <code>boolean</code> <p>True the file to be realigned is part of prestable</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/realign.py</code> <pre><code>def convert_and_copy(corpus_path1, corpus_path2):\n\"\"\"Reconvert and copy files to prestable/converted.\n\n    Args:\n        corpus_path1 (corpuspath.CorpusPath): A CorpusPath representing the\n            lang1 file that should be reconverted.\n        corpus_path2 (corpuspath.CorpusPath): A CorpusPath representing the\n            lang2 file that should be reconverted.\n        prestable (boolean): True the file to be realigned is part of prestable\n    \"\"\"\n    for corpus_path in [corpus_path1, corpus_path2]:\n        if os.path.exists(corpus_path.converted):\n            os.remove(corpus_path.converted)\n        if os.path.exists(corpus_path.prestable_converted):\n            os.remove(corpus_path.prestable_converted)\n\n    convertermanager.sanity_check()\n    converter_manager = convertermanager.ConverterManager()\n    converter_manager.collect_files([corpus_path1.orig, corpus_path2.orig])\n    converter_manager.convert_serially()\n</code></pre>"},{"location":"reference/realign/#corpustools.realign.main","title":"<code>main()</code>","text":"<p>Sentence align a given file anew.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/realign.py</code> <pre><code>def main():\n\"\"\"Sentence align a given file anew.\"\"\"\n    convertermanager.LOGGER.setLevel(logging.DEBUG)\n    args = parse_options()\n    orig_path = os.path.normpath(os.path.abspath(args.tmxhtml))\n\n    corpus_path1, corpus_path2 = calculate_paths(orig_path)\n\n    print_filenames(corpus_path1, corpus_path2)\n\n    if args.files:\n        raise SystemExit(\"Only printing file names\")\n\n    try:\n        convert_and_copy(corpus_path1, corpus_path2)\n    except Exception as error:\n        raise SystemExit(error)\n\n    if args.convert:\n        raise SystemExit(\"Only converting\")\n\n    parallelize.parallelise_file(\n        corpus_path1.converted,\n        corpus_path2.metadata.get_variable(\"mainlang\"),\n        dictionary=None,\n        quiet=False,\n        aligner=\"tca2\",\n        stdout=False,\n        force=True,\n    )\n</code></pre>"},{"location":"reference/realign/#corpustools.realign.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/realign.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Sentence align a given file anew.\\n\"\n        \"Files are converted before being parallelised.\\n\"\n        \"This is mainly thought of as a debugging program \"\n        \"when trying to solve issues in parallelised files.\",\n    )\n    parser.add_argument(\n        \"--files\",\n        action=\"store_true\",\n        help=\"Only show the interesting filenames \"\n        \"that are needed for improving sentence \"\n        \"alignment.\",\n    )\n    parser.add_argument(\n        \"--convert\",\n        action=\"store_true\",\n        help=\"Only convert the original files \"\n        \"that are the source of the .tmx.html file. \"\n        \"This is useful when improving the content of \"\n        \"the converted files.\",\n    )\n    parser.add_argument(\"tmxhtml\", help=\"The tmx.html file to realign.\")\n\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"reference/realign/#corpustools.realign.print_filename","title":"<code>print_filename(corpus_path)</code>","text":"<p>Print interesting filenames for doing sentence alignment.</p> <p>Parameters:</p> Name Type Description Default <code>corpus_path</code> <code>corpuspath.CorpusPath</code> <p>filenames</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/realign.py</code> <pre><code>def print_filename(corpus_path):\n\"\"\"Print interesting filenames for doing sentence alignment.\n\n    Args:\n        corpus_path (corpuspath.CorpusPath): filenames\n    \"\"\"\n    print(\n        \"\\toriginal: {}\\n\\tmetatada: {}\\n\\tconverted: {}\".format(\n            corpus_path.orig, corpus_path.xsl, corpus_path.converted\n        )\n    )\n</code></pre>"},{"location":"reference/realign/#corpustools.realign.print_filenames","title":"<code>print_filenames(corpus_path1, corpus_path2)</code>","text":"<p>Print interesting filenames for doing sentence alignment.</p> <p>Parameters:</p> Name Type Description Default <code>corpus_path1</code> <code>corpuspath.CorpusPath</code> <p>filenames for the lang1 file.</p> required <code>corpus_path2</code> <code>corpuspath.CorpusPath</code> <p>filenames for the lang2 file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/realign.py</code> <pre><code>def print_filenames(corpus_path1, corpus_path2):\n\"\"\"Print interesting filenames for doing sentence alignment.\n\n    Args:\n        corpus_path1 (corpuspath.CorpusPath): filenames for the lang1 file.\n        corpus_path2 (corpuspath.CorpusPath): filenames for the lang2 file.\n    \"\"\"\n    print(\"\\nLanguage 1 filenames:\")\n    print_filename(corpus_path1)\n    print(\"\\nLanguage 2 filenames:\")\n    print_filename(corpus_path2)\n</code></pre>"},{"location":"reference/saami_crawler/","title":"saami_crawler","text":"<p>This file contains routines to crawl sites containing saami text.</p>"},{"location":"reference/saami_crawler/#corpustools.saami_crawler.main","title":"<code>main()</code>","text":"<p>Crawl sites.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/saami_crawler.py</code> <pre><code>def main():\n\"\"\"Crawl sites.\"\"\"\n    args = parse_options()\n\n    crawlers = {\n        \"www.samediggi.fi\": samediggi_fi_crawler.SamediggiFiCrawler(),\n        \"samediggi.no\": samediggi_no_crawler.SamediggiNoCrawler(),\n        \"nrk.no\": nrk_no_crawler.NrkSmeCrawler(),\n        \"samas.no\": samas_crawler.SamasCrawler(),\n    }\n\n    for site in args.sites:\n        crawler = crawlers[site]\n        crawler.crawl_site()\n</code></pre>"},{"location":"reference/saami_crawler/#corpustools.saami_crawler.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/saami_crawler.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Crawl saami sites (for now, only www.samediggi.fi).\",\n    )\n\n    parser.add_argument(\"sites\", nargs=\"+\", help=\"The sites to crawl\")\n\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"reference/samas_crawler/","title":"samas_crawler","text":"<p>This file contains routines to crawl samas.no.</p>"},{"location":"reference/samas_crawler/#corpustools.samas_crawler.SamasCrawler","title":"<code>SamasCrawler</code>","text":"<p>Collect pages from samas.no.</p> <p>We only want to fetch saami pages, and their parallels.</p> <ul> tells which language is active. If se is active, save the page and its parallels. If se is not active, check to see if it has a parallel. Save the page and its parallels. If the link of one of the list elements contain /node, skip it.            Source code in <code>/home/anders/projects/CorpusTools/corpustools/samas_crawler.py</code> <pre><code>class SamasCrawler:\n\"\"\"Collect pages from samas.no.\n\n    We only want to fetch saami pages, and their parallels.\n\n    &lt;ul class=\"language-switcher-locale-url\"&gt; tells which language is active.\n    If se is active, save the page and its parallels.\n    If se is not active, check to see if it has a parallel. Save the page and its parallels.\n    If the link of one of the list elements contain /node, skip it.\n\n    Attributes:\n    \"\"\"\n\n    goaldir = str(os.getenv(\"GTFREE\"))\n    external_links = set()\n    samas_languages = {\"se\": \"sme\", \"nb\": \"nob\", \"en-UK\": \"eng\"}\n\n    def __init__(self):\n        self.fetched_links = {\n            \"http://samas.no/en\",\n            \"http://samas.no/nb\",\n            \"http://samas.no/se\",\n        }\n        self.corpus_adders = {\n            lang: adder.AddToCorpus(\n                self.goaldir, self.samas_languages[lang], \"admin/allaskuvla/samas.no\"\n            )\n            for lang in self.samas_languages\n        }\n        self.downloader = adder.UrlDownloader(os.path.join(self.goaldir, \"tmp\"))\n\n    @staticmethod\n    def get_samas_href(href):\n        return f\"http://samas.no{href}\"\n\n    def harvest_links(self, content):\n\"\"\"Find interesting pages inside a topic.\n\n        Args:\n            content (etree.Element): content of a samas page, without the\n                language_switcher element.\n\n        Yields:\n            str: a url to a samas.no page\n        \"\"\"\n        lang_switcher = content.find('.//ul[@class=\"language-switcher-locale-url\"]')\n        lang_switcher.getparent().remove(lang_switcher)\n\n        for address in content.xpath(\"//a\"):\n            if self.is_internal(address.get(\"href\")):\n                yield self.get_samas_href(address.get(\"href\").strip())\n\n    def is_internal(self, href):\n        return (\n            href\n            and \"/node\" not in href\n            and \"/Node\" not in href\n            and href.startswith(\"/\")\n            and \"field_\" not in href\n            and \"page=\" not in href\n            and \"/user\" not in href\n        )\n\n    def get_uff(self, tmpname):\n        content = html.parse(tmpname).getroot()\n        lang_switcher = content.find('.//ul[@class=\"language-switcher-locale-url\"]')\n\n        return {\n            address.get(\"xml:lang\"): address.get(\"href\")\n            for address in lang_switcher.xpath(\".//a\")\n            if self.is_internal(address.get(\"href\"))\n        }\n\n    def add_samas_page(self, link):\n\"\"\"Get a saami samas.no page and its parallels.\n\n        Args:\n            link (str): a url to samas.no page, that has been vetted by\n                the is_internal function.\n        \"\"\"\n        paths = set()\n        if link not in self.fetched_links:\n            try:\n                (request, tmpname) = self.downloader.download(link)\n                uff = self.get_uff(tmpname)\n\n                if \"se\" in uff:\n                    util.note(\"\")\n                    util.print_frame(link, uff)\n                    path = paths.add(self.uff_fetcher(uff, \"se\", link, tmpname, \"\"))\n\n                    for lang in [\"nb\", \"en-UK\"]:\n                        if lang in uff:\n                            paths.add(self.uff_fetcher(uff, lang, link, tmpname, path))\n\n            except (adder.AdderError, UserWarning) as error:\n                util.note(error)\n\n        for puth in paths:\n            for lunk in self.harvest_links(html.parse(puth)):\n                self.add_samas_page(lunk)\n\n    def uff_fetcher(self, uff, lang, link, tmpname, path):\n        lunk = self.get_samas_href(uff[lang])\n        self.fetched_links.add(lunk)\n        if lunk == link:\n            return self.corpus_adders[lang].copy_file_to_corpus(\n                tmpname, lunk, parallelpath=path\n            )\n        else:\n            return self.corpus_adders[lang].copy_url_to_corpus(lunk, parallelpath=path)\n\n    def crawl_site(self):\n        for lang in self.samas_languages:\n            (request, tmpname) = self.downloader.download(f\"http://samas.no/{lang[:2]}\")\n            for link in self.harvest_links(html.parse(tmpname).getroot()):\n                self.add_samas_page(link)\n\n        for lang in self.corpus_adders:\n            self.corpus_adders[lang].add_files_to_working_copy()\n</code></pre>"},{"location":"reference/samas_crawler/#corpustools.samas_crawler.SamasCrawler.add_samas_page","title":"<code>add_samas_page(link)</code>","text":"<p>Get a saami samas.no page and its parallels.</p> <p>Parameters:</p> Name Type Description Default <code>link</code> <code>str</code> <p>a url to samas.no page, that has been vetted by the is_internal function.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/samas_crawler.py</code> <pre><code>def add_samas_page(self, link):\n\"\"\"Get a saami samas.no page and its parallels.\n\n    Args:\n        link (str): a url to samas.no page, that has been vetted by\n            the is_internal function.\n    \"\"\"\n    paths = set()\n    if link not in self.fetched_links:\n        try:\n            (request, tmpname) = self.downloader.download(link)\n            uff = self.get_uff(tmpname)\n\n            if \"se\" in uff:\n                util.note(\"\")\n                util.print_frame(link, uff)\n                path = paths.add(self.uff_fetcher(uff, \"se\", link, tmpname, \"\"))\n\n                for lang in [\"nb\", \"en-UK\"]:\n                    if lang in uff:\n                        paths.add(self.uff_fetcher(uff, lang, link, tmpname, path))\n\n        except (adder.AdderError, UserWarning) as error:\n            util.note(error)\n\n    for puth in paths:\n        for lunk in self.harvest_links(html.parse(puth)):\n            self.add_samas_page(lunk)\n</code></pre>"},{"location":"reference/samas_crawler/#corpustools.samas_crawler.SamasCrawler.harvest_links","title":"<code>harvest_links(content)</code>","text":"<p>Find interesting pages inside a topic.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>etree.Element</code> <p>content of a samas page, without the language_switcher element.</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>a url to a samas.no page</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samas_crawler.py</code> <pre><code>def harvest_links(self, content):\n\"\"\"Find interesting pages inside a topic.\n\n    Args:\n        content (etree.Element): content of a samas page, without the\n            language_switcher element.\n\n    Yields:\n        str: a url to a samas.no page\n    \"\"\"\n    lang_switcher = content.find('.//ul[@class=\"language-switcher-locale-url\"]')\n    lang_switcher.getparent().remove(lang_switcher)\n\n    for address in content.xpath(\"//a\"):\n        if self.is_internal(address.get(\"href\")):\n            yield self.get_samas_href(address.get(\"href\").strip())\n</code></pre>"},{"location":"reference/samediggi_fi_crawler/","title":"samediggi_fi_crawler","text":"<p>This file contains routines to crawl sites containing saami text.</p>"},{"location":"reference/samediggi_fi_crawler/#corpustools.samediggi_fi_crawler.SamediggiFiCrawler","title":"<code>SamediggiFiCrawler</code>","text":"<p>         Bases: <code>crawler.Crawler</code></p> <p>Notes about samediggi.fi.</p> <p>Start page is: http://www.samediggi.fi/index.php?option=com_frontpage&amp;Itemid=39</p> <p>Empty pages contain either * \"K\u00e4\u00e4nn\u00f6st\u00e4 ei ole saatavilla\" * \"There are no translations available\"</p> <p>Follow links starting with: * http://www.samediggi.fi/index (www.samediggi.fi == samediggi.fi) * index: prepend these adresses with http://www.samediggi.fi</p> <p>Remove any &amp;lang=* parts from links, then re-add languages * &amp;lang=finnish * &amp;lang=davvi * &amp;lang=anaras * &amp;lang=nuortta * &amp;lang=english</p> <p>Main content in div id=\"keski_mainbody\" Content parts in table class=\"contentpaneopen\"</p> <p>www.samediggi.fi/nuorat is a separate \"domain\" Links start with: * http://www.samediggi.fi/nuorat * nuorat/index</p> <p>languages * &amp;lang=fi * &amp;lang=sme * &amp;lang=smn * &amp;lang=sms</p> <p>Same procedure with links here</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_fi_crawler.py</code> <pre><code>class SamediggiFiCrawler(crawler.Crawler):\n\"\"\"Notes about samediggi.fi.\n\n    Start page is:\n    http://www.samediggi.fi/index.php?option=com_frontpage&amp;Itemid=39\n\n\n    Empty pages contain either\n    * \"K\u00e4\u00e4nn\u00f6st\u00e4 ei ole saatavilla\"\n    * \"There are no translations available\"\n\n    Follow links starting with:\n    * http://www.samediggi.fi/index (www.samediggi.fi == samediggi.fi)\n    * index: prepend these adresses with http://www.samediggi.fi\n\n    Remove any &amp;lang=* parts from links,\n    then re-add languages\n    * &amp;lang=finnish\n    * &amp;lang=davvi\n    * &amp;lang=anaras\n    * &amp;lang=nuortta\n    * &amp;lang=english\n\n    Main content in div id=\"keski_mainbody\"\n    Content parts in table class=\"contentpaneopen\"\n\n    www.samediggi.fi/nuorat is a separate \"domain\"\n    Links start with:\n    * http://www.samediggi.fi/nuorat\n    * nuorat/index\n\n    languages\n    * &amp;lang=fi\n    * &amp;lang=sme\n    * &amp;lang=smn\n    * &amp;lang=sms\n\n    Same procedure with links here\n    \"\"\"\n\n    def __init__(self):\n\"\"\"Initialise the SamediggiFiCrawler class.\"\"\"\n        super().__init__()\n\n        self.unvisited_links.add(\"http://www.samediggi.fi/\")\n        self.old_urls = {}\n        self.langs = {\n            \"finnish\": \"fin\",\n            \"davvi\": \"sme\",\n            \"anaras\": \"smn\",\n            \"nuortta\": \"sms\",\n            \"english\": \"eng\",\n        }\n\n        for (natural, iso) in self.langs.items():\n            self.corpus_adders[natural] = adder.AddToCorpus(\n                self.goaldir, iso, \"admin/sd/www.samediggi.fi\"\n            )\n\n        self.get_old_urls()\n\n    def get_old_urls(self):\n\"\"\"Collect the urls of already downloaded pages.\"\"\"\n        for (_, corpus_adder) in self.corpus_adders.items():\n            for root, _, files in os.walk(corpus_adder.goaldir):\n                for file_ in files:\n                    if file_.endswith(\".xsl\"):\n                        path = os.path.join(root, file_)\n                        mdh = xslsetter.MetadataHandler(path)\n                        self.old_urls[mdh.get_variable(\"filename\")] = path.replace(\n                            \".xsl\", \"\"\n                        )\n\n    def crawl_site(self):\n\"\"\"Crawl samediggi.fi.\"\"\"\n        while self.unvisited_links:\n            link = self.unvisited_links.pop()\n\n            if link not in self.visited_links:\n                util.print_frame(debug=link.encode(\"utf8\"))\n                util.print_frame(\n                    debug=f\"Before: unvisited_links {len(self.unvisited_links)}\"\n                )\n\n                parallel_pages = []\n                found_saami = False\n                for lang in self.langs.keys():\n                    result = requests.get(link, params={\"lang\": lang})\n\n                    if result.history:\n                        print(\"history\", result.history)\n\n                    if \"samediggi.fi\" not in result.url:\n                        print(\"url\", result.url)\n\n                    if (\n                        \"www.samediggi.fi\" in result.url\n                        and result.status_code == requests.codes.ok\n                        and not self.invalid_content(str(result.content, \"utf-8\"))\n                    ):\n                        if lang in [\"davvi\", \"anaras\", \"nuortta\"]:\n                            found_saami = True\n                        self.harvest_links(result.content)\n                        print_url = self.get_print_url(result.content, lang)\n                        if print_url is not None:\n                            parallel_pages.append((print_url, lang))\n                    else:\n                        if \"samediggi.fi\" not in result.url:\n                            util.print_frame(\n                                debug=\"Not fetching {} which was {}\\n\".format(\n                                    result.url.encode(\"utf8\"), link.encode(\"utf8\")\n                                )\n                            )\n\n                if found_saami and parallel_pages:\n                    self.save_pages(parallel_pages)\n\n                util.print_frame(\n                    debug=f\"After: unvisited_links {len(self.unvisited_links)}\"\n                )\n\n            self.visited_links.add(link)\n            util.print_frame(debug=f\"visited_links {len(self.visited_links)}\\n\")\n\n    @staticmethod\n    def get_print_url(content, lang):\n\"\"\"Compute the print url of the page.\"\"\"\n        tree = html.document_fromstring(content)\n        print_img = tree.find(\n            './/img[@src=\"http://www.samediggi.fi/' 'images/M_images/printButton.png\"]'\n        )\n\n        if print_img is not None:\n            parent = print_img.getparent()\n            href = urlparse(parent.get(\"href\"))\n\n            query = href.query\n            newquery = [\n                part\n                for part in query.split(\"&amp;\")\n                if (\n                    part.startswith(\"option\")\n                    or part.startswith(\"id\")\n                    or part.startswith(\"task\")\n                )\n            ]\n            newquery.append(\"lang=\" + lang)\n\n            newhref = urlunparse(\n                (\n                    href.scheme,\n                    href.netloc,\n                    href.path,\n                    href.params,\n                    \"&amp;\".join(newquery),\n                    href.fragment,\n                )\n            )\n\n            return newhref\n\n    @staticmethod\n    def invalid_content(content):\n\"\"\"Return true if the page does not contain the strings.\n\n        * \"K\u00e4\u00e4nn\u00f6st\u00e4 ei ole saatavilla\"\n        * \"There are no translations available\"\n        \"\"\"\n        return (\n            \"ei ole saatavilla\" in content\n            or \"There are no translations available\" in content\n            or '&lt;div class=\"login-form\"&gt;' in content\n            or \"Sinulla ei ole tarvittavia\" in content\n            or \"You need to login\" in content\n        )\n\n    def harvest_links(self, content):\n\"\"\"Harvest all links, bar some restrictions.\n\n        Insert links into a set\n\n        Discard links containing a href=\n        * \"#\"\n        * \"*do_pdf*\"\n        * \"pop=1\"\n        * com_events\n        * com_search\n        * www.samediggi.fi/haettavana\n        * http://klemetti.blogspot.com/\n\n        Don't follow (don't save content), but save links containg\n        doc_download\n        \"\"\"\n        tree = html.document_fromstring(content)\n\n        for address in tree.findall(\".//a\"):\n            href = address.get(\"href\")\n            if href is not None:\n                href = href.replace(\"?lang=finnish\", \"\")\n                href = href.replace(\"?lang=davvi\", \"\")\n                href = href.replace(\"?lang=anaras\", \"\")\n                href = href.replace(\"?lang=nuortta\", \"\")\n                href = href.replace(\"?lang=english\", \"\")\n                href = href.replace(\"&amp;lang=finnish\", \"\")\n                href = href.replace(\"&amp;lang=davvi\", \"\")\n                href = href.replace(\"&amp;lang=anaras\", \"\")\n                href = href.replace(\"&amp;lang=nuortta\", \"\")\n                href = href.replace(\"&amp;lang=english\", \"\")\n\n                if not href.startswith(\"http\"):\n                    href = os.path.join(\"http://www.samediggi.fi\", href)\n\n                if (\n                    href not in self.visited_links\n                    and not re.search(\n                        \"klemetti.blogspot|/nuorat|/#|com_events|\"\n                        \"com_search|haettavana|do_pdf|pop=1|com_docman|\"\n                        \"/images|com_weblink|task=vcard|view_contact_id|\"\n                        \"com_contact|mad4joomla|mailto|javascript|\"\n                        \"administrator/\",\n                        href,\n                    )\n                    and href.startswith(\"http://www.samediggi.fi\")\n                ):\n                    self.unvisited_links.add(href)\n</code></pre>"},{"location":"reference/samediggi_fi_crawler/#corpustools.samediggi_fi_crawler.SamediggiFiCrawler.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the SamediggiFiCrawler class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_fi_crawler.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the SamediggiFiCrawler class.\"\"\"\n    super().__init__()\n\n    self.unvisited_links.add(\"http://www.samediggi.fi/\")\n    self.old_urls = {}\n    self.langs = {\n        \"finnish\": \"fin\",\n        \"davvi\": \"sme\",\n        \"anaras\": \"smn\",\n        \"nuortta\": \"sms\",\n        \"english\": \"eng\",\n    }\n\n    for (natural, iso) in self.langs.items():\n        self.corpus_adders[natural] = adder.AddToCorpus(\n            self.goaldir, iso, \"admin/sd/www.samediggi.fi\"\n        )\n\n    self.get_old_urls()\n</code></pre>"},{"location":"reference/samediggi_fi_crawler/#corpustools.samediggi_fi_crawler.SamediggiFiCrawler.crawl_site","title":"<code>crawl_site()</code>","text":"<p>Crawl samediggi.fi.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_fi_crawler.py</code> <pre><code>def crawl_site(self):\n\"\"\"Crawl samediggi.fi.\"\"\"\n    while self.unvisited_links:\n        link = self.unvisited_links.pop()\n\n        if link not in self.visited_links:\n            util.print_frame(debug=link.encode(\"utf8\"))\n            util.print_frame(\n                debug=f\"Before: unvisited_links {len(self.unvisited_links)}\"\n            )\n\n            parallel_pages = []\n            found_saami = False\n            for lang in self.langs.keys():\n                result = requests.get(link, params={\"lang\": lang})\n\n                if result.history:\n                    print(\"history\", result.history)\n\n                if \"samediggi.fi\" not in result.url:\n                    print(\"url\", result.url)\n\n                if (\n                    \"www.samediggi.fi\" in result.url\n                    and result.status_code == requests.codes.ok\n                    and not self.invalid_content(str(result.content, \"utf-8\"))\n                ):\n                    if lang in [\"davvi\", \"anaras\", \"nuortta\"]:\n                        found_saami = True\n                    self.harvest_links(result.content)\n                    print_url = self.get_print_url(result.content, lang)\n                    if print_url is not None:\n                        parallel_pages.append((print_url, lang))\n                else:\n                    if \"samediggi.fi\" not in result.url:\n                        util.print_frame(\n                            debug=\"Not fetching {} which was {}\\n\".format(\n                                result.url.encode(\"utf8\"), link.encode(\"utf8\")\n                            )\n                        )\n\n            if found_saami and parallel_pages:\n                self.save_pages(parallel_pages)\n\n            util.print_frame(\n                debug=f\"After: unvisited_links {len(self.unvisited_links)}\"\n            )\n\n        self.visited_links.add(link)\n        util.print_frame(debug=f\"visited_links {len(self.visited_links)}\\n\")\n</code></pre>"},{"location":"reference/samediggi_fi_crawler/#corpustools.samediggi_fi_crawler.SamediggiFiCrawler.get_old_urls","title":"<code>get_old_urls()</code>","text":"<p>Collect the urls of already downloaded pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_fi_crawler.py</code> <pre><code>def get_old_urls(self):\n\"\"\"Collect the urls of already downloaded pages.\"\"\"\n    for (_, corpus_adder) in self.corpus_adders.items():\n        for root, _, files in os.walk(corpus_adder.goaldir):\n            for file_ in files:\n                if file_.endswith(\".xsl\"):\n                    path = os.path.join(root, file_)\n                    mdh = xslsetter.MetadataHandler(path)\n                    self.old_urls[mdh.get_variable(\"filename\")] = path.replace(\n                        \".xsl\", \"\"\n                    )\n</code></pre>"},{"location":"reference/samediggi_fi_crawler/#corpustools.samediggi_fi_crawler.SamediggiFiCrawler.get_print_url","title":"<code>get_print_url(content, lang)</code>  <code>staticmethod</code>","text":"<p>Compute the print url of the page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_fi_crawler.py</code> <pre><code>@staticmethod\ndef get_print_url(content, lang):\n\"\"\"Compute the print url of the page.\"\"\"\n    tree = html.document_fromstring(content)\n    print_img = tree.find(\n        './/img[@src=\"http://www.samediggi.fi/' 'images/M_images/printButton.png\"]'\n    )\n\n    if print_img is not None:\n        parent = print_img.getparent()\n        href = urlparse(parent.get(\"href\"))\n\n        query = href.query\n        newquery = [\n            part\n            for part in query.split(\"&amp;\")\n            if (\n                part.startswith(\"option\")\n                or part.startswith(\"id\")\n                or part.startswith(\"task\")\n            )\n        ]\n        newquery.append(\"lang=\" + lang)\n\n        newhref = urlunparse(\n            (\n                href.scheme,\n                href.netloc,\n                href.path,\n                href.params,\n                \"&amp;\".join(newquery),\n                href.fragment,\n            )\n        )\n\n        return newhref\n</code></pre>"},{"location":"reference/samediggi_fi_crawler/#corpustools.samediggi_fi_crawler.SamediggiFiCrawler.harvest_links","title":"<code>harvest_links(content)</code>","text":"<p>Harvest all links, bar some restrictions.</p> <p>Insert links into a set</p> <p>Discard links containing a href= * \"#\" * \"do_pdf\" * \"pop=1\" * com_events * com_search * www.samediggi.fi/haettavana * http://klemetti.blogspot.com/</p> <p>Don't follow (don't save content), but save links containg doc_download</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_fi_crawler.py</code> <pre><code>def harvest_links(self, content):\n\"\"\"Harvest all links, bar some restrictions.\n\n    Insert links into a set\n\n    Discard links containing a href=\n    * \"#\"\n    * \"*do_pdf*\"\n    * \"pop=1\"\n    * com_events\n    * com_search\n    * www.samediggi.fi/haettavana\n    * http://klemetti.blogspot.com/\n\n    Don't follow (don't save content), but save links containg\n    doc_download\n    \"\"\"\n    tree = html.document_fromstring(content)\n\n    for address in tree.findall(\".//a\"):\n        href = address.get(\"href\")\n        if href is not None:\n            href = href.replace(\"?lang=finnish\", \"\")\n            href = href.replace(\"?lang=davvi\", \"\")\n            href = href.replace(\"?lang=anaras\", \"\")\n            href = href.replace(\"?lang=nuortta\", \"\")\n            href = href.replace(\"?lang=english\", \"\")\n            href = href.replace(\"&amp;lang=finnish\", \"\")\n            href = href.replace(\"&amp;lang=davvi\", \"\")\n            href = href.replace(\"&amp;lang=anaras\", \"\")\n            href = href.replace(\"&amp;lang=nuortta\", \"\")\n            href = href.replace(\"&amp;lang=english\", \"\")\n\n            if not href.startswith(\"http\"):\n                href = os.path.join(\"http://www.samediggi.fi\", href)\n\n            if (\n                href not in self.visited_links\n                and not re.search(\n                    \"klemetti.blogspot|/nuorat|/#|com_events|\"\n                    \"com_search|haettavana|do_pdf|pop=1|com_docman|\"\n                    \"/images|com_weblink|task=vcard|view_contact_id|\"\n                    \"com_contact|mad4joomla|mailto|javascript|\"\n                    \"administrator/\",\n                    href,\n                )\n                and href.startswith(\"http://www.samediggi.fi\")\n            ):\n                self.unvisited_links.add(href)\n</code></pre>"},{"location":"reference/samediggi_fi_crawler/#corpustools.samediggi_fi_crawler.SamediggiFiCrawler.invalid_content","title":"<code>invalid_content(content)</code>  <code>staticmethod</code>","text":"<p>Return true if the page does not contain the strings.</p> <ul> <li>\"K\u00e4\u00e4nn\u00f6st\u00e4 ei ole saatavilla\"</li> <li>\"There are no translations available\"</li> </ul> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_fi_crawler.py</code> <pre><code>@staticmethod\ndef invalid_content(content):\n\"\"\"Return true if the page does not contain the strings.\n\n    * \"K\u00e4\u00e4nn\u00f6st\u00e4 ei ole saatavilla\"\n    * \"There are no translations available\"\n    \"\"\"\n    return (\n        \"ei ole saatavilla\" in content\n        or \"There are no translations available\" in content\n        or '&lt;div class=\"login-form\"&gt;' in content\n        or \"Sinulla ei ole tarvittavia\" in content\n        or \"You need to login\" in content\n    )\n</code></pre>"},{"location":"reference/samediggi_no_crawler/","title":"samediggi_no_crawler","text":"<p>This file contains routines to crawl sites containing saami text.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler","title":"<code>SamediggiNoCrawler</code>","text":"<p>         Bases: <code>crawler.Crawler</code></p> <p>Crawl samediggi.no and save html documents to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>class SamediggiNoCrawler(crawler.Crawler):\n\"\"\"Crawl samediggi.no and save html documents to the corpus.\"\"\"\n\n    langs = [\"nob\", \"sma\", \"sme\", \"smj\"]\n    languageguesser = text_cat.Classifier()\n\n    def __init__(self):\n\"\"\"Initialise the SamediggiNoCrawler class.\"\"\"\n        super().__init__()\n        self.unvisited_links.add(\"https://www.samediggi.no/\")\n        self.unvisited_links.add(\"https://www.sametinget.no/\")\n        self.unvisited_links.add(\"https://www.saemiedigkie.no/\")\n        self.unvisited_links.add(\"https://www.samedigge.no/\")\n\n        self.vcs = versioncontrol.vcs(self.goaldir)\n        self.dupe_table = {digest: name for digest, name in self.make_dupe_tuple()}\n\n    def make_dupe_tuple(self):\n\"\"\"Make a hash/filename tuple to be used in the dupe table.\"\"\"\n        for lang in self.langs:\n            root = os.path.join(\n                os.getenv(\"GTFREE\"), \"orig\", lang, \"admin/sd/samediggi.no\"\n            )\n            for path, _, filelist in os.walk(root):\n                for name in fnmatch.filter(filelist, \"*.html\"):\n                    fullpath = os.path.join(path, name)\n                    with open(fullpath, \"rb\") as html_stream:\n                        yield make_digest(html_stream.read()), fullpath\n\n    def crawl_page(self, link):\n\"\"\"Collect links from a page.\"\"\"\n        self.visited_links.add(link)\n        result = requests.get(link)\n\n        if result.ok and \"html\" in result.headers[\"content-type\"].lower():\n            orig_page = SamediggiNoPage(result, self.dupe_table)\n            orig_page.sanity_test()\n            self.visited_links.add(orig_page.url)\n            self.unvisited_links = self.unvisited_links.union(orig_page.links)\n\n            return orig_page\n\n        return None\n\n    def crawl_site(self):\n\"\"\"Crawl samediggi.no.\"\"\"\n        while self.unvisited_links:\n            link = self.unvisited_links.pop()\n\n            if link not in self.visited_links:\n                self.crawl_pageset(link)\n\n    def add_page(self, page, parallel_pages):\n\"\"\"Add a page to the list of parallel pages.\"\"\"\n        if page is not None and page.saveable:\n            body_lang = self.languageguesser.classify(page.body_text, langs=self.langs)\n            if page.lang == body_lang:\n                if body_lang == \"nob\":\n                    parallel_pages.append(page)\n                else:\n                    parallel_pages.insert(0, page)\n\n    @staticmethod\n    def set_parallel_info(parallel_pages):\n\"\"\"Set the parallels for this set of parallel pages.\"\"\"\n        for parallel_page1 in parallel_pages:\n            for parallel_page2 in parallel_pages:\n                if parallel_page1 != parallel_page2:\n                    parallel_page1.set_parallel_file(\n                        parallel_page2.lang, parallel_page2.basename\n                    )\n\n    def crawl_pageset(self, link):\n\"\"\"Crawl a pageset that link gives us.\"\"\"\n        pages = []\n\n        print(link)\n        orig_page = self.crawl_page(link)\n        if orig_page is not None:\n            self.add_page(orig_page, pages)\n            for parallel_link in orig_page.parallel_links:\n                self.add_page(self.crawl_page(parallel_link), pages)\n\n            if pages and pages[0].lang != \"nob\":\n                self.set_parallel_info(pages)\n                for parallel_page in pages:\n                    print(f\"\\t{parallel_page.corpuspath.orig}\")\n                    self.dupe_table[\n                        make_digest(parallel_page.content_string)\n                    ] = parallel_page.corpuspath.orig\n                    parallel_page.save()\n                    self.vcs.add(parallel_page.corpuspath.orig)\n                    self.vcs.add(parallel_page.corpuspath.xsl)\n                print()\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the SamediggiNoCrawler class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the SamediggiNoCrawler class.\"\"\"\n    super().__init__()\n    self.unvisited_links.add(\"https://www.samediggi.no/\")\n    self.unvisited_links.add(\"https://www.sametinget.no/\")\n    self.unvisited_links.add(\"https://www.saemiedigkie.no/\")\n    self.unvisited_links.add(\"https://www.samedigge.no/\")\n\n    self.vcs = versioncontrol.vcs(self.goaldir)\n    self.dupe_table = {digest: name for digest, name in self.make_dupe_tuple()}\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler.add_page","title":"<code>add_page(page, parallel_pages)</code>","text":"<p>Add a page to the list of parallel pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def add_page(self, page, parallel_pages):\n\"\"\"Add a page to the list of parallel pages.\"\"\"\n    if page is not None and page.saveable:\n        body_lang = self.languageguesser.classify(page.body_text, langs=self.langs)\n        if page.lang == body_lang:\n            if body_lang == \"nob\":\n                parallel_pages.append(page)\n            else:\n                parallel_pages.insert(0, page)\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler.crawl_page","title":"<code>crawl_page(link)</code>","text":"<p>Collect links from a page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def crawl_page(self, link):\n\"\"\"Collect links from a page.\"\"\"\n    self.visited_links.add(link)\n    result = requests.get(link)\n\n    if result.ok and \"html\" in result.headers[\"content-type\"].lower():\n        orig_page = SamediggiNoPage(result, self.dupe_table)\n        orig_page.sanity_test()\n        self.visited_links.add(orig_page.url)\n        self.unvisited_links = self.unvisited_links.union(orig_page.links)\n\n        return orig_page\n\n    return None\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler.crawl_pageset","title":"<code>crawl_pageset(link)</code>","text":"<p>Crawl a pageset that link gives us.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def crawl_pageset(self, link):\n\"\"\"Crawl a pageset that link gives us.\"\"\"\n    pages = []\n\n    print(link)\n    orig_page = self.crawl_page(link)\n    if orig_page is not None:\n        self.add_page(orig_page, pages)\n        for parallel_link in orig_page.parallel_links:\n            self.add_page(self.crawl_page(parallel_link), pages)\n\n        if pages and pages[0].lang != \"nob\":\n            self.set_parallel_info(pages)\n            for parallel_page in pages:\n                print(f\"\\t{parallel_page.corpuspath.orig}\")\n                self.dupe_table[\n                    make_digest(parallel_page.content_string)\n                ] = parallel_page.corpuspath.orig\n                parallel_page.save()\n                self.vcs.add(parallel_page.corpuspath.orig)\n                self.vcs.add(parallel_page.corpuspath.xsl)\n            print()\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler.crawl_site","title":"<code>crawl_site()</code>","text":"<p>Crawl samediggi.no.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def crawl_site(self):\n\"\"\"Crawl samediggi.no.\"\"\"\n    while self.unvisited_links:\n        link = self.unvisited_links.pop()\n\n        if link not in self.visited_links:\n            self.crawl_pageset(link)\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler.make_dupe_tuple","title":"<code>make_dupe_tuple()</code>","text":"<p>Make a hash/filename tuple to be used in the dupe table.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def make_dupe_tuple(self):\n\"\"\"Make a hash/filename tuple to be used in the dupe table.\"\"\"\n    for lang in self.langs:\n        root = os.path.join(\n            os.getenv(\"GTFREE\"), \"orig\", lang, \"admin/sd/samediggi.no\"\n        )\n        for path, _, filelist in os.walk(root):\n            for name in fnmatch.filter(filelist, \"*.html\"):\n                fullpath = os.path.join(path, name)\n                with open(fullpath, \"rb\") as html_stream:\n                    yield make_digest(html_stream.read()), fullpath\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoCrawler.set_parallel_info","title":"<code>set_parallel_info(parallel_pages)</code>  <code>staticmethod</code>","text":"<p>Set the parallels for this set of parallel pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>@staticmethod\ndef set_parallel_info(parallel_pages):\n\"\"\"Set the parallels for this set of parallel pages.\"\"\"\n    for parallel_page1 in parallel_pages:\n        for parallel_page2 in parallel_pages:\n            if parallel_page1 != parallel_page2:\n                parallel_page1.set_parallel_file(\n                    parallel_page2.lang, parallel_page2.basename\n                )\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage","title":"<code>SamediggiNoPage</code>","text":"<p>Save a samediggi.no page to the corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>class SamediggiNoPage:\n\"\"\"Save a samediggi.no page to the corpus.\"\"\"\n\n    address_re = re.compile(r\"/\\w\")\n    unwanted_endings = (\n        \".pdf\",\n        \".jpg\",\n        \".docx\",\n        \".xlsx\",\n        \".csv\",\n        \".pptx\",\n        \".eps\",\n        \".doc\",\n        \".png\",\n        \".xls\",\n    )\n    language_mapper = {\n        \"no-bokmaal\": \"nob\",\n        \"sma-NO\": \"sma\",\n        \"sme-NO\": \"sme\",\n        \"smj-NO\": \"smj\",\n    }\n    corpus_dir = os.path.join(os.getenv(\"GTFREE\"), \"orig\")\n\n    def __init__(self, result, dupe_table):\n\"\"\"Initialise the SamediggiNoPage class.\"\"\"\n        self.result = result\n        self.url = result.url\n        self.parsed_url = urlparse(self.url)\n        self.tree = etree.HTML(result.text)\n        fullpath = os.path.join(\n            self.corpus_dir,\n            self.lang,\n            \"admin/sd/samediggi.no\",\n            namechanger.normalise_filename(adder.url_to_filename(self.result)),\n        )\n        possible_dupe = dupe_table.get(make_digest(self.content_string), fullpath)\n        self.corpuspath = corpuspath.CorpusPath(possible_dupe)\n        if fullpath == possible_dupe:\n            self.set_initial_metadata()\n        else:\n            print(f\"\\nDupe! {self.url} is dupe of {possible_dupe}\\n\")\n\n    @property\n    def content(self):\n\"\"\"Extract only the content that is interesting from the web page.\"\"\"\n        content = etree.Element(\"html\")\n        body = etree.SubElement(content, \"body\")\n        for xpath_directive in [\n            './/div[@class=\"newsIntroBox\"]',\n            \".//article\",\n            './/div[@class=\"news\"]',\n            './/section[@class=\"blockInfo\"]',\n        ]:\n            for element in self.tree.xpath(xpath_directive):\n                body.append(\n                    self.filter_content(etree.fromstring(etree.tostring(element)))\n                )\n\n        return content\n\n    @staticmethod\n    def filter_content(element):\n\"\"\"Remove elements without interesting content.\"\"\"\n        for unwanted in [\n            './/div[@class=\"embedFile\"]',\n            './/div[@class=\"date\"]',\n            './/div[starts-with(@class, \"person \")]',\n            './/div[starts-with(@class, \"listArticleLink\")]',\n            './/div[@class=\"accordion document-list\"]',\n            './/article[@class=\"regionPage\"]',\n            './/ul[@class=\"listLinksLine\"]',\n        ]:\n            for unwanted_element in element.xpath(unwanted):\n                unwanted_element.getparent().remove(unwanted_element)\n\n        return element\n\n    @property\n    def content_string(self):\n\"\"\"This will be the content of the saved file.\"\"\"\n        return etree.tostring(self.content, encoding=\"utf8\", pretty_print=True)\n\n    def set_initial_metadata(self):\n\"\"\"Extract metadata from the web page.\"\"\"\n        self.corpuspath.metadata.set_variable(\n            \"title\", self.tree.find(\".//title\").text.strip()\n        )\n        self.corpuspath.metadata.set_variable(\"filename\", self.url)\n        self.corpuspath.metadata.set_variable(\"genre\", \"admin\")\n        self.corpuspath.metadata.set_variable(\"mainlang\", self.lang)\n        self.corpuspath.metadata.set_variable(\"license_type\", \"free\")\n        if self.lang != \"nob\":\n            self.corpuspath.metadata.set_variable(\"translated_from\", \"nob\")\n        time = self.tree.find(\".//time\")\n        if time is not None:\n            self.corpuspath.metadata.set_variable(\n                \"year\", self.tree.find(\".//time\").get(\"datetime\")[:4]\n            )\n\n    @property\n    def basename(self):\n\"\"\"Get the basename of the corpus filename.\"\"\"\n        return os.path.basename(self.corpuspath.orig)\n\n    def sanity_test(self):\n\"\"\"Check if the pages seem to have the expected structure.\"\"\"\n        if not self.parallel_links:\n            raise SystemExit(\n                \"The format of links to parallel documents has changed {}\".format(\n                    self.url\n                )\n            )\n        for parallel_link in self.parallel_links:\n            if not parallel_link.startswith(\"https://www.sa\"):\n                raise SystemExit(\n                    f\"The links to parallel documents has changed {self.url}\"\n                )\n        if self.lang is None:\n            raise SystemExit(\"Language format has changed.\")\n\n    @property\n    def parallel_links(self):\n\"\"\"Get links to the parallels of this document.\"\"\"\n        return [\n            \"https:{}\".format(a.get(\"href\"))\n            for a in self.tree.xpath('.//li[@class=\"itemLanguage\"]/div/ul/li/a[@href]')\n        ]\n\n    @property\n    def saveable(self):\n\"\"\"Check if the content of this file is worth saving.\"\"\"\n        return self.result.ok and len(self.content) and len(self.body_text.split()) &gt; 40\n\n    @property\n    def lang(self):\n\"\"\"Return the language of the file.\"\"\"\n        content_language = self.tree.find('.//meta[@name=\"Content-language\"]')\n\n        return self.language_mapper[content_language.get(\"content\")]\n\n    def is_valid_address(self, href):\n\"\"\"Check if this is an address that should be crawled.\"\"\"\n        match = self.address_re.match(href)\n        return (\n            match\n            and \"sametingets-vedtak-1989-2004\" not in href\n            and not href.endswith(self.unwanted_endings)\n        )\n\n    @property\n    def links(self):\n\"\"\"Get all the links found in a file.\"\"\"\n        return {\n            urlunparse(\n                (\n                    self.parsed_url.scheme,\n                    self.parsed_url.netloc,\n                    address.get(\"href\"),\n                    \"\",\n                    \"\",\n                    \"\",\n                )\n            )\n            for address in self.tree.xpath(\".//a[@href]\")\n            if self.is_valid_address(address.get(\"href\").lower())\n        }\n\n    @property\n    def body_text(self):\n\"\"\"Get all the text inside 'body'.\"\"\"\n        return \" \".join(self.content.xpath(\".//text()\"))\n\n    def set_parallel_file(self, lang, name):\n\"\"\"Update metadata info on parallel files.\"\"\"\n        self.corpuspath.metadata.set_parallel_text(lang, name)\n\n    def save(self):\n\"\"\"Save html and metadata.\"\"\"\n        with open(self.corpuspath.orig, \"wb\") as xml:\n            html = etree.Element(\"html\")\n            html.append(self.content)\n            xml.write(self.content_string)\n        self.corpuspath.metadata.write_file()\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.basename","title":"<code>basename</code>  <code>property</code>","text":"<p>Get the basename of the corpus filename.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.body_text","title":"<code>body_text</code>  <code>property</code>","text":"<p>Get all the text inside 'body'.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.content","title":"<code>content</code>  <code>property</code>","text":"<p>Extract only the content that is interesting from the web page.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.content_string","title":"<code>content_string</code>  <code>property</code>","text":"<p>This will be the content of the saved file.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.lang","title":"<code>lang</code>  <code>property</code>","text":"<p>Return the language of the file.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.links","title":"<code>links</code>  <code>property</code>","text":"<p>Get all the links found in a file.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.parallel_links","title":"<code>parallel_links</code>  <code>property</code>","text":"<p>Get links to the parallels of this document.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.saveable","title":"<code>saveable</code>  <code>property</code>","text":"<p>Check if the content of this file is worth saving.</p>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.__init__","title":"<code>__init__(result, dupe_table)</code>","text":"<p>Initialise the SamediggiNoPage class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def __init__(self, result, dupe_table):\n\"\"\"Initialise the SamediggiNoPage class.\"\"\"\n    self.result = result\n    self.url = result.url\n    self.parsed_url = urlparse(self.url)\n    self.tree = etree.HTML(result.text)\n    fullpath = os.path.join(\n        self.corpus_dir,\n        self.lang,\n        \"admin/sd/samediggi.no\",\n        namechanger.normalise_filename(adder.url_to_filename(self.result)),\n    )\n    possible_dupe = dupe_table.get(make_digest(self.content_string), fullpath)\n    self.corpuspath = corpuspath.CorpusPath(possible_dupe)\n    if fullpath == possible_dupe:\n        self.set_initial_metadata()\n    else:\n        print(f\"\\nDupe! {self.url} is dupe of {possible_dupe}\\n\")\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.filter_content","title":"<code>filter_content(element)</code>  <code>staticmethod</code>","text":"<p>Remove elements without interesting content.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>@staticmethod\ndef filter_content(element):\n\"\"\"Remove elements without interesting content.\"\"\"\n    for unwanted in [\n        './/div[@class=\"embedFile\"]',\n        './/div[@class=\"date\"]',\n        './/div[starts-with(@class, \"person \")]',\n        './/div[starts-with(@class, \"listArticleLink\")]',\n        './/div[@class=\"accordion document-list\"]',\n        './/article[@class=\"regionPage\"]',\n        './/ul[@class=\"listLinksLine\"]',\n    ]:\n        for unwanted_element in element.xpath(unwanted):\n            unwanted_element.getparent().remove(unwanted_element)\n\n    return element\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.is_valid_address","title":"<code>is_valid_address(href)</code>","text":"<p>Check if this is an address that should be crawled.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def is_valid_address(self, href):\n\"\"\"Check if this is an address that should be crawled.\"\"\"\n    match = self.address_re.match(href)\n    return (\n        match\n        and \"sametingets-vedtak-1989-2004\" not in href\n        and not href.endswith(self.unwanted_endings)\n    )\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.sanity_test","title":"<code>sanity_test()</code>","text":"<p>Check if the pages seem to have the expected structure.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def sanity_test(self):\n\"\"\"Check if the pages seem to have the expected structure.\"\"\"\n    if not self.parallel_links:\n        raise SystemExit(\n            \"The format of links to parallel documents has changed {}\".format(\n                self.url\n            )\n        )\n    for parallel_link in self.parallel_links:\n        if not parallel_link.startswith(\"https://www.sa\"):\n            raise SystemExit(\n                f\"The links to parallel documents has changed {self.url}\"\n            )\n    if self.lang is None:\n        raise SystemExit(\"Language format has changed.\")\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.save","title":"<code>save()</code>","text":"<p>Save html and metadata.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def save(self):\n\"\"\"Save html and metadata.\"\"\"\n    with open(self.corpuspath.orig, \"wb\") as xml:\n        html = etree.Element(\"html\")\n        html.append(self.content)\n        xml.write(self.content_string)\n    self.corpuspath.metadata.write_file()\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.set_initial_metadata","title":"<code>set_initial_metadata()</code>","text":"<p>Extract metadata from the web page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def set_initial_metadata(self):\n\"\"\"Extract metadata from the web page.\"\"\"\n    self.corpuspath.metadata.set_variable(\n        \"title\", self.tree.find(\".//title\").text.strip()\n    )\n    self.corpuspath.metadata.set_variable(\"filename\", self.url)\n    self.corpuspath.metadata.set_variable(\"genre\", \"admin\")\n    self.corpuspath.metadata.set_variable(\"mainlang\", self.lang)\n    self.corpuspath.metadata.set_variable(\"license_type\", \"free\")\n    if self.lang != \"nob\":\n        self.corpuspath.metadata.set_variable(\"translated_from\", \"nob\")\n    time = self.tree.find(\".//time\")\n    if time is not None:\n        self.corpuspath.metadata.set_variable(\n            \"year\", self.tree.find(\".//time\").get(\"datetime\")[:4]\n        )\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.SamediggiNoPage.set_parallel_file","title":"<code>set_parallel_file(lang, name)</code>","text":"<p>Update metadata info on parallel files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def set_parallel_file(self, lang, name):\n\"\"\"Update metadata info on parallel files.\"\"\"\n    self.corpuspath.metadata.set_parallel_text(lang, name)\n</code></pre>"},{"location":"reference/samediggi_no_crawler/#corpustools.samediggi_no_crawler.make_digest","title":"<code>make_digest(bytestring)</code>","text":"<p>Make a md5 hash to identify possible dupes.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/samediggi_no_crawler.py</code> <pre><code>def make_digest(bytestring):\n\"\"\"Make a md5 hash to identify possible dupes.\"\"\"\n    hasher = hashlib.md5()\n    hasher.update(bytestring)\n    return hasher.hexdigest()\n</code></pre>"},{"location":"reference/sentencedivider/","title":"sentencedivider","text":"<p>Classes and functions to sentence align two files.</p>"},{"location":"reference/sentencedivider/#corpustools.sentencedivider.SentenceDivider","title":"<code>SentenceDivider</code>","text":"<p>A class to divide plain text output into sentences.</p> <p>Uses hfst-tokenise as the motor for this purpose.</p> <p>Attributes:</p> Name Type Description <code>stops</code> <code>list of str</code> <p>tokens that imply where a sentence ends.</p> <code>lang</code> <code>str</code> <p>three character language code</p> <code>relative_path</code> <code>str</code> <p>relative path to where files needed by modes.xml are found.</p> <code>tokeniser</code> <code>modes.Pipeline</code> <p>tokeniser pipeline</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/sentencedivider.py</code> <pre><code>class SentenceDivider:\n\"\"\"A class to divide plain text output into sentences.\n\n    Uses hfst-tokenise as the motor for this purpose.\n\n    Attributes:\n        stops (list of str): tokens that imply where a sentence ends.\n        lang (str): three character language code\n        relative_path (str): relative path to where files needed by\n            modes.xml are found.\n        tokeniser (modes.Pipeline): tokeniser pipeline\n    \"\"\"\n\n    stops = [\";\", \"!\", \"?\", \".\", \"..\", \"...\", \"\u00b6\", \"\u2026\"]\n\n    def __init__(self, lang, giella_prefix=None):\n\"\"\"Set the files needed by the tokeniser.\n\n        Args:\n            lang (str): language the analyser can tokenise\n        \"\"\"\n        self.tokeniser = modes.Pipeline(\"tokenise\", lang, giella_prefix)\n\n    def make_sentences(self, tokenised_output):\n\"\"\"Turn ccat output into cleaned up sentences.\n\n        Args:\n            ccat_output (str): plain text output of ccat.\n\n        Yields:\n            str: a cleaned up sentence\n        \"\"\"\n\n        token_buffer = []\n        for token in tokenised_output.split(\"\\n\"):\n            if token != \"\u00b6\":\n                token_buffer.append(token)\n            if token.strip() in self.stops:\n                yield \"\".join(token_buffer).strip()\n                token_buffer[:] = []\n        if token_buffer:\n            yield \"\".join(token_buffer).strip()\n\n    def make_valid_sentences(self, ccat_output):\n\"\"\"Turn ccat output into full sentences.\n\n        Args:\n            ccat_output (str): the plain text output of ccat\n\n        Returns:\n            list of str: The ccat output has been turned into a list\n                of full sentences.\n        \"\"\"\n        return [\n            sentence\n            for sentence in self.make_sentences(\n                self.tokeniser.run(ccat_output.encode(\"utf8\"))\n            )\n            if sentence\n        ]\n</code></pre>"},{"location":"reference/sentencedivider/#corpustools.sentencedivider.SentenceDivider.__init__","title":"<code>__init__(lang, giella_prefix=None)</code>","text":"<p>Set the files needed by the tokeniser.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>language the analyser can tokenise</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/sentencedivider.py</code> <pre><code>def __init__(self, lang, giella_prefix=None):\n\"\"\"Set the files needed by the tokeniser.\n\n    Args:\n        lang (str): language the analyser can tokenise\n    \"\"\"\n    self.tokeniser = modes.Pipeline(\"tokenise\", lang, giella_prefix)\n</code></pre>"},{"location":"reference/sentencedivider/#corpustools.sentencedivider.SentenceDivider.make_sentences","title":"<code>make_sentences(tokenised_output)</code>","text":"<p>Turn ccat output into cleaned up sentences.</p> <p>Parameters:</p> Name Type Description Default <code>ccat_output</code> <code>str</code> <p>plain text output of ccat.</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>a cleaned up sentence</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/sentencedivider.py</code> <pre><code>def make_sentences(self, tokenised_output):\n\"\"\"Turn ccat output into cleaned up sentences.\n\n    Args:\n        ccat_output (str): plain text output of ccat.\n\n    Yields:\n        str: a cleaned up sentence\n    \"\"\"\n\n    token_buffer = []\n    for token in tokenised_output.split(\"\\n\"):\n        if token != \"\u00b6\":\n            token_buffer.append(token)\n        if token.strip() in self.stops:\n            yield \"\".join(token_buffer).strip()\n            token_buffer[:] = []\n    if token_buffer:\n        yield \"\".join(token_buffer).strip()\n</code></pre>"},{"location":"reference/sentencedivider/#corpustools.sentencedivider.SentenceDivider.make_valid_sentences","title":"<code>make_valid_sentences(ccat_output)</code>","text":"<p>Turn ccat output into full sentences.</p> <p>Parameters:</p> Name Type Description Default <code>ccat_output</code> <code>str</code> <p>the plain text output of ccat</p> required <p>Returns:</p> Type Description <p>list of str: The ccat output has been turned into a list of full sentences.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/sentencedivider.py</code> <pre><code>def make_valid_sentences(self, ccat_output):\n\"\"\"Turn ccat output into full sentences.\n\n    Args:\n        ccat_output (str): the plain text output of ccat\n\n    Returns:\n        list of str: The ccat output has been turned into a list\n            of full sentences.\n    \"\"\"\n    return [\n        sentence\n        for sentence in self.make_sentences(\n            self.tokeniser.run(ccat_output.encode(\"utf8\"))\n        )\n        if sentence\n    ]\n</code></pre>"},{"location":"reference/sentencedivider/#corpustools.sentencedivider.to_plain_text","title":"<code>to_plain_text(lang, filename)</code>","text":"<p>Turn an xml formatted file into clean text.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>three character name of main language of document.</p> required <code>filename</code> <code>str</code> <p>name of the xmlfile</p> required <p>Raises:</p> Type Description <code>UserWarning</code> <p>if there is no text, raise a UserWarning</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the content of ccat output</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/sentencedivider.py</code> <pre><code>def to_plain_text(lang, filename):\n\"\"\"Turn an xml formatted file into clean text.\n\n    Args:\n        lang (str): three character name of main language of document.\n        filename (str): name of the xmlfile\n\n    Raises:\n        UserWarning: if there is no text, raise a UserWarning\n\n    Returns:\n        str: the content of ccat output\n    \"\"\"\n    xml_printer = ccat.XMLPrinter(lang=lang, all_paragraphs=True)\n    xml_printer.parse_file(filename)\n    text = xml_printer.process_file().getvalue()\n    if text:\n        return text\n    else:\n        raise UserWarning(f\"Empty file {filename}\")\n</code></pre>"},{"location":"reference/svgconverter/","title":"svgconverter","text":"<p>This file contains classes to convert svg files to the Giella xml format.</p>"},{"location":"reference/svgconverter/#corpustools.svgconverter.convert2intermediate","title":"<code>convert2intermediate(filename)</code>","text":"<p>Transform svg to an intermediate xml document.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of the file that should be converted</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/svgconverter.py</code> <pre><code>def convert2intermediate(filename):\n\"\"\"Transform svg to an intermediate xml document.\n\n    Args:\n        filename (str): name of the file that should be converted\n    \"\"\"\n    svg_xslt_root = etree.parse(os.path.join(HERE, \"xslt/svg2corpus.xsl\"))\n    transform = etree.XSLT(svg_xslt_root)\n    doc = etree.parse(filename)\n    intermediate = transform(doc)\n\n    return intermediate.getroot()\n</code></pre>"},{"location":"reference/text_cat/","title":"text_cat","text":"<p>An implementation of the ``N-Gram-Based Text Categorization'' algorithm.</p> <p>Original article:</p> <p>Cavnar, W. B. and J. M. Trenkle, ``N-Gram-Based Text Categorization'' In Proceedings of Third Annual Symposium on Document Analysis and Information Retrieval, Las Vegas, NV, UNLV Publications/Reprographics, pp. 161-175, 11-13 April 1994.</p> <p>Original Perl implementation and article available from http://odur.let.rug.nl/~vannoord/TextCat/</p>"},{"location":"reference/text_cat/#corpustools.text_cat.Classifier","title":"<code>Classifier</code>","text":"<p>Guess which language a text is written in.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>class Classifier:\n\"\"\"Guess which language a text is written in.\"\"\"\n\n    DROP_RATIO = 1.10\n\n    def __init__(self, folder=None, langs=[], verbose=False):\n        if folder is None:\n            folder = os.path.join(here, \"lm\")\n        self.cmodels = {}\n        self.wmodels = {}\n\n        ext = \".lm\"\n        fnames = []\n\n        folder_glob = os.path.join(folder, \"*\" + ext)\n        found_fnames = glob.glob(os.path.normcase(folder_glob))\n        if not found_fnames:\n            raise ValueError(f\"No language files found in {folder}\")\n\n        if not langs:\n            fnames = found_fnames\n        else:\n            fnames = [os.path.join(folder, lang + ext) for lang in langs]\n            not_found = set(fnames) - set(found_fnames)\n            if not_found:\n                raise ValueError(\"Unknown language(s): \" + \", \".join(not_found))\n\n        for fname in fnames:\n            lang = util.basename_noext(fname, ext)\n            with codecs.open(fname, \"r\", encoding=\"utf8\") as fname_stream:\n                self.cmodels[lang] = CharModel(lang).of_model_file(fname_stream, fname)\n                if verbose:\n                    util.note(f\"Loaded {fname}\")\n\n            fname_wm = os.path.join(folder, lang + \".wm\")\n            # fname_wmgz = os.path.join(folder, lang+'.wm.gz')\n            if os.path.exists(fname_wm):\n                with codecs.open(fname_wm, \"r\", encoding=\"utf8\") as fname_wm_stream:\n                    self.wmodels[lang] = WordModel(lang).of_model_file(\n                        fname_wm_stream, fname_wm\n                    )\n                    if verbose:\n                        util.note(f\"Loaded {fname_wm}\")\n            else:\n                self.wmodels[lang] = WordModel(lang).of_freq({})\n\n        if not self.cmodels:\n            raise ValueError(\"No character models created!\")\n        else:\n            self.langs = set(self.cmodels.keys())\n            self.langs_warned = set()\n\n    def get_langs(self, langs=[]):\n\"\"\"Get the set of wanted languages.\n\n        Args:\n            langs (list of str): list of probable languages\n\n        Returns:\n            set: The set of languages that should be considered\n        \"\"\"\n        if langs == []:\n            return self.langs\n        else:\n            langs = set(langs)\n            active_langs = self.langs &amp; langs\n            if len(langs) != len(active_langs):\n                missing = langs - active_langs - self.langs_warned\n                if missing:\n                    # only warn once per lang\n                    self.langs_warned.update(missing)\n                    util.note(\n                        \"WARNING: No language model for {}\".format(\"/\".join(missing))\n                    )\n            return active_langs\n\n    def classify_full(self, intext, langs=[], verbose=False):\n        active_langs = self.get_langs(langs)\n\n        text = ensure_unicode(intext)\n        ingram = CharModel().of_text(text)\n\n        cscored = {\n            l: model.compare(ingram)\n            for l, model in self.cmodels.items()\n            if l in active_langs\n        }\n        cranked = util.sort_by_value(cscored)\n        cbest = cranked[0]\n        cfiltered = {l: d for l, d in cranked if d &lt;= cbest[1] * self.DROP_RATIO}\n\n        if len(cfiltered) &lt;= 1:\n            if verbose:\n                util.note(f\"lm gave: {cfiltered} as only result for input: {text}\")\n            return list(cfiltered.items())\n        else:\n            # Along with compare_tc, implements text_cat.pl line\n            # 442 and on:\n            wscored = {\n                l: model.compare_tc(text, cscored[l])\n                for l, model in self.wmodels.items()\n                if l in cfiltered\n            }\n            cwcombined = {l: (cscored[l] - wscore) for l, wscore in wscored.items()}\n            cwranked = util.sort_by_value(cwcombined)\n            if verbose:\n                if cranked[: len(cwranked)] == cwranked:\n                    util.note(\n                        \"lm gave: {}\\t\\twm gave no change\\t\\tfor\"\n                        \"input: {}\".format(pretty_tbl(cranked), text)\n                    )\n                else:\n                    util.note(\n                        \"lm gave: {}\\t\\twm-weighted to: \"\n                        \"{}\\t\\tfor input: {}\".format(\n                            pretty_tbl(cranked), pretty_tbl(cwranked), text\n                        )\n                    )\n            return cwranked\n\n    def classify(self, text, langs=[], verbose=False):\n        return self.classify_full(text, langs, verbose)[0][0]\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.Classifier.get_langs","title":"<code>get_langs(langs=[])</code>","text":"<p>Get the set of wanted languages.</p> <p>Parameters:</p> Name Type Description Default <code>langs</code> <code>list of str</code> <p>list of probable languages</p> <code>[]</code> <p>Returns:</p> Name Type Description <code>set</code> <p>The set of languages that should be considered</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>def get_langs(self, langs=[]):\n\"\"\"Get the set of wanted languages.\n\n    Args:\n        langs (list of str): list of probable languages\n\n    Returns:\n        set: The set of languages that should be considered\n    \"\"\"\n    if langs == []:\n        return self.langs\n    else:\n        langs = set(langs)\n        active_langs = self.langs &amp; langs\n        if len(langs) != len(active_langs):\n            missing = langs - active_langs - self.langs_warned\n            if missing:\n                # only warn once per lang\n                self.langs_warned.update(missing)\n                util.note(\n                    \"WARNING: No language model for {}\".format(\"/\".join(missing))\n                )\n        return active_langs\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.FileTrainer","title":"<code>FileTrainer</code>","text":"<p>Train the language guesser from a file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>class FileTrainer:\n\"\"\"Train the language guesser from a file.\"\"\"\n\n    def __init__(self, fil, Model=CharModel, verbose=False):\n        self.model = Model().of_text_file(fil)\n\n    def save(self, fil, verbose=False):\n        self.model.to_model_file(fil)\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.FolderTrainer","title":"<code>FolderTrainer</code>","text":"<p>Train the language guesser from a directory.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>class FolderTrainer:\n\"\"\"Train the language guesser from a directory.\"\"\"\n\n    def __init__(\n        self, folder, exts=[\".txt\", \".txt.gz\"], Model=CharModel, verbose=False\n    ):\n        self.models = {}\n\n        for ext in exts:\n            files = glob.glob(os.path.normcase(os.path.join(folder, \"*\" + ext)))\n            for fname in files:\n                if verbose:\n                    msg = f\"Processing {fname}\"\n                    if os.path.getsize(fname) &gt; 5000000:\n                        msg += \" (this may take a while)\"\n                    util.note(msg)\n                    sys.stderr.flush()\n                lang = util.basename_noext(fname, ext)\n                self.models[lang] = Model(lang).of_text_file(self.open_corpus(fname))\n\n        if not self.models:\n            raise Exception(\n                \"No suitable files found matching {}/*.{}{}{}!\".format(\n                    folder, \"{\", \",\".join(exts), \"}\"\n                )\n            )\n\n    def open_corpus(self, fname):\n        if fname.endswith(\".gz\"):\n            return gzip.open(fname, \"rb\")\n        else:\n            return codecs.open(fname, \"r\", encoding=\"utf8\")\n\n    def save(self, folder, ext=\".lm\", verbose=False):\n        for lang, model in self.models.items():\n            fname = os.path.join(folder, lang + ext)\n            model.to_model_file(codecs.open(fname, \"w\", encoding=\"utf8\"))\n        if verbose and self.models:\n            util.note(\"Wrote {{{}}}{}\".format(\",\".join(list(self.models.keys())), ext))\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.NGramModel","title":"<code>NGramModel</code>","text":"Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>class NGramModel:\n    SPLITCHARS = re.compile(\n        r\"[][}{)(&gt;&lt; \\n\\t:;!.?_,\u00b6\u00a7%&amp;\u00a3\u20ac$\u00b9\u00b0\u00bd\u00bc\u00be\u00a9\u2190\u2192\u25aa\u27a2\u221a|#\u2013\u2012\u2026\u00b7\u2022@~\\\\/\u201d\u201c\u00ab\u00bb\\\"\uf0b70-9=*+\u2011-]\"\n    )\n    NB_NGRAMS = 400\n    MISSING_VALUE = 400\n\n    def __init__(self, arg={}, lang=\"input\"):\n        self.lang = lang  # for debugging\n        self.unicode_warned = 0\n\n    def of_text(self, text):\n        self.finish(self.freq_of_text(ensure_unicode(text), {}))\n        return self\n\n    def of_freq(self, freq):\n        self.finish(freq)\n        return self\n\n    def of_text_file(self, fil):\n        self.finish(self.freq_of_text_file(fil))\n        return self\n\n    def of_model_file(self, fil, fname):\n        raise NotImplementedError(\"You have to subclass and override of_model_file\")\n\n    def freq_of_model_file(self, fil, fname, gram_column, freq_column):\n        freq = {}\n        for nl, strline in enumerate(fil.readlines()):\n            line = strline.strip()\n            if line == \"\":\n                continue\n            parts = line.split()\n            if len(parts) != 2:\n                raise ValueError(\n                    \"%s:%d invalid line, was split to %s\" % (fname, nl + 1, parts)\n                )\n            try:\n                g = parts[gram_column]\n                f = int(parts[freq_column])\n                freq[g] = f\n            except ValueError as e:\n                raise ValueError(\"%s: %d %s\" % (fname, nl + 1, e))\n        return freq\n\n    def tokenise(self, text):\n\"\"\"Tokenise the text\n\n        Since we use split() when loading the model file, we also use split()\n        on the input text; this includes whitespace (like byte order\n        marks) that might not all be in SPLITCHARS\n        \"\"\"\n        tokens = (re.split(self.SPLITCHARS, t) for t in text.split())\n        return sum(tokens, [])  # flatten\n\n    def freq_of_text(self, text, freq):\n\"\"\"This should update freq and return it.\"\"\"\n        raise NotImplementedError(\"You have to subclass and override freq_of_text\")\n\n    def to_model_file(self, fil, fname):\n        raise NotImplementedError(\"You have to subclass and override to_model_file\")\n\n    def freq_of_text_file(self, fil):\n        freq = {}\n        for nl, strline in enumerate(fil.readlines()):\n            try:\n                line = strline\n            except UnicodeDecodeError as e:\n                if self.unicode_warned == 0:\n                    util.note(\n                        \"WARNING: Line {} gave {}, skipping ... \"\n                        \"(not warning again)\".format(nl, e)\n                    )\n                self.unicode_warned += 1\n                continue\n            freq = self.freq_of_text(line, freq)\n        if self.unicode_warned != 0:\n            util.note(f\"Saw {self.unicode_warned} UnicodeDecodeErrors\")\n        return freq\n\n    def finish(self, freq):\n        self.ngrams = {\n            gram: rank\n            for rank, (gram, freq) in enumerate(\n                util.sort_by_value(freq, reverse=True)[: self.NB_NGRAMS]\n            )\n            if gram != \"\"\n        }\n        # Only store the top NB_NGRAMS with frequency:\n        self.freq = {gram: freq[gram] for gram in self.ngrams}\n        self.ngramskeyset = set(self.ngrams.keys())\n\n    def compare(self, unknown):\n        missing_count = len(unknown.ngramskeyset - self.ngramskeyset)\n        d_missing = self.MISSING_VALUE * missing_count\n        d_found = sum(\n            abs(rank - self.ngrams[gram])\n            for gram, rank in unknown.ngrams.items()\n            if gram in self.ngrams\n        )\n        # util.print_frame(debug=missing_count)\n        # util.print_frame(debug=d_missing)\n        # util.print_frame(debug=d_found)\n\n        return d_missing + d_found\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.NGramModel.freq_of_text","title":"<code>freq_of_text(text, freq)</code>","text":"<p>This should update freq and return it.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>def freq_of_text(self, text, freq):\n\"\"\"This should update freq and return it.\"\"\"\n    raise NotImplementedError(\"You have to subclass and override freq_of_text\")\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.NGramModel.tokenise","title":"<code>tokenise(text)</code>","text":"<p>Tokenise the text</p> <p>Since we use split() when loading the model file, we also use split() on the input text; this includes whitespace (like byte order marks) that might not all be in SPLITCHARS</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>def tokenise(self, text):\n\"\"\"Tokenise the text\n\n    Since we use split() when loading the model file, we also use split()\n    on the input text; this includes whitespace (like byte order\n    marks) that might not all be in SPLITCHARS\n    \"\"\"\n    tokens = (re.split(self.SPLITCHARS, t) for t in text.split())\n    return sum(tokens, [])  # flatten\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.WordModel","title":"<code>WordModel</code>","text":"<p>         Bases: <code>NGramModel</code></p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>class WordModel(NGramModel):\n    NB_NGRAMS = 30000\n\n    def of_model_file(self, fil, fname):\n        self.finish(self.freq_of_model_file(fil, fname, gram_column=1, freq_column=0))\n        return self\n\n    def to_model_file(self, fil):\n        lines = \"\".join(\n            [\n                \"%d\\t%s\\n\" % (f, g)\n                for g, f in util.sort_by_value(self.freq, reverse=True)\n                if g != \"\"\n            ]\n        )\n        fil.write(lines)\n\n    def freq_of_text(self, text, freq):\n        words = self.tokenise(text)\n        for word in words:\n            freq[word] = freq.get(word, 0) + 1\n        return freq\n\n    def finish(self, freq):\n        super().finish(freq)\n        # See text_cat.pl line 642ff; we invert and normalise the\n        # ranking to make it possible to use compare_tc where one wm\n        # is shorter than the other, e.g. if there is only a small\n        # corpus for one language, or if we manually deleted some\n        # words:\n        n_words = len(self.ngrams)\n        normaliser = float(n_words) / float(self.NB_NGRAMS)\n        self.invrank = {\n            gram: ((n_words - rank) / normaliser) for gram, rank in self.ngrams.items()\n        }\n\n    def compare_tc(self, unknown_text, normaliser):\n\"\"\"Implements line 442 of text_cat.pl\n\n        `normaliser` is results[language] from CharModel\n        \"\"\"\n        if normaliser &lt;= 0:\n            return normaliser\n        else:\n            unknown_freq = self.freq_of_text(unknown_text, {})\n            return sum(\n                self.invrank[word] ** 2 * unknown_freq[word] * 100 / normaliser\n                for word in unknown_freq.keys()\n                if word in self.ngrams\n            )\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.WordModel.compare_tc","title":"<code>compare_tc(unknown_text, normaliser)</code>","text":"<p>Implements line 442 of text_cat.pl</p> <p><code>normaliser</code> is results[language] from CharModel</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>def compare_tc(self, unknown_text, normaliser):\n\"\"\"Implements line 442 of text_cat.pl\n\n    `normaliser` is results[language] from CharModel\n    \"\"\"\n    if normaliser &lt;= 0:\n        return normaliser\n    else:\n        unknown_freq = self.freq_of_text(unknown_text, {})\n        return sum(\n            self.invrank[word] ** 2 * unknown_freq[word] * 100 / normaliser\n            for word in unknown_freq.keys()\n            if word in self.ngrams\n        )\n</code></pre>"},{"location":"reference/text_cat/#corpustools.text_cat.ensure_unicode","title":"<code>ensure_unicode(text)</code>","text":"<p>Make sure text is unicode</p> <p>Helper for functions that should be able to operate on either utf-8 encoded bytes or decoded unicode objects</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/text_cat.py</code> <pre><code>def ensure_unicode(text):\n\"\"\"Make sure text is unicode\n\n    Helper for functions that should be able to operate on either utf-8\n    encoded bytes or decoded unicode objects\n    \"\"\"\n    if type(text) == bytes:\n        return text.decode(\"utf-8\")\n    else:\n        assert type(text) == str\n        return text\n</code></pre>"},{"location":"reference/tmx/","title":"tmx","text":"<p>Classes and functions to make and handle Translation Memory eXchange files.</p>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx","title":"<code>AlignmentToTmx</code>","text":"<p>         Bases: <code>Tmx</code></p> <p>A class to make tmx files based on the output of an aligner.</p> <p>This just implements some common methods for the TCA2 and hunalign subclasses.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>class AlignmentToTmx(Tmx):\n\"\"\"A class to make tmx files based on the output of an aligner.\n\n    This just implements some common methods for the TCA2 and hunalign\n    subclasses.\n    \"\"\"\n\n    def __init__(self, origfiles):\n\"\"\"Input is a list of CorpusXMLFile objects.\"\"\"\n        self.origfiles = origfiles\n        super().__init__(self.make_tmx())\n\n    def make_tu(self, line1, line2):\n\"\"\"Make a tmx tu element based on line1 and line2 as input.\"\"\"\n        transl_unit = etree.Element(\"tu\")\n\n        transl_unit.append(self.make_tuv(line1, self.origfiles[0].pathcomponents.lang))\n        transl_unit.append(self.make_tuv(line2, self.origfiles[1].pathcomponents.lang))\n\n        return transl_unit\n\n    @staticmethod\n    def make_tuv(line, lang):\n\"\"\"Make a tuv element given an input line and a lang variable.\"\"\"\n        tuv = etree.Element(\"tuv\")\n        tuv.attrib[\"{http://www.w3.org/XML/1998/namespace}lang\"] = lang\n        seg = etree.Element(\"seg\")\n        seg.text = line.strip()\n        tuv.append(seg)\n\n        return tuv\n\n    @staticmethod\n    def add_filename_id(filename):\n\"\"\"Add the tmx filename as an prop element in the header.\"\"\"\n        prop = etree.Element(\"prop\")\n        prop.attrib[\"type\"] = \"x-filename\"\n        prop.text = os.path.basename(filename)\n\n        return prop\n\n    def make_tmx_header(self, filename, lang):\n\"\"\"Make a tmx header based on the lang variable.\"\"\"\n        header = etree.Element(\"header\")\n\n        # Set various attributes\n        header.attrib[\"segtype\"] = \"sentence\"\n        header.attrib[\"o-tmf\"] = \"OmegaT TMX\"\n        header.attrib[\"adminlang\"] = \"en-US\"\n        header.attrib[\"srclang\"] = lang\n        header.attrib[\"datatype\"] = \"plaintext\"\n\n        header.append(self.add_filename_id(filename))\n\n        return header\n\n    def make_tmx(self):\n\"\"\"Make tmx file based on the output of the aligner.\"\"\"\n        tmx = etree.Element(\"tmx\")\n        header = self.make_tmx_header(\n            self.origfiles[0].pathcomponents.basename,\n            self.origfiles[0].pathcomponents.lang,\n        )\n        tmx.append(header)\n\n        pfile1_data, pfile2_data = self.parse_alignment_results()\n\n        body = etree.SubElement(tmx, \"body\")\n        for line1, line2 in zip(pfile1_data, pfile2_data):\n            transl_unit = self.make_tu(line1, line2)\n            body.append(transl_unit)\n\n        return tmx\n\n    def parse_alignment_results(self):\n\"\"\"Meta function.\"\"\"\n        raise NotImplementedError(\n            \"You have to subclass and override parse_alignment_results\"\n        )\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx.__init__","title":"<code>__init__(origfiles)</code>","text":"<p>Input is a list of CorpusXMLFile objects.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def __init__(self, origfiles):\n\"\"\"Input is a list of CorpusXMLFile objects.\"\"\"\n    self.origfiles = origfiles\n    super().__init__(self.make_tmx())\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx.add_filename_id","title":"<code>add_filename_id(filename)</code>  <code>staticmethod</code>","text":"<p>Add the tmx filename as an prop element in the header.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef add_filename_id(filename):\n\"\"\"Add the tmx filename as an prop element in the header.\"\"\"\n    prop = etree.Element(\"prop\")\n    prop.attrib[\"type\"] = \"x-filename\"\n    prop.text = os.path.basename(filename)\n\n    return prop\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx.make_tmx","title":"<code>make_tmx()</code>","text":"<p>Make tmx file based on the output of the aligner.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def make_tmx(self):\n\"\"\"Make tmx file based on the output of the aligner.\"\"\"\n    tmx = etree.Element(\"tmx\")\n    header = self.make_tmx_header(\n        self.origfiles[0].pathcomponents.basename,\n        self.origfiles[0].pathcomponents.lang,\n    )\n    tmx.append(header)\n\n    pfile1_data, pfile2_data = self.parse_alignment_results()\n\n    body = etree.SubElement(tmx, \"body\")\n    for line1, line2 in zip(pfile1_data, pfile2_data):\n        transl_unit = self.make_tu(line1, line2)\n        body.append(transl_unit)\n\n    return tmx\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx.make_tmx_header","title":"<code>make_tmx_header(filename, lang)</code>","text":"<p>Make a tmx header based on the lang variable.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def make_tmx_header(self, filename, lang):\n\"\"\"Make a tmx header based on the lang variable.\"\"\"\n    header = etree.Element(\"header\")\n\n    # Set various attributes\n    header.attrib[\"segtype\"] = \"sentence\"\n    header.attrib[\"o-tmf\"] = \"OmegaT TMX\"\n    header.attrib[\"adminlang\"] = \"en-US\"\n    header.attrib[\"srclang\"] = lang\n    header.attrib[\"datatype\"] = \"plaintext\"\n\n    header.append(self.add_filename_id(filename))\n\n    return header\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx.make_tu","title":"<code>make_tu(line1, line2)</code>","text":"<p>Make a tmx tu element based on line1 and line2 as input.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def make_tu(self, line1, line2):\n\"\"\"Make a tmx tu element based on line1 and line2 as input.\"\"\"\n    transl_unit = etree.Element(\"tu\")\n\n    transl_unit.append(self.make_tuv(line1, self.origfiles[0].pathcomponents.lang))\n    transl_unit.append(self.make_tuv(line2, self.origfiles[1].pathcomponents.lang))\n\n    return transl_unit\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx.make_tuv","title":"<code>make_tuv(line, lang)</code>  <code>staticmethod</code>","text":"<p>Make a tuv element given an input line and a lang variable.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef make_tuv(line, lang):\n\"\"\"Make a tuv element given an input line and a lang variable.\"\"\"\n    tuv = etree.Element(\"tuv\")\n    tuv.attrib[\"{http://www.w3.org/XML/1998/namespace}lang\"] = lang\n    seg = etree.Element(\"seg\")\n    seg.text = line.strip()\n    tuv.append(seg)\n\n    return tuv\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.AlignmentToTmx.parse_alignment_results","title":"<code>parse_alignment_results()</code>","text":"<p>Meta function.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def parse_alignment_results(self):\n\"\"\"Meta function.\"\"\"\n    raise NotImplementedError(\n        \"You have to subclass and override parse_alignment_results\"\n    )\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.HunalignToTmx","title":"<code>HunalignToTmx</code>","text":"<p>         Bases: <code>AlignmentToTmx</code></p> <p>A class to make tmx files based on the output from hunalign.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>class HunalignToTmx(AlignmentToTmx):\n\"\"\"A class to make tmx files based on the output from hunalign.\"\"\"\n\n    def __init__(self, origfiles, output, threshold=0.0):\n\"\"\"Input is a list of CorpusXMLFile objects.\"\"\"\n        self.output = output\n        self.threshold = threshold\n        super().__init__(origfiles)\n\n    def parse_alignment_results(self):\n\"\"\"Return parsed output files of tca2.\"\"\"\n        pairs = [line.split(\"\\t\") for line in self.output.split(\"\\n\") if line]\n        pairs = [pair for pair in pairs if self.is_good_line(pair)]\n\n        src_lines = [self.clean_line(l[0]) for l in pairs]\n        trg_lines = [self.clean_line(l[1]) for l in pairs]\n        return src_lines, trg_lines\n\n    def is_good_line(self, line):\n\"\"\"Determine whether this line should be used.\"\"\"\n        return (\n            len(line) == 3\n            and line[0] != \"&lt;p&gt;\"\n            and line[1] != \"&lt;p&gt;\"\n            and float(line[2]) &gt; self.threshold\n        )\n\n    @staticmethod\n    def clean_line(line):\n\"\"\"Remove the ~~~ occuring in multi-sentence alignments.\"\"\"\n        multi_sep = re.compile(r\" *~~~ *\")\n        return multi_sep.sub(\" \", line)\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.HunalignToTmx.__init__","title":"<code>__init__(origfiles, output, threshold=0.0)</code>","text":"<p>Input is a list of CorpusXMLFile objects.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def __init__(self, origfiles, output, threshold=0.0):\n\"\"\"Input is a list of CorpusXMLFile objects.\"\"\"\n    self.output = output\n    self.threshold = threshold\n    super().__init__(origfiles)\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.HunalignToTmx.clean_line","title":"<code>clean_line(line)</code>  <code>staticmethod</code>","text":"<p>Remove the ~~~ occuring in multi-sentence alignments.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef clean_line(line):\n\"\"\"Remove the ~~~ occuring in multi-sentence alignments.\"\"\"\n    multi_sep = re.compile(r\" *~~~ *\")\n    return multi_sep.sub(\" \", line)\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.HunalignToTmx.is_good_line","title":"<code>is_good_line(line)</code>","text":"<p>Determine whether this line should be used.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def is_good_line(self, line):\n\"\"\"Determine whether this line should be used.\"\"\"\n    return (\n        len(line) == 3\n        and line[0] != \"&lt;p&gt;\"\n        and line[1] != \"&lt;p&gt;\"\n        and float(line[2]) &gt; self.threshold\n    )\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.HunalignToTmx.parse_alignment_results","title":"<code>parse_alignment_results()</code>","text":"<p>Return parsed output files of tca2.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def parse_alignment_results(self):\n\"\"\"Return parsed output files of tca2.\"\"\"\n    pairs = [line.split(\"\\t\") for line in self.output.split(\"\\n\") if line]\n    pairs = [pair for pair in pairs if self.is_good_line(pair)]\n\n    src_lines = [self.clean_line(l[0]) for l in pairs]\n    trg_lines = [self.clean_line(l[1]) for l in pairs]\n    return src_lines, trg_lines\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tca2ToTmx","title":"<code>Tca2ToTmx</code>","text":"<p>         Bases: <code>AlignmentToTmx</code></p> <p>A class to make tmx files based on the output from tca2.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>class Tca2ToTmx(AlignmentToTmx):\n\"\"\"A class to make tmx files based on the output from tca2.\"\"\"\n\n    def __init__(self, origfiles, sentfiles):\n\"\"\"Input is a list of CorpusXMLFile objects.\"\"\"\n        self.sentfiles = sentfiles\n        super().__init__(origfiles)\n\n    def parse_alignment_results(self):\n\"\"\"Return parsed output files of tca2.\"\"\"\n        return (\n            self.read_tca2_output(self.sentfiles[0]),\n            self.read_tca2_output(self.sentfiles[1]),\n        )\n\n    def read_tca2_output(self, sentfile):\n\"\"\"Read the output of tca2.\n\n        Args:\n            sentfile (str): name of the output file of convert2xml\n\n        Returns:\n            list of str: The sentences found in the tca2 file\n        \"\"\"\n        sentfile_name = sentfile.replace(\".sent\", \"_new.txt\")\n\n        with codecs.open(sentfile_name, encoding=\"utf8\") as tca2_output:\n            return [self.remove_s_tag(line) for line in tca2_output]\n\n    @staticmethod\n    def remove_s_tag(line):\n\"\"\"Remove the s tags that tca2 has added.\"\"\"\n        sregex = re.compile('&lt;s id=\"[^ ]*\"&gt;')\n        line = line.replace(\"&lt;/s&gt;\", \"\")\n        line = sregex.sub(\"\", line)\n        return line\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tca2ToTmx.__init__","title":"<code>__init__(origfiles, sentfiles)</code>","text":"<p>Input is a list of CorpusXMLFile objects.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def __init__(self, origfiles, sentfiles):\n\"\"\"Input is a list of CorpusXMLFile objects.\"\"\"\n    self.sentfiles = sentfiles\n    super().__init__(origfiles)\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tca2ToTmx.parse_alignment_results","title":"<code>parse_alignment_results()</code>","text":"<p>Return parsed output files of tca2.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def parse_alignment_results(self):\n\"\"\"Return parsed output files of tca2.\"\"\"\n    return (\n        self.read_tca2_output(self.sentfiles[0]),\n        self.read_tca2_output(self.sentfiles[1]),\n    )\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tca2ToTmx.read_tca2_output","title":"<code>read_tca2_output(sentfile)</code>","text":"<p>Read the output of tca2.</p> <p>Parameters:</p> Name Type Description Default <code>sentfile</code> <code>str</code> <p>name of the output file of convert2xml</p> required <p>Returns:</p> Type Description <p>list of str: The sentences found in the tca2 file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def read_tca2_output(self, sentfile):\n\"\"\"Read the output of tca2.\n\n    Args:\n        sentfile (str): name of the output file of convert2xml\n\n    Returns:\n        list of str: The sentences found in the tca2 file\n    \"\"\"\n    sentfile_name = sentfile.replace(\".sent\", \"_new.txt\")\n\n    with codecs.open(sentfile_name, encoding=\"utf8\") as tca2_output:\n        return [self.remove_s_tag(line) for line in tca2_output]\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tca2ToTmx.remove_s_tag","title":"<code>remove_s_tag(line)</code>  <code>staticmethod</code>","text":"<p>Remove the s tags that tca2 has added.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef remove_s_tag(line):\n\"\"\"Remove the s tags that tca2 has added.\"\"\"\n    sregex = re.compile('&lt;s id=\"[^ ]*\"&gt;')\n    line = line.replace(\"&lt;/s&gt;\", \"\")\n    line = sregex.sub(\"\", line)\n    return line\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx","title":"<code>Tmx</code>","text":"<p>A tmx file handler.</p> <p>A class that reads a tmx file, and implements a bare minimum of functionality to be able to compare two tmx's. It also contains functions to manipulate the tmx in several ways.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>class Tmx:\n\"\"\"A tmx file handler.\n\n    A class that reads a tmx file, and implements a bare minimum of\n    functionality to be able to compare two tmx's.\n    It also contains functions to manipulate the tmx in several ways.\n    \"\"\"\n\n    def __init__(self, tmx):\n\"\"\"Input is a tmx element.\"\"\"\n        self.tmx = tmx\n\n    @property\n    def src_lang(self):\n\"\"\"Get the srclang from the header element.\"\"\"\n        return self.tmx.find(\".//header\").attrib[\"srclang\"][:3]\n\n    @staticmethod\n    def tu_to_string(transl_unit):\n\"\"\"Extract the two strings of a tu element.\"\"\"\n        string = \"\"\n        with util.ignored(AttributeError):\n            string = string + transl_unit[0][0].text.strip()\n\n        string += \"\\t\"\n\n        with util.ignored(AttributeError):\n            string = string + transl_unit[1][0].text.strip()\n\n        string += \"\\n\"\n        return string\n\n    @staticmethod\n    def tuv_to_string(tuv):\n\"\"\"Extract the string from the tuv element.\"\"\"\n        string = \"\"\n        with util.ignored(AttributeError):\n            string = tuv[0].text.strip()\n\n        return string\n\n    def lang_to_stringlist(self, lang):\n\"\"\"Find all sentences of lang.\"\"\"\n        all_tuv = self.tmx.xpath(\n            './/tuv[@xml:lang=\"' + lang + '\"]',\n            namespaces={\"xml\": \"http://www.w3.org/XML/1998/namespace\"},\n        )\n\n        strings = []\n        for tuv in all_tuv:\n            strings.append(self.tuv_to_string(tuv))\n\n        return strings\n\n    def tmx_to_stringlist(self):\n\"\"\"Extract all string pairs in a tmx to a list of strings.\"\"\"\n        all_tu = self.tmx.findall(\".//tu\")\n        strings = []\n        for transl_unit in all_tu:\n            strings.append(self.tu_to_string(transl_unit))\n\n        return strings\n\n    @staticmethod\n    def prettify_segs(transl_unit):\n\"\"\"Strip white space from start and end of the strings.\n\n        Input is a tu element\n        Output is a tu element with white space stripped strings\n        \"\"\"\n        with util.ignored(AttributeError):\n            string = transl_unit[0][0].text.strip()\n            transl_unit[0][0].text = string\n\n        with util.ignored(AttributeError):\n            string = transl_unit[1][0].text.strip()\n            transl_unit[1][0].text = string\n\n        return transl_unit\n\n    # to debug here\n    def reverse_langs(self):\n\"\"\"Reverse the langs in a tmx.\n\n        Return the reverted tmx\n        \"\"\"\n        all_tu = self.tmx.findall(\".//tu\")\n        body = etree.Element(\"body\")\n        for transl_unit in all_tu:\n            tmp = etree.Element(\"tu\")\n            tmp.append(transl_unit[1])\n            tmp.append(transl_unit[0])\n            tmp = self.prettify_segs(tmp)\n            body.append(tmp)\n\n        tmx = etree.Element(\"tmx\")\n        tmx.append(body)\n\n        self.tmx = tmx\n\n    def remove_unwanted_space(self):\n\"\"\"Remove unwanted spaces from sentences.\n\n        The SentenceDivider adds spaces before and after punctuation,\n        quotemarks, parentheses and so on.\n        Remove those spaces so that the tmxes are more appropriate for real\n        world\u2122 use cases.\n        \"\"\"\n        root = self.tmx\n        for transl_unit in root.iter(\"tu\"):\n            transl_unit = self.remove_unwanted_space_from_segs(transl_unit)\n\n    def remove_unwanted_space_from_segs(self, transl_unit):\n\"\"\"Remove unwanted spaces.\n\n        Remove spaces before and after punctuation,\n        quotemarks, parentheses and so on as appropriate in the seg elements\n        in the tu elements.\n        Input is a tu element\n        Output is a tu element with modified seg elements\n        \"\"\"\n        with util.ignored(AttributeError):\n            string = transl_unit[0][0].text.strip()\n            string = self.remove_unwanted_space_from_string(string)\n            transl_unit[0][0].text = string\n\n        with util.ignored(AttributeError):\n            string = transl_unit[1][0].text.strip()\n            string = self.remove_unwanted_space_from_string(string)\n            transl_unit[1][0].text = string\n\n        return transl_unit\n\n    @staticmethod\n    def remove_unwanted_space_from_string(input_string):\n\"\"\"Remove unwanted space from string.\n\n        Args:\n            input_string (str): the string we would like to remove\n                unwanted space from:\n\n        Returns:\n            str without unwanted space.\n        \"\"\"\n        result = input_string\n\n        # regex to find space followed by punctuation\n        space_punctuation = re.compile(r\"(?P&lt;space&gt;\\s)(?P&lt;punctuation&gt;[\\)\\]\\.\u00bb:;,])\")\n        # for every match in the result string, replace the match\n        # (space+punctuation) with the punctuation part\n        result = space_punctuation.sub(lambda match: match.group(\"punctuation\"), result)\n\n        # regex to find punctuation followed by space\n        punctuation_space = re.compile(r\"(?P&lt;punctuation&gt;[\\[\\(\u00ab])(?P&lt;space&gt;\\s)+\")\n        result = punctuation_space.sub(lambda match: match.group(\"punctuation\"), result)\n\n        # regex which matches multiple spaces\n        multiple_space = re.compile(r\"\\s+\")\n        result = multiple_space.sub(lambda match: \" \", result)\n\n        return result\n\n    def write_tmx_file(self, out_filename):\n\"\"\"Write a tmx file given a tmx etree element and a filename.\"\"\"\n        out_dir = os.path.dirname(out_filename)\n        with util.ignored(OSError):\n            os.makedirs(out_dir)\n\n        with open(out_filename, \"wb\") as tmx_file:\n            tmx_file.write(\n                etree.tostring(\n                    self.tmx, pretty_print=True, encoding=\"utf-8\", xml_declaration=True\n                )\n            )\n\n    def tmx2html(self, out_filename):\n\"\"\"Convert tmx to html.\n\n        Args:\n            out_filename (str): name of the html file\n        \"\"\"\n        html2tmx_transformer = etree.XSLT(\n            etree.parse(os.path.join(HERE, \"xslt/tmx2html.xsl\"))\n        )\n\n        with open(out_filename, \"wb\") as html_file:\n            html_file.write(\n                etree.tostring(\n                    html2tmx_transformer(self.tmx),\n                    pretty_print=True,\n                    encoding=\"utf-8\",\n                    xml_declaration=True,\n                )\n            )\n\n    def remove_tu_with_empty_seg(self):\n\"\"\"Remove tu elements that contain empty seg element.\"\"\"\n        root = self.tmx\n        for transl_unit in root.iter(\"tu\"):\n            try:\n                self.check_if_emtpy_seg(transl_unit)\n            except AttributeError:\n                transl_unit.getparent().remove(transl_unit)\n\n    @staticmethod\n    def check_if_emtpy_seg(transl_units):\n\"\"\"Check if a tu element contains empty strings.\n\n        If there are any empty elements an AttributeError is raised\n        \"\"\"\n        for transl_unit in transl_units:\n            if not transl_unit[0].text.strip():\n                raise AttributeError(\"Empty translation unit\")\n\n    def clean_toktmx(self):\n\"\"\"Do the cleanup of the toktmx file.\"\"\"\n        self.remove_unwanted_space()\n        self.remove_tu_with_empty_seg()\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.src_lang","title":"<code>src_lang</code>  <code>property</code>","text":"<p>Get the srclang from the header element.</p>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.__init__","title":"<code>__init__(tmx)</code>","text":"<p>Input is a tmx element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def __init__(self, tmx):\n\"\"\"Input is a tmx element.\"\"\"\n    self.tmx = tmx\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.check_if_emtpy_seg","title":"<code>check_if_emtpy_seg(transl_units)</code>  <code>staticmethod</code>","text":"<p>Check if a tu element contains empty strings.</p> <p>If there are any empty elements an AttributeError is raised</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef check_if_emtpy_seg(transl_units):\n\"\"\"Check if a tu element contains empty strings.\n\n    If there are any empty elements an AttributeError is raised\n    \"\"\"\n    for transl_unit in transl_units:\n        if not transl_unit[0].text.strip():\n            raise AttributeError(\"Empty translation unit\")\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.clean_toktmx","title":"<code>clean_toktmx()</code>","text":"<p>Do the cleanup of the toktmx file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def clean_toktmx(self):\n\"\"\"Do the cleanup of the toktmx file.\"\"\"\n    self.remove_unwanted_space()\n    self.remove_tu_with_empty_seg()\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.lang_to_stringlist","title":"<code>lang_to_stringlist(lang)</code>","text":"<p>Find all sentences of lang.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def lang_to_stringlist(self, lang):\n\"\"\"Find all sentences of lang.\"\"\"\n    all_tuv = self.tmx.xpath(\n        './/tuv[@xml:lang=\"' + lang + '\"]',\n        namespaces={\"xml\": \"http://www.w3.org/XML/1998/namespace\"},\n    )\n\n    strings = []\n    for tuv in all_tuv:\n        strings.append(self.tuv_to_string(tuv))\n\n    return strings\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.prettify_segs","title":"<code>prettify_segs(transl_unit)</code>  <code>staticmethod</code>","text":"<p>Strip white space from start and end of the strings.</p> <p>Input is a tu element Output is a tu element with white space stripped strings</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef prettify_segs(transl_unit):\n\"\"\"Strip white space from start and end of the strings.\n\n    Input is a tu element\n    Output is a tu element with white space stripped strings\n    \"\"\"\n    with util.ignored(AttributeError):\n        string = transl_unit[0][0].text.strip()\n        transl_unit[0][0].text = string\n\n    with util.ignored(AttributeError):\n        string = transl_unit[1][0].text.strip()\n        transl_unit[1][0].text = string\n\n    return transl_unit\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.remove_tu_with_empty_seg","title":"<code>remove_tu_with_empty_seg()</code>","text":"<p>Remove tu elements that contain empty seg element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def remove_tu_with_empty_seg(self):\n\"\"\"Remove tu elements that contain empty seg element.\"\"\"\n    root = self.tmx\n    for transl_unit in root.iter(\"tu\"):\n        try:\n            self.check_if_emtpy_seg(transl_unit)\n        except AttributeError:\n            transl_unit.getparent().remove(transl_unit)\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.remove_unwanted_space","title":"<code>remove_unwanted_space()</code>","text":"<p>Remove unwanted spaces from sentences.</p> <p>The SentenceDivider adds spaces before and after punctuation, quotemarks, parentheses and so on. Remove those spaces so that the tmxes are more appropriate for real world\u2122 use cases.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def remove_unwanted_space(self):\n\"\"\"Remove unwanted spaces from sentences.\n\n    The SentenceDivider adds spaces before and after punctuation,\n    quotemarks, parentheses and so on.\n    Remove those spaces so that the tmxes are more appropriate for real\n    world\u2122 use cases.\n    \"\"\"\n    root = self.tmx\n    for transl_unit in root.iter(\"tu\"):\n        transl_unit = self.remove_unwanted_space_from_segs(transl_unit)\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.remove_unwanted_space_from_segs","title":"<code>remove_unwanted_space_from_segs(transl_unit)</code>","text":"<p>Remove unwanted spaces.</p> <p>Remove spaces before and after punctuation, quotemarks, parentheses and so on as appropriate in the seg elements in the tu elements. Input is a tu element Output is a tu element with modified seg elements</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def remove_unwanted_space_from_segs(self, transl_unit):\n\"\"\"Remove unwanted spaces.\n\n    Remove spaces before and after punctuation,\n    quotemarks, parentheses and so on as appropriate in the seg elements\n    in the tu elements.\n    Input is a tu element\n    Output is a tu element with modified seg elements\n    \"\"\"\n    with util.ignored(AttributeError):\n        string = transl_unit[0][0].text.strip()\n        string = self.remove_unwanted_space_from_string(string)\n        transl_unit[0][0].text = string\n\n    with util.ignored(AttributeError):\n        string = transl_unit[1][0].text.strip()\n        string = self.remove_unwanted_space_from_string(string)\n        transl_unit[1][0].text = string\n\n    return transl_unit\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.remove_unwanted_space_from_string","title":"<code>remove_unwanted_space_from_string(input_string)</code>  <code>staticmethod</code>","text":"<p>Remove unwanted space from string.</p> <p>Parameters:</p> Name Type Description Default <code>input_string</code> <code>str</code> <p>the string we would like to remove unwanted space from:</p> required <p>Returns:</p> Type Description <p>str without unwanted space.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef remove_unwanted_space_from_string(input_string):\n\"\"\"Remove unwanted space from string.\n\n    Args:\n        input_string (str): the string we would like to remove\n            unwanted space from:\n\n    Returns:\n        str without unwanted space.\n    \"\"\"\n    result = input_string\n\n    # regex to find space followed by punctuation\n    space_punctuation = re.compile(r\"(?P&lt;space&gt;\\s)(?P&lt;punctuation&gt;[\\)\\]\\.\u00bb:;,])\")\n    # for every match in the result string, replace the match\n    # (space+punctuation) with the punctuation part\n    result = space_punctuation.sub(lambda match: match.group(\"punctuation\"), result)\n\n    # regex to find punctuation followed by space\n    punctuation_space = re.compile(r\"(?P&lt;punctuation&gt;[\\[\\(\u00ab])(?P&lt;space&gt;\\s)+\")\n    result = punctuation_space.sub(lambda match: match.group(\"punctuation\"), result)\n\n    # regex which matches multiple spaces\n    multiple_space = re.compile(r\"\\s+\")\n    result = multiple_space.sub(lambda match: \" \", result)\n\n    return result\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.reverse_langs","title":"<code>reverse_langs()</code>","text":"<p>Reverse the langs in a tmx.</p> <p>Return the reverted tmx</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def reverse_langs(self):\n\"\"\"Reverse the langs in a tmx.\n\n    Return the reverted tmx\n    \"\"\"\n    all_tu = self.tmx.findall(\".//tu\")\n    body = etree.Element(\"body\")\n    for transl_unit in all_tu:\n        tmp = etree.Element(\"tu\")\n        tmp.append(transl_unit[1])\n        tmp.append(transl_unit[0])\n        tmp = self.prettify_segs(tmp)\n        body.append(tmp)\n\n    tmx = etree.Element(\"tmx\")\n    tmx.append(body)\n\n    self.tmx = tmx\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.tmx2html","title":"<code>tmx2html(out_filename)</code>","text":"<p>Convert tmx to html.</p> <p>Parameters:</p> Name Type Description Default <code>out_filename</code> <code>str</code> <p>name of the html file</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def tmx2html(self, out_filename):\n\"\"\"Convert tmx to html.\n\n    Args:\n        out_filename (str): name of the html file\n    \"\"\"\n    html2tmx_transformer = etree.XSLT(\n        etree.parse(os.path.join(HERE, \"xslt/tmx2html.xsl\"))\n    )\n\n    with open(out_filename, \"wb\") as html_file:\n        html_file.write(\n            etree.tostring(\n                html2tmx_transformer(self.tmx),\n                pretty_print=True,\n                encoding=\"utf-8\",\n                xml_declaration=True,\n            )\n        )\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.tmx_to_stringlist","title":"<code>tmx_to_stringlist()</code>","text":"<p>Extract all string pairs in a tmx to a list of strings.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def tmx_to_stringlist(self):\n\"\"\"Extract all string pairs in a tmx to a list of strings.\"\"\"\n    all_tu = self.tmx.findall(\".//tu\")\n    strings = []\n    for transl_unit in all_tu:\n        strings.append(self.tu_to_string(transl_unit))\n\n    return strings\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.tu_to_string","title":"<code>tu_to_string(transl_unit)</code>  <code>staticmethod</code>","text":"<p>Extract the two strings of a tu element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef tu_to_string(transl_unit):\n\"\"\"Extract the two strings of a tu element.\"\"\"\n    string = \"\"\n    with util.ignored(AttributeError):\n        string = string + transl_unit[0][0].text.strip()\n\n    string += \"\\t\"\n\n    with util.ignored(AttributeError):\n        string = string + transl_unit[1][0].text.strip()\n\n    string += \"\\n\"\n    return string\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.tuv_to_string","title":"<code>tuv_to_string(tuv)</code>  <code>staticmethod</code>","text":"<p>Extract the string from the tuv element.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>@staticmethod\ndef tuv_to_string(tuv):\n\"\"\"Extract the string from the tuv element.\"\"\"\n    string = \"\"\n    with util.ignored(AttributeError):\n        string = tuv[0].text.strip()\n\n    return string\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.Tmx.write_tmx_file","title":"<code>write_tmx_file(out_filename)</code>","text":"<p>Write a tmx file given a tmx etree element and a filename.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def write_tmx_file(self, out_filename):\n\"\"\"Write a tmx file given a tmx etree element and a filename.\"\"\"\n    out_dir = os.path.dirname(out_filename)\n    with util.ignored(OSError):\n        os.makedirs(out_dir)\n\n    with open(out_filename, \"wb\") as tmx_file:\n        tmx_file.write(\n            etree.tostring(\n                self.tmx, pretty_print=True, encoding=\"utf-8\", xml_declaration=True\n            )\n        )\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.main","title":"<code>main()</code>","text":"<p>Parallelise files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def main():\n\"\"\"Parallelise files.\"\"\"\n    args = parse_options()\n\n    for source in args.sources:\n        if os.path.isfile(source):\n            if source.endswith(\".tmx\"):\n                tmx2html(source)\n            else:\n                SystemExit(f\"Not a tmx file:\\n{source}\")\n        elif os.path.isdir(source):\n            found = False\n            for tmx_file in find_files(source, \".tmx\"):\n                found = True\n                tmx2html(tmx_file)\n\n            if not found:\n                raise SystemExit(f\"No tmx files found in:\\n{source}\")\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser], description=\"Convert tmx files to html\"\n    )\n\n    parser.add_argument(\n        \"sources\", nargs=\"+\", help=\"Files or directories to search for tmx files\"\n    )\n\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"reference/tmx/#corpustools.tmx.tmx2html","title":"<code>tmx2html(filename)</code>","text":"<p>Turn a tmx file into an html file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of a tmx file</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/tmx.py</code> <pre><code>def tmx2html(filename):\n\"\"\"Turn a tmx file into an html file.\n\n    Args:\n        filename (str): name of a tmx file\n    \"\"\"\n    translation_mem_ex = Tmx(etree.parse(filename))\n    html_name = filename + \".html\"\n    translation_mem_ex.tmx2html(html_name)\n    print(f\"Wrote {html_name}\")\n</code></pre>"},{"location":"reference/trainingcorpusmaker/","title":"trainingcorpusmaker","text":"<p>Classes and functions to make corpus training files.</p>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker","title":"<code>TrainingCorpusMaker</code>","text":"<p>Turn analysed giella xml files into training corpus.</p> <p>Filter out all sentences containing words unknown to the giella fst analysers.</p> <p>Attributes:</p> Name Type Description <code>only_words</code> <p>regex catching word made up of letters.</p> <code>xml_printer</code> <code>ccat.XMLPrinter</code> <p>extracts the dependency analysis from the giella xml files.</p> <code>lang</code> <code>str</code> <p>the language of the training corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>class TrainingCorpusMaker:\n\"\"\"Turn analysed giella xml files into training corpus.\n\n    Filter out all sentences containing words unknown to the\n    giella fst analysers.\n\n    Attributes:\n        only_words: regex catching word made up of letters.\n        xml_printer (ccat.XMLPrinter): extracts the dependency analysis\n            from the giella xml files.\n        lang (str): the language of the training corpus.\n    \"\"\"\n\n    only_words = regex.compile(r\"\\p{L}+\")\n    xml_printer = ccat.XMLPrinter(dependency=True)\n\n    def __init__(self, lang):\n\"\"\"Initialise the TrainingCorpusMaker class.\"\"\"\n        self.lang = lang\n\n    def parse_dependency(self, text):\n\"\"\"Parse the dependency element found in a giella xml file.\n\n        Args:\n            text (str): contains the dependency element of a giella xml file.\n\n        Yields:\n            str: a sentence containing only words known to the giella fst\n                analysers, that contain at least a word as identified by\n                the only_words regex.\n        \"\"\"\n        sentence_buffer = []\n        uff_buffer = []\n        for line in io.StringIO(text):\n            line = line.rstrip()\n            if line == \":\" or line == \":\\\\n\":\n                sentence_buffer.append(\" \")\n            elif line.startswith(\":\"):\n                uff_buffer.append(line)\n            elif line.startswith('\"'):\n                sentence_buffer.append(line[2:-2])\n            elif \"CLB\" in line:\n                if not (\n                    '\".' not in line\n                    and '\"\u00b6\"' not in line\n                    and '\"?\"' not in line\n                    and '\"!\"' not in line\n                    and '\"\u2026\"' not in line\n                ):\n                    if uff_buffer:\n                        for uff in uff_buffer:\n                            util.print_frame(uff)\n                    else:\n                        sentence_line = (\n                            \"\".join(sentence_buffer).replace(\"\u00b6\", \"\").strip()\n                        )\n                        if self.only_words.search(sentence_line):\n                            yield sentence_line\n                    uff_buffer[:] = []\n                    sentence_buffer[:] = []\n            elif '\" ?' in line:\n                uff_buffer.append(line)\n\n    def file_to_sentences(self, filename):\n\"\"\"Turn a giella xml into a list of sentences.\n\n        Args:\n            filename (str): name of the giella xml file containing a\n                dependency element.\n\n        Returns:\n            list of str\n        \"\"\"\n        self.xml_printer.parse_file(filename)\n        text = self.xml_printer.process_file().getvalue()\n        if text.strip():\n            return [sentence for sentence in self.parse_dependency(text) if sentence]\n        else:\n            return []\n\n    def analysed_files(self):\n\"\"\"Find analysed files.\n\n        Yields:\n            str: filename of an analysed file.\n        \"\"\"\n        for corpus in [\n            os.path.join(os.getenv(\"GTFREE\"), \"analysed\", self.lang),\n            os.path.join(os.getenv(\"GTBOUND\"), \"analysed\", self.lang),\n        ]:\n            for root, _, files in os.walk(corpus):\n                for file_ in files:\n                    yield os.path.join(root, file_)\n\n    def make_corpus_files(self):\n\"\"\"Make .txt files from .xml files.\n\n        The .txt files contain only sentences with words known to the\n        giella fsts.\n        \"\"\"\n        for analysed_file in self.analysed_files():\n            if analysed_file.endswith(\".xml\"):\n                with open(analysed_file.replace(\".xml\", \".txt\"), \"w\") as txt_stream:\n                    txt_stream.write(\"\\n\".join(self.file_to_sentences(analysed_file)))\n                    txt_stream.write(\"\\n\")\n\n    def pytextcat_corpus(self):\n\"\"\"Turn the free and bound corpus into a pytextcat training corpus.\"\"\"\n        corpus_dir = os.path.join(\"pytextcat\", self.lang)\n        with util.ignored(OSError):\n            os.makedirs(corpus_dir)\n\n        with open(f\"{os.path.join(corpus_dir, self.lang)}.txt\", \"w\") as corpusfile:\n            for analysed_file in self.analysed_files():\n                if analysed_file.endswith(\".txt\"):\n                    with open(analysed_file) as analysed:\n                        corpusfile.write(analysed.read())\n\n    def langid_corpus(self):\n\"\"\"Turn the free and bound corpus into a langid training corpus.\"\"\"\n        for analysed_file in self.analysed_files():\n            if analysed_file.endswith(\".txt\"):\n                langid_dir = \"langid/{}/{}\".format(\n                    util.split_path(analysed_file).genre, self.lang\n                )\n                with util.ignored(OSError):\n                    os.makedirs(langid_dir)\n                copy(analysed_file, langid_dir)\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker.__init__","title":"<code>__init__(lang)</code>","text":"<p>Initialise the TrainingCorpusMaker class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def __init__(self, lang):\n\"\"\"Initialise the TrainingCorpusMaker class.\"\"\"\n    self.lang = lang\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker.analysed_files","title":"<code>analysed_files()</code>","text":"<p>Find analysed files.</p> <p>Yields:</p> Name Type Description <code>str</code> <p>filename of an analysed file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def analysed_files(self):\n\"\"\"Find analysed files.\n\n    Yields:\n        str: filename of an analysed file.\n    \"\"\"\n    for corpus in [\n        os.path.join(os.getenv(\"GTFREE\"), \"analysed\", self.lang),\n        os.path.join(os.getenv(\"GTBOUND\"), \"analysed\", self.lang),\n    ]:\n        for root, _, files in os.walk(corpus):\n            for file_ in files:\n                yield os.path.join(root, file_)\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker.file_to_sentences","title":"<code>file_to_sentences(filename)</code>","text":"<p>Turn a giella xml into a list of sentences.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of the giella xml file containing a dependency element.</p> required <p>Returns:</p> Type Description <p>list of str</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def file_to_sentences(self, filename):\n\"\"\"Turn a giella xml into a list of sentences.\n\n    Args:\n        filename (str): name of the giella xml file containing a\n            dependency element.\n\n    Returns:\n        list of str\n    \"\"\"\n    self.xml_printer.parse_file(filename)\n    text = self.xml_printer.process_file().getvalue()\n    if text.strip():\n        return [sentence for sentence in self.parse_dependency(text) if sentence]\n    else:\n        return []\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker.langid_corpus","title":"<code>langid_corpus()</code>","text":"<p>Turn the free and bound corpus into a langid training corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def langid_corpus(self):\n\"\"\"Turn the free and bound corpus into a langid training corpus.\"\"\"\n    for analysed_file in self.analysed_files():\n        if analysed_file.endswith(\".txt\"):\n            langid_dir = \"langid/{}/{}\".format(\n                util.split_path(analysed_file).genre, self.lang\n            )\n            with util.ignored(OSError):\n                os.makedirs(langid_dir)\n            copy(analysed_file, langid_dir)\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker.make_corpus_files","title":"<code>make_corpus_files()</code>","text":"<p>Make .txt files from .xml files.</p> <p>The .txt files contain only sentences with words known to the giella fsts.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def make_corpus_files(self):\n\"\"\"Make .txt files from .xml files.\n\n    The .txt files contain only sentences with words known to the\n    giella fsts.\n    \"\"\"\n    for analysed_file in self.analysed_files():\n        if analysed_file.endswith(\".xml\"):\n            with open(analysed_file.replace(\".xml\", \".txt\"), \"w\") as txt_stream:\n                txt_stream.write(\"\\n\".join(self.file_to_sentences(analysed_file)))\n                txt_stream.write(\"\\n\")\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker.parse_dependency","title":"<code>parse_dependency(text)</code>","text":"<p>Parse the dependency element found in a giella xml file.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>contains the dependency element of a giella xml file.</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>a sentence containing only words known to the giella fst analysers, that contain at least a word as identified by the only_words regex.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def parse_dependency(self, text):\n\"\"\"Parse the dependency element found in a giella xml file.\n\n    Args:\n        text (str): contains the dependency element of a giella xml file.\n\n    Yields:\n        str: a sentence containing only words known to the giella fst\n            analysers, that contain at least a word as identified by\n            the only_words regex.\n    \"\"\"\n    sentence_buffer = []\n    uff_buffer = []\n    for line in io.StringIO(text):\n        line = line.rstrip()\n        if line == \":\" or line == \":\\\\n\":\n            sentence_buffer.append(\" \")\n        elif line.startswith(\":\"):\n            uff_buffer.append(line)\n        elif line.startswith('\"'):\n            sentence_buffer.append(line[2:-2])\n        elif \"CLB\" in line:\n            if not (\n                '\".' not in line\n                and '\"\u00b6\"' not in line\n                and '\"?\"' not in line\n                and '\"!\"' not in line\n                and '\"\u2026\"' not in line\n            ):\n                if uff_buffer:\n                    for uff in uff_buffer:\n                        util.print_frame(uff)\n                else:\n                    sentence_line = (\n                        \"\".join(sentence_buffer).replace(\"\u00b6\", \"\").strip()\n                    )\n                    if self.only_words.search(sentence_line):\n                        yield sentence_line\n                uff_buffer[:] = []\n                sentence_buffer[:] = []\n        elif '\" ?' in line:\n            uff_buffer.append(line)\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.TrainingCorpusMaker.pytextcat_corpus","title":"<code>pytextcat_corpus()</code>","text":"<p>Turn the free and bound corpus into a pytextcat training corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def pytextcat_corpus(self):\n\"\"\"Turn the free and bound corpus into a pytextcat training corpus.\"\"\"\n    corpus_dir = os.path.join(\"pytextcat\", self.lang)\n    with util.ignored(OSError):\n        os.makedirs(corpus_dir)\n\n    with open(f\"{os.path.join(corpus_dir, self.lang)}.txt\", \"w\") as corpusfile:\n        for analysed_file in self.analysed_files():\n            if analysed_file.endswith(\".txt\"):\n                with open(analysed_file) as analysed:\n                    corpusfile.write(analysed.read())\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.main","title":"<code>main()</code>","text":"<p>Turn the corpus into a pytextcat training corpus.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def main():\n\"\"\"Turn the corpus into a pytextcat training corpus.\"\"\"\n    args = parse_options()\n\n    for lang in args.langs:\n        sentence_maker = TrainingCorpusMaker(lang)\n        sentence_maker.make_corpus_files()\n        sentence_maker.pytextcat_corpus()\n        sentence_maker.langid_corpus()\n\n    print(\n        \"Now you will find training corpus for pytextcat and langid \"\n        \"in the pytextcat and langid directories in the current directory.\"\n    )\n</code></pre>"},{"location":"reference/trainingcorpusmaker/#corpustools.trainingcorpusmaker.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the options given to the program.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/trainingcorpusmaker.py</code> <pre><code>def parse_options():\n\"\"\"Parse the options given to the program.\"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Make training corpus from analysed giella xml files.\\n\"\n        \"Sentences with words unknown for the giella fsts are not included.\",\n    )\n    parser.add_argument(\n        \"langs\", nargs=\"+\", help=\"The languages to make a training corpus for.\"\n    )\n\n    return parser.parse_args()\n</code></pre>"},{"location":"reference/typosfile/","title":"typosfile","text":"<p>Classes to handle .typos files in $GTFREE.</p>"},{"location":"reference/typosfile/#corpustools.typosfile.Typoline","title":"<code>Typoline</code>","text":"<p>Class to parse a line of a .typos file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/typosfile.py</code> <pre><code>class Typoline:\n\"\"\"Class to parse a line of a .typos file\"\"\"\n\n    def __init__(self, typoline):\n\"\"\"Parse a typoline\n\n        A typoline has a number showing frequency of the typo, the typo and\n        possibly a correction\n        \"\"\"\n        parts = typoline.split(\"\\t\")\n\n        self.typo = parts[0]\n\n        if len(parts) == 2:\n            self.correction = parts[1]\n        else:\n            self.correction = None\n\n    def getTypo(self):\n        return self.typo\n\n    def setCorrection(self, correction):\n        self.correction = correction\n\n    def getCorrection(self):\n        return self.correction\n\n    def makeTypoline(self):\n\"\"\"Make a typoline from the three data parts in this class\"\"\"\n        result = self.typo\n        if self.correction and self.correction != self.typo:\n            result = f\"{result}\\t{self.correction}\"\n\n        return result\n</code></pre>"},{"location":"reference/typosfile/#corpustools.typosfile.Typoline.__init__","title":"<code>__init__(typoline)</code>","text":"<p>Parse a typoline</p> <p>A typoline has a number showing frequency of the typo, the typo and possibly a correction</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/typosfile.py</code> <pre><code>def __init__(self, typoline):\n\"\"\"Parse a typoline\n\n    A typoline has a number showing frequency of the typo, the typo and\n    possibly a correction\n    \"\"\"\n    parts = typoline.split(\"\\t\")\n\n    self.typo = parts[0]\n\n    if len(parts) == 2:\n        self.correction = parts[1]\n    else:\n        self.correction = None\n</code></pre>"},{"location":"reference/typosfile/#corpustools.typosfile.Typoline.makeTypoline","title":"<code>makeTypoline()</code>","text":"<p>Make a typoline from the three data parts in this class</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/typosfile.py</code> <pre><code>def makeTypoline(self):\n\"\"\"Make a typoline from the three data parts in this class\"\"\"\n    result = self.typo\n    if self.correction and self.correction != self.typo:\n        result = f\"{result}\\t{self.correction}\"\n\n    return result\n</code></pre>"},{"location":"reference/typosfile/#corpustools.typosfile.Typos","title":"<code>Typos</code>","text":"<p>A class that reads typos and corrections from a .typos files</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/typosfile.py</code> <pre><code>class Typos:\n\"\"\"A class that reads typos and corrections from a .typos files\"\"\"\n\n    def __init__(self, typosfile):\n\"\"\"Read typos from typosfile.\n\n        If a correction exists, insert the typos\n        and corrections into self.typos\n        \"\"\"\n        self.typos = {}\n        typofile = open(typosfile)\n\n        for strline in typofile:\n            line = strline.decode(\"utf-8\")\n            if line.strip():\n                tl = Typoline(line.rstrip())\n                if tl.getCorrection() and tl.getTypo() != tl.getCorrection():\n                    self.typos[tl.getTypo()] = tl.getCorrection()\n        typofile.close()\n\n    def getTypos(self):\n\"\"\"Return the typos dict\"\"\"\n        return self.typos\n</code></pre>"},{"location":"reference/typosfile/#corpustools.typosfile.Typos.__init__","title":"<code>__init__(typosfile)</code>","text":"<p>Read typos from typosfile.</p> <p>If a correction exists, insert the typos and corrections into self.typos</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/typosfile.py</code> <pre><code>def __init__(self, typosfile):\n\"\"\"Read typos from typosfile.\n\n    If a correction exists, insert the typos\n    and corrections into self.typos\n    \"\"\"\n    self.typos = {}\n    typofile = open(typosfile)\n\n    for strline in typofile:\n        line = strline.decode(\"utf-8\")\n        if line.strip():\n            tl = Typoline(line.rstrip())\n            if tl.getCorrection() and tl.getTypo() != tl.getCorrection():\n                self.typos[tl.getTypo()] = tl.getCorrection()\n    typofile.close()\n</code></pre>"},{"location":"reference/typosfile/#corpustools.typosfile.Typos.getTypos","title":"<code>getTypos()</code>","text":"<p>Return the typos dict</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/typosfile.py</code> <pre><code>def getTypos(self):\n\"\"\"Return the typos dict\"\"\"\n    return self.typos\n</code></pre>"},{"location":"reference/update_metadata/","title":"update_metadata","text":"<p>Update metadata files in given directories.</p>"},{"location":"reference/update_metadata/#corpustools.update_metadata.find_xsl_files","title":"<code>find_xsl_files(directories)</code>","text":"<p>Find .xsl files found in directories.</p> <p>Parameters:</p> Name Type Description Default <code>directories</code> <code>list of str</code> <p>paths to directories</p> required <p>Yields:</p> Name Type Description <code>str</code> <p>path to an .xsl file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/update_metadata.py</code> <pre><code>def find_xsl_files(directories):\n\"\"\"Find .xsl files found in directories.\n\n    Args:\n        directories (list of str): paths to directories\n\n    Yields:\n        str: path to an .xsl file\n    \"\"\"\n    for directory in directories:\n        for root, _, files in os.walk(directory):\n            for file_ in files:\n                if file_.endswith(\".xsl\"):\n                    yield os.path.join(root, file_)\n</code></pre>"},{"location":"reference/update_metadata/#corpustools.update_metadata.main","title":"<code>main()</code>","text":"<p>Update metadata files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/update_metadata.py</code> <pre><code>def main():\n\"\"\"Update metadata files.\"\"\"\n    args = parse_options()\n    for xsl_file in find_xsl_files(args.directories):\n        try:\n            update_xsl_file(xsl_file)\n        except (AttributeError, UserWarning, xslsetter.XsltError) as error:\n            print(xsl_file)\n            raise SystemExit(4)\n</code></pre>"},{"location":"reference/update_metadata/#corpustools.update_metadata.parse_options","title":"<code>parse_options()</code>","text":"<p>Parse the commandline options.</p> <p>Returns:</p> Type Description <p>a list of arguments as parsed by argparse.Argumentparser.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/update_metadata.py</code> <pre><code>def parse_options():\n\"\"\"Parse the commandline options.\n\n    Returns:\n        a list of arguments as parsed by argparse.Argumentparser.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        parents=[argparse_version.parser],\n        description=\"Update metadata files to look like XSL-template.xsl, \"\n        \"but with original content. This script exists because the \"\n        \"XSL-template is updated with new variables and documentation. \"\n        \"This script will propagate these changes to existing \"\n        \"metadata files.\",\n    )\n\n    parser.add_argument(\n        \"directories\",\n        nargs=\"+\",\n        help=\"Directories where metadata files should be updated.\",\n    )\n\n    args = parser.parse_args()\n\n    return args\n</code></pre>"},{"location":"reference/update_metadata/#corpustools.update_metadata.update_xsl_file","title":"<code>update_xsl_file(filename)</code>","text":"<p>Update the xsl file with XSL-template.xsl.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to a metadata file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/update_metadata.py</code> <pre><code>def update_xsl_file(filename):\n\"\"\"Update the xsl file with XSL-template.xsl.\n\n    Args:\n        filename (str): path to a metadata file.\n    \"\"\"\n    avoid_names = [\n        \"danlang\",\n        \"englang\",\n        \"finlang\",\n        \"fkvlang\",\n        \"gerlang\",\n        \"isllang\",\n        \"kallang\",\n        \"nnolang\",\n        \"noblang\",\n        \"smalang\",\n        \"smelang\",\n        \"smjlang\",\n        \"swelang\",\n        \"kpvlang\",\n        \"ruslang\",\n        \"multilingual\",\n        \"columns\",\n        \"parallel_texts\",\n        \"lower\",\n    ]\n\n    orig_metadata = xslsetter.MetadataHandler(filename)\n    template_metadata = xslsetter.MetadataHandler(TEMPLATE_PATH)\n\n    for language in orig_metadata.mlangs:\n        template_metadata.set_mlang(language)\n\n    for name, value in orig_metadata.get_set_variables():\n        if name not in avoid_names:\n            if name.startswith(\"mlang_\"):\n                template_metadata.set_mlang(name.replace(\"mlang_\", \"\"))\n            elif name.startswith(\"para_\"):\n                template_metadata.set_parallel_text(name.replace(\"para_\", \"\"), value)\n            elif name == \"excluded\":\n                template_metadata.set_variable(\"skip_pages\", value)\n            else:\n                template_metadata.set_variable(name, value)\n\n    for language, location in orig_metadata.get_parallel_texts().items():\n        template_metadata.set_parallel_text(language, location)\n\n    template_element = template_metadata.tree.getroot()\n    for template in orig_metadata.xsl_templates:\n        template_element.append(template)\n\n    orig_metadata.tree = template_metadata.tree\n    orig_metadata.write_file()\n</code></pre>"},{"location":"reference/usxconverter/","title":"usxconverter","text":"<p>Convert bible usx xml files to giella xml format.</p>"},{"location":"reference/usxconverter/#corpustools.usxconverter.convert2intermediate","title":"<code>convert2intermediate(filename)</code>","text":"<p>Convert usx xml files to the giellatekno xml format.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/usxconverter.py</code> <pre><code>def convert2intermediate(filename):\n\"\"\"Convert usx xml files to the giellatekno xml format.\"\"\"\n    usx_doc = etree.parse(filename).getroot()\n    remove_unwanted(usx_doc)\n    char_to_span(usx_doc)\n\n    return usx_to_document(usx_doc)\n</code></pre>"},{"location":"reference/util/","title":"util","text":"<p>Utility functions and classes used by other modules in CorpusTools.</p>"},{"location":"reference/util/#corpustools.util.ArgumentError","title":"<code>ArgumentError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>This exception is raised when argument errors occur.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>class ArgumentError(Exception):\n\"\"\"This exception is raised when argument errors occur.\"\"\"\n</code></pre>"},{"location":"reference/util/#corpustools.util.ConversionError","title":"<code>ConversionError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raise this exception when conversions error occur.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>class ConversionError(Exception):\n\"\"\"Raise this exception when conversions error occur.\"\"\"\n</code></pre>"},{"location":"reference/util/#corpustools.util.ExecutableMissingError","title":"<code>ExecutableMissingError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>This exception is raised when wanted executables are missing.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>class ExecutableMissingError(Exception):\n\"\"\"This exception is raised when wanted executables are missing.\"\"\"\n</code></pre>"},{"location":"reference/util/#corpustools.util.ExternalCommandRunner","title":"<code>ExternalCommandRunner</code>","text":"<p>Class to run external command through subprocess.</p> <p>Attributes:</p> Name Type Description <code>stdout</code> <p>save the stdout of the command here.</p> <code>stderr</code> <p>save the stderr of the command here.</p> <code>returncode</code> <p>save the returncode of the command here.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>class ExternalCommandRunner:\n\"\"\"Class to run external command through subprocess.\n\n    Attributes:\n        stdout: save the stdout of the command here.\n        stderr: save the stderr of the command here.\n        returncode: save the returncode of the command here.\n    \"\"\"\n\n    def __init__(self):\n\"\"\"Initialise the ExternalCommandRunner class.\"\"\"\n        self.stdout = None\n        self.stderr = None\n        self.returncode = None\n\n    def run(self, command, cwd=None, to_stdin=None):\n\"\"\"Run the command, save the result.\"\"\"\n        try:\n            subp = subprocess.Popen(\n                command,\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                cwd=cwd,\n            )\n        except OSError:\n            raise ExecutableMissingError(\n                f\"Please install {command[0]}, can not continue without it.\"\n            )\n\n        (self.stdout, self.stderr) = subp.communicate(to_stdin)\n        self.returncode = subp.returncode\n</code></pre>"},{"location":"reference/util/#corpustools.util.ExternalCommandRunner.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the ExternalCommandRunner class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the ExternalCommandRunner class.\"\"\"\n    self.stdout = None\n    self.stderr = None\n    self.returncode = None\n</code></pre>"},{"location":"reference/util/#corpustools.util.ExternalCommandRunner.run","title":"<code>run(command, cwd=None, to_stdin=None)</code>","text":"<p>Run the command, save the result.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def run(self, command, cwd=None, to_stdin=None):\n\"\"\"Run the command, save the result.\"\"\"\n    try:\n        subp = subprocess.Popen(\n            command,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            cwd=cwd,\n        )\n    except OSError:\n        raise ExecutableMissingError(\n            f\"Please install {command[0]}, can not continue without it.\"\n        )\n\n    (self.stdout, self.stderr) = subp.communicate(to_stdin)\n    self.returncode = subp.returncode\n</code></pre>"},{"location":"reference/util/#corpustools.util.SetupError","title":"<code>SetupError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>This exception is raised when setup is faulty.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>class SetupError(Exception):\n\"\"\"This exception is raised when setup is faulty.\"\"\"\n</code></pre>"},{"location":"reference/util/#corpustools.util.basename_noext","title":"<code>basename_noext(fname, ext)</code>","text":"<p>Get the basename without the extension.</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> <code>str</code> <p>path to the file.</p> required <code>ext</code> <code>str</code> <p>the extension that should be removed.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>fname without the extension.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def basename_noext(fname, ext):\n\"\"\"Get the basename without the extension.\n\n    Args:\n        fname (str): path to the file.\n        ext (str): the extension that should be removed.\n\n    Returns:\n        str: fname without the extension.\n    \"\"\"\n    return os.path.basename(fname)[: -len(ext)]\n</code></pre>"},{"location":"reference/util/#corpustools.util.collect_files","title":"<code>collect_files(entities, suffix)</code>","text":"<p>Collect files with the specified suffix.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def collect_files(entities, suffix):\n\"\"\"Collect files with the specified suffix.\"\"\"\n    for entity in entities:\n        if os.path.isfile(entity) and entity.endswith(suffix):\n            yield entity\n        else:\n            for root, _, files in os.walk(entity):\n                for file_ in files:\n                    if file_.endswith(suffix):\n                        yield os.path.join(root, file_)\n</code></pre>"},{"location":"reference/util/#corpustools.util.executable_in_path","title":"<code>executable_in_path(program)</code>","text":"<p>Check if program is in path.</p> <p>Parameters:</p> Name Type Description Default <code>program</code> <code>str</code> <p>name of the program</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if program is found, False otherwise.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def executable_in_path(program):\n\"\"\"Check if program is in path.\n\n    Args:\n        program (str): name of the program\n\n    Returns:\n        bool: True if program is found, False otherwise.\n    \"\"\"\n    fpath, _ = os.path.split(program)\n    if fpath:\n        return is_executable(program)\n    else:\n        return any(\n            is_executable(possible_path)\n            for possible_path in path_possibilities(program)\n        )\n</code></pre>"},{"location":"reference/util/#corpustools.util.get_lang_resource","title":"<code>get_lang_resource(lang, resource, fallback=None)</code>","text":"<p>Get a language resource.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>the language of the resource.</p> required <code>resource</code> <code>str</code> <p>the resource that is needed.</p> required <code>fallback</code> <code>str or None</code> <p>the fallback resource. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <p>path to the resource or fallback.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def get_lang_resource(lang, resource, fallback=None):\n\"\"\"Get a language resource.\n\n    Args:\n        lang (str): the language of the resource.\n        resource (str): the resource that is needed.\n        fallback (str or None): the fallback resource. Default is None.\n\n    Returns:\n        str: path to the resource or fallback.\n    \"\"\"\n    path = os.path.join(os.environ[\"GTHOME\"], \"langs\", lang, resource)\n    if os.path.exists(path):\n        return path\n    else:\n        return fallback\n</code></pre>"},{"location":"reference/util/#corpustools.util.get_preprocess_command","title":"<code>get_preprocess_command(lang)</code>","text":"<p>Get the complete proprocess command for lang.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>the language</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>the complete preprocess command.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def get_preprocess_command(lang):\n\"\"\"Get the complete proprocess command for lang.\n\n    Args:\n        lang (str): the language\n\n    Returns:\n        str: the complete preprocess command.\n    \"\"\"\n    preprocess_script = os.path.join(os.environ[\"GTHOME\"], \"gt/script/preprocess\")\n    sanity_check([preprocess_script])\n    abbr_fb = get_lang_resource(\"sme\", \"tools/preprocess/abbr.txt\")\n    abbr = get_lang_resource(lang, \"tools/preprocess/abbr.txt\", abbr_fb)\n    return [preprocess_script, f\"--abbr={abbr}\"]\n</code></pre>"},{"location":"reference/util/#corpustools.util.ignored","title":"<code>ignored(*exceptions)</code>","text":"<p>Ignore exceptions.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>@contextmanager\ndef ignored(*exceptions):\n\"\"\"Ignore exceptions.\"\"\"\n    try:\n        yield\n    except exceptions:\n        pass\n</code></pre>"},{"location":"reference/util/#corpustools.util.is_executable","title":"<code>is_executable(fullpath)</code>","text":"<p>Check if the program in fullpath is executable.</p> <p>Parameters:</p> Name Type Description Default <code>fullpath</code> <code>str</code> <p>the path to the program or script.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if fullpath contains a executable, False otherwise.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def is_executable(fullpath):\n\"\"\"Check if the program in fullpath is executable.\n\n    Args:\n        fullpath (str): the path to the program or script.\n\n    Returns:\n        bool: True if fullpath contains a executable, False otherwise.\n    \"\"\"\n    return os.path.isfile(fullpath) and os.access(fullpath, os.X_OK)\n</code></pre>"},{"location":"reference/util/#corpustools.util.lineno","title":"<code>lineno()</code>","text":"<p>Return the current line number in our program.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def lineno():\n\"\"\"Return the current line number in our program.\"\"\"\n    return inspect.currentframe().f_back.f_lineno\n</code></pre>"},{"location":"reference/util/#corpustools.util.name_to_unicode","title":"<code>name_to_unicode(filename)</code>","text":"<p>Turn a filename to a unicode string.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>name of the file</p> required <p>Returns:</p> Type Description <p>A unicode string.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def name_to_unicode(filename):\n\"\"\"Turn a filename to a unicode string.\n\n    Args:\n        filename (str): name of the file\n\n    Returns:\n        A unicode string.\n    \"\"\"\n    if platform.system() == \"Windows\":\n        return filename\n    else:\n        return filename.decode(\"utf-8\")\n</code></pre>"},{"location":"reference/util/#corpustools.util.note","title":"<code>note(msg)</code>","text":"<p>Print msg to stderr.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>the message</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def note(msg):\n\"\"\"Print msg to stderr.\n\n    Args:\n        msg (str): the message\n    \"\"\"\n    print(msg, file=sys.stderr)\n</code></pre>"},{"location":"reference/util/#corpustools.util.path_possibilities","title":"<code>path_possibilities(program)</code>","text":"<p>Check if program is found in $PATH.</p> <p>Parameters:</p> Name Type Description Default <code>program</code> <p>name of program of script.</p> required <p>Yields:</p> Type Description <p>possible fullpath to the program</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def path_possibilities(program):\n\"\"\"Check if program is found in $PATH.\n\n    Args:\n        program: name of program of script.\n\n    Yields:\n        possible fullpath to the program\n    \"\"\"\n    return (\n        os.path.join(path.strip('\"'), program)\n        for path in os.environ[\"PATH\"].split(os.pathsep)\n    )\n</code></pre>"},{"location":"reference/util/#corpustools.util.print_element","title":"<code>print_element(element, level, indent, out)</code>","text":"<p>Format an html document.</p> <p>This function formats html documents for readability, to see the structure of the given document. It ruins white space in text parts.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>etree._Element</code> <p>the element to format.</p> required <code>level</code> <code>int</code> <p>indicate at what level this element is.</p> required <code>indent</code> <code>int</code> <p>indicate how many spaces this element should be indented</p> required <code>out</code> <code>stream</code> <p>a buffer where the formatted element is written.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def print_element(element, level, indent, out):\n\"\"\"Format an html document.\n\n    This function formats html documents for readability, to see\n    the structure of the given document. It ruins white space in\n    text parts.\n\n    Args:\n        element (etree._Element): the element to format.\n        level (int): indicate at what level this element is.\n        indent (int): indicate how many spaces this element should be indented\n        out (stream): a buffer where the formatted element is written.\n    \"\"\"\n    tag = element.tag.replace(\"{http://www.w3.org/1999/xhtml}\", \"\")\n\n    out.write(\" \" * (level * indent))\n    out.write(f\"&lt;{tag}\")\n\n    for k, v in element.attrib.items():\n        out.write(\" \")\n        if isinstance(k, str):\n            out.write(k)\n        else:\n            out.write(k)\n        out.write('=\"')\n        if isinstance(v, str):\n            out.write(v)\n        else:\n            out.write(v)\n        out.write('\"')\n    out.write(\"&gt;\\n\")\n\n    if element.text is not None and element.text.strip() != \"\":\n        out.write(\" \" * ((level + 1) * indent))\n        out.write(element.text.strip())\n        out.write(\"\\n\")\n\n    for child in element:\n        print_element(child, level + 1, indent, out)\n\n    out.write(\" \" * (level * indent))\n    out.write(f\"&lt;/{tag}&gt;\\n\")\n\n    if level &gt; 0 and element.tail is not None and element.tail.strip() != \"\":\n        for _ in range(0, (level - 1) * indent):\n            out.write(\" \")\n        out.write(element.tail.strip())\n        out.write(\"\\n\")\n</code></pre>"},{"location":"reference/util/#corpustools.util.print_frame","title":"<code>print_frame(debug='', *args)</code>","text":"<p>Print debug output.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def print_frame(debug=\"\", *args):\n\"\"\"Print debug output.\"\"\"\n    # 0 represents this line, 1 represents line at caller\n    callerframerecord = inspect.stack()[1]\n    frame = callerframerecord[0]\n    info = inspect.getframeinfo(frame)\n\n    print(info.lineno, info.function, debug, file=sys.stderr, end=\" \")\n    for arg in args:\n        print(arg, file=sys.stderr, end=\" \")\n    print(file=sys.stderr)\n</code></pre>"},{"location":"reference/util/#corpustools.util.replace_all","title":"<code>replace_all(replacements, string)</code>","text":"<p>Replace unwanted strings with wanted strings.</p> <p>Parameters:</p> Name Type Description Default <code>replacements</code> <code>list of tuple</code> <p>unwanted:wanted string pairs.</p> required <code>string</code> <code>str</code> <p>the string where replacements should be done.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>string with replaced strings.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def replace_all(replacements, string):\n\"\"\"Replace unwanted strings with wanted strings.\n\n    Args:\n        replacements (list of tuple): unwanted:wanted string pairs.\n        string (str): the string where replacements should be done.\n\n    Returns:\n        str: string with replaced strings.\n    \"\"\"\n    for unwanted, wanted in replacements:\n        string = string.replace(unwanted, wanted)\n\n    return string\n</code></pre>"},{"location":"reference/util/#corpustools.util.sanity_check","title":"<code>sanity_check(program_list)</code>","text":"<p>Look for programs and files that are needed to do the analysis.</p> <p>If they don't exist, raise an exception.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def sanity_check(program_list):\n\"\"\"Look for programs and files that are needed to do the analysis.\n\n    If they don't exist, raise an exception.\n    \"\"\"\n    if \"GTHOME\" not in os.environ:\n        raise SetupError(\n            \"You have to set the environment variable GTHOME \"\n            \"to your checkout of langtech/trunk!\"\n        )\n    for program in program_list:\n        if executable_in_path(program) is False:\n            raise ExecutableMissingError(\n                f\"Please install {program}, can not continue without it.\"\n            )\n</code></pre>"},{"location":"reference/util/#corpustools.util.sort_by_value","title":"<code>sort_by_value(table, **kwargs)</code>","text":"<p>Sort the table by value.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>dict</code> <p>the dictionary that should be sorted.</p> required <code>**kwargs</code> <p>Keyword arguments passed on to the sorted function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>sorted by value.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/util.py</code> <pre><code>def sort_by_value(table, **kwargs):\n\"\"\"Sort the table by value.\n\n    Args:\n        table (dict): the dictionary that should be sorted.\n        **kwargs: Keyword arguments passed on to the sorted function.\n\n    Returns:\n        dict: sorted by value.\n    \"\"\"\n    return sorted(table.items(), key=operator.itemgetter(1), **kwargs)\n</code></pre>"},{"location":"reference/versioncontrol/","title":"versioncontrol","text":"<p>Classes and functions to change names of corpus files.</p>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.GIT","title":"<code>GIT</code>","text":"<p>         Bases: <code>VersionController</code></p> <p>Implement basic git functionality.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>class GIT(VersionController):\n\"\"\"Implement basic git functionality.\"\"\"\n\n    def __init__(self, gitrepo):\n\"\"\"Initialise the GIT class.\n\n        Args:\n            gitrepo (git.Repo): client to control the git repo\n        \"\"\"\n        super().__init__()\n        self.gitrepo = gitrepo\n        self.config = self.gitrepo.config_reader()\n\n    def add(self, path):\n\"\"\"Add path to the repo.\n\n        Args:\n            path (str): path that should be added to the git repo.\n        \"\"\"\n        self.gitrepo.git.add(path)\n\n    def move(self, oldpath, newpath):\n\"\"\"Move a file within the repo.\n\n        Args:\n            oldpath (src): path of the file that should be moved\n            newpath (scr): new path of the file to be moved\n        \"\"\"\n        self.gitrepo.git.mv(oldpath, newpath)\n\n    def remove(self, path):\n\"\"\"Remove a file from the repo.\n\n        Args:\n            path (src); path of the file that should be removed.\n        \"\"\"\n        self.gitrepo.git.rm(path)\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.GIT.__init__","title":"<code>__init__(gitrepo)</code>","text":"<p>Initialise the GIT class.</p> <p>Parameters:</p> Name Type Description Default <code>gitrepo</code> <code>git.Repo</code> <p>client to control the git repo</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def __init__(self, gitrepo):\n\"\"\"Initialise the GIT class.\n\n    Args:\n        gitrepo (git.Repo): client to control the git repo\n    \"\"\"\n    super().__init__()\n    self.gitrepo = gitrepo\n    self.config = self.gitrepo.config_reader()\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.GIT.add","title":"<code>add(path)</code>","text":"<p>Add path to the repo.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>path that should be added to the git repo.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def add(self, path):\n\"\"\"Add path to the repo.\n\n    Args:\n        path (str): path that should be added to the git repo.\n    \"\"\"\n    self.gitrepo.git.add(path)\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.GIT.move","title":"<code>move(oldpath, newpath)</code>","text":"<p>Move a file within the repo.</p> <p>Parameters:</p> Name Type Description Default <code>oldpath</code> <code>src</code> <p>path of the file that should be moved</p> required <code>newpath</code> <code>scr</code> <p>new path of the file to be moved</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def move(self, oldpath, newpath):\n\"\"\"Move a file within the repo.\n\n    Args:\n        oldpath (src): path of the file that should be moved\n        newpath (scr): new path of the file to be moved\n    \"\"\"\n    self.gitrepo.git.mv(oldpath, newpath)\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.GIT.remove","title":"<code>remove(path)</code>","text":"<p>Remove a file from the repo.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def remove(self, path):\n\"\"\"Remove a file from the repo.\n\n    Args:\n        path (src); path of the file that should be removed.\n    \"\"\"\n    self.gitrepo.git.rm(path)\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionControlError","title":"<code>VersionControlError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raise this exception when errors arise in this module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>class VersionControlError(Exception):\n\"\"\"Raise this exception when errors arise in this module.\"\"\"\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionController","title":"<code>VersionController</code>","text":"<p>A very basic version control class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>class VersionController:\n\"\"\"A very basic version control class.\"\"\"\n\n    def __init__(self):\n\"\"\"Initialise the VersionController class.\"\"\"\n        # non-repo config to get at global values\n        self.config = git.GitConfigParser(\n            [os.path.normpath(os.path.expanduser(\"~/.gitconfig\"))], read_only=True\n        )\n\n    def add(self, path):\n\"\"\"Meta function.\"\"\"\n        raise NotImplementedError(\"You have to subclass and override add\")\n\n    def move(self, oldpath, newpath):\n\"\"\"Meta function.\"\"\"\n        raise NotImplementedError(\"You have to subclass and override move\")\n\n    def remove(self, path):\n\"\"\"Meta function.\"\"\"\n        raise NotImplementedError(\"You have to subclass and override remove\")\n\n    def user_name(self):\n\"\"\"Try to get a username.\"\"\"\n        if self.config.has_option(\"user\", \"name\"):\n            return self.config.get(\"user\", \"name\")\n        else:\n            pwnam = pwd.getpwnam(getpass.getuser()).pw_gecos\n            if pwnam is not None:\n                return pwnam\n            else:\n                return \"\"\n\n    def user_email(self):\n\"\"\"Try to get the users email.\"\"\"\n        if self.config.has_option(\"user\", \"email\"):\n            return self.config.get(\"user\", \"email\")\n        else:\n            return \"\"\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionController.__init__","title":"<code>__init__()</code>","text":"<p>Initialise the VersionController class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def __init__(self):\n\"\"\"Initialise the VersionController class.\"\"\"\n    # non-repo config to get at global values\n    self.config = git.GitConfigParser(\n        [os.path.normpath(os.path.expanduser(\"~/.gitconfig\"))], read_only=True\n    )\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionController.add","title":"<code>add(path)</code>","text":"<p>Meta function.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def add(self, path):\n\"\"\"Meta function.\"\"\"\n    raise NotImplementedError(\"You have to subclass and override add\")\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionController.move","title":"<code>move(oldpath, newpath)</code>","text":"<p>Meta function.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def move(self, oldpath, newpath):\n\"\"\"Meta function.\"\"\"\n    raise NotImplementedError(\"You have to subclass and override move\")\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionController.remove","title":"<code>remove(path)</code>","text":"<p>Meta function.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def remove(self, path):\n\"\"\"Meta function.\"\"\"\n    raise NotImplementedError(\"You have to subclass and override remove\")\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionController.user_email","title":"<code>user_email()</code>","text":"<p>Try to get the users email.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def user_email(self):\n\"\"\"Try to get the users email.\"\"\"\n    if self.config.has_option(\"user\", \"email\"):\n        return self.config.get(\"user\", \"email\")\n    else:\n        return \"\"\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.VersionController.user_name","title":"<code>user_name()</code>","text":"<p>Try to get a username.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def user_name(self):\n\"\"\"Try to get a username.\"\"\"\n    if self.config.has_option(\"user\", \"name\"):\n        return self.config.get(\"user\", \"name\")\n    else:\n        pwnam = pwd.getpwnam(getpass.getuser()).pw_gecos\n        if pwnam is not None:\n            return pwnam\n        else:\n            return \"\"\n</code></pre>"},{"location":"reference/versioncontrol/#corpustools.versioncontrol.vcs","title":"<code>vcs(directory)</code>","text":"<p>Make a version control client.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>the directory where the working copy is found.</p> required <p>Returns:</p> Type Description <p>Either the SVN or the GIT class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/versioncontrol.py</code> <pre><code>def vcs(directory):\n\"\"\"Make a version control client.\n\n    Args:\n        directory (str): the directory where the working copy is found.\n\n    Returns:\n        Either the SVN or the GIT class.\n    \"\"\"\n    try:\n        git_repo = git.Repo(directory)\n        return GIT(git_repo)\n    except git.exc.InvalidGitRepositoryError:\n        raise VersionControlError(\n            f\"{directory} is not a Git repo. Files can only be added to a git repo.\"\n        )\n</code></pre>"},{"location":"reference/winsami2/","title":"winsami2","text":"<p>Python Character Mapping Codec for winsami2.</p>"},{"location":"reference/winsami2/#corpustools.winsami2.Codec","title":"<code>Codec</code>","text":"<p>         Bases: <code>codecs.Codec</code></p> <p>Implement the interface for stateless encoders/decoders.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>class Codec(codecs.Codec):\n\"\"\"Implement the interface for stateless encoders/decoders.\"\"\"\n\n    def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n                'backslashreplace'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_encode(instring, errors, encoding_table)\n\n    def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n            errors (str): define the error handling to apply. One of\n                'strict', 'replace' or 'ignore'.\n\n        Returns:\n            tuple (output object, length consumed)\n        \"\"\"\n        return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.Codec.decode","title":"<code>decode(instring, errors='strict')</code>","text":"<p>Decode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace' or 'ignore'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>def decode(self, instring, errors=\"strict\"):\n\"\"\"Decode the object instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace' or 'ignore'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_decode(instring, errors, decoding_table)\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.Codec.encode","title":"<code>encode(instring, errors='strict')</code>","text":"<p>Encode the object instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <code>errors</code> <code>str</code> <p>define the error handling to apply. One of 'strict', 'replace', 'ignore',  'xmlcharrefreplace' or 'backslashreplace'.</p> <code>'strict'</code> <p>Returns:</p> Type Description <p>tuple (output object, length consumed)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>def encode(self, instring, errors=\"strict\"):\n\"\"\"Encode the object instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n        errors (str): define the error handling to apply. One of\n            'strict', 'replace', 'ignore',  'xmlcharrefreplace' or\n            'backslashreplace'.\n\n    Returns:\n        tuple (output object, length consumed)\n    \"\"\"\n    return codecs.charmap_encode(instring, errors, encoding_table)\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.IncrementalDecoder","title":"<code>IncrementalDecoder</code>","text":"<p>         Bases: <code>codecs.IncrementalDecoder</code></p> <p>Implement an IncrementalDecoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>class IncrementalDecoder(codecs.IncrementalDecoder):\n\"\"\"Implement an IncrementalDecoder.\"\"\"\n\n    def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n        Args:\n            instring (str): the string that should be decoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.IncrementalDecoder.decode","title":"<code>decode(instring, final=False)</code>","text":"<p>Decode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be decoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>def decode(self, instring, final=False):\n\"\"\"Decode instring.\n\n    Args:\n        instring (str): the string that should be decoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_decode(instring, self.errors, decoding_table)[0]\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.IncrementalEncoder","title":"<code>IncrementalEncoder</code>","text":"<p>         Bases: <code>codecs.IncrementalEncoder</code></p> <p>Implement an IncrementalEncoder.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>class IncrementalEncoder(codecs.IncrementalEncoder):\n\"\"\"Implement an IncrementalEncoder.\"\"\"\n\n    def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n        Args:\n            instring (str): the string that should be encoded with this\n                codec.\n\n        Returns:\n            output object.\n        \"\"\"\n        return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.IncrementalEncoder.encode","title":"<code>encode(instring, final=False)</code>","text":"<p>Encode instring.</p> <p>Parameters:</p> Name Type Description Default <code>instring</code> <code>str</code> <p>the string that should be encoded with this codec.</p> required <p>Returns:</p> Type Description <p>output object.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>def encode(self, instring, final=False):\n\"\"\"Encode instring.\n\n    Args:\n        instring (str): the string that should be encoded with this\n            codec.\n\n    Returns:\n        output object.\n    \"\"\"\n    return codecs.charmap_encode(instring, self.errors, encoding_table)[0]\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.getregentry","title":"<code>getregentry()</code>","text":"<p>Get the info for this encoding.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>def getregentry():\n\"\"\"Get the info for this encoding.\"\"\"\n    return codecs.CodecInfo(\n        name=\"ws2\",\n        encode=Codec().encode,\n        decode=Codec().decode,\n        incrementalencoder=IncrementalEncoder,\n        incrementaldecoder=IncrementalDecoder,\n        streamreader=codecs.StreamReader,\n        streamwriter=codecs.StreamWriter,\n    )\n</code></pre>"},{"location":"reference/winsami2/#corpustools.winsami2.lookup","title":"<code>lookup(encoding)</code>","text":"<p>Lookup the name of the encoding.</p> <p>Parameters:</p> Name Type Description Default <code>encoding</code> <code>str</code> <p>name of the encoding</p> required <p>Returns:</p> Type Description <p>Codecs.CodecInfo if encoding is the name of the encoding of this file, None otherwise.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/winsami2.py</code> <pre><code>def lookup(encoding):\n\"\"\"Lookup the name of the encoding.\n\n    Args:\n        encoding (str): name of the encoding\n\n    Returns:\n        Codecs.CodecInfo if encoding is the name of the encoding of\n            this file, None otherwise.\n    \"\"\"\n    if encoding == \"ws2\":\n        return getregentry()\n    return None\n</code></pre>"},{"location":"reference/xmlconverter/","title":"xmlconverter","text":"<p>Convert udhr files to the Giella xml format.</p>"},{"location":"reference/xmlconverter/#corpustools.xmlconverter.to_html_elt","title":"<code>to_html_elt(filename)</code>","text":"<p>Turn a udhr xml file to giella xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xmlconverter.py</code> <pre><code>def to_html_elt(filename):\n\"\"\"Turn a udhr xml file to giella xml.\"\"\"\n    udhr_tree = etree.parse(filename)\n    udhr_transformer = etree.XSLT(etree.parse(os.path.join(HERE, \"xslt/udhr2html.xsl\")))\n\n    return udhr_transformer(udhr_tree)\n</code></pre>"},{"location":"reference/xslmaker/","title":"xslmaker","text":"<p>Implement the XslMaker class.</p>"},{"location":"reference/xslmaker/#corpustools.xslmaker.XslMaker","title":"<code>XslMaker</code>","text":"<p>Make an xsl file to combine with the intermediate xml file.</p> <p>To convert the intermediate xml to a fullfledged  giellatekno document a combination of three xsl files + the intermediate xml file is needed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslmaker.py</code> <pre><code>class XslMaker:\n\"\"\"Make an xsl file to combine with the intermediate xml file.\n\n    To convert the intermediate xml to a fullfledged  giellatekno document\n    a combination of three xsl files + the intermediate xml file is needed.\n    \"\"\"\n\n    def __init__(self, xslfile):\n\"\"\"Initialise the XslMaker class.\n\n        Args:\n            xslfile: a string containing the path to the xsl file.\n        \"\"\"\n        self.filename = xslfile\n\n    @property\n    def logfile(self):\n\"\"\"Return the name of the logfile.\"\"\"\n        return self.filename + \".log\"\n\n    @property\n    def xsl(self):\n\"\"\"Return an etree of the xsl file.\n\n        Raises:\n            In case of an xml syntax error, raise ConversionException.\n        \"\"\"\n        xsl = etree.parse(os.path.join(HERE, \"xslt/preprocxsl.xsl\"))\n        transformer = etree.XSLT(xsl)\n\n        common_xsl_path = os.path.join(HERE, \"xslt/common.xsl\").replace(\" \", \"%20\")\n\n        return transformer(\n            self.filename,\n            commonxsl=etree.XSLT.strparam(f\"file://{common_xsl_path}\"),\n        )\n\n    @property\n    def transformer(self):\n\"\"\"Make an etree.XSLT transformer.\n\n        Raises:\n            raise a ConversionException in case of invalid XML in the xsl file.\n        Returns:\n            an etree.XSLT transformer\n        \"\"\"\n        return etree.XSLT(self.xsl)\n</code></pre>"},{"location":"reference/xslmaker/#corpustools.xslmaker.XslMaker.logfile","title":"<code>logfile</code>  <code>property</code>","text":"<p>Return the name of the logfile.</p>"},{"location":"reference/xslmaker/#corpustools.xslmaker.XslMaker.transformer","title":"<code>transformer</code>  <code>property</code>","text":"<p>Make an etree.XSLT transformer.</p> <p>Returns:</p> Type Description <p>an etree.XSLT transformer</p>"},{"location":"reference/xslmaker/#corpustools.xslmaker.XslMaker.xsl","title":"<code>xsl</code>  <code>property</code>","text":"<p>Return an etree of the xsl file.</p>"},{"location":"reference/xslmaker/#corpustools.xslmaker.XslMaker.__init__","title":"<code>__init__(xslfile)</code>","text":"<p>Initialise the XslMaker class.</p> <p>Parameters:</p> Name Type Description Default <code>xslfile</code> <p>a string containing the path to the xsl file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslmaker.py</code> <pre><code>def __init__(self, xslfile):\n\"\"\"Initialise the XslMaker class.\n\n    Args:\n        xslfile: a string containing the path to the xsl file.\n    \"\"\"\n    self.filename = xslfile\n</code></pre>"},{"location":"reference/xslsetter/","title":"xslsetter","text":"<p>Get and set metadata in metadata files.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler","title":"<code>MetadataHandler</code>","text":"<p>Class to handle metadata in .xsl files.</p> <p>This class makes the xsl file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>class MetadataHandler:\n\"\"\"Class to handle metadata in .xsl files.\n\n    This class makes the xsl file\n    \"\"\"\n\n    lang_key = \"{http://www.w3.org/XML/1998/namespace}lang\"\n\n    def __init__(self, filename, create=False):\n\"\"\"Initialise the MetadataHandler class.\n\n        Args:\n            filename (str): path to the metadata file.\n            create (bool): Define if a MetadataHandler will be created from a\n                metadata file belonging to a original file inside the corpus or\n                created from a template file containing default values.\n\n                If false, try to read a metadata file, and create a\n                MetadataHandler from this. If the file does not exist, raise a\n                util.ArgumentError.\n\n                If True, create a new MetadataHandler with default values\n                from the template file.\n\n        Raises:\n            util.ArgumentError if create is False and the filename does not\n            exist.\n            XsltException if there is a syntax error in the metadata file.\n        \"\"\"\n        self.filename = filename\n\n        if not os.path.exists(filename):\n            if not create:\n                raise util.ArgumentError(f\"{filename} does not exist!\")\n            self.tree = etree.parse(os.path.join(here, \"xslt/XSL-template.xsl\"))\n        else:\n            try:\n                self.tree = etree.parse(filename)\n            except etree.XMLSyntaxError as e:\n                raise XsltError(f\"Syntax error in {self.filename}:\\n{e}\")\n\n    def _get_variable_elt(self, key):\n\"\"\"Get the variable element.\n\n        Args:\n            key (str): The name of the variable that should be looked up.\n\n        Returns:\n            etree._Element: The element that contains the key.\n        \"\"\"\n        return self.tree.getroot().find(\n            \"{{http://www.w3.org/1999/XSL/Transform}}\"\n            \"variable[@name='{}']\".format(key)\n        )\n\n    def set_variable(self, key, value):\n\"\"\"Set the value of a variable.\n\n        Args:\n            key (str): Name of the variable to set.\n            value (str): The value the variable should be set to.\n        \"\"\"\n        try:\n            variable = self._get_variable_elt(key)\n            variable.attrib[\"select\"] = f\"'{value}'\"\n        except AttributeError as e:\n            raise UserWarning(\n                \"Tried to update {} with value {}\\n\"\n                \"Error was {}\".format(key, value, str(e))\n            )\n\n    def get_variable(self, key):\n\"\"\"Get the value associated with the key.\n\n        Args:\n            key (str): Name of the variable to get.\n\n        Returns:\n            str or None: The string contains the value associated with the key.\n        \"\"\"\n        variable = self._get_variable_elt(key)\n        if variable is not None:\n            value = variable.attrib[\"select\"]\n            if value is not None:\n                clean_value = value.replace(\"'\", \"\")\n                if clean_value:\n                    return clean_value\n        return None\n\n    def get_set_variables(self):\n\"\"\"Find all set variables.\n\n        Yields:\n            tuple of str: a key/value pair\n        \"\"\"\n        ns = {\"xsl\": \"http://www.w3.org/1999/XSL/Transform\"}\n        for variable in self.tree.getroot().xpath(\n            \".//xsl:variable[@select]\", namespaces=ns\n        ):\n            value = self.get_variable(variable.get(\"name\"))\n            if value is not None and value.strip():\n                yield variable.get(\"name\"), value\n\n    def get_parallel_texts(self):\n\"\"\"Get the parallel texts.\n\n        Returns:\n            dict: A dict of parallel files containing language:filename pairs.\n        \"\"\"\n        parallels = self._get_variable_elt(\"parallels\")\n        if parallels is None:\n            return {}\n        else:\n            elts = parallels.findall(\"parallel_text\")\n            return {\n                p.attrib[self.lang_key]: p.attrib[\"location\"].strip(\"'\")\n                for p in elts\n                if p.attrib[\"location\"].strip(\"'\") != \"\"\n            }\n\n    @property\n    def mlangs(self):\n\"\"\"Get the languages to look for in the document.\n\n        Returns:\n            set: A set of languages to look for in the document\n        \"\"\"\n        mlangs = self._get_variable_elt(\"mlangs\")\n        if mlangs is None:\n            return set()\n        else:\n            return {mlang.get(self.lang_key) for mlang in mlangs.findall(\"language\")}\n\n    def make_xsl_variable(self, name):\n        elt = etree.Element(\"{http://www.w3.org/1999/XSL/Transform}variable\", name=name)\n        self.tree.getroot().append(elt)\n\n        return elt\n\n    def set_mlang(self, language):\n\"\"\"Set a language in mlangs.\n\n        Args:\n            language (str): a language code that should be set.\n        \"\"\"\n        mlangs = self._get_variable_elt(\"mlangs\")\n        if mlangs is None:\n            mlangs = self.make_xsl_variable(\"mlangs\")\n\n        if language not in self.mlangs:\n            mlang = etree.Element(\"language\")\n            mlang.attrib.update({self.lang_key: language})\n            mlangs.append(mlang)\n\n    def set_parallel_text(self, language, location):\n\"\"\"Insert the name of a parallel file into the parallels element.\n\n        Args:\n            language (str): the language of the parallel file.\n            location (str): the name of the parallel file.\n        \"\"\"\n        attrib = {self.lang_key: language, \"location\": location}\n        parallels = self._get_variable_elt(\"parallels\")\n        if parallels is None:\n            parallels = self.make_xsl_variable(\"parallels\")\n\n        elt = parallels.find(f\"parallel_text[@{self.lang_key}='{language}']\")\n        if elt is not None:\n            elt.attrib.update(attrib)\n        else:\n            elt = etree.Element(\"parallel_text\", attrib=attrib)\n            elt.tail = \"\\n\"\n            parallels.append(elt)\n\n    @property\n    def skip_pages(self):\n\"\"\"Turn a skip_pages entry into a list of pages.\n\n        Returns:\n            list (mixed): the list can contain the strings 'all',\n                'even' and 'odd' or specific page numbers as integers.\n        \"\"\"\n        pages = []\n        skip_pages = self.get_variable(\"skip_pages\")\n        if skip_pages is not None:\n            if \"odd\" in skip_pages and \"even\" in skip_pages:\n                raise XsltError(\n                    'Invalid format: Cannot have both \"even\" and \"odd\" in this line\\n'\n                    \"{}\".format(skip_pages)\n                )\n\n            if \"odd\" in skip_pages:\n                pages.append(\"odd\")\n                skip_pages = skip_pages.replace(\"odd\", \"\")\n            if \"even\" in skip_pages:\n                pages.append(\"even\")\n                skip_pages = skip_pages.replace(\"even\", \"\")\n\n            # Turn single pages into single-page ranges, e.g. 7 \u2192 7-7\n            skip_ranges_norm = (\n                (r if \"-\" in r else r + \"-\" + r)\n                for r in skip_pages.strip().split(\",\")\n                if r != \"\"\n            )\n\n            skip_ranges = (tuple(map(int, r.split(\"-\"))) for r in skip_ranges_norm)\n\n            try:\n                pages.extend(\n                    [\n                        page\n                        for start, end in sorted(skip_ranges)\n                        for page in range(start, end + 1)\n                    ]\n                )\n\n            except ValueError:\n                raise XsltError(f\"Invalid format: {skip_pages}\")\n\n        return pages\n\n    @property\n    def skip_lines(self):\n\"\"\"Turn a skip_lines entry into a list of lines.\n\n        Returns:\n            list (int): list of line to skip numbers as integers.\n        \"\"\"\n        lines = []\n        skip_lines = self.get_variable(\"skip_lines\")\n        if skip_lines is not None:\n            # Turn single lines into single-page ranges, e.g. 7 \u2192 7-7\n            skip_ranges_norm = (\n                (r if \"-\" in r else r + \"-\" + r)\n                for r in skip_lines.strip().split(\",\")\n                if r != \"\"\n            )\n\n            skip_ranges = (tuple(map(int, r.split(\"-\"))) for r in skip_ranges_norm)\n\n            try:\n                lines.extend(\n                    [\n                        line\n                        for start, end in sorted(skip_ranges)\n                        for line in range(start, end + 1)\n                    ]\n                )\n\n            except ValueError:\n                raise XsltError(f\"Invalid format: {skip_lines}\")\n\n        return lines\n\n    @property\n    def epub_excluded_chapters(self):\n\"\"\"Turn a skip_lines entry into a list of lines.\n\n        Returns:\n            list (int): list of line to skip numbers as integers.\n        \"\"\"\n        lines = []\n        chosen = self.get_variable(\"epub_excluded_chapters\")\n        if chosen is not None:\n            # Turn single lines into single-page ranges, e.g. 7 \u2192 7-7\n            skip_ranges_norm = (\n                (r if \"-\" in r else r + \"-\" + r)\n                for r in chosen.strip().split(\",\")\n                if r != \"\"\n            )\n\n            skip_ranges = (tuple(map(int, r.split(\"-\"))) for r in skip_ranges_norm)\n\n            try:\n                lines.extend(\n                    [\n                        line\n                        for start, end in sorted(skip_ranges)\n                        for line in range(start, end + 1)\n                    ]\n                )\n\n            except ValueError:\n                raise XsltError(f\"Invalid format: {chosen}\")\n\n        return lines\n\n    def get_margin_lines(self, position=\"\"):\n\"\"\"Get the margin lines from the metadata file.\n\n        Args:\n            position (str): empty if getting regular margin lines,\n                otherwise inner_ if getting inner margin lines.\n\n        Returns:\n            dict: Contains marginname:percentage pairs.\n        \"\"\"\n        margin_lines = {\n            key: self.get_variable(key).strip()\n            for key in [\n                position + \"right_margin\",\n                position + \"top_margin\",\n                position + \"left_margin\",\n                position + \"bottom_margin\",\n            ]\n            if (\n                self.get_variable(key) is not None\n                and self.get_variable(key).strip() != \"\"\n            )\n        }\n\n        return margin_lines\n\n    def validate_and_set_margins(self, margin_lines):\n\"\"\"Set and validate the margin lines.\n\n        Args:\n            margin_lines (dict): The dict consists of\n                marginname:percentage pairs\n\n        Returns:\n            dict: The dict consists of marginname:percentage pairs.\n\n        Raises:\n            XsltException: Raise this exception if there are errors in the\n                margin_lines.\n        \"\"\"\n        _margins = {}\n        for key, value in margin_lines.items():\n            if (\n                \"all\" in value\n                and (\"odd\" in value or \"even\" in value)\n                or \"=\" not in value\n            ):\n                raise XsltError(\n                    \"Invalid format in the variable {} in the file:\\n{}\\n{}\\n\"\n                    \"Format must be [all|odd|even|pagenumber]=integer\".format(\n                        key, self.filename, value\n                    )\n                )\n            try:\n                _margins[key] = self.parse_margin_line(value)\n            except ValueError:\n                raise XsltError(\n                    \"Invalid format in the variable {} in the file:\\n{}\\n{}\\n\"\n                    \"Format must be [all|odd|even|pagenumber]=integer\".format(\n                        key, self.filename, value\n                    )\n                )\n\n        return _margins\n\n    @property\n    def margins(self):\n\"\"\"Parse margin lines fetched from the .xsl file.\n\n        Returns:\n            dict: The dict consists of marginname:percentage pairs.\n        \"\"\"\n        margin_lines = self.get_margin_lines()\n\n        return self.validate_and_set_margins(margin_lines)\n\n    @property\n    def inner_margins(self):\n\"\"\"Parse inner margin lines fetched from the .xsl file.\n\n        Returns:\n            dict: The dict consists of marginname:percentage pairs.\n\n        Raises:\n            XsltException: Raise this exception if there are errors in the\n                inner_margin_lines.\n        \"\"\"\n        margin_lines = self.get_margin_lines(position=\"inner_\")\n        _inner_margins = self.validate_and_set_margins(margin_lines)\n\n        keys = list(_inner_margins.keys())\n        for key in keys:\n            if key == \"inner_left_margin\":\n                if \"inner_right_margin\" not in keys:\n                    raise XsltError(\n                        \"Invalid format in {}:\\nboth \"\n                        \"inner_right_margin and inner_left_margin must \"\n                        \"be set\".format(self.filename)\n                    )\n                if sorted(_inner_margins[\"inner_left_margin\"]) != sorted(\n                    _inner_margins[\"inner_right_margin\"]\n                ):\n                    raise XsltError(\n                        \"Invalid format in {}:\\nboth \"\n                        \"margins for the same pages must be set in \"\n                        \"inner_right_margin and inner_left_margin\".format(self.filename)\n                    )\n            if key == \"inner_right_margin\" and \"inner_left_margin\" not in keys:\n                raise XsltError(\n                    \"Invalid format in {}:\\nboth inner_right_margin \"\n                    \"and inner_left_margin must be set\".format(self.filename)\n                )\n            if key == \"inner_bottom_margin\":\n                if \"inner_top_margin\" not in keys:\n                    raise XsltError(\n                        \"Invalid format in {}:\\nboth \"\n                        \"inner_bottom_margin and inner_top_margin must \"\n                        \"be set\".format(self.filename)\n                    )\n                if sorted(_inner_margins[\"inner_bottom_margin\"]) != sorted(\n                    _inner_margins[\"inner_top_margin\"]\n                ):\n                    raise XsltError(\n                        \"Invalid format in {}:\\n\"\n                        \"margins for the same pages must be set in \"\n                        \"inner_top_margin and inner_bottom_margin\".format(self.filename)\n                    )\n            if key == \"inner_top_margin\" and \"inner_bottom_margin\" not in keys:\n                raise XsltError(\n                    \"Invalid format in {}:\\nboth inner_bottom_margin \"\n                    \"and inner_top_margin must be set\".format(self.filename)\n                )\n\n        return _inner_margins\n\n    @staticmethod\n    def parse_margin_line(value):\n\"\"\"Parse a margin line read from the .xsl file.\n\n        Args:\n            param (str): contains the margin settings for a particular\n                margin (right_margin, left_margin, top_margin, bottom_margin)\n\n        Returns:\n            dict: marginname: int (in percentage) pairs\n        \"\"\"\n        m = {}\n        for part in value.split(\",\"):\n            (pages, margin) = tuple(part.split(\"=\"))\n            for page in pages.split(\";\"):\n                m[page.strip()] = int(margin)\n\n        return m\n\n    def set_lang_genre_xsl(self):\n\"\"\"Set the mainlang and genre variables in the xsl file.\"\"\"\n        with util.ignored(TypeError):\n            path = corpuspath.CorpusPath(self.filename)\n            self.set_variable(\"mainlang\", path.pathcomponents.lang)\n            self.set_variable(\"genre\", path.pathcomponents.genre)\n\n    def write_file(self):\n\"\"\"Write self.tree to self.filename.\"\"\"\n        try:\n            with open(self.filename, \"wb\") as outfile:\n                self.tree.write(outfile, encoding=\"utf-8\", xml_declaration=True)\n                outfile.write(b\"\\n\")\n        except OSError as e:\n            print(\"cannot write\", self.filename)\n            print(e)\n            sys.exit(254)\n\n    @property\n    def skip_elements(self):\n\"\"\"Get the skip_elements variable.\n\n        Returns:\n            list of tuples of str: each tuple has a (start, end) xpath path\n            pair. If the skip_elements variable is empty, return None.\n        \"\"\"\n\n        def get_with_ns(path):\n            return \"/\".join(\n                [\n                    \"html:\" + part\n                    if not part.startswith(\"html:\") and re.match(r\"^\\w\", part)\n                    else part\n                    for part in path.split(\"/\")\n                ]\n            )\n\n        def get_pair(pair):\n            p = pair.split(\";\")\n            return (get_with_ns(p[0].strip()), get_with_ns(p[1].strip()))\n\n        if self.get_variable(\"skip_elements\"):\n            return [\n                get_pair(pair) for pair in self.get_variable(\"skip_elements\").split(\",\")\n            ]\n\n    @property\n    def linespacing(self):\n\"\"\":obj:`dict` of :obj:`str` pairs\n\n        The key may be all, odd, even or a pagenumber, the value is a\n        floating point number.\n        \"\"\"\n        value = self.get_variable(\"linespacing\")\n\n        if (value) and (\n            \"all\" in value and (\"odd\" in value or \"even\" in value) or \"=\" not in value\n        ):\n            raise XsltError(\n                \"Invalid format in the variable linespacing in the file:\"\n                \"\\n{}\\n{}\\n\"\n                \"Format must be [all|odd|even|pagenumber]=float\".format(\n                    self.filename, value\n                )\n            )\n\n        try:\n            return self.parse_linespacing_line(value)\n        except ValueError:\n            raise XsltError(\n                \"Invalid format in the variable linespacing in the file:\"\n                \"\\n{}\\n{}\\n\"\n                \"Format must be [all|odd|even|pagenumber]=float\".format(\n                    self.filename, value\n                )\n            )\n\n    @staticmethod\n    def parse_linespacing_line(value):\n\"\"\"Parse a linespacing line read from the .xsl file.\n\n        Args:\n            param (str): contains the linespacing\n\n        Returns:\n            dict: page: float pairs\n        \"\"\"\n        l = {}\n        if value:\n            for part in value.split(\",\"):\n                (pages, linespacing) = tuple(part.split(\"=\"))\n                for page in pages.split(\";\"):\n                    l[page.strip()] = float(linespacing)\n\n        return l\n\n    @property\n    def xsl_templates(self):\n\"\"\"Find all xsl:template elements.\n\n        Returns:\n            List of etree.Element\n        \"\"\"\n        ns = {\"xsl\": \"http://www.w3.org/1999/XSL/Transform\"}\n        return self.tree.getroot().xpath(\".//xsl:template\", namespaces=ns)\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.epub_excluded_chapters","title":"<code>epub_excluded_chapters</code>  <code>property</code>","text":"<p>Turn a skip_lines entry into a list of lines.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>int</code> <p>list of line to skip numbers as integers.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.inner_margins","title":"<code>inner_margins</code>  <code>property</code>","text":"<p>Parse inner margin lines fetched from the .xsl file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>The dict consists of marginname:percentage pairs.</p> <p>Raises:</p> Type Description <code>XsltException</code> <p>Raise this exception if there are errors in the inner_margin_lines.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.linespacing","title":"<code>linespacing</code>  <code>property</code>","text":"<p>:obj:<code>dict</code> of :obj:<code>str</code> pairs</p> <p>The key may be all, odd, even or a pagenumber, the value is a floating point number.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.margins","title":"<code>margins</code>  <code>property</code>","text":"<p>Parse margin lines fetched from the .xsl file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>The dict consists of marginname:percentage pairs.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.mlangs","title":"<code>mlangs</code>  <code>property</code>","text":"<p>Get the languages to look for in the document.</p> <p>Returns:</p> Name Type Description <code>set</code> <p>A set of languages to look for in the document</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.skip_elements","title":"<code>skip_elements</code>  <code>property</code>","text":"<p>Get the skip_elements variable.</p> <p>Returns:</p> Type Description <p>list of tuples of str: each tuple has a (start, end) xpath path</p> <p>pair. If the skip_elements variable is empty, return None.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.skip_lines","title":"<code>skip_lines</code>  <code>property</code>","text":"<p>Turn a skip_lines entry into a list of lines.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>int</code> <p>list of line to skip numbers as integers.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.skip_pages","title":"<code>skip_pages</code>  <code>property</code>","text":"<p>Turn a skip_pages entry into a list of pages.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>mixed</code> <p>the list can contain the strings 'all', 'even' and 'odd' or specific page numbers as integers.</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.xsl_templates","title":"<code>xsl_templates</code>  <code>property</code>","text":"<p>Find all xsl:template elements.</p> <p>Returns:</p> Type Description <p>List of etree.Element</p>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.__init__","title":"<code>__init__(filename, create=False)</code>","text":"<p>Initialise the MetadataHandler class.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to the metadata file.</p> required <code>create</code> <code>bool</code> <p>Define if a MetadataHandler will be created from a metadata file belonging to a original file inside the corpus or created from a template file containing default values.</p> <p>If false, try to read a metadata file, and create a MetadataHandler from this. If the file does not exist, raise a util.ArgumentError.</p> <p>If True, create a new MetadataHandler with default values from the template file.</p> <code>False</code> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def __init__(self, filename, create=False):\n\"\"\"Initialise the MetadataHandler class.\n\n    Args:\n        filename (str): path to the metadata file.\n        create (bool): Define if a MetadataHandler will be created from a\n            metadata file belonging to a original file inside the corpus or\n            created from a template file containing default values.\n\n            If false, try to read a metadata file, and create a\n            MetadataHandler from this. If the file does not exist, raise a\n            util.ArgumentError.\n\n            If True, create a new MetadataHandler with default values\n            from the template file.\n\n    Raises:\n        util.ArgumentError if create is False and the filename does not\n        exist.\n        XsltException if there is a syntax error in the metadata file.\n    \"\"\"\n    self.filename = filename\n\n    if not os.path.exists(filename):\n        if not create:\n            raise util.ArgumentError(f\"{filename} does not exist!\")\n        self.tree = etree.parse(os.path.join(here, \"xslt/XSL-template.xsl\"))\n    else:\n        try:\n            self.tree = etree.parse(filename)\n        except etree.XMLSyntaxError as e:\n            raise XsltError(f\"Syntax error in {self.filename}:\\n{e}\")\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.get_margin_lines","title":"<code>get_margin_lines(position='')</code>","text":"<p>Get the margin lines from the metadata file.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>str</code> <p>empty if getting regular margin lines, otherwise inner_ if getting inner margin lines.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Contains marginname:percentage pairs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def get_margin_lines(self, position=\"\"):\n\"\"\"Get the margin lines from the metadata file.\n\n    Args:\n        position (str): empty if getting regular margin lines,\n            otherwise inner_ if getting inner margin lines.\n\n    Returns:\n        dict: Contains marginname:percentage pairs.\n    \"\"\"\n    margin_lines = {\n        key: self.get_variable(key).strip()\n        for key in [\n            position + \"right_margin\",\n            position + \"top_margin\",\n            position + \"left_margin\",\n            position + \"bottom_margin\",\n        ]\n        if (\n            self.get_variable(key) is not None\n            and self.get_variable(key).strip() != \"\"\n        )\n    }\n\n    return margin_lines\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.get_parallel_texts","title":"<code>get_parallel_texts()</code>","text":"<p>Get the parallel texts.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dict of parallel files containing language:filename pairs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def get_parallel_texts(self):\n\"\"\"Get the parallel texts.\n\n    Returns:\n        dict: A dict of parallel files containing language:filename pairs.\n    \"\"\"\n    parallels = self._get_variable_elt(\"parallels\")\n    if parallels is None:\n        return {}\n    else:\n        elts = parallels.findall(\"parallel_text\")\n        return {\n            p.attrib[self.lang_key]: p.attrib[\"location\"].strip(\"'\")\n            for p in elts\n            if p.attrib[\"location\"].strip(\"'\") != \"\"\n        }\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.get_set_variables","title":"<code>get_set_variables()</code>","text":"<p>Find all set variables.</p> <p>Yields:</p> Type Description <p>tuple of str: a key/value pair</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def get_set_variables(self):\n\"\"\"Find all set variables.\n\n    Yields:\n        tuple of str: a key/value pair\n    \"\"\"\n    ns = {\"xsl\": \"http://www.w3.org/1999/XSL/Transform\"}\n    for variable in self.tree.getroot().xpath(\n        \".//xsl:variable[@select]\", namespaces=ns\n    ):\n        value = self.get_variable(variable.get(\"name\"))\n        if value is not None and value.strip():\n            yield variable.get(\"name\"), value\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.get_variable","title":"<code>get_variable(key)</code>","text":"<p>Get the value associated with the key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the variable to get.</p> required <p>Returns:</p> Type Description <p>str or None: The string contains the value associated with the key.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def get_variable(self, key):\n\"\"\"Get the value associated with the key.\n\n    Args:\n        key (str): Name of the variable to get.\n\n    Returns:\n        str or None: The string contains the value associated with the key.\n    \"\"\"\n    variable = self._get_variable_elt(key)\n    if variable is not None:\n        value = variable.attrib[\"select\"]\n        if value is not None:\n            clean_value = value.replace(\"'\", \"\")\n            if clean_value:\n                return clean_value\n    return None\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.parse_linespacing_line","title":"<code>parse_linespacing_line(value)</code>  <code>staticmethod</code>","text":"<p>Parse a linespacing line read from the .xsl file.</p> <p>Parameters:</p> Name Type Description Default <code>param</code> <code>str</code> <p>contains the linespacing</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>page: float pairs</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>@staticmethod\ndef parse_linespacing_line(value):\n\"\"\"Parse a linespacing line read from the .xsl file.\n\n    Args:\n        param (str): contains the linespacing\n\n    Returns:\n        dict: page: float pairs\n    \"\"\"\n    l = {}\n    if value:\n        for part in value.split(\",\"):\n            (pages, linespacing) = tuple(part.split(\"=\"))\n            for page in pages.split(\";\"):\n                l[page.strip()] = float(linespacing)\n\n    return l\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.parse_margin_line","title":"<code>parse_margin_line(value)</code>  <code>staticmethod</code>","text":"<p>Parse a margin line read from the .xsl file.</p> <p>Parameters:</p> Name Type Description Default <code>param</code> <code>str</code> <p>contains the margin settings for a particular margin (right_margin, left_margin, top_margin, bottom_margin)</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>marginname: int (in percentage) pairs</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>@staticmethod\ndef parse_margin_line(value):\n\"\"\"Parse a margin line read from the .xsl file.\n\n    Args:\n        param (str): contains the margin settings for a particular\n            margin (right_margin, left_margin, top_margin, bottom_margin)\n\n    Returns:\n        dict: marginname: int (in percentage) pairs\n    \"\"\"\n    m = {}\n    for part in value.split(\",\"):\n        (pages, margin) = tuple(part.split(\"=\"))\n        for page in pages.split(\";\"):\n            m[page.strip()] = int(margin)\n\n    return m\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.set_lang_genre_xsl","title":"<code>set_lang_genre_xsl()</code>","text":"<p>Set the mainlang and genre variables in the xsl file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def set_lang_genre_xsl(self):\n\"\"\"Set the mainlang and genre variables in the xsl file.\"\"\"\n    with util.ignored(TypeError):\n        path = corpuspath.CorpusPath(self.filename)\n        self.set_variable(\"mainlang\", path.pathcomponents.lang)\n        self.set_variable(\"genre\", path.pathcomponents.genre)\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.set_mlang","title":"<code>set_mlang(language)</code>","text":"<p>Set a language in mlangs.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>str</code> <p>a language code that should be set.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def set_mlang(self, language):\n\"\"\"Set a language in mlangs.\n\n    Args:\n        language (str): a language code that should be set.\n    \"\"\"\n    mlangs = self._get_variable_elt(\"mlangs\")\n    if mlangs is None:\n        mlangs = self.make_xsl_variable(\"mlangs\")\n\n    if language not in self.mlangs:\n        mlang = etree.Element(\"language\")\n        mlang.attrib.update({self.lang_key: language})\n        mlangs.append(mlang)\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.set_parallel_text","title":"<code>set_parallel_text(language, location)</code>","text":"<p>Insert the name of a parallel file into the parallels element.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>str</code> <p>the language of the parallel file.</p> required <code>location</code> <code>str</code> <p>the name of the parallel file.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def set_parallel_text(self, language, location):\n\"\"\"Insert the name of a parallel file into the parallels element.\n\n    Args:\n        language (str): the language of the parallel file.\n        location (str): the name of the parallel file.\n    \"\"\"\n    attrib = {self.lang_key: language, \"location\": location}\n    parallels = self._get_variable_elt(\"parallels\")\n    if parallels is None:\n        parallels = self.make_xsl_variable(\"parallels\")\n\n    elt = parallels.find(f\"parallel_text[@{self.lang_key}='{language}']\")\n    if elt is not None:\n        elt.attrib.update(attrib)\n    else:\n        elt = etree.Element(\"parallel_text\", attrib=attrib)\n        elt.tail = \"\\n\"\n        parallels.append(elt)\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.set_variable","title":"<code>set_variable(key, value)</code>","text":"<p>Set the value of a variable.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the variable to set.</p> required <code>value</code> <code>str</code> <p>The value the variable should be set to.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def set_variable(self, key, value):\n\"\"\"Set the value of a variable.\n\n    Args:\n        key (str): Name of the variable to set.\n        value (str): The value the variable should be set to.\n    \"\"\"\n    try:\n        variable = self._get_variable_elt(key)\n        variable.attrib[\"select\"] = f\"'{value}'\"\n    except AttributeError as e:\n        raise UserWarning(\n            \"Tried to update {} with value {}\\n\"\n            \"Error was {}\".format(key, value, str(e))\n        )\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.validate_and_set_margins","title":"<code>validate_and_set_margins(margin_lines)</code>","text":"<p>Set and validate the margin lines.</p> <p>Parameters:</p> Name Type Description Default <code>margin_lines</code> <code>dict</code> <p>The dict consists of marginname:percentage pairs</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The dict consists of marginname:percentage pairs.</p> <p>Raises:</p> Type Description <code>XsltException</code> <p>Raise this exception if there are errors in the margin_lines.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def validate_and_set_margins(self, margin_lines):\n\"\"\"Set and validate the margin lines.\n\n    Args:\n        margin_lines (dict): The dict consists of\n            marginname:percentage pairs\n\n    Returns:\n        dict: The dict consists of marginname:percentage pairs.\n\n    Raises:\n        XsltException: Raise this exception if there are errors in the\n            margin_lines.\n    \"\"\"\n    _margins = {}\n    for key, value in margin_lines.items():\n        if (\n            \"all\" in value\n            and (\"odd\" in value or \"even\" in value)\n            or \"=\" not in value\n        ):\n            raise XsltError(\n                \"Invalid format in the variable {} in the file:\\n{}\\n{}\\n\"\n                \"Format must be [all|odd|even|pagenumber]=integer\".format(\n                    key, self.filename, value\n                )\n            )\n        try:\n            _margins[key] = self.parse_margin_line(value)\n        except ValueError:\n            raise XsltError(\n                \"Invalid format in the variable {} in the file:\\n{}\\n{}\\n\"\n                \"Format must be [all|odd|even|pagenumber]=integer\".format(\n                    key, self.filename, value\n                )\n            )\n\n    return _margins\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.MetadataHandler.write_file","title":"<code>write_file()</code>","text":"<p>Write self.tree to self.filename.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>def write_file(self):\n\"\"\"Write self.tree to self.filename.\"\"\"\n    try:\n        with open(self.filename, \"wb\") as outfile:\n            self.tree.write(outfile, encoding=\"utf-8\", xml_declaration=True)\n            outfile.write(b\"\\n\")\n    except OSError as e:\n        print(\"cannot write\", self.filename)\n        print(e)\n        sys.exit(254)\n</code></pre>"},{"location":"reference/xslsetter/#corpustools.xslsetter.XsltError","title":"<code>XsltError</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raise this exception when errors arise in this module.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/xslsetter.py</code> <pre><code>class XsltError(Exception):\n\"\"\"Raise this exception when errors arise in this module.\"\"\"\n</code></pre>"},{"location":"reference/test/","title":"Index","text":""},{"location":"reference/test/test_adder/","title":"test_adder","text":""},{"location":"reference/test/test_analyser/","title":"test_analyser","text":""},{"location":"reference/test/test_analyser/#corpustools.test.test_analyser.TestAnalyser","title":"<code>TestAnalyser</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_analyser.py</code> <pre><code>class TestAnalyser(unittest.TestCase):\n    def setUp(self):\n        self.a = analyser.Analyser(\n            \"sme\", \"xfst\", giella_prefix=os.path.join(HERE, \"giella_shared\")\n        )\n        self.a.xml_file = corpusxmlfile.CorpusXMLFile(\n            os.path.join(\n                HERE,\n                \"parallelize_data/converted/sme/facta/skuvlahistorja2/\",\n                \"smefile.xml\",\n            )\n        )\n\n    def assertXmlEqual(self, got, want):\n\"\"\"Check if two stringified xml snippets are equal.\"\"\"\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(want, got, 0):\n            message = checker.output_difference(\n                doctest.Example(\"\", want), got, 0\n            ).encode(\"utf-8\")\n            raise AssertionError(message)\n\n    def test_raise_on_None_file(self):\n        with self.assertRaises(TypeError):\n            analyser.Analyser(\"sme\", \"xfst\", None, None, None, None)\n\n    def test_sme_ccat_output(self):\n\"\"\"Test if the ccat output is what we expect it to be.\"\"\"\n        got = self.a.ccat()\n        want = (\n            \"Muhto gaskkohagaid, ja erenoam\u00e1\u017eit dalle go lei buola\u0161, \"\n            \"de aggreg\u00e1hta bill\u00e1nii. \u00b6\\n\"\n        )\n\n        self.assertEqual(got, want)\n\n    def test_analysisXml(self):\n\"\"\"Check if the xml is what it is supposed to be.\"\"\"\n        self.a.dependency_analysis()\n        got = self.a.xml_file.etree\n        want = (\n            '&lt;document xml:lang=\"sme\" id=\"no_id\"&gt;\\n'\n            \"  &lt;header&gt;\\n\"\n            \"    &lt;title&gt;Intern\u00e1htta sosi\u00e1lala\u0161 giliguovdd\u00e1\u017ein&lt;/title&gt;\\n\"\n            '    &lt;genre code=\"facta\"/&gt;\\n'\n            \"    &lt;author&gt;\\n\"\n            '      &lt;person firstname=\"Abba\" lastname=\"Abbamar\" sex=\"m\" '\n            'born=\"1900\" nationality=\"nor\"/&gt;\\n'\n            \"    &lt;/author&gt;\\n\"\n            \"    &lt;translator&gt;\\n\"\n            '      &lt;person firstname=\"Ibba\" lastname=\"Ibbamar\" sex=\"unknown\" '\n            'born=\"\" nationality=\"\"/&gt;\\n'\n            \"    &lt;/translator&gt;\\n\"\n            '    &lt;translated_from xml:lang=\"nob\"/&gt;\\n'\n            \"    &lt;year&gt;2005&lt;/year&gt;\\n\"\n            \"    &lt;publChannel&gt;\\n\"\n            \"      &lt;publication&gt;\\n\"\n            \"        &lt;publisher&gt;Almmuheaddji OS&lt;/publisher&gt;\\n\"\n            \"      &lt;/publication&gt;\\n\"\n            \"    &lt;/publChannel&gt;\\n\"\n            \"    &lt;wordcount&gt;10&lt;/wordcount&gt;\\n\"\n            \"    &lt;availability&gt;\\n\"\n            \"      &lt;free/&gt;\\n\"\n            \"    &lt;/availability&gt;\\n\"\n            '    &lt;submitter name=\"B\u00f8rre Gaup\" '\n            'email=\"boerre.gaup@samediggi.no\"/&gt;\\n'\n            \"    &lt;multilingual&gt;\\n\"\n            '      &lt;language xml:lang=\"nob\"/&gt;\\n'\n            \"    &lt;/multilingual&gt;\\n\"\n            \"    &lt;origFileName&gt;aarseth_s.htm&lt;/origFileName&gt;\\n\"\n            \"    &lt;metadata&gt;\\n\"\n            \"      &lt;uncomplete/&gt;\\n\"\n            \"    &lt;/metadata&gt;\\n\"\n            \"    &lt;version&gt;XSLtemplate  1.9 ; file-specific xsl  \"\n            \"$Revision: 1.3 $; common.xsl  $Revision$; &lt;/version&gt;\\n\"\n            \"  &lt;/header&gt;\\n\"\n            '  &lt;body&gt;&lt;dependency&gt;&lt;![CDATA[\"&lt;Muhto&gt;\"\\n'\n            '\\t\"muhto\" CC @CVP #1-&gt;1\\n\"&lt;gaskkohagaid&gt;\"\\n'\n            '\\t\"gaskkohagaid\" Adv @ADVL&gt; #2-&gt;12\\n\"&lt;,&gt;\"\\n'\n            '\\t\",\" CLB #3-&gt;4\\n\"&lt;ja&gt;\"\\n\\t\"ja\" CC @CNP #4-&gt;2\\n\"&lt;erenoam\u00e1\u017eit&gt;\"\\n'\n            '\\t\"erenoam\u00e1\u017eit\" Adv @ADVL&gt; #5-&gt;12\\n\"&lt;dalle_go&gt;\"\\n'\n            '\\t\"dalle_go\" CS @CVP #6-&gt;7\\n\"&lt;lei&gt;\"\\n'\n            '\\t\"leat\" V IV Ind Prt Sg3 @FS-ADVL&gt; #7-&gt;12\\n\"&lt;buola\u0161&gt;\"\\n'\n            '\\t\"buola\u0161\" N Sg Nom @&lt;SPRED #8-&gt;7\\n\"&lt;,&gt;\"\\n'\n            '\\t\",\" CLB #9-&gt;6\\n\"&lt;de&gt;\"\\n'\n            '\\t\"de\" Adv @ADVL&gt; #10-&gt;12\\n\"&lt;aggreg\u00e1hta&gt;\"\\n'\n            '\\t\"aggreg\u00e1hta\" N Sg Nom @SUBJ&gt; #11-&gt;12\\n\"&lt;bill\u00e1nii&gt;\"\\n'\n            '\\t\"bill\u00e1nit\" V IV Ind Prt Sg3 @FS-ADVL&gt; #12-&gt;0\\n\"&lt;.&gt;\"\\n'\n            '\\t\".\" CLB #13-&gt;12\\n\\n\"&lt;\u00b6&gt;\"\\n'\n            '\\t\"\u00b6\" CLB #1-&gt;1\\n\\n]]&gt;&lt;/dependency&gt;&lt;/body&gt;&lt;/document&gt;'\n        )\n        self.maxDiff = None\n        self.assertEqual(etree.tostring(got, encoding=\"unicode\"), want)\n</code></pre>"},{"location":"reference/test/test_analyser/#corpustools.test.test_analyser.TestAnalyser.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>","text":"<p>Check if two stringified xml snippets are equal.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_analyser.py</code> <pre><code>def assertXmlEqual(self, got, want):\n\"\"\"Check if two stringified xml snippets are equal.\"\"\"\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(want, got, 0):\n        message = checker.output_difference(\n            doctest.Example(\"\", want), got, 0\n        ).encode(\"utf-8\")\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_analyser/#corpustools.test.test_analyser.TestAnalyser.test_analysisXml","title":"<code>test_analysisXml()</code>","text":"<p>Check if the xml is what it is supposed to be.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_analyser.py</code> <pre><code>def test_analysisXml(self):\n\"\"\"Check if the xml is what it is supposed to be.\"\"\"\n    self.a.dependency_analysis()\n    got = self.a.xml_file.etree\n    want = (\n        '&lt;document xml:lang=\"sme\" id=\"no_id\"&gt;\\n'\n        \"  &lt;header&gt;\\n\"\n        \"    &lt;title&gt;Intern\u00e1htta sosi\u00e1lala\u0161 giliguovdd\u00e1\u017ein&lt;/title&gt;\\n\"\n        '    &lt;genre code=\"facta\"/&gt;\\n'\n        \"    &lt;author&gt;\\n\"\n        '      &lt;person firstname=\"Abba\" lastname=\"Abbamar\" sex=\"m\" '\n        'born=\"1900\" nationality=\"nor\"/&gt;\\n'\n        \"    &lt;/author&gt;\\n\"\n        \"    &lt;translator&gt;\\n\"\n        '      &lt;person firstname=\"Ibba\" lastname=\"Ibbamar\" sex=\"unknown\" '\n        'born=\"\" nationality=\"\"/&gt;\\n'\n        \"    &lt;/translator&gt;\\n\"\n        '    &lt;translated_from xml:lang=\"nob\"/&gt;\\n'\n        \"    &lt;year&gt;2005&lt;/year&gt;\\n\"\n        \"    &lt;publChannel&gt;\\n\"\n        \"      &lt;publication&gt;\\n\"\n        \"        &lt;publisher&gt;Almmuheaddji OS&lt;/publisher&gt;\\n\"\n        \"      &lt;/publication&gt;\\n\"\n        \"    &lt;/publChannel&gt;\\n\"\n        \"    &lt;wordcount&gt;10&lt;/wordcount&gt;\\n\"\n        \"    &lt;availability&gt;\\n\"\n        \"      &lt;free/&gt;\\n\"\n        \"    &lt;/availability&gt;\\n\"\n        '    &lt;submitter name=\"B\u00f8rre Gaup\" '\n        'email=\"boerre.gaup@samediggi.no\"/&gt;\\n'\n        \"    &lt;multilingual&gt;\\n\"\n        '      &lt;language xml:lang=\"nob\"/&gt;\\n'\n        \"    &lt;/multilingual&gt;\\n\"\n        \"    &lt;origFileName&gt;aarseth_s.htm&lt;/origFileName&gt;\\n\"\n        \"    &lt;metadata&gt;\\n\"\n        \"      &lt;uncomplete/&gt;\\n\"\n        \"    &lt;/metadata&gt;\\n\"\n        \"    &lt;version&gt;XSLtemplate  1.9 ; file-specific xsl  \"\n        \"$Revision: 1.3 $; common.xsl  $Revision$; &lt;/version&gt;\\n\"\n        \"  &lt;/header&gt;\\n\"\n        '  &lt;body&gt;&lt;dependency&gt;&lt;![CDATA[\"&lt;Muhto&gt;\"\\n'\n        '\\t\"muhto\" CC @CVP #1-&gt;1\\n\"&lt;gaskkohagaid&gt;\"\\n'\n        '\\t\"gaskkohagaid\" Adv @ADVL&gt; #2-&gt;12\\n\"&lt;,&gt;\"\\n'\n        '\\t\",\" CLB #3-&gt;4\\n\"&lt;ja&gt;\"\\n\\t\"ja\" CC @CNP #4-&gt;2\\n\"&lt;erenoam\u00e1\u017eit&gt;\"\\n'\n        '\\t\"erenoam\u00e1\u017eit\" Adv @ADVL&gt; #5-&gt;12\\n\"&lt;dalle_go&gt;\"\\n'\n        '\\t\"dalle_go\" CS @CVP #6-&gt;7\\n\"&lt;lei&gt;\"\\n'\n        '\\t\"leat\" V IV Ind Prt Sg3 @FS-ADVL&gt; #7-&gt;12\\n\"&lt;buola\u0161&gt;\"\\n'\n        '\\t\"buola\u0161\" N Sg Nom @&lt;SPRED #8-&gt;7\\n\"&lt;,&gt;\"\\n'\n        '\\t\",\" CLB #9-&gt;6\\n\"&lt;de&gt;\"\\n'\n        '\\t\"de\" Adv @ADVL&gt; #10-&gt;12\\n\"&lt;aggreg\u00e1hta&gt;\"\\n'\n        '\\t\"aggreg\u00e1hta\" N Sg Nom @SUBJ&gt; #11-&gt;12\\n\"&lt;bill\u00e1nii&gt;\"\\n'\n        '\\t\"bill\u00e1nit\" V IV Ind Prt Sg3 @FS-ADVL&gt; #12-&gt;0\\n\"&lt;.&gt;\"\\n'\n        '\\t\".\" CLB #13-&gt;12\\n\\n\"&lt;\u00b6&gt;\"\\n'\n        '\\t\"\u00b6\" CLB #1-&gt;1\\n\\n]]&gt;&lt;/dependency&gt;&lt;/body&gt;&lt;/document&gt;'\n    )\n    self.maxDiff = None\n    self.assertEqual(etree.tostring(got, encoding=\"unicode\"), want)\n</code></pre>"},{"location":"reference/test/test_analyser/#corpustools.test.test_analyser.TestAnalyser.test_sme_ccat_output","title":"<code>test_sme_ccat_output()</code>","text":"<p>Test if the ccat output is what we expect it to be.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_analyser.py</code> <pre><code>def test_sme_ccat_output(self):\n\"\"\"Test if the ccat output is what we expect it to be.\"\"\"\n    got = self.a.ccat()\n    want = (\n        \"Muhto gaskkohagaid, ja erenoam\u00e1\u017eit dalle go lei buola\u0161, \"\n        \"de aggreg\u00e1hta bill\u00e1nii. \u00b6\\n\"\n    )\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/","title":"test_avvirconverter","text":"<p>Test conversion of \u00c1vvir xml files.</p>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter","title":"<code>TestAvvirConverter</code>","text":"<p>         Bases: <code>xmltester.XMLTester</code></p> <p>Test the functionality of the Avvir class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>class TestAvvirConverter(xmltester.XMLTester):\n\"\"\"Test the functionality of the Avvir class.\"\"\"\n\n    def setUp(self):\n\"\"\"Setup a common AvvirConverter instance.\"\"\"\n        self.avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '    &lt;story id=\"a\" class=\"Tittel\"&gt;'\n            \"        &lt;p&gt;a&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"b\" class=\"Undertittel\"&gt;'\n            \"        &lt;p&gt;b&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"c\" class=\"ingress\"&gt;'\n            \"        &lt;p&gt;c&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"d\" class=\"body\"&gt;'\n            '        &lt;p class=\"tekst\"&gt;d&lt;br/&gt;e&lt;br/&gt;&lt;/p&gt;'\n            \"        &lt;p&gt;f&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"g\" class=\"body\"&gt;'\n            '        &lt;p class=\"tekst\"&gt;h&lt;span&gt;i&lt;/span&gt;j&lt;/p&gt;'\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"k\" class=\"body\"&gt;'\n            \"        &lt;p&gt;l\"\n            \"            &lt;span&gt;\"\n            \"                m\"\n            \"                &lt;br/&gt;\"\n            \"                n\"\n            \"            &lt;/span&gt;\"\n            \"            o\"\n            \"        &lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"a\"&gt;'\n            \"        &lt;p&gt;a&lt;p&gt;b&lt;/p&gt;&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n    def test_remove_identical_ids(self):\n\"\"\"Check that only the first of stories with identical ids are kept.\"\"\"\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '    &lt;story id=\"a\" class=\"Tittel\"&gt;'\n            \"        &lt;p&gt;a&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"b\" class=\"Undertittel\"&gt;'\n            \"        &lt;p&gt;b&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"c\" class=\"ingress\"&gt;'\n            \"        &lt;p&gt;c&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"d\" class=\"body\"&gt;'\n            '        &lt;p class=\"tekst\"&gt;d&lt;br/&gt;e&lt;br/&gt;&lt;/p&gt;'\n            \"        &lt;p&gt;f&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"g\" class=\"body\"&gt;'\n            '        &lt;p class=\"tekst\"&gt;h&lt;span&gt;i&lt;/span&gt;j&lt;/p&gt;'\n            \"    &lt;/story&gt;\"\n            '    &lt;story id=\"k\" class=\"body\"&gt;'\n            \"        &lt;p&gt;l\"\n            \"            &lt;span&gt;\"\n            \"                m\"\n            \"                &lt;br/&gt;\"\n            \"                n\"\n            \"            &lt;/span&gt;\"\n            \"            o\"\n            \"        &lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.remove_identical_ids(self.avvir)\n        self.assertXmlEqual(self.avvir, want)\n\n    def test_convert_p_1(self):\n\"\"\"Check when p does not contain p.\"\"\"\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '    &lt;story class=\"Tittel\" id=\"a\"&gt;'\n            \"        &lt;p&gt;a&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story class=\"Undertittel\" id=\"b\"&gt;'\n            \"        &lt;p&gt;b&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story class=\"ingress\" id=\"c\"&gt;'\n            \"        &lt;p&gt;c&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story class=\"body\" id=\"d\"&gt;'\n            \"        &lt;p&gt;d&lt;/p&gt;\"\n            \"        &lt;p&gt;e&lt;/p&gt;\"\n            \"        &lt;p&gt;f&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story class=\"body\" id=\"g\"&gt;'\n            \"        &lt;p&gt;h&lt;/p&gt;\"\n            \"        &lt;p&gt;i&lt;/p&gt;\"\n            \"        &lt;p&gt;j&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            '    &lt;story class=\"body\" id=\"k\"&gt;'\n            \"        &lt;p&gt;l&lt;/p&gt;\"\n            \"        &lt;p&gt;m&lt;/p&gt;\"\n            \"        &lt;p&gt;n&lt;/p&gt;\"\n            \"        &lt;p&gt;o&lt;/p&gt;\"\n            \"    &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.remove_identical_ids(self.avvir)\n        avvirconverter.convert_p(self.avvir)\n\n        self.assertXmlEqual(self.avvir, want)\n\n    def test_convert_p_2(self):\n\"\"\"Check when p contains only p.\"\"\"\n        avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;corrected text &lt;p&gt;text with typo&lt;/p&gt;with tail&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;corrected text with tail&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.convert_p(avvir)\n\n        self.assertXmlEqual(avvir, want)\n\n    def test_convert_p_3(self):\n\"\"\"Check when p contains span and p.\"\"\"\n        avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;\"\n            \"           &lt;span&gt;bla bla&lt;/span&gt;\"\n            \"           corrected text &lt;p&gt;text with typo&lt;/p&gt;with tail\"\n            \"       &lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;bla bla&lt;/p&gt;\"\n            \"       &lt;p&gt;corrected text with tail&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.convert_p(avvir)\n\n        self.assertXmlEqual(avvir, want)\n\n    def test_convert_p_4(self):\n\"\"\"p.text is None.\"\"\"\n        avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;&lt;p&gt; &lt;/p&gt;with tail\"\n            \"       &lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt; with tail&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.convert_p(avvir)\n\n        self.assertXmlEqual(avvir, want)\n\n    def test_convert_p_5(self):\n\"\"\"sub_p.tail is None.\"\"\"\n        avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            '       &lt;p&gt;l\u00e1igovistti &lt;p class=\"NormalParagraphStyle\"&gt;85&lt;/p&gt;'\n            \"       &lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;l\u00e1igovistti &lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.convert_p(avvir)\n\n        self.assertXmlEqual(avvir, want)\n\n    def test_convert_p_6(self):\n\"\"\"previous.text not None, sub_p.tail is None.\"\"\"\n        avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            '       &lt;p class=\"Privat ann tittel\"&gt;Stohpu&lt;br/&gt;vuovdemassi'\n            '&lt;p class=\"NormalParagraphStyle\"&gt;85&lt;/p&gt;&lt;br/&gt;&lt;/p&gt;'\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;Stohpu&lt;/p&gt;\"\n            \"       &lt;p&gt;vuovdemassi&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.convert_p(avvir)\n\n        self.assertXmlEqual(avvir, want)\n\n    def test_convert_p_7(self):\n\"\"\"previous.tail is None, sub_p.tail not None.\"\"\"\n        avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            '       &lt;p class=\"Privat ann tittel\"&gt;'\n            '&lt;br/&gt;&lt;p class=\"NormalParagraphStyle\"&gt;157&lt;/p&gt;Ozan vistt\u00e1\u017ea &lt;br/&gt;'\n            \"       &lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;Ozan vistt\u00e1\u017ea&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.convert_p(avvir)\n\n        self.assertXmlEqual(avvir, want)\n\n    def test_convert_p_9(self):\n\"\"\"Fix quotemarks.\"\"\"\n        avvir = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;a \u2039\u2039b\u203a\u203a c&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            '   &lt;story class=\"body\"&gt;'\n            \"       &lt;p&gt;a \u00abb\u00bb c&lt;/p&gt;\"\n            \"   &lt;/story&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.fix_quotemarks(avvir)\n\n        self.assertXmlEqual(avvir, want)\n\n    def test_convert_story(self):\n\"\"\"Test convert_story.\"\"\"\n        want = etree.fromstring(\n            \"&lt;article&gt;\"\n            \"    &lt;section&gt;\"\n            '        &lt;p type=\"title\"&gt;a&lt;/p&gt;'\n            \"    &lt;/section&gt;\"\n            \"    &lt;section&gt;\"\n            '        &lt;p type=\"title\"&gt;b&lt;/p&gt;'\n            \"    &lt;/section&gt;\"\n            \"    &lt;p&gt;c&lt;/p&gt;\"\n            \"    &lt;p&gt;d&lt;/p&gt;\"\n            \"    &lt;p&gt;e&lt;/p&gt;\"\n            \"    &lt;p&gt;f&lt;/p&gt;\"\n            \"    &lt;p&gt;h&lt;/p&gt;\"\n            \"    &lt;p&gt;i&lt;/p&gt;\"\n            \"    &lt;p&gt;j&lt;/p&gt;\"\n            \"    &lt;p&gt;l&lt;/p&gt;\"\n            \"    &lt;p&gt;m&lt;/p&gt;\"\n            \"    &lt;p&gt;n&lt;/p&gt;\"\n            \"    &lt;p&gt;o&lt;/p&gt;\"\n            \"&lt;/article&gt;\"\n        )\n\n        avvirconverter.remove_identical_ids(self.avvir)\n        avvirconverter.convert_p(self.avvir)\n        avvirconverter.convert_story(self.avvir)\n\n        self.assertXmlEqual(self.avvir, want)\n\n    def test_convert_article(self):\n\"\"\"Test convert_article.\"\"\"\n        want = etree.fromstring(\n            \"&lt;document&gt;\"\n            \"    &lt;body&gt;\"\n            \"        &lt;section&gt;\"\n            '            &lt;p type=\"title\"&gt;a&lt;/p&gt;'\n            \"        &lt;/section&gt;\"\n            \"        &lt;section&gt;\"\n            '            &lt;p type=\"title\"&gt;b&lt;/p&gt;'\n            \"        &lt;/section&gt;\"\n            \"        &lt;p&gt;c&lt;/p&gt;\"\n            \"        &lt;p&gt;d&lt;/p&gt;\"\n            \"        &lt;p&gt;e&lt;/p&gt;\"\n            \"        &lt;p&gt;f&lt;/p&gt;\"\n            \"        &lt;p&gt;h&lt;/p&gt;\"\n            \"        &lt;p&gt;i&lt;/p&gt;\"\n            \"        &lt;p&gt;j&lt;/p&gt;\"\n            \"        &lt;p&gt;l&lt;/p&gt;\"\n            \"        &lt;p&gt;m&lt;/p&gt;\"\n            \"        &lt;p&gt;n&lt;/p&gt;\"\n            \"        &lt;p&gt;o&lt;/p&gt;\"\n            \"    &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        avvirconverter.remove_identical_ids(self.avvir)\n        avvirconverter.convert_p(self.avvir)\n        avvirconverter.convert_story(self.avvir)\n\n        self.assertXmlEqual(avvirconverter.convert_article(self.avvir), want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.setUp","title":"<code>setUp()</code>","text":"<p>Setup a common AvvirConverter instance.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def setUp(self):\n\"\"\"Setup a common AvvirConverter instance.\"\"\"\n    self.avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '    &lt;story id=\"a\" class=\"Tittel\"&gt;'\n        \"        &lt;p&gt;a&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"b\" class=\"Undertittel\"&gt;'\n        \"        &lt;p&gt;b&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"c\" class=\"ingress\"&gt;'\n        \"        &lt;p&gt;c&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"d\" class=\"body\"&gt;'\n        '        &lt;p class=\"tekst\"&gt;d&lt;br/&gt;e&lt;br/&gt;&lt;/p&gt;'\n        \"        &lt;p&gt;f&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"g\" class=\"body\"&gt;'\n        '        &lt;p class=\"tekst\"&gt;h&lt;span&gt;i&lt;/span&gt;j&lt;/p&gt;'\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"k\" class=\"body\"&gt;'\n        \"        &lt;p&gt;l\"\n        \"            &lt;span&gt;\"\n        \"                m\"\n        \"                &lt;br/&gt;\"\n        \"                n\"\n        \"            &lt;/span&gt;\"\n        \"            o\"\n        \"        &lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"a\"&gt;'\n        \"        &lt;p&gt;a&lt;p&gt;b&lt;/p&gt;&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_article","title":"<code>test_convert_article()</code>","text":"<p>Test convert_article.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_article(self):\n\"\"\"Test convert_article.\"\"\"\n    want = etree.fromstring(\n        \"&lt;document&gt;\"\n        \"    &lt;body&gt;\"\n        \"        &lt;section&gt;\"\n        '            &lt;p type=\"title\"&gt;a&lt;/p&gt;'\n        \"        &lt;/section&gt;\"\n        \"        &lt;section&gt;\"\n        '            &lt;p type=\"title\"&gt;b&lt;/p&gt;'\n        \"        &lt;/section&gt;\"\n        \"        &lt;p&gt;c&lt;/p&gt;\"\n        \"        &lt;p&gt;d&lt;/p&gt;\"\n        \"        &lt;p&gt;e&lt;/p&gt;\"\n        \"        &lt;p&gt;f&lt;/p&gt;\"\n        \"        &lt;p&gt;h&lt;/p&gt;\"\n        \"        &lt;p&gt;i&lt;/p&gt;\"\n        \"        &lt;p&gt;j&lt;/p&gt;\"\n        \"        &lt;p&gt;l&lt;/p&gt;\"\n        \"        &lt;p&gt;m&lt;/p&gt;\"\n        \"        &lt;p&gt;n&lt;/p&gt;\"\n        \"        &lt;p&gt;o&lt;/p&gt;\"\n        \"    &lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    avvirconverter.remove_identical_ids(self.avvir)\n    avvirconverter.convert_p(self.avvir)\n    avvirconverter.convert_story(self.avvir)\n\n    self.assertXmlEqual(avvirconverter.convert_article(self.avvir), want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_1","title":"<code>test_convert_p_1()</code>","text":"<p>Check when p does not contain p.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_1(self):\n\"\"\"Check when p does not contain p.\"\"\"\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '    &lt;story class=\"Tittel\" id=\"a\"&gt;'\n        \"        &lt;p&gt;a&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story class=\"Undertittel\" id=\"b\"&gt;'\n        \"        &lt;p&gt;b&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story class=\"ingress\" id=\"c\"&gt;'\n        \"        &lt;p&gt;c&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story class=\"body\" id=\"d\"&gt;'\n        \"        &lt;p&gt;d&lt;/p&gt;\"\n        \"        &lt;p&gt;e&lt;/p&gt;\"\n        \"        &lt;p&gt;f&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story class=\"body\" id=\"g\"&gt;'\n        \"        &lt;p&gt;h&lt;/p&gt;\"\n        \"        &lt;p&gt;i&lt;/p&gt;\"\n        \"        &lt;p&gt;j&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story class=\"body\" id=\"k\"&gt;'\n        \"        &lt;p&gt;l&lt;/p&gt;\"\n        \"        &lt;p&gt;m&lt;/p&gt;\"\n        \"        &lt;p&gt;n&lt;/p&gt;\"\n        \"        &lt;p&gt;o&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.remove_identical_ids(self.avvir)\n    avvirconverter.convert_p(self.avvir)\n\n    self.assertXmlEqual(self.avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_2","title":"<code>test_convert_p_2()</code>","text":"<p>Check when p contains only p.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_2(self):\n\"\"\"Check when p contains only p.\"\"\"\n    avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;corrected text &lt;p&gt;text with typo&lt;/p&gt;with tail&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;corrected text with tail&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.convert_p(avvir)\n\n    self.assertXmlEqual(avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_3","title":"<code>test_convert_p_3()</code>","text":"<p>Check when p contains span and p.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_3(self):\n\"\"\"Check when p contains span and p.\"\"\"\n    avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;\"\n        \"           &lt;span&gt;bla bla&lt;/span&gt;\"\n        \"           corrected text &lt;p&gt;text with typo&lt;/p&gt;with tail\"\n        \"       &lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;bla bla&lt;/p&gt;\"\n        \"       &lt;p&gt;corrected text with tail&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.convert_p(avvir)\n\n    self.assertXmlEqual(avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_4","title":"<code>test_convert_p_4()</code>","text":"<p>p.text is None.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_4(self):\n\"\"\"p.text is None.\"\"\"\n    avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;&lt;p&gt; &lt;/p&gt;with tail\"\n        \"       &lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt; with tail&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.convert_p(avvir)\n\n    self.assertXmlEqual(avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_5","title":"<code>test_convert_p_5()</code>","text":"<p>sub_p.tail is None.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_5(self):\n\"\"\"sub_p.tail is None.\"\"\"\n    avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        '       &lt;p&gt;l\u00e1igovistti &lt;p class=\"NormalParagraphStyle\"&gt;85&lt;/p&gt;'\n        \"       &lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;l\u00e1igovistti &lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.convert_p(avvir)\n\n    self.assertXmlEqual(avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_6","title":"<code>test_convert_p_6()</code>","text":"<p>previous.text not None, sub_p.tail is None.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_6(self):\n\"\"\"previous.text not None, sub_p.tail is None.\"\"\"\n    avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        '       &lt;p class=\"Privat ann tittel\"&gt;Stohpu&lt;br/&gt;vuovdemassi'\n        '&lt;p class=\"NormalParagraphStyle\"&gt;85&lt;/p&gt;&lt;br/&gt;&lt;/p&gt;'\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;Stohpu&lt;/p&gt;\"\n        \"       &lt;p&gt;vuovdemassi&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.convert_p(avvir)\n\n    self.assertXmlEqual(avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_7","title":"<code>test_convert_p_7()</code>","text":"<p>previous.tail is None, sub_p.tail not None.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_7(self):\n\"\"\"previous.tail is None, sub_p.tail not None.\"\"\"\n    avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        '       &lt;p class=\"Privat ann tittel\"&gt;'\n        '&lt;br/&gt;&lt;p class=\"NormalParagraphStyle\"&gt;157&lt;/p&gt;Ozan vistt\u00e1\u017ea &lt;br/&gt;'\n        \"       &lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;Ozan vistt\u00e1\u017ea&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.convert_p(avvir)\n\n    self.assertXmlEqual(avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_p_9","title":"<code>test_convert_p_9()</code>","text":"<p>Fix quotemarks.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_p_9(self):\n\"\"\"Fix quotemarks.\"\"\"\n    avvir = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;a \u2039\u2039b\u203a\u203a c&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '   &lt;story class=\"body\"&gt;'\n        \"       &lt;p&gt;a \u00abb\u00bb c&lt;/p&gt;\"\n        \"   &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.fix_quotemarks(avvir)\n\n    self.assertXmlEqual(avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_convert_story","title":"<code>test_convert_story()</code>","text":"<p>Test convert_story.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_convert_story(self):\n\"\"\"Test convert_story.\"\"\"\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        \"    &lt;section&gt;\"\n        '        &lt;p type=\"title\"&gt;a&lt;/p&gt;'\n        \"    &lt;/section&gt;\"\n        \"    &lt;section&gt;\"\n        '        &lt;p type=\"title\"&gt;b&lt;/p&gt;'\n        \"    &lt;/section&gt;\"\n        \"    &lt;p&gt;c&lt;/p&gt;\"\n        \"    &lt;p&gt;d&lt;/p&gt;\"\n        \"    &lt;p&gt;e&lt;/p&gt;\"\n        \"    &lt;p&gt;f&lt;/p&gt;\"\n        \"    &lt;p&gt;h&lt;/p&gt;\"\n        \"    &lt;p&gt;i&lt;/p&gt;\"\n        \"    &lt;p&gt;j&lt;/p&gt;\"\n        \"    &lt;p&gt;l&lt;/p&gt;\"\n        \"    &lt;p&gt;m&lt;/p&gt;\"\n        \"    &lt;p&gt;n&lt;/p&gt;\"\n        \"    &lt;p&gt;o&lt;/p&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.remove_identical_ids(self.avvir)\n    avvirconverter.convert_p(self.avvir)\n    avvirconverter.convert_story(self.avvir)\n\n    self.assertXmlEqual(self.avvir, want)\n</code></pre>"},{"location":"reference/test/test_avvirconverter/#corpustools.test.test_avvirconverter.TestAvvirConverter.test_remove_identical_ids","title":"<code>test_remove_identical_ids()</code>","text":"<p>Check that only the first of stories with identical ids are kept.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_avvirconverter.py</code> <pre><code>def test_remove_identical_ids(self):\n\"\"\"Check that only the first of stories with identical ids are kept.\"\"\"\n    want = etree.fromstring(\n        \"&lt;article&gt;\"\n        '    &lt;story id=\"a\" class=\"Tittel\"&gt;'\n        \"        &lt;p&gt;a&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"b\" class=\"Undertittel\"&gt;'\n        \"        &lt;p&gt;b&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"c\" class=\"ingress\"&gt;'\n        \"        &lt;p&gt;c&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"d\" class=\"body\"&gt;'\n        '        &lt;p class=\"tekst\"&gt;d&lt;br/&gt;e&lt;br/&gt;&lt;/p&gt;'\n        \"        &lt;p&gt;f&lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"g\" class=\"body\"&gt;'\n        '        &lt;p class=\"tekst\"&gt;h&lt;span&gt;i&lt;/span&gt;j&lt;/p&gt;'\n        \"    &lt;/story&gt;\"\n        '    &lt;story id=\"k\" class=\"body\"&gt;'\n        \"        &lt;p&gt;l\"\n        \"            &lt;span&gt;\"\n        \"                m\"\n        \"                &lt;br/&gt;\"\n        \"                n\"\n        \"            &lt;/span&gt;\"\n        \"            o\"\n        \"        &lt;/p&gt;\"\n        \"    &lt;/story&gt;\"\n        \"&lt;/article&gt;\"\n    )\n\n    avvirconverter.remove_identical_ids(self.avvir)\n    self.assertXmlEqual(self.avvir, want)\n</code></pre>"},{"location":"reference/test/test_biblexmlconverter/","title":"test_biblexmlconverter","text":"<p>Test the BiblexmlConverter class.</p>"},{"location":"reference/test/test_biblexmlconverter/#corpustools.test.test_biblexmlconverter.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>","text":"<p>Check if two xml snippets are equal.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_biblexmlconverter.py</code> <pre><code>def assertXmlEqual(got, want):\n\"\"\"Check if two xml snippets are equal.\"\"\"\n    got = lxml.etree.tostring(got, encoding=\"unicode\")\n    want = lxml.etree.tostring(want, encoding=\"unicode\")\n    checker = lxml.doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(want, got, 0):\n        message = checker.output_difference(doctest.Example(\"\", want), got, 0)\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_biblexmlconverter/#corpustools.test.test_biblexmlconverter.check_conversion","title":"<code>check_conversion(testname, bible_xml)</code>","text":"<p>Check that the bible xml is correctly converted.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_biblexmlconverter.py</code> <pre><code>def check_conversion(testname, bible_xml):\n\"\"\"Check that the bible xml is correctly converted.\"\"\"\n    with TempDirectory() as temp_dir:\n        corpusfilename = \"orig/sme/bible/nt/bogus.bible.xml\"\n        temp_dir.write(corpusfilename, bible_xml[\"orig\"].encode(\"utf8\"))\n\n        got = biblexmlconverter.convert2intermediate(\n            os.path.join(temp_dir.path, corpusfilename)\n        )\n        want = lxml.etree.fromstring(bible_xml[\"converted\"])\n\n        assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_biblexmlconverter/#corpustools.test.test_biblexmlconverter.test_conversion","title":"<code>test_conversion()</code>","text":"<p>Test conversion of bible xml elements.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_biblexmlconverter.py</code> <pre><code>def test_conversion():\n\"\"\"Test conversion of bible xml elements.\"\"\"\n    for testname, bible_xml in TESTS.items():\n        yield check_conversion, testname, bible_xml\n</code></pre>"},{"location":"reference/test/test_ccat/","title":"test_ccat","text":""},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat","title":"<code>TestCcat</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>class TestCcat(unittest.TestCase):\n    def test_p(self):\n\"\"\"Test the output of a plain p with default text flow\"\"\"\n        xml_printer = ccat.XMLPrinter()\n        buffer = io.StringIO()\n        input_p = etree.fromstring(\n            \"&lt;p&gt;Et stykke av Norge som er lite kjent - \"\n            \"Litt om Norge i mellomkrigstiden&lt;/p&gt;\"\n        )\n\n        xml_printer.collect_text(input_p, \"nob\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"Et stykke av Norge som er lite kjent - \"\n                \"Litt om Norge i mellomkrigstiden \u00b6\\n\"\n            ),\n        )\n\n    def test_p_with_span(self):\n\"\"\"The output of a plain p with a span element\"\"\"\n        xml_printer = ccat.XMLPrinter()\n        buffer = io.StringIO()\n\n        input_p = etree.fromstring(\n            \"&lt;p&gt;I 1864 ga han ut boka \"\n            '&lt;span type=\"quote\" xml:lang=\"dan\"&gt;'\n            '\"Fornuftigt Madstel\"'\n            \"&lt;/span&gt;.\"\n            \"&lt;/p&gt;\"\n        )\n\n        xml_printer.collect_text(input_p, \"nob\", buffer)\n        self.assertEqual(\n            buffer.getvalue(), 'I 1864 ga han ut boka \"Fornuftigt Madstel\". \u00b6\\n'\n        )\n\n    def test_p_with_error(self):\n\"\"\"The output of a p containing a nested error element\"\"\"\n        xml_printer = ccat.XMLPrinter()\n        buffer = io.StringIO()\n\n        input_p = etree.fromstring(\n            \"&lt;p&gt;\"\n            \"&lt;errormorphsyn&gt;\"\n            '&lt;errorort correct=\"Bearpmehat\" errtype=\"svow\" pos=\"noun\"&gt;'\n            \"Bearpmahat\"\n            \"&lt;/errorort&gt;\"\n            \"&lt;errorlex&gt;\"\n            \" earuha\"\n            '&lt;correct errtype=\"w\" origpos=\"v\" pos=\"verb\"&gt;sirre&lt;/correct&gt;'\n            \"&lt;/errorlex&gt;\"\n            '&lt;correct cat=\"pl3prs\" const=\"fin\"  errtype=\"agr\" orig=\"sg3prs\" '\n            'pos=\"verb\"&gt;Bearpmehat sirrejit&lt;/correct&gt;'\n            \"&lt;/errormorphsyn&gt;\"\n            \" uskki ja loaiddu.\"\n            \"&lt;/p&gt;\"\n        )\n\n        xml_printer.collect_text(input_p, \"sme\", buffer)\n        self.assertEqual(buffer.getvalue(), \"Bearpmahat earuha uskki ja loaiddu. \u00b6\\n\")\n\n    def test_p_one_word_per_line(self):\n\"\"\"Test the output of a plain p element, one word per line\"\"\"\n        input_p = etree.fromstring(\n            \"&lt;p&gt;Et stykke av Norge som er lite kjent - \"\n            \"Litt om Norge i mellomkrigstiden&lt;/p&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(one_word_per_line=True)\n\n        buffer = io.StringIO()\n\n        xml_printer.collect_text(input_p, \"nob\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"Et\\n\"\n                \"stykke\\n\"\n                \"av\\n\"\n                \"Norge\\n\"\n                \"som\\n\"\n                \"er\\n\"\n                \"lite\\n\"\n                \"kjent\\n\"\n                \"-\\n\"\n                \"Litt\\n\"\n                \"om\\n\"\n                \"Norge\\n\"\n                \"i\\n\"\n                \"mellomkrigstiden\\n\"\n            ),\n        )\n\n    def test_p_with_span_one_word_per_line(self):\n\"\"\"Output a plain p that contains a span element\n\n        one_word_per-line is True\n        \"\"\"\n        input_p = etree.fromstring(\n            \"&lt;p&gt;I 1864 ga han ut boka \"\n            '    &lt;span type=\"quote\" xml:lang=\"dan\"&gt;'\n            '        \"Fornuftigt Madstel\"'\n            \"    &lt;/span&gt;.\"\n            \"&lt;/p&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(one_word_per_line=True)\n        buffer = io.StringIO()\n\n        xml_printer.collect_text(input_p, \"nob\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"I\\n\"\n                \"1864\\n\"\n                \"ga\\n\"\n                \"han\\n\"\n                \"ut\\n\"\n                \"boka\\n\"\n                '\"Fornuftigt\\n'\n                'Madstel\"\\n'\n                \".\\n\"\n            ),\n        )\n\n    def test_p_with_error_one_word_per_line(self):\n        input_p = etree.fromstring(\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(one_word_per_line=True)\n\n        buffer = io.StringIO()\n        xml_printer.collect_text(input_p, \"sme\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"liv\u010d\u010dii\\n\"\n                \"makkarge\\tmakk\u00e1rge\\t#errtype=\u00e1,pos=adv\\n\"\n                \"politihkka,\\nmuhto\\nrahpasit\\nbaicca\\nmuitaliv\u010d\u010de\\n\"\n                \"makk\u00e1r soga\\tman soga\\n\"\n                \"makkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\\nsoga\\nsii\\n\"\n            ),\n        )\n\n    def test_p_with_error_correction(self):\n\"\"\"correction = True, print all corrections\"\"\"\n        input_p = etree.fromstring(\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(correction=True)\n\n        buffer = io.StringIO()\n        xml_printer.collect_text(input_p, \"sme\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"liv\u010d\u010dii makk\u00e1rge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n                \"man soga sii \u00b6\\n\"\n            ),\n        )\n\n    def test_p_with_error_filtering_errorlex(self):\n\"\"\"errorlex = True, print errorlex corrections\"\"\"\n        input_p = etree.fromstring(\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(errorlex=True)\n\n        buffer = io.StringIO()\n        xml_printer.collect_text(input_p, \"sme\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"liv\u010d\u010dii makkarge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n                \"man soga sii \u00b6\\n\"\n            ),\n        )\n\n    def test_p_with_error_filtering_errormorphsyn(self):\n\"\"\"errormorphsyn = True, print errormorphsyn corrections\"\"\"\n        input_p = etree.fromstring(\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(errormorphsyn=True)\n\n        buffer = io.StringIO()\n        xml_printer.collect_text(input_p, \"sme\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"liv\u010d\u010dii makkarge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n                \"makkar soga sii \u00b6\\n\"\n            ),\n        )\n\n    def test_p_with_error_filtering_errorort(self):\n\"\"\"errorort = True, print errorort corrections\"\"\"\n        xml_printer = ccat.XMLPrinter(errorort=True)\n\n        input_p = etree.fromstring(\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n        )\n\n        buffer = io.StringIO()\n        xml_printer.collect_text(input_p, \"sme\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"liv\u010d\u010dii makk\u00e1rge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n                \"makk\u00e1r soga sii \u00b6\\n\"\n            ),\n        )\n\n    def test_p_with_error_filtering_errorortreal(self):\n        xml_printer = ccat.XMLPrinter(errorortreal=True)\n\n        input_p = etree.fromstring(\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n        )\n\n        buffer = io.StringIO()\n        xml_printer.collect_text(input_p, \"sme\", buffer)\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"liv\u010d\u010dii makkarge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n                \"makkar soga sii \u00b6\\n\"\n            ),\n        )\n\n    def test_visit_this_p_default(self):\n\"\"\"Visit only plain p and &lt;p type=text&gt; elements\"\"\"\n        xml_printer = ccat.XMLPrinter()\n\n        for types in [' type=\"title\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n        for types in [\"\", ' type=\"text\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertTrue(xml_printer.visit_this_node(input_xml))\n\n    def test_visit_this_p_title_set(self):\n\"\"\"Visit only &lt;p type=title&gt; elements when title is True\"\"\"\n        xml_printer = ccat.XMLPrinter(title=True)\n\n        for types in [\"\", ' type=\"text\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n        for types in [' type=\"title\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertTrue(xml_printer.visit_this_node(input_xml))\n\n    def test_visit_this_p_listitem_set(self):\n\"\"\"Visit only &lt;p type=listitem&gt; elements when listitem is True\"\"\"\n        xml_printer = ccat.XMLPrinter(listitem=True)\n\n        for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"tablecell\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n        for types in [' type=\"listitem\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertTrue(xml_printer.visit_this_node(input_xml))\n\n    def test_visit_this_p_tablecell_set(self):\n\"\"\"Visit only &lt;p type=tablecell&gt; elements when table is True\"\"\"\n        xml_printer = ccat.XMLPrinter(table=True)\n\n        for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"listitem\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n        for types in [' type=\"tablecell\"']:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertTrue(xml_printer.visit_this_node(input_xml))\n\n    def test_visit_this_p_allp_set(self):\n\"\"\"Visit all p elements when all_paragraphs is True\"\"\"\n        xml_printer = ccat.XMLPrinter(all_paragraphs=True)\n\n        for types in [\n            \"\",\n            ' type=\"text\"',\n            ' type=\"title\"',\n            ' type=\"listitem\"',\n            ' type=\"tablecell\"',\n        ]:\n            input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n            self.assertTrue(xml_printer.visit_this_node(input_xml))\n\n    def test_process_file_default(self):\n\"\"\"Default settings, print content of p elements\n\n        Check the output of plain p elements, with default settings\n        Specifically, check that only plain p gets output, whereas\n        p elements with the type title, listitem and tablecell get no output.\n        \"\"\"\n        xml_printer = ccat.XMLPrinter()\n\n        for types in [' type=\"title\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n            document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n                + types\n                + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n            )\n\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\")\n\n        for types in [\"\", ' type=\"text\"']:\n            document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n                + types\n                + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n            )\n\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n\n    def test_process_file_title_set(self):\n\"\"\"Print only content of p elements with type=title.\"\"\"\n        xml_printer = ccat.XMLPrinter(title=True)\n\n        for types in [\"\", ' type=\"text\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n            document = (\n                '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p {}&gt;'\n                \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\".format(types)\n            )\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\")\n\n        for types in [' type=\"title\"']:\n            document = (\n                '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p {}&gt;'\n                \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\".format(types)\n            )\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n\n    def test_process_file_listitem_set(self):\n\"\"\"Print only content of p elements with type=listitem.\"\"\"\n        xml_printer = ccat.XMLPrinter(listitem=True)\n\n        for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"tablecell\"']:\n            document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n                + types\n                + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n            )\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\")\n\n        for types in [' type=\"listitem\"']:\n            document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n                + types\n                + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n            )\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n\n    def test_process_file_tablecell_set(self):\n\"\"\"Print only content of p elements with type=title gets output.\"\"\"\n        xml_printer = ccat.XMLPrinter(table=True)\n\n        for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"listitem\"']:\n            document = (\n                '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p '\n                + types\n                + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n            )\n\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\")\n\n        for types in [' type=\"tablecell\"']:\n            document = (\n                '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p '\n                + types\n                + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n            )\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n\n    def test_process_file_allp_set(self):\n\"\"\"all_paragraphs option is True, all p elements get output.\"\"\"\n        xml_printer = ccat.XMLPrinter(all_paragraphs=True)\n\n        for types in [\n            \"\",\n            ' type=\"text\"',\n            ' type=\"title\"',\n            ' type=\"listitem\"',\n            ' type=\"tablecell\"',\n        ]:\n            document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n                + types\n                + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n            )\n            xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n            buffer = xml_printer.process_file()\n            self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n\n    def test_process_file_one_word_per_line_errorlex(self):\n\"\"\"Print only errorlex content\n\n        Check the output of a p element containing two error elements,\n        a plain errorort one, and a nested errorlex one when\n        the one_word_per_line and errorlex options are True.\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(one_word_per_line=True, errorlex=True)\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"liv\u010d\u010dii\\n\"\n                \"makkarge\\n\"\n                \"politihkka,\\n\"\n                \"muhto\\n\"\n                \"rahpasit\\n\"\n                \"baicca\\n\"\n                \"muitaliv\u010d\u010de\\n\"\n                \"makk\u00e1r soga\\tman soga\\n\"\n                \"sii\\n\"\n            ),\n        )\n\n    def test_process_file_one_word_per_line_errorort(self):\n\"\"\"Print only errorort content\n\n        Check the output of a p element containing two error elements,\n        a plain errorort one, and a nested errorlex one when\n        the one_word_per_line and errorort options are True\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(one_word_per_line=True, errorort=True)\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        got = buffer.getvalue()\n        want = (\n            \"liv\u010d\u010dii\\n\"\n            \"makkarge\\tmakk\u00e1rge\\t#errtype=\u00e1,pos=adv\\n\"\n            \"politihkka,\\n\"\n            \"muhto\\n\"\n            \"rahpasit\\n\"\n            \"baicca\\n\"\n            \"muitaliv\u010d\u010de\\n\"\n            \"makkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\\n\"\n            \"soga\\n\"\n            \"sii\\n\"\n        )\n        self.assertEqual(got, want)\n\n    def test_process_file_typos(self):\n\"\"\"Print all error content\n\n        Check the output of a p element containing two error elements,\n        a plain errorort one, and a nested errorlex one when\n        the typos option True\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(typos=True)\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"makkarge\\tmakk\u00e1rge\\t#errtype=\u00e1,pos=adv\\n\"\n                \"makk\u00e1r soga\\tman soga\\n\"\n                \"makkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\\n\"\n            ),\n        )\n\n    def test_process_file_typos_errorlex(self):\n\"\"\"Print only errorlex content\n\n        Check the output of a p element containing two error elements,\n        a plain errorort one, and a nested errorlex one when\n        the typos and errorlex options are True\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(typos=True, errorlex=True)\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"makk\u00e1r soga\\tman soga\\n\")\n\n    def test_process_file_typos_errorort(self):\n\"\"\"Print only errorort content\n\n        Check the output of a p element containing two error elements,\n        a plain errorort one, and a nested errorlex one when\n        the one_word_per_line, typos and errorort options are True\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;liv\u010d\u010dii \"\n            \"&lt;errorort&gt;\"\n            \"makkarge\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n            \" sii\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(typos=True, one_word_per_line=True, errorort=True)\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"makkarge\\tmakk\u00e1rge\\t#errtype=\u00e1,pos=adv\\n\"\n                \"makkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\\n\"\n            ),\n        )\n\n    def test_get_lang(self):\n\"\"\"Check that get_lang finds the main lang of the document\"\"\"\n        xml_printer = ccat.XMLPrinter()\n        xml_printer.etree = etree.parse(\n            io.BytesIO(b'&lt;document id=\"no_id\" xml:lang=\"sme\"/&gt;')\n        )\n\n        self.assertEqual(xml_printer.get_lang(), \"sme\")\n\n    def test_get_element_language_same_as_parent(self):\n\"\"\"xml:lang is not set in the p element. Return parent language.\"\"\"\n        xml_printer = ccat.XMLPrinter()\n\n        element = etree.fromstring(\"&lt;p/&gt;\")\n        self.assertEqual(xml_printer.get_element_language(element, \"sme\"), \"sme\")\n\n    def test_get_element_language_different_from_parent(self):\n\"\"\"Check that the value of xml:lang is returned when it is set.\"\"\"\n        xml_printer = ccat.XMLPrinter()\n\n        element = etree.fromstring('&lt;p xml:lang=\"nob\"/&gt;')\n        self.assertEqual(xml_printer.get_element_language(element, \"sme\"), \"nob\")\n\n    def test_process_file_language_nob(self):\n\"\"\"lang=nob, only nob content should be output\"\"\"\n        xml_printer = ccat.XMLPrinter(lang=\"nob\")\n        xml_printer.etree = etree.parse(\n            io.BytesIO(\n                    b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                    b\"&lt;body&gt;\"\n                    b\"&lt;p&gt;\"\n                    b\"nob1 \"\n                    b'&lt;span type=\"quote\" xml:lang=\"dan\"&gt;dan1&lt;/span&gt;'\n                    b\" nob2&lt;/p&gt;\"\n                    b\"&lt;/body&gt;\"\n                    b\"&lt;/document&gt;\"\n            )\n        )\n\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"nob1  nob2 \u00b6\\n\")\n\n    def test_process_two_paragraphs(self):\n\"\"\"Check that the \u00b6 character is printed\"\"\"\n        xml_printer = ccat.XMLPrinter()\n        xml_printer.etree = etree.parse(\n            io.BytesIO(\n                    b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                    b\"    &lt;body&gt;\"\n                    b\"        &lt;p&gt;nob1&lt;/p&gt;\"\n                    b\"        &lt;p&gt;nob2&lt;/p&gt;\"\n                    b\"    &lt;/body&gt;\"\n                    b\"&lt;/document&gt;\"\n            )\n        )\n\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"nob1 \u00b6\\nnob2 \u00b6\\n\")\n\n    def test_process_minus_l_sme(self):\n\"\"\"lang=sme, no elements are sme\n\n        Check that nothing is output when the wanted language\n        (set in the lang option) is not the same language as any of the\n        content of the elements.\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            \"&lt;body&gt;\"\n            '&lt;p type=\"text\"&gt;'\n            \"men \"\n            \"&lt;errormorphsyn&gt;\"\n            \"skoledagene er s\u00e5 \"\n            \"&lt;errorort&gt;\"\n            \"vanskerlig\"\n            '&lt;correct errtype=\"nosilent\" pos=\"adj\"&gt;vanskelig&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            '&lt;correct cat=\"x\" const=\"spred\" errtype=\"agr\" orig=\"x\" pos=\"adj\"&gt;'\n            \"koledagene er s\u00e5 vanskelige\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n            \" \u00e5 komme igjennom,\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(lang=\"sme\")\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n\n        self.assertEqual(buffer.getvalue(), \"\")\n\n    def test_foreign(self):\n\"\"\"Check the output of a p containing an errorlang element\n\n        The errorlang option is True.\n        \"\"\"\n        xml_printer = ccat.XMLPrinter(errorlang=True)\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;\"\n            \"Vijmak bierjjedak! \"\n            \"&lt;errorlang&gt;\"\n            \"Pjuh\"\n            \"&lt;correct&gt;nor&lt;/correct&gt;\"\n            \"&lt;/errorlang&gt;\"\n            \" vijmak de bierjjedak \"\n            \"&lt;errorort&gt;\"\n            \"sjatt\u00e1j\"\n            '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;sjattaj&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \".\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n\n        self.assertEqual(\n            buffer.getvalue(),\n            (\"Vijmak bierjjedak! nor vijmak de bierjjedak sjatt\u00e1j. \u00b6\\n\"),\n        )\n\n    def test_no_foreign(self):\n\"\"\"noforeign option is True\n\n        Neither the errorlang.text nor the correct attribute should be output.\n        Check that this really happens.\n        \"\"\"\n        xml_printer = ccat.XMLPrinter(noforeign=True)\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;\"\n            \"Vijmak bierjjedak! \"\n            \"&lt;errorlang&gt;\"\n            \"Pjuh\"\n            \"&lt;correct&gt;nor&lt;/correct&gt;\"\n            \"&lt;/errorlang&gt;\"\n            \" vijmak de bierjjedak \"\n            \"&lt;errorort&gt;\"\n            \"sjatt\u00e1j\"\n            '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;sjattaj&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \".\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n\n        self.assertEqual(\n            buffer.getvalue(), (\"Vijmak bierjjedak!  vijmak de bierjjedak sjatt\u00e1j. \u00b6\\n\")\n        )\n\n    def test_no_foreign_typos(self):\n\"\"\"noforeign is True, typos is True\n\n        When the noforeign option is True, neither the errorlang.text\n        nor the correct attribute should be output. Check that this really\n        happens even when the typos option is set.\n        \"\"\"\n        xml_printer = ccat.XMLPrinter(typos=True, noforeign=True)\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;\"\n            \"Vijmak bierjjedak! \"\n            \"&lt;errorlang&gt;\"\n            \"Pjuh\"\n            \"&lt;correct&gt;nor&lt;/correct&gt;\"\n            \"&lt;/errorlang&gt;\"\n            \" vijmak de bierjjedak \"\n            \"&lt;errorort&gt;\"\n            \"sjatt\u00e1j\"\n            '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;sjattaj&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \".\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n\n        self.assertEqual(buffer.getvalue(), \"sjatt\u00e1j\\tsjattaj\\t#errorinfo=vowlat,\u00e1-a\\n\")\n\n    def test_typos_errordepth3(self):\n\"\"\"Check the output of a p containing a nested error element\n\n        typos option is True, depth is 3\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;\"\n            \"&lt;errormorphsyn&gt;\"\n            \"&lt;errormorphsyn&gt;\"\n            \"&lt;errorort&gt;\"\n            \"\u010doaggen\"\n            '&lt;correct errtype=\"mono\" pos=\"verb\"&gt;\u010doggen&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            \" ollu jok\u014bat\"\n            '&lt;correct cat=\"genpl\" const=\"obj\" errtype=\"case\" orig=\"nompl\" pos=\"noun\"&gt;'\n            \"\u010doggen ollu jo\u014baid\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n            \" ja sarridat\"\n            '&lt;correct cat=\"genpl\" const=\"obj\" errtype=\"case\" orig=\"nompl\" pos=\"noun\"&gt;'\n            \"\u010doggen ollu jo\u014baid ja sarridiid\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n        xml_printer = ccat.XMLPrinter(typos=True)\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n\n        buffer = xml_printer.process_file()\n        got = buffer.getvalue()\n        want = (\n            \"\u010doggen ollu jo\u014baid ja sarridat\"\n            \"\\t\u010doggen ollu jo\u014baid ja sarridiid\"\n            \"\\t#cat=genpl,const=obj,errtype=case,orig=nompl,pos=noun\\n\"\n            \"\u010doggen ollu jok\u014bat\\t\u010doggen ollu jo\u014baid\"\n            \"\\t#cat=genpl,const=obj,errtype=case,orig=nompl,pos=noun\\n\"\n            \"\u010doaggen\\t\u010doggen\\t#errtype=mono,pos=verb\\n\"\n        )\n\n        self.maxDiff = None\n        self.assertEqual(got, want)\n\n    def test_typos_errormorphsyn_twice(self):\n\"\"\"Check the output of a plain p\n\n        The p contains a doubly nested\n        errormorphsyn element when the typos and errormorphsyn\n        options are True\n        \"\"\"\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            \"&lt;body&gt;\"\n            \"&lt;p&gt;\"\n            \"&lt;errormorphsyn&gt;\"\n            \"leat \"\n            \"&lt;errormorphsyn&gt;\"\n            \"okta m\u00e1n\u00e1\"\n            '&lt;correct cat=\"nomsg\" const=\"spred\" errtype=\"case\" orig=\"gensg\" pos=\"n\"&gt;'\n            \"okta m\u00e1nn\u00e1\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n            '&lt;correct cat=\"sg3prs\" const=\"v\" errtype=\"agr\" orig=\"pl3prs\" pos=\"v\"&gt;'\n            \"lea okta m\u00e1nn\u00e1\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n            \"&lt;/p&gt;\"\n            \"&lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(typos=True, errormorphsyn=True)\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n\n        buffer = xml_printer.process_file()\n\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                \"leat okta m\u00e1nn\u00e1\\tlea okta m\u00e1nn\u00e1\"\n                \"\\t#cat=sg3prs,const=v,errtype=agr,orig=pl3prs,pos=v\\n\"\n                \"okta m\u00e1n\u00e1\\tokta m\u00e1nn\u00e1\"\n                \"\\t#cat=nomsg,const=spred,errtype=case,orig=gensg,pos=n\\n\"\n            ),\n        )\n\n    def test_process_file1(self):\n\"\"\"Test process_file with a disambiguation element as input\"\"\"\n        xml_printer = ccat.XMLPrinter(disambiguation=True)\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;\\n'\n            \"    &lt;body&gt;\\n\"\n            '        &lt;disambiguation&gt;\"&amp;lt;Muhto&amp;gt;\"\\n'\n            '\\t\"muhto\" CC &amp;lt;sme&amp;gt; @CVP\\n\"&amp;lt;gaskkohagaid&amp;gt;\"\\n'\n            '\\t\"gaskkohagaid\" Adv &amp;lt;sme&amp;gt;\\n\"&amp;lt;,&amp;gt;\"\\n'\n            '\\t\",\" CLB\\n\"&amp;lt;ja&amp;gt;\"\\n'\n            '\\t\"ja\" CC &amp;lt;sme&amp;gt; @CNP\\n\"&amp;lt;erenoam\u00e1\u017eit&amp;gt;\"\\n'\n            '\\t\"erenoam\u00e1\u017eit\" Adv &amp;lt;sme&amp;gt;\\n\"&amp;lt;dalle_go&amp;gt;\"\\n'\n            '\\t\"dalle_go\" MWE CS &amp;lt;sme&amp;gt; @CVP\\n\"&amp;lt;lei&amp;gt;\"\\n'\n            '\\t\"leat\" V &amp;lt;sme&amp;gt; IV Ind Prt Sg3 @+FMAINV\\n'\n            '\"&amp;lt;buola\u0161&amp;gt;\"\\n'\n            '\\t\"buola\u0161\" Sem/Wthr N &amp;lt;sme&amp;gt; Sg Nom\\n\"&amp;lt;,&amp;gt;\"\\n'\n            '\\t\",\" CLB\\n\"&amp;lt;de&amp;gt;\"\\n'\n            '\\t\"de\" Adv &amp;lt;sme&amp;gt;\\n\"&amp;lt;aggreg\u00e1hta&amp;gt;\"\\n'\n            '\\t\"aggreg\u00e1hta\" N &amp;lt;sme&amp;gt; Sg Nom\\n\"&amp;lt;bill\u00e1nii&amp;gt;\"\\n'\n            '\\t\"bill\u00e1nit\" V &amp;lt;sme&amp;gt; IV Ind Prt Sg3 @+FMAINV\\n'\n            '\"&amp;lt;.&amp;gt;\"\\n\\t\".\" CLB\\n\\n\"&amp;lt;\u00b6&amp;gt;\"\\n'\n            '\\t\"\u00b6\" CLB\\n\\n&lt;/disambiguation&gt;&lt;/body&gt;&lt;/document&gt;'\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                '\"&lt;Muhto&gt;\"\\n\\t\"muhto\" CC &lt;sme&gt; @CVP\\n\"&lt;gaskkohagaid&gt;\"\\n'\n                '\\t\"gaskkohagaid\" Adv &lt;sme&gt;\\n\"&lt;,&gt;\"\\n'\n                '\\t\",\" CLB\\n\"&lt;ja&gt;\"\\n\\t\"ja\" CC &lt;sme&gt; @CNP\\n\"&lt;erenoam\u00e1\u017eit&gt;\"\\n'\n                '\\t\"erenoam\u00e1\u017eit\" Adv &lt;sme&gt;\\n\"&lt;dalle_go&gt;\"\\n'\n                '\\t\"dalle_go\" MWE CS &lt;sme&gt; @CVP\\n\"&lt;lei&gt;\"\\n'\n                '\\t\"leat\" V &lt;sme&gt; IV Ind Prt Sg3 @+FMAINV\\n\"&lt;buola\u0161&gt;\"\\n'\n                '\\t\"buola\u0161\" Sem/Wthr N &lt;sme&gt; Sg Nom\\n\"&lt;,&gt;\"\\n'\n                '\\t\",\" CLB\\n\"&lt;de&gt;\"\\n\\t\"de\" Adv &lt;sme&gt;\\n\"&lt;aggreg\u00e1hta&gt;\"\\n'\n                '\\t\"aggreg\u00e1hta\" N &lt;sme&gt; Sg Nom\\n\"&lt;bill\u00e1nii&gt;\"\\n'\n                '\\t\"bill\u00e1nit\" V &lt;sme&gt; IV Ind Prt Sg3 @+FMAINV\\n\"&lt;.&gt;\"\\n'\n                '\\t\".\" CLB\\n\\n\"&lt;\u00b6&gt;\"\\n\\t\"\u00b6\" CLB\\n\\n'\n            ),\n        )\n\n    def test_process_file2(self):\n\"\"\"Test process_file with a dependency element as input\"\"\"\n        xml_printer = ccat.XMLPrinter(dependency=True)\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;\\n'\n            \"    &lt;body&gt;\\n\"\n            '        &lt;dependency&gt;\"&amp;lt;Muhto&amp;gt;\"\\n'\n            '\\t\"muhto\" CC @CVP #1-&amp;gt;1 \\n\"&amp;lt;gaskkohagaid&amp;gt;\"\\n'\n            '\\t\"gaskkohagaid\" Adv @ADVL&amp;gt; #2-&amp;gt;12 \\n\"&amp;lt;,&amp;gt;\"\\n'\n            '\\t\",\" CLB #3-&amp;gt;4 \\n\"&amp;lt;ja&amp;gt;\"\\n'\n            '\\t\"ja\" CC @CNP #4-&amp;gt;2 \\n\"&amp;lt;erenoam\u00e1\u017eit&amp;gt;\"\\n'\n            '\\t\"erenoam\u00e1\u017eit\" Adv @ADVL&amp;gt; #5-&amp;gt;12 \\n'\n            '\"&amp;lt;dalle_go&amp;gt;\"\\n'\n            '\\t\"dalle_go\" CS @CVP #6-&amp;gt;7 \\n\"&amp;lt;lei&amp;gt;\"\\n'\n            '\\t\"leat\" V IV Ind Prt Sg3 @FS-ADVL&amp;gt; #7-&amp;gt;12 \\n'\n            '\"&amp;lt;buola\u0161&amp;gt;\"\\n'\n            '\\t\"buola\u0161\" N Sg Nom @&amp;lt;SPRED #8-&amp;gt;7 \\n\"&amp;lt;,&amp;gt;\"\\n'\n            '\\t\",\" CLB #9-&amp;gt;6 \\n\"&amp;lt;de&amp;gt;\"\\n'\n            '\\t\"de\" Adv @ADVL&amp;gt; #10-&amp;gt;12 \\n\"&amp;lt;aggreg\u00e1hta&amp;gt;\"\\n'\n            '\\t\"aggreg\u00e1hta\" N Sg Nom @SUBJ&amp;gt; #11-&amp;gt;12 \\n'\n            '\"&amp;lt;bill\u00e1nii&amp;gt;\"\\n'\n            '\\t\"bill\u00e1nit\" V IV Ind Prt Sg3 @FS-ADVL&amp;gt; #12-&amp;gt;0 \\n'\n            '\"&amp;lt;.&amp;gt;\"\\n\\t\".\" CLB #13-&amp;gt;12 \\n\\n\"&amp;lt;\u00b6&amp;gt;\"\\n'\n            '\\t\"\u00b6\" CLB #1-&amp;gt;1 \\n\\n&lt;/dependency&gt;\\n'\n            \"    &lt;/body&gt;\\n\"\n            \"&lt;/document&gt;\"\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n\n        self.assertEqual(\n            buffer.getvalue(),\n            (\n                '\"&lt;Muhto&gt;\"\\n\\t\"muhto\" CC @CVP #1-&gt;1 \\n\"&lt;gaskkohagaid&gt;\"\\n'\n                '\\t\"gaskkohagaid\" Adv @ADVL&gt; #2-&gt;12 \\n\"&lt;,&gt;\"\\n'\n                '\\t\",\" CLB #3-&gt;4 \\n\"&lt;ja&gt;\"\\n'\n                '\\t\"ja\" CC @CNP #4-&gt;2 \\n\"&lt;erenoam\u00e1\u017eit&gt;\"\\n'\n                '\\t\"erenoam\u00e1\u017eit\" Adv @ADVL&gt; #5-&gt;12 \\n\"&lt;dalle_go&gt;\"\\n'\n                '\\t\"dalle_go\" CS @CVP #6-&gt;7 \\n\"&lt;lei&gt;\"\\n'\n                '\\t\"leat\" V IV Ind Prt Sg3 @FS-ADVL&gt; #7-&gt;12 \\n\"&lt;buola\u0161&gt;\"\\n'\n                '\\t\"buola\u0161\" N Sg Nom @&lt;SPRED #8-&gt;7 \\n\"&lt;,&gt;\"\\n'\n                '\\t\",\" CLB #9-&gt;6 \\n\"&lt;de&gt;\"\\n'\n                '\\t\"de\" Adv @ADVL&gt; #10-&gt;12 \\n\"&lt;aggreg\u00e1hta&gt;\"\\n'\n                '\\t\"aggreg\u00e1hta\" N Sg Nom @SUBJ&gt; #11-&gt;12 \\n\"&lt;bill\u00e1nii&gt;\"\\n'\n                '\\t\"bill\u00e1nit\" V IV Ind Prt Sg3 @FS-ADVL&gt; #12-&gt;0 \\n\"&lt;.&gt;\"\\n'\n                '\\t\".\" CLB #13-&gt;12 \\n\\n\"&lt;\u00b6&gt;\"\\n\\t\"\u00b6\" CLB #1-&gt;1 \\n\\n'\n            ),\n        )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_foreign","title":"<code>test_foreign()</code>","text":"<p>Check the output of a p containing an errorlang element</p> <p>The errorlang option is True.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_foreign(self):\n\"\"\"Check the output of a p containing an errorlang element\n\n    The errorlang option is True.\n    \"\"\"\n    xml_printer = ccat.XMLPrinter(errorlang=True)\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;\"\n        \"Vijmak bierjjedak! \"\n        \"&lt;errorlang&gt;\"\n        \"Pjuh\"\n        \"&lt;correct&gt;nor&lt;/correct&gt;\"\n        \"&lt;/errorlang&gt;\"\n        \" vijmak de bierjjedak \"\n        \"&lt;errorort&gt;\"\n        \"sjatt\u00e1j\"\n        '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;sjattaj&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \".\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n\n    self.assertEqual(\n        buffer.getvalue(),\n        (\"Vijmak bierjjedak! nor vijmak de bierjjedak sjatt\u00e1j. \u00b6\\n\"),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_get_element_language_different_from_parent","title":"<code>test_get_element_language_different_from_parent()</code>","text":"<p>Check that the value of xml:lang is returned when it is set.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_get_element_language_different_from_parent(self):\n\"\"\"Check that the value of xml:lang is returned when it is set.\"\"\"\n    xml_printer = ccat.XMLPrinter()\n\n    element = etree.fromstring('&lt;p xml:lang=\"nob\"/&gt;')\n    self.assertEqual(xml_printer.get_element_language(element, \"sme\"), \"nob\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_get_element_language_same_as_parent","title":"<code>test_get_element_language_same_as_parent()</code>","text":"<p>xml:lang is not set in the p element. Return parent language.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_get_element_language_same_as_parent(self):\n\"\"\"xml:lang is not set in the p element. Return parent language.\"\"\"\n    xml_printer = ccat.XMLPrinter()\n\n    element = etree.fromstring(\"&lt;p/&gt;\")\n    self.assertEqual(xml_printer.get_element_language(element, \"sme\"), \"sme\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_get_lang","title":"<code>test_get_lang()</code>","text":"<p>Check that get_lang finds the main lang of the document</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_get_lang(self):\n\"\"\"Check that get_lang finds the main lang of the document\"\"\"\n    xml_printer = ccat.XMLPrinter()\n    xml_printer.etree = etree.parse(\n        io.BytesIO(b'&lt;document id=\"no_id\" xml:lang=\"sme\"/&gt;')\n    )\n\n    self.assertEqual(xml_printer.get_lang(), \"sme\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_no_foreign","title":"<code>test_no_foreign()</code>","text":"<p>noforeign option is True</p> <p>Neither the errorlang.text nor the correct attribute should be output. Check that this really happens.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_no_foreign(self):\n\"\"\"noforeign option is True\n\n    Neither the errorlang.text nor the correct attribute should be output.\n    Check that this really happens.\n    \"\"\"\n    xml_printer = ccat.XMLPrinter(noforeign=True)\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;\"\n        \"Vijmak bierjjedak! \"\n        \"&lt;errorlang&gt;\"\n        \"Pjuh\"\n        \"&lt;correct&gt;nor&lt;/correct&gt;\"\n        \"&lt;/errorlang&gt;\"\n        \" vijmak de bierjjedak \"\n        \"&lt;errorort&gt;\"\n        \"sjatt\u00e1j\"\n        '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;sjattaj&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \".\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n\n    self.assertEqual(\n        buffer.getvalue(), (\"Vijmak bierjjedak!  vijmak de bierjjedak sjatt\u00e1j. \u00b6\\n\")\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_no_foreign_typos","title":"<code>test_no_foreign_typos()</code>","text":"<p>noforeign is True, typos is True</p> <p>When the noforeign option is True, neither the errorlang.text nor the correct attribute should be output. Check that this really happens even when the typos option is set.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_no_foreign_typos(self):\n\"\"\"noforeign is True, typos is True\n\n    When the noforeign option is True, neither the errorlang.text\n    nor the correct attribute should be output. Check that this really\n    happens even when the typos option is set.\n    \"\"\"\n    xml_printer = ccat.XMLPrinter(typos=True, noforeign=True)\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;\"\n        \"Vijmak bierjjedak! \"\n        \"&lt;errorlang&gt;\"\n        \"Pjuh\"\n        \"&lt;correct&gt;nor&lt;/correct&gt;\"\n        \"&lt;/errorlang&gt;\"\n        \" vijmak de bierjjedak \"\n        \"&lt;errorort&gt;\"\n        \"sjatt\u00e1j\"\n        '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;sjattaj&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \".\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n\n    self.assertEqual(buffer.getvalue(), \"sjatt\u00e1j\\tsjattaj\\t#errorinfo=vowlat,\u00e1-a\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p","title":"<code>test_p()</code>","text":"<p>Test the output of a plain p with default text flow</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p(self):\n\"\"\"Test the output of a plain p with default text flow\"\"\"\n    xml_printer = ccat.XMLPrinter()\n    buffer = io.StringIO()\n    input_p = etree.fromstring(\n        \"&lt;p&gt;Et stykke av Norge som er lite kjent - \"\n        \"Litt om Norge i mellomkrigstiden&lt;/p&gt;\"\n    )\n\n    xml_printer.collect_text(input_p, \"nob\", buffer)\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"Et stykke av Norge som er lite kjent - \"\n            \"Litt om Norge i mellomkrigstiden \u00b6\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_one_word_per_line","title":"<code>test_p_one_word_per_line()</code>","text":"<p>Test the output of a plain p element, one word per line</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_one_word_per_line(self):\n\"\"\"Test the output of a plain p element, one word per line\"\"\"\n    input_p = etree.fromstring(\n        \"&lt;p&gt;Et stykke av Norge som er lite kjent - \"\n        \"Litt om Norge i mellomkrigstiden&lt;/p&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(one_word_per_line=True)\n\n    buffer = io.StringIO()\n\n    xml_printer.collect_text(input_p, \"nob\", buffer)\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"Et\\n\"\n            \"stykke\\n\"\n            \"av\\n\"\n            \"Norge\\n\"\n            \"som\\n\"\n            \"er\\n\"\n            \"lite\\n\"\n            \"kjent\\n\"\n            \"-\\n\"\n            \"Litt\\n\"\n            \"om\\n\"\n            \"Norge\\n\"\n            \"i\\n\"\n            \"mellomkrigstiden\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_with_error","title":"<code>test_p_with_error()</code>","text":"<p>The output of a p containing a nested error element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_with_error(self):\n\"\"\"The output of a p containing a nested error element\"\"\"\n    xml_printer = ccat.XMLPrinter()\n    buffer = io.StringIO()\n\n    input_p = etree.fromstring(\n        \"&lt;p&gt;\"\n        \"&lt;errormorphsyn&gt;\"\n        '&lt;errorort correct=\"Bearpmehat\" errtype=\"svow\" pos=\"noun\"&gt;'\n        \"Bearpmahat\"\n        \"&lt;/errorort&gt;\"\n        \"&lt;errorlex&gt;\"\n        \" earuha\"\n        '&lt;correct errtype=\"w\" origpos=\"v\" pos=\"verb\"&gt;sirre&lt;/correct&gt;'\n        \"&lt;/errorlex&gt;\"\n        '&lt;correct cat=\"pl3prs\" const=\"fin\"  errtype=\"agr\" orig=\"sg3prs\" '\n        'pos=\"verb\"&gt;Bearpmehat sirrejit&lt;/correct&gt;'\n        \"&lt;/errormorphsyn&gt;\"\n        \" uskki ja loaiddu.\"\n        \"&lt;/p&gt;\"\n    )\n\n    xml_printer.collect_text(input_p, \"sme\", buffer)\n    self.assertEqual(buffer.getvalue(), \"Bearpmahat earuha uskki ja loaiddu. \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_with_error_correction","title":"<code>test_p_with_error_correction()</code>","text":"<p>correction = True, print all corrections</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_with_error_correction(self):\n\"\"\"correction = True, print all corrections\"\"\"\n    input_p = etree.fromstring(\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(correction=True)\n\n    buffer = io.StringIO()\n    xml_printer.collect_text(input_p, \"sme\", buffer)\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"liv\u010d\u010dii makk\u00e1rge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"man soga sii \u00b6\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_with_error_filtering_errorlex","title":"<code>test_p_with_error_filtering_errorlex()</code>","text":"<p>errorlex = True, print errorlex corrections</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_with_error_filtering_errorlex(self):\n\"\"\"errorlex = True, print errorlex corrections\"\"\"\n    input_p = etree.fromstring(\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(errorlex=True)\n\n    buffer = io.StringIO()\n    xml_printer.collect_text(input_p, \"sme\", buffer)\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"liv\u010d\u010dii makkarge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"man soga sii \u00b6\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_with_error_filtering_errormorphsyn","title":"<code>test_p_with_error_filtering_errormorphsyn()</code>","text":"<p>errormorphsyn = True, print errormorphsyn corrections</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_with_error_filtering_errormorphsyn(self):\n\"\"\"errormorphsyn = True, print errormorphsyn corrections\"\"\"\n    input_p = etree.fromstring(\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(errormorphsyn=True)\n\n    buffer = io.StringIO()\n    xml_printer.collect_text(input_p, \"sme\", buffer)\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"liv\u010d\u010dii makkarge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"makkar soga sii \u00b6\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_with_error_filtering_errorort","title":"<code>test_p_with_error_filtering_errorort()</code>","text":"<p>errorort = True, print errorort corrections</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_with_error_filtering_errorort(self):\n\"\"\"errorort = True, print errorort corrections\"\"\"\n    xml_printer = ccat.XMLPrinter(errorort=True)\n\n    input_p = etree.fromstring(\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n    )\n\n    buffer = io.StringIO()\n    xml_printer.collect_text(input_p, \"sme\", buffer)\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"liv\u010d\u010dii makk\u00e1rge politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n            \"makk\u00e1r soga sii \u00b6\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_with_span","title":"<code>test_p_with_span()</code>","text":"<p>The output of a plain p with a span element</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_with_span(self):\n\"\"\"The output of a plain p with a span element\"\"\"\n    xml_printer = ccat.XMLPrinter()\n    buffer = io.StringIO()\n\n    input_p = etree.fromstring(\n        \"&lt;p&gt;I 1864 ga han ut boka \"\n        '&lt;span type=\"quote\" xml:lang=\"dan\"&gt;'\n        '\"Fornuftigt Madstel\"'\n        \"&lt;/span&gt;.\"\n        \"&lt;/p&gt;\"\n    )\n\n    xml_printer.collect_text(input_p, \"nob\", buffer)\n    self.assertEqual(\n        buffer.getvalue(), 'I 1864 ga han ut boka \"Fornuftigt Madstel\". \u00b6\\n'\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_p_with_span_one_word_per_line","title":"<code>test_p_with_span_one_word_per_line()</code>","text":"<p>Output a plain p that contains a span element</p> <p>one_word_per-line is True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_p_with_span_one_word_per_line(self):\n\"\"\"Output a plain p that contains a span element\n\n    one_word_per-line is True\n    \"\"\"\n    input_p = etree.fromstring(\n        \"&lt;p&gt;I 1864 ga han ut boka \"\n        '    &lt;span type=\"quote\" xml:lang=\"dan\"&gt;'\n        '        \"Fornuftigt Madstel\"'\n        \"    &lt;/span&gt;.\"\n        \"&lt;/p&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(one_word_per_line=True)\n    buffer = io.StringIO()\n\n    xml_printer.collect_text(input_p, \"nob\", buffer)\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"I\\n\"\n            \"1864\\n\"\n            \"ga\\n\"\n            \"han\\n\"\n            \"ut\\n\"\n            \"boka\\n\"\n            '\"Fornuftigt\\n'\n            'Madstel\"\\n'\n            \".\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file1","title":"<code>test_process_file1()</code>","text":"<p>Test process_file with a disambiguation element as input</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file1(self):\n\"\"\"Test process_file with a disambiguation element as input\"\"\"\n    xml_printer = ccat.XMLPrinter(disambiguation=True)\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;\\n'\n        \"    &lt;body&gt;\\n\"\n        '        &lt;disambiguation&gt;\"&amp;lt;Muhto&amp;gt;\"\\n'\n        '\\t\"muhto\" CC &amp;lt;sme&amp;gt; @CVP\\n\"&amp;lt;gaskkohagaid&amp;gt;\"\\n'\n        '\\t\"gaskkohagaid\" Adv &amp;lt;sme&amp;gt;\\n\"&amp;lt;,&amp;gt;\"\\n'\n        '\\t\",\" CLB\\n\"&amp;lt;ja&amp;gt;\"\\n'\n        '\\t\"ja\" CC &amp;lt;sme&amp;gt; @CNP\\n\"&amp;lt;erenoam\u00e1\u017eit&amp;gt;\"\\n'\n        '\\t\"erenoam\u00e1\u017eit\" Adv &amp;lt;sme&amp;gt;\\n\"&amp;lt;dalle_go&amp;gt;\"\\n'\n        '\\t\"dalle_go\" MWE CS &amp;lt;sme&amp;gt; @CVP\\n\"&amp;lt;lei&amp;gt;\"\\n'\n        '\\t\"leat\" V &amp;lt;sme&amp;gt; IV Ind Prt Sg3 @+FMAINV\\n'\n        '\"&amp;lt;buola\u0161&amp;gt;\"\\n'\n        '\\t\"buola\u0161\" Sem/Wthr N &amp;lt;sme&amp;gt; Sg Nom\\n\"&amp;lt;,&amp;gt;\"\\n'\n        '\\t\",\" CLB\\n\"&amp;lt;de&amp;gt;\"\\n'\n        '\\t\"de\" Adv &amp;lt;sme&amp;gt;\\n\"&amp;lt;aggreg\u00e1hta&amp;gt;\"\\n'\n        '\\t\"aggreg\u00e1hta\" N &amp;lt;sme&amp;gt; Sg Nom\\n\"&amp;lt;bill\u00e1nii&amp;gt;\"\\n'\n        '\\t\"bill\u00e1nit\" V &amp;lt;sme&amp;gt; IV Ind Prt Sg3 @+FMAINV\\n'\n        '\"&amp;lt;.&amp;gt;\"\\n\\t\".\" CLB\\n\\n\"&amp;lt;\u00b6&amp;gt;\"\\n'\n        '\\t\"\u00b6\" CLB\\n\\n&lt;/disambiguation&gt;&lt;/body&gt;&lt;/document&gt;'\n    )\n\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            '\"&lt;Muhto&gt;\"\\n\\t\"muhto\" CC &lt;sme&gt; @CVP\\n\"&lt;gaskkohagaid&gt;\"\\n'\n            '\\t\"gaskkohagaid\" Adv &lt;sme&gt;\\n\"&lt;,&gt;\"\\n'\n            '\\t\",\" CLB\\n\"&lt;ja&gt;\"\\n\\t\"ja\" CC &lt;sme&gt; @CNP\\n\"&lt;erenoam\u00e1\u017eit&gt;\"\\n'\n            '\\t\"erenoam\u00e1\u017eit\" Adv &lt;sme&gt;\\n\"&lt;dalle_go&gt;\"\\n'\n            '\\t\"dalle_go\" MWE CS &lt;sme&gt; @CVP\\n\"&lt;lei&gt;\"\\n'\n            '\\t\"leat\" V &lt;sme&gt; IV Ind Prt Sg3 @+FMAINV\\n\"&lt;buola\u0161&gt;\"\\n'\n            '\\t\"buola\u0161\" Sem/Wthr N &lt;sme&gt; Sg Nom\\n\"&lt;,&gt;\"\\n'\n            '\\t\",\" CLB\\n\"&lt;de&gt;\"\\n\\t\"de\" Adv &lt;sme&gt;\\n\"&lt;aggreg\u00e1hta&gt;\"\\n'\n            '\\t\"aggreg\u00e1hta\" N &lt;sme&gt; Sg Nom\\n\"&lt;bill\u00e1nii&gt;\"\\n'\n            '\\t\"bill\u00e1nit\" V &lt;sme&gt; IV Ind Prt Sg3 @+FMAINV\\n\"&lt;.&gt;\"\\n'\n            '\\t\".\" CLB\\n\\n\"&lt;\u00b6&gt;\"\\n\\t\"\u00b6\" CLB\\n\\n'\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file2","title":"<code>test_process_file2()</code>","text":"<p>Test process_file with a dependency element as input</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file2(self):\n\"\"\"Test process_file with a dependency element as input\"\"\"\n    xml_printer = ccat.XMLPrinter(dependency=True)\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;\\n'\n        \"    &lt;body&gt;\\n\"\n        '        &lt;dependency&gt;\"&amp;lt;Muhto&amp;gt;\"\\n'\n        '\\t\"muhto\" CC @CVP #1-&amp;gt;1 \\n\"&amp;lt;gaskkohagaid&amp;gt;\"\\n'\n        '\\t\"gaskkohagaid\" Adv @ADVL&amp;gt; #2-&amp;gt;12 \\n\"&amp;lt;,&amp;gt;\"\\n'\n        '\\t\",\" CLB #3-&amp;gt;4 \\n\"&amp;lt;ja&amp;gt;\"\\n'\n        '\\t\"ja\" CC @CNP #4-&amp;gt;2 \\n\"&amp;lt;erenoam\u00e1\u017eit&amp;gt;\"\\n'\n        '\\t\"erenoam\u00e1\u017eit\" Adv @ADVL&amp;gt; #5-&amp;gt;12 \\n'\n        '\"&amp;lt;dalle_go&amp;gt;\"\\n'\n        '\\t\"dalle_go\" CS @CVP #6-&amp;gt;7 \\n\"&amp;lt;lei&amp;gt;\"\\n'\n        '\\t\"leat\" V IV Ind Prt Sg3 @FS-ADVL&amp;gt; #7-&amp;gt;12 \\n'\n        '\"&amp;lt;buola\u0161&amp;gt;\"\\n'\n        '\\t\"buola\u0161\" N Sg Nom @&amp;lt;SPRED #8-&amp;gt;7 \\n\"&amp;lt;,&amp;gt;\"\\n'\n        '\\t\",\" CLB #9-&amp;gt;6 \\n\"&amp;lt;de&amp;gt;\"\\n'\n        '\\t\"de\" Adv @ADVL&amp;gt; #10-&amp;gt;12 \\n\"&amp;lt;aggreg\u00e1hta&amp;gt;\"\\n'\n        '\\t\"aggreg\u00e1hta\" N Sg Nom @SUBJ&amp;gt; #11-&amp;gt;12 \\n'\n        '\"&amp;lt;bill\u00e1nii&amp;gt;\"\\n'\n        '\\t\"bill\u00e1nit\" V IV Ind Prt Sg3 @FS-ADVL&amp;gt; #12-&amp;gt;0 \\n'\n        '\"&amp;lt;.&amp;gt;\"\\n\\t\".\" CLB #13-&amp;gt;12 \\n\\n\"&amp;lt;\u00b6&amp;gt;\"\\n'\n        '\\t\"\u00b6\" CLB #1-&amp;gt;1 \\n\\n&lt;/dependency&gt;\\n'\n        \"    &lt;/body&gt;\\n\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            '\"&lt;Muhto&gt;\"\\n\\t\"muhto\" CC @CVP #1-&gt;1 \\n\"&lt;gaskkohagaid&gt;\"\\n'\n            '\\t\"gaskkohagaid\" Adv @ADVL&gt; #2-&gt;12 \\n\"&lt;,&gt;\"\\n'\n            '\\t\",\" CLB #3-&gt;4 \\n\"&lt;ja&gt;\"\\n'\n            '\\t\"ja\" CC @CNP #4-&gt;2 \\n\"&lt;erenoam\u00e1\u017eit&gt;\"\\n'\n            '\\t\"erenoam\u00e1\u017eit\" Adv @ADVL&gt; #5-&gt;12 \\n\"&lt;dalle_go&gt;\"\\n'\n            '\\t\"dalle_go\" CS @CVP #6-&gt;7 \\n\"&lt;lei&gt;\"\\n'\n            '\\t\"leat\" V IV Ind Prt Sg3 @FS-ADVL&gt; #7-&gt;12 \\n\"&lt;buola\u0161&gt;\"\\n'\n            '\\t\"buola\u0161\" N Sg Nom @&lt;SPRED #8-&gt;7 \\n\"&lt;,&gt;\"\\n'\n            '\\t\",\" CLB #9-&gt;6 \\n\"&lt;de&gt;\"\\n'\n            '\\t\"de\" Adv @ADVL&gt; #10-&gt;12 \\n\"&lt;aggreg\u00e1hta&gt;\"\\n'\n            '\\t\"aggreg\u00e1hta\" N Sg Nom @SUBJ&gt; #11-&gt;12 \\n\"&lt;bill\u00e1nii&gt;\"\\n'\n            '\\t\"bill\u00e1nit\" V IV Ind Prt Sg3 @FS-ADVL&gt; #12-&gt;0 \\n\"&lt;.&gt;\"\\n'\n            '\\t\".\" CLB #13-&gt;12 \\n\\n\"&lt;\u00b6&gt;\"\\n\\t\"\u00b6\" CLB #1-&gt;1 \\n\\n'\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_allp_set","title":"<code>test_process_file_allp_set()</code>","text":"<p>all_paragraphs option is True, all p elements get output.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_allp_set(self):\n\"\"\"all_paragraphs option is True, all p elements get output.\"\"\"\n    xml_printer = ccat.XMLPrinter(all_paragraphs=True)\n\n    for types in [\n        \"\",\n        ' type=\"text\"',\n        ' type=\"title\"',\n        ' type=\"listitem\"',\n        ' type=\"tablecell\"',\n    ]:\n        document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n            + types\n            + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n        )\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_default","title":"<code>test_process_file_default()</code>","text":"<p>Default settings, print content of p elements</p> <p>Check the output of plain p elements, with default settings Specifically, check that only plain p gets output, whereas p elements with the type title, listitem and tablecell get no output.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_default(self):\n\"\"\"Default settings, print content of p elements\n\n    Check the output of plain p elements, with default settings\n    Specifically, check that only plain p gets output, whereas\n    p elements with the type title, listitem and tablecell get no output.\n    \"\"\"\n    xml_printer = ccat.XMLPrinter()\n\n    for types in [' type=\"title\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n        document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n            + types\n            + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\")\n\n    for types in [\"\", ' type=\"text\"']:\n        document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n            + types\n            + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_language_nob","title":"<code>test_process_file_language_nob()</code>","text":"<p>lang=nob, only nob content should be output</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_language_nob(self):\n\"\"\"lang=nob, only nob content should be output\"\"\"\n    xml_printer = ccat.XMLPrinter(lang=\"nob\")\n    xml_printer.etree = etree.parse(\n        io.BytesIO(\n                b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                b\"&lt;body&gt;\"\n                b\"&lt;p&gt;\"\n                b\"nob1 \"\n                b'&lt;span type=\"quote\" xml:lang=\"dan\"&gt;dan1&lt;/span&gt;'\n                b\" nob2&lt;/p&gt;\"\n                b\"&lt;/body&gt;\"\n                b\"&lt;/document&gt;\"\n        )\n    )\n\n    buffer = xml_printer.process_file()\n    self.assertEqual(buffer.getvalue(), \"nob1  nob2 \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_listitem_set","title":"<code>test_process_file_listitem_set()</code>","text":"<p>Print only content of p elements with type=listitem.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_listitem_set(self):\n\"\"\"Print only content of p elements with type=listitem.\"\"\"\n    xml_printer = ccat.XMLPrinter(listitem=True)\n\n    for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"tablecell\"']:\n        document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n            + types\n            + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n        )\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\")\n\n    for types in [' type=\"listitem\"']:\n        document = (\n\"\"\"&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p\"\"\"\n            + types\n            + \"\"\"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\"\"\n        )\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_one_word_per_line_errorlex","title":"<code>test_process_file_one_word_per_line_errorlex()</code>","text":"<p>Print only errorlex content</p> <p>Check the output of a p element containing two error elements, a plain errorort one, and a nested errorlex one when the one_word_per_line and errorlex options are True.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_one_word_per_line_errorlex(self):\n\"\"\"Print only errorlex content\n\n    Check the output of a p element containing two error elements,\n    a plain errorort one, and a nested errorlex one when\n    the one_word_per_line and errorlex options are True.\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(one_word_per_line=True, errorlex=True)\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"liv\u010d\u010dii\\n\"\n            \"makkarge\\n\"\n            \"politihkka,\\n\"\n            \"muhto\\n\"\n            \"rahpasit\\n\"\n            \"baicca\\n\"\n            \"muitaliv\u010d\u010de\\n\"\n            \"makk\u00e1r soga\\tman soga\\n\"\n            \"sii\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_one_word_per_line_errorort","title":"<code>test_process_file_one_word_per_line_errorort()</code>","text":"<p>Print only errorort content</p> <p>Check the output of a p element containing two error elements, a plain errorort one, and a nested errorlex one when the one_word_per_line and errorort options are True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_one_word_per_line_errorort(self):\n\"\"\"Print only errorort content\n\n    Check the output of a p element containing two error elements,\n    a plain errorort one, and a nested errorlex one when\n    the one_word_per_line and errorort options are True\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(one_word_per_line=True, errorort=True)\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n    got = buffer.getvalue()\n    want = (\n        \"liv\u010d\u010dii\\n\"\n        \"makkarge\\tmakk\u00e1rge\\t#errtype=\u00e1,pos=adv\\n\"\n        \"politihkka,\\n\"\n        \"muhto\\n\"\n        \"rahpasit\\n\"\n        \"baicca\\n\"\n        \"muitaliv\u010d\u010de\\n\"\n        \"makkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\\n\"\n        \"soga\\n\"\n        \"sii\\n\"\n    )\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_tablecell_set","title":"<code>test_process_file_tablecell_set()</code>","text":"<p>Print only content of p elements with type=title gets output.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_tablecell_set(self):\n\"\"\"Print only content of p elements with type=title gets output.\"\"\"\n    xml_printer = ccat.XMLPrinter(table=True)\n\n    for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"listitem\"']:\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p '\n            + types\n            + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n        )\n\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\")\n\n    for types in [' type=\"tablecell\"']:\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p '\n            + types\n            + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n        )\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_title_set","title":"<code>test_process_file_title_set()</code>","text":"<p>Print only content of p elements with type=title.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_title_set(self):\n\"\"\"Print only content of p elements with type=title.\"\"\"\n    xml_printer = ccat.XMLPrinter(title=True)\n\n    for types in [\"\", ' type=\"text\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p {}&gt;'\n            \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\".format(types)\n        )\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\")\n\n    for types in [' type=\"title\"']:\n        document = (\n            '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;&lt;body&gt;&lt;p {}&gt;'\n            \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\".format(types)\n        )\n        xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6 \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_typos","title":"<code>test_process_file_typos()</code>","text":"<p>Print all error content</p> <p>Check the output of a p element containing two error elements, a plain errorort one, and a nested errorlex one when the typos option True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_typos(self):\n\"\"\"Print all error content\n\n    Check the output of a p element containing two error elements,\n    a plain errorort one, and a nested errorlex one when\n    the typos option True\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(typos=True)\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"makkarge\\tmakk\u00e1rge\\t#errtype=\u00e1,pos=adv\\n\"\n            \"makk\u00e1r soga\\tman soga\\n\"\n            \"makkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_typos_errorlex","title":"<code>test_process_file_typos_errorlex()</code>","text":"<p>Print only errorlex content</p> <p>Check the output of a p element containing two error elements, a plain errorort one, and a nested errorlex one when the typos and errorlex options are True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_typos_errorlex(self):\n\"\"\"Print only errorlex content\n\n    Check the output of a p element containing two error elements,\n    a plain errorort one, and a nested errorlex one when\n    the typos and errorlex options are True\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(typos=True, errorlex=True)\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n    self.assertEqual(buffer.getvalue(), \"makk\u00e1r soga\\tman soga\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_file_typos_errorort","title":"<code>test_process_file_typos_errorort()</code>","text":"<p>Print only errorort content</p> <p>Check the output of a p element containing two error elements, a plain errorort one, and a nested errorlex one when the one_word_per_line, typos and errorort options are True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_file_typos_errorort(self):\n\"\"\"Print only errorort content\n\n    Check the output of a p element containing two error elements,\n    a plain errorort one, and a nested errorlex one when\n    the one_word_per_line, typos and errorort options are True\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"sme\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;liv\u010d\u010dii \"\n        \"&lt;errorort&gt;\"\n        \"makkarge\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"adv\"&gt;makk\u00e1rge&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" politihkka, muhto rahpasit baicca muitaliv\u010d\u010de \"\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;makk\u00e1r&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n        \" sii\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(typos=True, one_word_per_line=True, errorort=True)\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"makkarge\\tmakk\u00e1rge\\t#errtype=\u00e1,pos=adv\\n\"\n            \"makkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_minus_l_sme","title":"<code>test_process_minus_l_sme()</code>","text":"<p>lang=sme, no elements are sme</p> <p>Check that nothing is output when the wanted language (set in the lang option) is not the same language as any of the content of the elements.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_minus_l_sme(self):\n\"\"\"lang=sme, no elements are sme\n\n    Check that nothing is output when the wanted language\n    (set in the lang option) is not the same language as any of the\n    content of the elements.\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n        \"&lt;body&gt;\"\n        '&lt;p type=\"text\"&gt;'\n        \"men \"\n        \"&lt;errormorphsyn&gt;\"\n        \"skoledagene er s\u00e5 \"\n        \"&lt;errorort&gt;\"\n        \"vanskerlig\"\n        '&lt;correct errtype=\"nosilent\" pos=\"adj\"&gt;vanskelig&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        '&lt;correct cat=\"x\" const=\"spred\" errtype=\"agr\" orig=\"x\" pos=\"adj\"&gt;'\n        \"koledagene er s\u00e5 vanskelige\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n        \" \u00e5 komme igjennom,\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(lang=\"sme\")\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n    buffer = xml_printer.process_file()\n\n    self.assertEqual(buffer.getvalue(), \"\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_process_two_paragraphs","title":"<code>test_process_two_paragraphs()</code>","text":"<p>Check that the \u00b6 character is printed</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_process_two_paragraphs(self):\n\"\"\"Check that the \u00b6 character is printed\"\"\"\n    xml_printer = ccat.XMLPrinter()\n    xml_printer.etree = etree.parse(\n        io.BytesIO(\n                b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                b\"    &lt;body&gt;\"\n                b\"        &lt;p&gt;nob1&lt;/p&gt;\"\n                b\"        &lt;p&gt;nob2&lt;/p&gt;\"\n                b\"    &lt;/body&gt;\"\n                b\"&lt;/document&gt;\"\n        )\n    )\n\n    buffer = xml_printer.process_file()\n    self.assertEqual(buffer.getvalue(), \"nob1 \u00b6\\nnob2 \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_typos_errordepth3","title":"<code>test_typos_errordepth3()</code>","text":"<p>Check the output of a p containing a nested error element</p> <p>typos option is True, depth is 3</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_typos_errordepth3(self):\n\"\"\"Check the output of a p containing a nested error element\n\n    typos option is True, depth is 3\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;\"\n        \"&lt;errormorphsyn&gt;\"\n        \"&lt;errormorphsyn&gt;\"\n        \"&lt;errorort&gt;\"\n        \"\u010doaggen\"\n        '&lt;correct errtype=\"mono\" pos=\"verb\"&gt;\u010doggen&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        \" ollu jok\u014bat\"\n        '&lt;correct cat=\"genpl\" const=\"obj\" errtype=\"case\" orig=\"nompl\" pos=\"noun\"&gt;'\n        \"\u010doggen ollu jo\u014baid\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n        \" ja sarridat\"\n        '&lt;correct cat=\"genpl\" const=\"obj\" errtype=\"case\" orig=\"nompl\" pos=\"noun\"&gt;'\n        \"\u010doggen ollu jo\u014baid ja sarridiid\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n    xml_printer = ccat.XMLPrinter(typos=True)\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n\n    buffer = xml_printer.process_file()\n    got = buffer.getvalue()\n    want = (\n        \"\u010doggen ollu jo\u014baid ja sarridat\"\n        \"\\t\u010doggen ollu jo\u014baid ja sarridiid\"\n        \"\\t#cat=genpl,const=obj,errtype=case,orig=nompl,pos=noun\\n\"\n        \"\u010doggen ollu jok\u014bat\\t\u010doggen ollu jo\u014baid\"\n        \"\\t#cat=genpl,const=obj,errtype=case,orig=nompl,pos=noun\\n\"\n        \"\u010doaggen\\t\u010doggen\\t#errtype=mono,pos=verb\\n\"\n    )\n\n    self.maxDiff = None\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_typos_errormorphsyn_twice","title":"<code>test_typos_errormorphsyn_twice()</code>","text":"<p>Check the output of a plain p</p> <p>The p contains a doubly nested errormorphsyn element when the typos and errormorphsyn options are True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_typos_errormorphsyn_twice(self):\n\"\"\"Check the output of a plain p\n\n    The p contains a doubly nested\n    errormorphsyn element when the typos and errormorphsyn\n    options are True\n    \"\"\"\n    document = (\n        '&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n        \"&lt;body&gt;\"\n        \"&lt;p&gt;\"\n        \"&lt;errormorphsyn&gt;\"\n        \"leat \"\n        \"&lt;errormorphsyn&gt;\"\n        \"okta m\u00e1n\u00e1\"\n        '&lt;correct cat=\"nomsg\" const=\"spred\" errtype=\"case\" orig=\"gensg\" pos=\"n\"&gt;'\n        \"okta m\u00e1nn\u00e1\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n        '&lt;correct cat=\"sg3prs\" const=\"v\" errtype=\"agr\" orig=\"pl3prs\" pos=\"v\"&gt;'\n        \"lea okta m\u00e1nn\u00e1\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n        \"&lt;/p&gt;\"\n        \"&lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(typos=True, errormorphsyn=True)\n    xml_printer.etree = etree.parse(io.BytesIO(document.encode(\"utf8\")))\n\n    buffer = xml_printer.process_file()\n\n    self.assertEqual(\n        buffer.getvalue(),\n        (\n            \"leat okta m\u00e1nn\u00e1\\tlea okta m\u00e1nn\u00e1\"\n            \"\\t#cat=sg3prs,const=v,errtype=agr,orig=pl3prs,pos=v\\n\"\n            \"okta m\u00e1n\u00e1\\tokta m\u00e1nn\u00e1\"\n            \"\\t#cat=nomsg,const=spred,errtype=case,orig=gensg,pos=n\\n\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_visit_this_p_allp_set","title":"<code>test_visit_this_p_allp_set()</code>","text":"<p>Visit all p elements when all_paragraphs is True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_visit_this_p_allp_set(self):\n\"\"\"Visit all p elements when all_paragraphs is True\"\"\"\n    xml_printer = ccat.XMLPrinter(all_paragraphs=True)\n\n    for types in [\n        \"\",\n        ' type=\"text\"',\n        ' type=\"title\"',\n        ' type=\"listitem\"',\n        ' type=\"tablecell\"',\n    ]:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertTrue(xml_printer.visit_this_node(input_xml))\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_visit_this_p_default","title":"<code>test_visit_this_p_default()</code>","text":"<p>Visit only plain p and <p> elements</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_visit_this_p_default(self):\n\"\"\"Visit only plain p and &lt;p type=text&gt; elements\"\"\"\n    xml_printer = ccat.XMLPrinter()\n\n    for types in [' type=\"title\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n    for types in [\"\", ' type=\"text\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertTrue(xml_printer.visit_this_node(input_xml))\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_visit_this_p_listitem_set","title":"<code>test_visit_this_p_listitem_set()</code>","text":"<p>Visit only <p> elements when listitem is True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_visit_this_p_listitem_set(self):\n\"\"\"Visit only &lt;p type=listitem&gt; elements when listitem is True\"\"\"\n    xml_printer = ccat.XMLPrinter(listitem=True)\n\n    for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"tablecell\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n    for types in [' type=\"listitem\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertTrue(xml_printer.visit_this_node(input_xml))\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_visit_this_p_tablecell_set","title":"<code>test_visit_this_p_tablecell_set()</code>","text":"<p>Visit only <p> elements when table is True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_visit_this_p_tablecell_set(self):\n\"\"\"Visit only &lt;p type=tablecell&gt; elements when table is True\"\"\"\n    xml_printer = ccat.XMLPrinter(table=True)\n\n    for types in [\"\", ' type=\"text\"', ' type=\"title\"', ' type=\"listitem\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n    for types in [' type=\"tablecell\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertTrue(xml_printer.visit_this_node(input_xml))\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcat.test_visit_this_p_title_set","title":"<code>test_visit_this_p_title_set()</code>","text":"<p>Visit only <p> elements when title is True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_visit_this_p_title_set(self):\n\"\"\"Visit only &lt;p type=title&gt; elements when title is True\"\"\"\n    xml_printer = ccat.XMLPrinter(title=True)\n\n    for types in [\"\", ' type=\"text\"', ' type=\"listitem\"', ' type=\"tablecell\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertFalse(xml_printer.visit_this_node(input_xml))\n\n    for types in [' type=\"title\"']:\n        input_xml = etree.fromstring(\"&lt;p\" + types + \"&gt;\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00f8\u00e5\u00e6&lt;/p&gt;\")\n        self.assertTrue(xml_printer.visit_this_node(input_xml))\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup","title":"<code>TestCcatErrormarkup</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test how ccat handles errormarkup</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>class TestCcatErrormarkup(unittest.TestCase):\n\"\"\"Test how ccat handles errormarkup\"\"\"\n\n    def test_single_error_inline(self):\n\"\"\"Plain error element, default text flow\"\"\"\n        xml_printer = ccat.XMLPrinter()\n        input_error = etree.fromstring(\n            \"&lt;errorortreal&gt;\"\n            \"fiske leting\"\n            '&lt;correct errtype=\"nosplit\" pos=\"noun\"&gt;fiskeleting&lt;/correct&gt;'\n            \"&lt;/errorortreal&gt;\"\n        )\n\n        textlist = []\n        parentlang = \"sme\"\n        xml_printer.collect_inline_errors(input_error, textlist, parentlang)\n        got = \"\".join(textlist)\n\n        self.assertEqual(got, \"fiskeleting\")\n\n    def test_multi_error_inline(self):\n\"\"\"Nested error element, default text flow\"\"\"\n        xml_printer = ccat.XMLPrinter()\n\n        input_error = etree.fromstring(\n            \"&lt;errormorphsyn&gt;\"\n            \"skoledagene er s\u00e5 \"\n            \"&lt;errorort&gt;\"\n            \"vanskerlig\"\n            '&lt;correct errtype=\"nosilent\" pos=\"adj\"&gt;vanskelig&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            '&lt;correct cat=\"x\" const=\"spred\" errtype=\"agr\" orig=\"x\" pos=\"adj\"&gt;'\n            \"skoledagene er s\u00e5 vanskelige\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n        )\n        textlist = []\n        parentlang = \"nob\"\n        xml_printer.collect_inline_errors(input_error, textlist, parentlang)\n        got = \"\".join(textlist)\n\n        self.assertEqual(got, \"skoledagene er s\u00e5 vanskelige\")\n\n    def test_single_error_not_inline(self):\n\"\"\"Plain error element, one word per line output\"\"\"\n        xml_printer = ccat.XMLPrinter(one_word_per_line=True)\n        input_error = etree.fromstring(\n            \"&lt;errorortreal&gt;\"\n            \"fiske leting\"\n            '&lt;correct errtype=\"nosplit\" pos=\"noun\"&gt;fiskeleting&lt;/correct&gt;'\n            \"&lt;/errorortreal&gt;\"\n        )\n\n        textlist = []\n        xml_printer.collect_not_inline_errors(input_error, textlist)\n        got = \"\".join(textlist)\n\n        self.assertEqual(\n            got,\n            (\"fiske leting\\tfiskeleting\\t#errtype=nosplit,pos=noun\"),\n        )\n\n    def test_single_error_not_inline_with_filename(self):\n\"\"\"Plain error element, one word per line output, with filename\"\"\"\n        xml_printer = ccat.XMLPrinter(print_filename=True, one_word_per_line=True)\n        input_error = etree.fromstring(\n            \"&lt;errorortreal&gt;\"\n            \"fiske leting\"\n            '&lt;correct errtype=\"nosplit\" pos=\"noun\"&gt;fiskeleting&lt;/correct&gt;'\n            \"&lt;/errorortreal&gt;\"\n        )\n\n        xml_printer.filename = \"p.xml\"\n\n        textlist = []\n        xml_printer.collect_not_inline_errors(input_error, textlist)\n        got = \"\".join(textlist)\n\n        self.assertEqual(\n            got,\n            (\"fiske leting\\tfiskeleting\" \"\\t#errtype=nosplit,pos=noun, file: p.xml\"),\n        )\n\n    def test_single_error_not_inline_with_filename_without_attributes(self):\n        xml_printer = ccat.XMLPrinter(print_filename=True, one_word_per_line=True)\n        input_error = etree.fromstring(\n            \"&lt;errorortreal&gt;\"\n            \"fiske leting\"\n            \"&lt;correct&gt;fiskeleting&lt;/correct&gt;\"\n            \"&lt;/errorortreal&gt;\"\n        )\n\n        xml_printer.filename = \"p.xml\"\n\n        textlist = []\n        xml_printer.collect_not_inline_errors(input_error, textlist)\n        got = \"\".join(textlist)\n\n        self.assertEqual(got, \"fiske leting\\tfiskeleting\\t#file: p.xml\")\n\n    def test_multi_errormorphsyn_not_inline_with_filename(self):\n\"\"\"Nested error element, one word per line output, with filename\"\"\"\n        input_error = etree.fromstring(\n            \"&lt;errormorphsyn&gt;\"\n            \"skoledagene er s\u00e5 \"\n            \"&lt;errorort&gt;\"\n            \"vanskerlig\"\n            '&lt;correct errtype=\"nosilent\" pos=\"adj\"&gt;vanskelig&lt;/correct&gt;'\n            \"&lt;/errorort&gt;\"\n            '&lt;correct cat=\"x\" const=\"spred\" errtype=\"agr\" orig=\"x\" pos=\"adj\"&gt;'\n            \"skoledagene er s\u00e5 vanskelige\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(one_word_per_line=True, print_filename=True)\n        xml_printer.filename = \"p.xml\"\n\n        textlist = []\n        xml_printer.collect_not_inline_errors(input_error, textlist)\n        got = \"\\n\".join(textlist)\n\n        self.assertEqual(\n            got,\n            (\n                \"skoledagene er s\u00e5 vanskelig\\tskoledagene er s\u00e5 vanskelige\"\n                \"\\t#cat=x,const=spred,errtype=agr,orig=x,pos=adj, file: p.xml\\n\"\n                \"vanskerlig\\tvanskelig\\t#errtype=nosilent,pos=adj, file: p.xml\"\n            ),\n        )\n\n    def test_multi_errorlex_not_inline(self):\n\"\"\"Nested error element, one word per line output\"\"\"\n        input_error = etree.fromstring(\n            \"&lt;errorlex&gt;\"\n            \"&lt;errorort&gt;\"\n            \"makkar\"\n            '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;'\n            \"makk\u00e1r\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errorort&gt;\"\n            \" soga\"\n            \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n            \"&lt;/errorlex&gt;\"\n        )\n\n        xml_printer = ccat.XMLPrinter(typos=True)\n        textlist = []\n        xml_printer.collect_not_inline_errors(input_error, textlist)\n        got = \"\\n\".join(textlist)\n\n        self.assertEqual(\n            got,\n            (\"makk\u00e1r soga\\tman soga\\nmakkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\"),\n        )\n\n    def test_multiple_corrections(self):\n\"\"\"One word per line, multiple corrections.\"\"\"\n        input_error = etree.fromstring(\n            \"&lt;p&gt;\"\n            \"&lt;errormorphsyn&gt;\"\n            \"leimme\"\n            \"&lt;correct&gt;\"\n            \"leimmet\"\n            \"&lt;/correct&gt;\"\n            \"&lt;correct&gt;\"\n            \"leat\"\n            \"&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;\"\n            \"&lt;/p&gt;\",\n        )\n\n        xml_printer = ccat.XMLPrinter(typos=True)\n        textlist = []\n        xml_printer.collect_not_inline_errors(input_error, textlist)\n        got = \"\\n\".join(textlist)\n\n        self.assertEqual(\n            got,\n            (\"leimme\\tleimmet\\nleimme\\tleat\"),\n        )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup.test_multi_error_inline","title":"<code>test_multi_error_inline()</code>","text":"<p>Nested error element, default text flow</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_multi_error_inline(self):\n\"\"\"Nested error element, default text flow\"\"\"\n    xml_printer = ccat.XMLPrinter()\n\n    input_error = etree.fromstring(\n        \"&lt;errormorphsyn&gt;\"\n        \"skoledagene er s\u00e5 \"\n        \"&lt;errorort&gt;\"\n        \"vanskerlig\"\n        '&lt;correct errtype=\"nosilent\" pos=\"adj\"&gt;vanskelig&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        '&lt;correct cat=\"x\" const=\"spred\" errtype=\"agr\" orig=\"x\" pos=\"adj\"&gt;'\n        \"skoledagene er s\u00e5 vanskelige\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n    )\n    textlist = []\n    parentlang = \"nob\"\n    xml_printer.collect_inline_errors(input_error, textlist, parentlang)\n    got = \"\".join(textlist)\n\n    self.assertEqual(got, \"skoledagene er s\u00e5 vanskelige\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup.test_multi_errorlex_not_inline","title":"<code>test_multi_errorlex_not_inline()</code>","text":"<p>Nested error element, one word per line output</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_multi_errorlex_not_inline(self):\n\"\"\"Nested error element, one word per line output\"\"\"\n    input_error = etree.fromstring(\n        \"&lt;errorlex&gt;\"\n        \"&lt;errorort&gt;\"\n        \"makkar\"\n        '&lt;correct errtype=\"\u00e1\" pos=\"interr\"&gt;'\n        \"makk\u00e1r\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errorort&gt;\"\n        \" soga\"\n        \"&lt;correct&gt;man soga&lt;/correct&gt;\"\n        \"&lt;/errorlex&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(typos=True)\n    textlist = []\n    xml_printer.collect_not_inline_errors(input_error, textlist)\n    got = \"\\n\".join(textlist)\n\n    self.assertEqual(\n        got,\n        (\"makk\u00e1r soga\\tman soga\\nmakkar\\tmakk\u00e1r\\t#errtype=\u00e1,pos=interr\"),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup.test_multi_errormorphsyn_not_inline_with_filename","title":"<code>test_multi_errormorphsyn_not_inline_with_filename()</code>","text":"<p>Nested error element, one word per line output, with filename</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_multi_errormorphsyn_not_inline_with_filename(self):\n\"\"\"Nested error element, one word per line output, with filename\"\"\"\n    input_error = etree.fromstring(\n        \"&lt;errormorphsyn&gt;\"\n        \"skoledagene er s\u00e5 \"\n        \"&lt;errorort&gt;\"\n        \"vanskerlig\"\n        '&lt;correct errtype=\"nosilent\" pos=\"adj\"&gt;vanskelig&lt;/correct&gt;'\n        \"&lt;/errorort&gt;\"\n        '&lt;correct cat=\"x\" const=\"spred\" errtype=\"agr\" orig=\"x\" pos=\"adj\"&gt;'\n        \"skoledagene er s\u00e5 vanskelige\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n    )\n\n    xml_printer = ccat.XMLPrinter(one_word_per_line=True, print_filename=True)\n    xml_printer.filename = \"p.xml\"\n\n    textlist = []\n    xml_printer.collect_not_inline_errors(input_error, textlist)\n    got = \"\\n\".join(textlist)\n\n    self.assertEqual(\n        got,\n        (\n            \"skoledagene er s\u00e5 vanskelig\\tskoledagene er s\u00e5 vanskelige\"\n            \"\\t#cat=x,const=spred,errtype=agr,orig=x,pos=adj, file: p.xml\\n\"\n            \"vanskerlig\\tvanskelig\\t#errtype=nosilent,pos=adj, file: p.xml\"\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup.test_multiple_corrections","title":"<code>test_multiple_corrections()</code>","text":"<p>One word per line, multiple corrections.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_multiple_corrections(self):\n\"\"\"One word per line, multiple corrections.\"\"\"\n    input_error = etree.fromstring(\n        \"&lt;p&gt;\"\n        \"&lt;errormorphsyn&gt;\"\n        \"leimme\"\n        \"&lt;correct&gt;\"\n        \"leimmet\"\n        \"&lt;/correct&gt;\"\n        \"&lt;correct&gt;\"\n        \"leat\"\n        \"&lt;/correct&gt;\"\n        \"&lt;/errormorphsyn&gt;\"\n        \"&lt;/p&gt;\",\n    )\n\n    xml_printer = ccat.XMLPrinter(typos=True)\n    textlist = []\n    xml_printer.collect_not_inline_errors(input_error, textlist)\n    got = \"\\n\".join(textlist)\n\n    self.assertEqual(\n        got,\n        (\"leimme\\tleimmet\\nleimme\\tleat\"),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup.test_single_error_inline","title":"<code>test_single_error_inline()</code>","text":"<p>Plain error element, default text flow</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_single_error_inline(self):\n\"\"\"Plain error element, default text flow\"\"\"\n    xml_printer = ccat.XMLPrinter()\n    input_error = etree.fromstring(\n        \"&lt;errorortreal&gt;\"\n        \"fiske leting\"\n        '&lt;correct errtype=\"nosplit\" pos=\"noun\"&gt;fiskeleting&lt;/correct&gt;'\n        \"&lt;/errorortreal&gt;\"\n    )\n\n    textlist = []\n    parentlang = \"sme\"\n    xml_printer.collect_inline_errors(input_error, textlist, parentlang)\n    got = \"\".join(textlist)\n\n    self.assertEqual(got, \"fiskeleting\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup.test_single_error_not_inline","title":"<code>test_single_error_not_inline()</code>","text":"<p>Plain error element, one word per line output</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_single_error_not_inline(self):\n\"\"\"Plain error element, one word per line output\"\"\"\n    xml_printer = ccat.XMLPrinter(one_word_per_line=True)\n    input_error = etree.fromstring(\n        \"&lt;errorortreal&gt;\"\n        \"fiske leting\"\n        '&lt;correct errtype=\"nosplit\" pos=\"noun\"&gt;fiskeleting&lt;/correct&gt;'\n        \"&lt;/errorortreal&gt;\"\n    )\n\n    textlist = []\n    xml_printer.collect_not_inline_errors(input_error, textlist)\n    got = \"\".join(textlist)\n\n    self.assertEqual(\n        got,\n        (\"fiske leting\\tfiskeleting\\t#errtype=nosplit,pos=noun\"),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatErrormarkup.test_single_error_not_inline_with_filename","title":"<code>test_single_error_not_inline_with_filename()</code>","text":"<p>Plain error element, one word per line output, with filename</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_single_error_not_inline_with_filename(self):\n\"\"\"Plain error element, one word per line output, with filename\"\"\"\n    xml_printer = ccat.XMLPrinter(print_filename=True, one_word_per_line=True)\n    input_error = etree.fromstring(\n        \"&lt;errorortreal&gt;\"\n        \"fiske leting\"\n        '&lt;correct errtype=\"nosplit\" pos=\"noun\"&gt;fiskeleting&lt;/correct&gt;'\n        \"&lt;/errorortreal&gt;\"\n    )\n\n    xml_printer.filename = \"p.xml\"\n\n    textlist = []\n    xml_printer.collect_not_inline_errors(input_error, textlist)\n    got = \"\".join(textlist)\n\n    self.assertEqual(\n        got,\n        (\"fiske leting\\tfiskeleting\" \"\\t#errtype=nosplit,pos=noun, file: p.xml\"),\n    )\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatHyph","title":"<code>TestCcatHyph</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test how ccat handles hyph</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>class TestCcatHyph(unittest.TestCase):\n\"\"\"Test how ccat handles hyph\"\"\"\n\n    def test_hyph1(self):\n\"\"\"Test the default treatment of hyph tags\"\"\"\n        xml_printer = ccat.XMLPrinter()\n        buffer = io.StringIO()\n        xml_printer.etree = etree.parse(\n            io.BytesIO(\n                b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n                b\"&lt;/document&gt;\"\n            )\n        )\n\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"mellomkrigstiden \u00b6\\n\")\n\n    def test_hyph2(self):\n'''Test hyph tags when hyph_replacement is set to \"xml\"'''\n        xml_printer = ccat.XMLPrinter(hyph_replacement=\"xml\")\n        buffer = io.StringIO()\n        xml_printer.etree = etree.parse(\n            io.BytesIO(\n                b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n                b\"&lt;/document&gt;\"\n            )\n        )\n\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden \u00b6\\n\")\n\n    def test_hyph3(self):\n'''Test hyph tags when hyph_replacement is set to \"-\"'''\n        xml_printer = ccat.XMLPrinter(hyph_replacement=\"-\")\n        buffer = io.StringIO()\n        xml_printer.etree = etree.parse(\n            io.BytesIO(\n                b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n                b\"&lt;/document&gt;\"\n            )\n        )\n\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"mellom-krigs-tiden \u00b6\\n\")\n\n    def test_hyph4(self):\n\"\"\"Test the treatment of two hyph tags in a row\"\"\"\n        xml_printer = ccat.XMLPrinter(hyph_replacement=\"-\")\n        buffer = io.StringIO()\n\n        xml_printer.etree = etree.parse(\n            io.BytesIO(\n                b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n                b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n                b\"&lt;/document&gt;\"\n            )\n        )\n\n        buffer = xml_printer.process_file()\n        self.assertEqual(buffer.getvalue(), \"mellom-tiden \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatHyph.test_hyph1","title":"<code>test_hyph1()</code>","text":"<p>Test the default treatment of hyph tags</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_hyph1(self):\n\"\"\"Test the default treatment of hyph tags\"\"\"\n    xml_printer = ccat.XMLPrinter()\n    buffer = io.StringIO()\n    xml_printer.etree = etree.parse(\n        io.BytesIO(\n            b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n            b\"&lt;/document&gt;\"\n        )\n    )\n\n    buffer = xml_printer.process_file()\n    self.assertEqual(buffer.getvalue(), \"mellomkrigstiden \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatHyph.test_hyph2","title":"<code>test_hyph2()</code>","text":"<p>Test hyph tags when hyph_replacement is set to \"xml\"</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_hyph2(self):\n'''Test hyph tags when hyph_replacement is set to \"xml\"'''\n    xml_printer = ccat.XMLPrinter(hyph_replacement=\"xml\")\n    buffer = io.StringIO()\n    xml_printer.etree = etree.parse(\n        io.BytesIO(\n            b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n            b\"&lt;/document&gt;\"\n        )\n    )\n\n    buffer = xml_printer.process_file()\n    self.assertEqual(buffer.getvalue(), \"mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatHyph.test_hyph3","title":"<code>test_hyph3()</code>","text":"<p>Test hyph tags when hyph_replacement is set to \"-\"</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_hyph3(self):\n'''Test hyph tags when hyph_replacement is set to \"-\"'''\n    xml_printer = ccat.XMLPrinter(hyph_replacement=\"-\")\n    buffer = io.StringIO()\n    xml_printer.etree = etree.parse(\n        io.BytesIO(\n            b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;krigs&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n            b\"&lt;/document&gt;\"\n        )\n    )\n\n    buffer = xml_printer.process_file()\n    self.assertEqual(buffer.getvalue(), \"mellom-krigs-tiden \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_ccat/#corpustools.test.test_ccat.TestCcatHyph.test_hyph4","title":"<code>test_hyph4()</code>","text":"<p>Test the treatment of two hyph tags in a row</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_ccat.py</code> <pre><code>def test_hyph4(self):\n\"\"\"Test the treatment of two hyph tags in a row\"\"\"\n    xml_printer = ccat.XMLPrinter(hyph_replacement=\"-\")\n    buffer = io.StringIO()\n\n    xml_printer.etree = etree.parse(\n        io.BytesIO(\n            b'&lt;document id=\"no_id\" xml:lang=\"nob\"&gt;'\n            b\"&lt;body&gt;&lt;p&gt;mellom&lt;hyph/&gt;&lt;hyph/&gt;tiden&lt;/p&gt;&lt;/body&gt;\"\n            b\"&lt;/document&gt;\"\n        )\n    )\n\n    buffer = xml_printer.process_file()\n    self.assertEqual(buffer.getvalue(), \"mellom-tiden \u00b6\\n\")\n</code></pre>"},{"location":"reference/test/test_compare_tmx_goldstandard/","title":"test_compare_tmx_goldstandard","text":""},{"location":"reference/test/test_compare_tmx_goldstandard/#corpustools.test.test_compare_tmx_goldstandard.TestTmxComparator","title":"<code>TestTmxComparator</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>A test class for the TmxComparator class</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_compare_tmx_goldstandard.py</code> <pre><code>class TestTmxComparator(unittest.TestCase):\n\"\"\"A test class for the TmxComparator class\"\"\"\n\n    def test_equal_tmxes(self):\n        comp = compare_tmx_goldstandard.TmxComparator(\n            tmx.Tmx(\n                etree.parse(\n                    os.path.join(here, \"parallelize_data/aarseth2-n.htm.toktmx\")\n                )\n            ),\n            tmx.Tmx(\n                etree.parse(\n                    os.path.join(here, \"parallelize_data/aarseth2-n.htm.toktmx\")\n                )\n            ),\n        )\n\n        self.assertEqual(comp.get_number_of_differing_lines(), -1)\n        self.assertEqual(comp.get_lines_in_wantedfile(), 274)\n        self.assertEqual(len(comp.get_diff_as_text()), 0)\n</code></pre>"},{"location":"reference/test/test_converter/","title":"test_converter","text":"<p>Test the Converter class.</p>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter","title":"<code>TestConverter</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test the converter class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>class TestConverter(XMLTester):\n\"\"\"Test the converter class.\"\"\"\n\n    def setUp(self):\n        self.converter_inside_orig = converter.Converter(\n            os.path.join(\n                HERE,\n                \"converter_data/fakecorpus/orig/nob/admin/samediggi-\" \"article-16.html\",\n            ),\n            True,\n        )\n\n    def test_get_orig(self):\n\"\"\"Get the original name.\"\"\"\n        self.assertEqual(\n            self.converter_inside_orig.names.orig,\n            os.path.join(\n                HERE,\n                \"converter_data/fakecorpus/orig/nob/admin/samediggi-article-\" \"16.html\",\n            ),\n        )\n\n    def test_get_xsl(self):\n\"\"\"Get the name of the metadata file.\"\"\"\n        self.assertEqual(\n            self.converter_inside_orig.names.xsl,\n            os.path.join(\n                HERE,\n                \"converter_data/fakecorpus/orig/nob/admin/samediggi-\"\n                \"article-16.html.xsl\",\n            ),\n        )\n\n    def test_get_tmpdir(self):\n\"\"\"Get the temp dir.\"\"\"\n        self.assertEqual(\n            self.converter_inside_orig.tmpdir,\n            os.path.join(HERE, \"converter_data/fakecorpus/tmp\"),\n        )\n\n    def test_get_corpusdir(self):\n\"\"\"Get the corpus directory.\"\"\"\n        self.assertEqual(\n            self.converter_inside_orig.corpusdir.rstrip(os.path.sep),\n            os.path.join(HERE, \"converter_data/fakecorpus\"),\n        )\n\n    def test_get_converted_name(self):\n\"\"\"Get the name of the converted file.\"\"\"\n        self.assertEqual(\n            self.converter_inside_orig.names.converted,\n            os.path.join(\n                HERE,\n                \"converter_data/fakecorpus/converted/nob/admin/samediggi-\"\n                \"article-16.html.xml\",\n            ),\n        )\n\n    def test_validate_complete(self):\n\"\"\"Check that an exception is raised if a document is invalid.\"\"\"\n        complete = etree.fromstring(\"&lt;document/&gt;\")\n\n        self.assertRaises(\n            util.ConversionError, self.converter_inside_orig.validate_complete, complete\n        )\n\n    def test_detect_quote_is_skipped_on_errormarkup_documents(self):\n\"\"\"quote detection should not be done in errormarkup documents\n\n        This is a test for that covers the case covered in\n        http://giellatekno.uit.no/bugzilla/show_bug.cgi?id=2151\n        \"\"\"\n        want_string = \"\"\"\n            &lt;document xml:lang=\"smj\" id=\"no_id\"&gt;\n            &lt;header&gt;\n                &lt;title/&gt;\n                &lt;genre code=\"ficti\"/&gt;\n                &lt;year&gt;2011&lt;/year&gt;\n                &lt;wordcount&gt;15&lt;/wordcount&gt;\n            &lt;/header&gt;\n                &lt;body&gt;\n                    &lt;p&gt;\n                        Lev l\u00e4hk\u00e1m Sk\u00e1nen,\n                        &lt;errorort correct=\"Evenskjeran\" errorinfo=\"vowm,\u00e1-a\"&gt;\n                            Evenskjer\u00e1n\n                        &lt;/errorort&gt;\n                        S\u00e1me\n                        &lt;errorort correct=\"gilppusijn\" errorinfo=\"infl\"&gt;\n                            gilppojn\n                        &lt;/errorort&gt;\n                        ja lev aj d\u00e1n vahko l\u00e4hk\u00e1m\n                        &lt;errorort\n                            correct=\"&amp;quot;h\u00e1rjjidallamsk\u00e5vl\u00e5n&amp;quot;\"\n                            errorinfo=\"conc,rj-rjj;cmp,2-X\"&gt;\n                                h\u00e1rjidallam-\"sk\u00e5vl\u00e5n\"\n                        &lt;/errorort&gt;\n                        &lt;errorort correct=\"tjuojggusijn\" errorinfo=\"vowlat,o-u\"&gt;\n                            tjuojggosijn\n                        &lt;/errorort&gt;.\n                    &lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n        \"\"\"\n        got = etree.fromstring(want_string)\n\n        conv = converter.Converter(\"orig/sme/admin/blogg_5.correct.txt\")\n        conv.metadata = xslsetter.MetadataHandler(conv.names.xsl, create=True)\n        conv.metadata.set_variable(\"conversion_status\", \"correct\")\n        conv.fix_document(got)\n\n        self.assertXmlEqual(got, etree.fromstring(want_string))\n</code></pre>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter.test_detect_quote_is_skipped_on_errormarkup_documents","title":"<code>test_detect_quote_is_skipped_on_errormarkup_documents()</code>","text":"<p>quote detection should not be done in errormarkup documents</p> <p>This is a test for that covers the case covered in http://giellatekno.uit.no/bugzilla/show_bug.cgi?id=2151</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>def test_detect_quote_is_skipped_on_errormarkup_documents(self):\n\"\"\"quote detection should not be done in errormarkup documents\n\n    This is a test for that covers the case covered in\n    http://giellatekno.uit.no/bugzilla/show_bug.cgi?id=2151\n    \"\"\"\n    want_string = \"\"\"\n        &lt;document xml:lang=\"smj\" id=\"no_id\"&gt;\n        &lt;header&gt;\n            &lt;title/&gt;\n            &lt;genre code=\"ficti\"/&gt;\n            &lt;year&gt;2011&lt;/year&gt;\n            &lt;wordcount&gt;15&lt;/wordcount&gt;\n        &lt;/header&gt;\n            &lt;body&gt;\n                &lt;p&gt;\n                    Lev l\u00e4hk\u00e1m Sk\u00e1nen,\n                    &lt;errorort correct=\"Evenskjeran\" errorinfo=\"vowm,\u00e1-a\"&gt;\n                        Evenskjer\u00e1n\n                    &lt;/errorort&gt;\n                    S\u00e1me\n                    &lt;errorort correct=\"gilppusijn\" errorinfo=\"infl\"&gt;\n                        gilppojn\n                    &lt;/errorort&gt;\n                    ja lev aj d\u00e1n vahko l\u00e4hk\u00e1m\n                    &lt;errorort\n                        correct=\"&amp;quot;h\u00e1rjjidallamsk\u00e5vl\u00e5n&amp;quot;\"\n                        errorinfo=\"conc,rj-rjj;cmp,2-X\"&gt;\n                            h\u00e1rjidallam-\"sk\u00e5vl\u00e5n\"\n                    &lt;/errorort&gt;\n                    &lt;errorort correct=\"tjuojggusijn\" errorinfo=\"vowlat,o-u\"&gt;\n                        tjuojggosijn\n                    &lt;/errorort&gt;.\n                &lt;/p&gt;\n            &lt;/body&gt;\n        &lt;/document&gt;\n    \"\"\"\n    got = etree.fromstring(want_string)\n\n    conv = converter.Converter(\"orig/sme/admin/blogg_5.correct.txt\")\n    conv.metadata = xslsetter.MetadataHandler(conv.names.xsl, create=True)\n    conv.metadata.set_variable(\"conversion_status\", \"correct\")\n    conv.fix_document(got)\n\n    self.assertXmlEqual(got, etree.fromstring(want_string))\n</code></pre>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter.test_get_converted_name","title":"<code>test_get_converted_name()</code>","text":"<p>Get the name of the converted file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>def test_get_converted_name(self):\n\"\"\"Get the name of the converted file.\"\"\"\n    self.assertEqual(\n        self.converter_inside_orig.names.converted,\n        os.path.join(\n            HERE,\n            \"converter_data/fakecorpus/converted/nob/admin/samediggi-\"\n            \"article-16.html.xml\",\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter.test_get_corpusdir","title":"<code>test_get_corpusdir()</code>","text":"<p>Get the corpus directory.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>def test_get_corpusdir(self):\n\"\"\"Get the corpus directory.\"\"\"\n    self.assertEqual(\n        self.converter_inside_orig.corpusdir.rstrip(os.path.sep),\n        os.path.join(HERE, \"converter_data/fakecorpus\"),\n    )\n</code></pre>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter.test_get_orig","title":"<code>test_get_orig()</code>","text":"<p>Get the original name.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>def test_get_orig(self):\n\"\"\"Get the original name.\"\"\"\n    self.assertEqual(\n        self.converter_inside_orig.names.orig,\n        os.path.join(\n            HERE,\n            \"converter_data/fakecorpus/orig/nob/admin/samediggi-article-\" \"16.html\",\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter.test_get_tmpdir","title":"<code>test_get_tmpdir()</code>","text":"<p>Get the temp dir.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>def test_get_tmpdir(self):\n\"\"\"Get the temp dir.\"\"\"\n    self.assertEqual(\n        self.converter_inside_orig.tmpdir,\n        os.path.join(HERE, \"converter_data/fakecorpus/tmp\"),\n    )\n</code></pre>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter.test_get_xsl","title":"<code>test_get_xsl()</code>","text":"<p>Get the name of the metadata file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>def test_get_xsl(self):\n\"\"\"Get the name of the metadata file.\"\"\"\n    self.assertEqual(\n        self.converter_inside_orig.names.xsl,\n        os.path.join(\n            HERE,\n            \"converter_data/fakecorpus/orig/nob/admin/samediggi-\"\n            \"article-16.html.xsl\",\n        ),\n    )\n</code></pre>"},{"location":"reference/test/test_converter/#corpustools.test.test_converter.TestConverter.test_validate_complete","title":"<code>test_validate_complete()</code>","text":"<p>Check that an exception is raised if a document is invalid.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_converter.py</code> <pre><code>def test_validate_complete(self):\n\"\"\"Check that an exception is raised if a document is invalid.\"\"\"\n    complete = etree.fromstring(\"&lt;document/&gt;\")\n\n    self.assertRaises(\n        util.ConversionError, self.converter_inside_orig.validate_complete, complete\n    )\n</code></pre>"},{"location":"reference/test/test_corpuspath/","title":"test_corpuspath","text":"<p>Test the naming scheme of corpus files.</p>"},{"location":"reference/test/test_corpuspath/#corpustools.test.test_corpuspath.name","title":"<code>name(module, lang, extension, goallang)</code>","text":"<p>Produce a path to a corpus file.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>module of the corpus file</p> required <code>lang</code> <code>str</code> <p>language of the corpus file</p> required <code>extension</code> <code>str</code> <p>extension of the corpus file</p> required <code>goallang</code> <code>str</code> <p>goallang of tmx file</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>path to the corpus file</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_corpuspath.py</code> <pre><code>def name(module, lang, extension, goallang):\n\"\"\"Produce a path to a corpus file.\n\n    Args:\n        module (str): module of the corpus file\n        lang (str): language of the corpus file\n        extension (str): extension of the corpus file\n        goallang (str): goallang of tmx file\n\n    Returns:\n        str: path to the corpus file\n    \"\"\"\n    corpusdir = f\"corpus-{lang}-orig\" if module == \"orig\" else f\"corpus-{lang}\"\n    return os.path.join(\n        HERE,\n        corpusdir,\n        f\"{module if module != 'orig' else ''}\",\n        f\"{goallang if module.endswith('tmx') else ''}\",\n        \"subdir/subsubdir/filename.html\" + extension,\n    )\n</code></pre>"},{"location":"reference/test/test_corpuspath/#corpustools.test.test_corpuspath.test_path_to_orig","title":"<code>test_path_to_orig(filename)</code>","text":"<p>Check that the corpus file naming scheme works as it should.</p> <p>Parameters:</p> Name Type Description Default <code>testname</code> <code>str</code> <p>name of the test</p> required <code>testcontent</code> <code>dict</code> <p>mapping from given name to the wanted name</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>is raised if the result is not what is expected</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_corpuspath.py</code> <pre><code>@pytest.mark.parametrize(\n    \"filename\",\n    [\n        (name(\"orig\", \"sme\", \"\", \"\")),\n        (name(\"orig\", \"sme\", \".xsl\", \"\")),\n        (name(\"orig\", \"sme\", \".log\", \"\")),\n        (name(\"correct-no-gs/converted\", \"sme\", \".xml\", \"\")),\n        (name(\"goldstandard/converted\", \"sme\", \".xml\", \"\")),\n        (name(\"stable/converted\", \"sme\", \".xml\", \"\")),\n        (name(\"stable/tmx\", \"sme\", \".tmx\", \"nob\")),\n        (name(\"analysed\", \"sme\", \".xml\", \"\")),\n        (name(\"converted\", \"sme\", \".xml\", \"\")),\n        (name(\"korp\", \"sme\", \".xml\", \"\")),\n        (name(\"tmx\", \"sme\", \".tmx\", \"nob\")),\n    ],\n)\ndef test_path_to_orig(filename):\n\"\"\"Check that the corpus file naming scheme works as it should.\n\n    Args:\n        testname (str): name of the test\n        testcontent (dict): mapping from given name to the wanted name\n\n    Raises:\n        AssertionError: is raised if the result is not what is expected\n    \"\"\"\n\n    assert corpuspath.CorpusPath(filename).orig == name(\n        module=\"orig\", lang=\"sme\", extension=\"\", goallang=\"\"\n    )\n</code></pre>"},{"location":"reference/test/test_corpusxmlfile/","title":"test_corpusxmlfile","text":"<p>Class to test the class CorpusXMLFile.</p>"},{"location":"reference/test/test_corpusxmlfile/#corpustools.test.test_corpusxmlfile.TestCorpusXMLFile","title":"<code>TestCorpusXMLFile</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>A test class for the CorpusXMLFile class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_corpusxmlfile.py</code> <pre><code>class TestCorpusXMLFile(unittest.TestCase):\n\"\"\"A test class for the CorpusXMLFile class.\"\"\"\n\n    def setUp(self):\n        self.pfile = corpusxmlfile.CorpusXMLFile(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/sme/facta/skuvlahistorja2/\",\n                \"aarseth2-s.html.xml\",\n            )\n        )\n\n    @staticmethod\n    def assertXmlEqual(got, want):\n\"\"\"Check if two stringified xml snippets are equal.\"\"\"\n        string_got = etree.tostring(got, encoding=\"unicode\")\n        string_want = etree.tostring(want, encoding=\"unicode\")\n\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(string_want, string_got, 0):\n            message = checker.output_difference(\n                doctest.Example(\"\", string_want), string_got, 0\n            )\n            raise AssertionError(message)\n\n    def test_get_translated_from(self):\n        self.assertEqual(self.pfile.translated_from, \"nob\")\n\n    def test_get_word_count(self):\n        corpusfile = corpusxmlfile.CorpusXMLFile(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/sme/facta/skuvlahistorja2/\",\n                \"aarseth2-s.html.xml\",\n            )\n        )\n        self.assertEqual(corpusfile.word_count, \"3229\")\n\n    def test_remove_version(self):\n        file_with_version = corpusxmlfile.CorpusXMLFile(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/sme/facta/skuvlahistorja2/\",\n                \"aarseth2-s.html.xml\",\n            )\n        )\n        file_with_version.remove_version()\n\n        self.assertIsNone(file_with_version.root.find(\".//version\"))\n\n    def test_remove_skip(self):\n        file_with_skip = corpusxmlfile.CorpusXMLFile(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/sme/facta/skuvlahistorja2/\",\n                \"aarseth2-s-with-skip.html.xml\",\n            )\n        )\n        file_with_skip.remove_skip()\n        self.assertListEqual(file_with_skip.root.xpath(\".//skip\"), [])\n\n    def test_move_later(self):\n        file_with_later = corpusxmlfile.CorpusXMLFile(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/sme/facta/skuvlahistorja2/\",\n                \"aarseth2-s-with-later.html.xml\",\n            )\n        )\n\n        before = [\n            later.getparent().index(later)\n            for later in file_with_later.root.xpath(\".//later\")\n        ]\n        file_with_later.move_later()\n        after = [\n            later.getparent().index(later)\n            for later in file_with_later.root.xpath(\".//later\")\n        ]\n\n        self.assertNotEqual(before, after)\n</code></pre>"},{"location":"reference/test/test_corpusxmlfile/#corpustools.test.test_corpusxmlfile.TestCorpusXMLFile.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>  <code>staticmethod</code>","text":"<p>Check if two stringified xml snippets are equal.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_corpusxmlfile.py</code> <pre><code>@staticmethod\ndef assertXmlEqual(got, want):\n\"\"\"Check if two stringified xml snippets are equal.\"\"\"\n    string_got = etree.tostring(got, encoding=\"unicode\")\n    string_want = etree.tostring(want, encoding=\"unicode\")\n\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(string_want, string_got, 0):\n        message = checker.output_difference(\n            doctest.Example(\"\", string_want), string_got, 0\n        )\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_decode/","title":"test_decode","text":""},{"location":"reference/test/test_decode/#corpustools.test.test_decode.handler","title":"<code>handler(err)</code>","text":"<p>Handle UnicodeDecodeError.</p> <p>Parameters:</p> Name Type Description Default <code>err</code> <code>exceptions.UnicodeDecodeError</code> <p>the error.</p> required <p>Returns:</p> Type Description <p>The fixed string</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_decode.py</code> <pre><code>def handler(err):\n\"\"\"Handle UnicodeDecodeError.\n\n    Args:\n        err (exceptions.UnicodeDecodeError): the error.\n\n    Returns:\n        The fixed string\n    \"\"\"\n    start = err.start\n    end = err.end\n    return (\n        \"\".join([f\"&amp;#{err.object[i]};\" for i in range(start, end)]),\n        end,\n    )\n</code></pre>"},{"location":"reference/test/test_docconverter/","title":"test_docconverter","text":"<p>Test conversion of doc files.</p>"},{"location":"reference/test/test_docconverter/#corpustools.test.test_docconverter.TestDocConverter","title":"<code>TestDocConverter</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test docx conversion.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_docconverter.py</code> <pre><code>class TestDocConverter(XMLTester):\n\"\"\"Test docx conversion.\"\"\"\n\n    def test_convert2intermediate(self):\n\"\"\"Test conversion of a doc file.\"\"\"\n        got = htmlcontentconverter.convert2intermediate(\n            os.path.join(HERE, \"converter_data/fakecorpus/orig/sme/riddu/doc-test.doc\")\n        )\n        want = etree.parse(os.path.join(HERE, \"converter_data/doc-test.xml\"))\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_docconverter/#corpustools.test.test_docconverter.TestDocConverter.test_convert2intermediate","title":"<code>test_convert2intermediate()</code>","text":"<p>Test conversion of a doc file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_docconverter.py</code> <pre><code>def test_convert2intermediate(self):\n\"\"\"Test conversion of a doc file.\"\"\"\n    got = htmlcontentconverter.convert2intermediate(\n        os.path.join(HERE, \"converter_data/fakecorpus/orig/sme/riddu/doc-test.doc\")\n    )\n    want = etree.parse(os.path.join(HERE, \"converter_data/doc-test.xml\"))\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/","title":"test_documentfixer","text":""},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer","title":"<code>TestDocumentFixer</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test the DocumentFixer class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>class TestDocumentFixer(XMLTester):\n\"\"\"Test the DocumentFixer class.\"\"\"\n\n    def test_insert_spaces_after_semicolon(self):\n        a = {\n            \"Govven:\u00c1\": \"Govven: \u00c1\",\n            \"govven:\u00e1\": \"govven: \u00e1\",\n            \"GOVVEN:\u00c1\": \"GOVVEN: \u00c1\",\n            \"Govva:\u00c1\": \"Govva: \u00c1\",\n            \"govva:\u00e1\": \"govva: \u00e1\",\n            \"GOVVA:\u00c1\": \"GOVVA: \u00c1\",\n            \"GOVVEJEADDJI:\u00c1\": \"GOVVEJEADDJI: \u00c1\",\n            \"Govva:\": \"Govva:\",\n            \"&lt;em&gt;Govven:\u00c1&lt;/em&gt;\": \"&lt;em&gt;Govven: \u00c1&lt;/em&gt;\",\n        }\n        for key, value in a.items():\n            document_fixer = documentfixer.DocumentFixer(\n                etree.fromstring(\n\"\"\"\n                &lt;document&gt;\n                    &lt;header/&gt;\n                    &lt;body&gt;\n                        &lt;p&gt;\"\"\"\n                    + key\n                    + \"\"\"&lt;/p&gt;\n                    &lt;/body&gt;\n                &lt;/document&gt;\n            \"\"\"\n                )\n            )\n            document_fixer.insert_spaces_after_semicolon()\n            got = document_fixer.get_etree()\n            want = etree.fromstring(\n\"\"\"\n                &lt;document&gt;\n                    &lt;header/&gt;\n                    &lt;body&gt;\n                        &lt;p&gt;\"\"\"\n                + value\n                + \"\"\"&lt;/p&gt;\n                    &lt;/body&gt;\n                &lt;/document&gt;\n            \"\"\"\n            )\n\n            self.assertXmlEqual(got, want)\n\n    def test_fix_newstags_bold_1(self):\n\"\"\"Test conversion of the @bold: newstag.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bold:buoidi\nseaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em type=\"bold\"&gt;buoidi&lt;/em&gt;&lt;/p&gt;\n        &lt;p&gt;seaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_newstags_bold_2(self):\n\"\"\"Test conversion of the @bold: newstag.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bold:buoidi\n@tekst:seaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em type=\"bold\"&gt;buoidi&lt;/em&gt;&lt;/p&gt;\n        &lt;p&gt;seaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_newstags_bold_3(self):\n\"\"\"Test conversion of the @bold: newstag.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bold :DON&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em type=\"bold\"&gt;DON&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline1(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@byline: K\u00e1r\u00e1\u0161johka: Elle Merete Utsi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Elle Merete Utsi\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline2(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;&amp;lt;pstyle:byline&amp;gt;NORGA: \u00c5se Pulk&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"\u00c5se Pulk\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline3(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@byline:K\u00e7R\u00e7\u00b4JOHKA:Elle Merete Utsi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Elle Merete Utsi\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline4(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@byline:Elle Merete Utsi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Elle Merete Utsi\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline5(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt; @byline:Elle Merete Utsi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Elle Merete Utsi\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline6(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Juvven\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt; @byline:Elle Merete Utsi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Juvven\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline7(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt; @BYLINE:Elle Merete Utsi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Elle Merete Utsi\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_byline8(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;@BYLINE:Elle Merete Utsi &lt;/em&gt; &lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"Elle Merete Utsi\"/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body/&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_kursiv(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@kursiv:(G\u00e1ldu)&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em type=\"italic\"&gt;(G\u00e1ldu)&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_ledtekst(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@LEDtekst:Dat mearkka\u0161a&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Dat mearkka\u0161a&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_bildetekst(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Bildetekst:Dat mearkka\u0161a&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Dat mearkka\u0161a&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_logo(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@logo:Finnmark jordskifterett&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Finnmark jordskifterett&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fotobyline(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@fotobyline:Finnmark jordskifterett&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Finnmark jordskifterett&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_foto(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@foto: govva1&lt;/p&gt;\n        &lt;p&gt;&lt;em&gt;foto: govva2&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;govva1&lt;/p&gt;\n        &lt;p&gt;&lt;em&gt;govva2&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_bildetitt(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bildetitt:Finnmark jordskifterett&lt;/p&gt;\n        &lt;p&gt;Bildetitt:Finnmark jordskifterett&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Finnmark jordskifterett&lt;/p&gt;\n        &lt;p&gt;Finnmark jordskifterett&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_bilde(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bilde:NSR PRESIDEANTAEVTTOHAS? Berit Ranveig Nilssen\nB 13  @bilde:DEANU-LEAGIS: Nils Porsanger.\nB8  @bilde:SOHPPARIS: Bajit-Sohpparis Nils Andersen.\n@bilde :E\nBILDE 3:oahppat\n&amp;lt;pstyle:bilde&amp;gt;Ii\nBilledtekst: 3&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;NSR PRESIDEANTAEVTTOHAS? Berit Ranveig Nilssen&lt;/p&gt;\n        &lt;p&gt;DEANU-LEAGIS: Nils Porsanger.&lt;/p&gt;\n        &lt;p&gt;SOHPPARIS: Bajit-Sohpparis Nils Andersen.&lt;/p&gt;\n        &lt;p&gt;E&lt;/p&gt;\n        &lt;p&gt;oahppat&lt;/p&gt;\n        &lt;p&gt;Ii&lt;/p&gt;\n        &lt;p&gt;3&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_ingress_1(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@ingress:Ragnhild Nystad, Aili Keskitalo.\n@ingres:Guovdageainnu lagasradio\n @ingress: Eallu\n@ingress. duottar\n'@ingress:Golbma\n@ingress Odne\nSamleingress 1\nSamleingress: 2\n@Samleingress: 3\n&amp;lt;pstyle:ingress&amp;gt;Buot\nTEKST/INGRESS: 5\n@ Ingress: 6&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Ragnhild Nystad, Aili Keskitalo.&lt;/p&gt;\n        &lt;p&gt;Guovdageainnu lagasradio&lt;/p&gt;\n        &lt;p&gt;Eallu&lt;/p&gt;\n        &lt;p&gt;duottar&lt;/p&gt;\n        &lt;p&gt;Golbma&lt;/p&gt;\n        &lt;p&gt;Odne&lt;/p&gt;\n        &lt;p&gt;1&lt;/p&gt;\n        &lt;p&gt;2&lt;/p&gt;\n        &lt;p&gt;3&lt;/p&gt;\n        &lt;p&gt;Buot&lt;/p&gt;\n        &lt;p&gt;5&lt;/p&gt;\n        &lt;p&gt;6&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_ingress_2(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;@ingress: Gos?&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;Gos?&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_mtitt1(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@m.titt:Juovllat\nm.titt:Guolli\n@mtitt:Juovllat\nM:TITT:Lea go dus meahccebiila?\n@m.titt. Ma\u014bemus g\u00e1rtemat\n&amp;lt;pstyle:m.titt&amp;gt;Divvot\n @m.titt:Eai&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Juovllat&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Guolli&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Juovllat&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Lea go dus meahccebiila?&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Ma\u014bemus g\u00e1rtemat&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Divvot&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Eai&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_mtitt2(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;@m.titt: Maid?&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;&lt;em&gt;Maid?&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_tekst_1(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst:veadj\u00e1 \u0161addat.\ntekst:NSR ii \u00e1iggo.\nTEKST:\u00d0Mii lea suohttaseamos geassebargu dus?\n&amp;lt;pstyle:tekst&amp;gt;S\u00e1mi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;veadj\u00e1 \u0161addat.&lt;/p&gt;\n        &lt;p&gt;NSR ii \u00e1iggo.&lt;/p&gt;\n        &lt;p&gt;\u00d0Mii lea suohttaseamos geassebargu dus?&lt;/p&gt;\n        &lt;p&gt;S\u00e1mi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_tekst_2(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst:veadj\u00e1 \u0161addat.\nNSR ii \u00e1iggo.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;veadj\u00e1 \u0161addat. NSR ii \u00e1iggo.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_tekst_3(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst:veadj\u00e1 \u0161addat.\n@tekst:NSR ii \u00e1iggo.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;veadj\u00e1 \u0161addat.&lt;/p&gt;\n        &lt;p&gt;NSR ii \u00e1iggo.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_tekst_4(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;NSR &lt;em&gt;ii \u00e1iggo.&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;NSR &lt;em&gt;ii \u00e1iggo.&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_tekst_5(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;  @tekst:ii&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;ii&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_tekst_6(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n                \"&lt;document&gt;\"\n                \"   &lt;header/&gt;\"\n                \"   &lt;body&gt;\"\n                \"       &lt;p&gt;\u00ca@tekst:ii&lt;/p&gt;\"\n                \"   &lt;/body&gt;\"\n                \"&lt;/document&gt;\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n            \"&lt;document&gt;\"\n            \"   &lt;header/&gt;\"\n            \"   &lt;body&gt;\"\n            \"       &lt;p&gt;ii&lt;/p&gt;\"\n            \"   &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_stikktitt(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@stikktitt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n        &lt;p&gt;@stikk.titt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n        &lt;p&gt;@stikktittel:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n        &lt;p&gt; @stikk:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_utitt1(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@utitt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_utitt2(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt; @utitt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_udot_titt(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@u.titt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_undertitt(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@undertitt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis\nundertitt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_undertittel(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Undertittel: Ja&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Ja&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_ttitt(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@ttitt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_1(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tittel:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_2(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt; @tittel:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_3(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@titt:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_4(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt; @titt:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_5(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;TITT:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_6(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;Tittel:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_7(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@LEDtitt:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_8(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;&amp;lt;pstyle:tittel&amp;gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_9(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;HOVEDTITTEL:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_10(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;TITTEL:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_11(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@Titt:Guolli\ntitt:Ruovttusuodjaleaddjit\n @titt:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Guolli&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Guolli&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Ruovttusuodjaleaddjit&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_12(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;Hovedtitt:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_13(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@hovedtitt:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_14(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@titt 2:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_15(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;OVERTITTEL:Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Eanebuidda&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Eanebuidda&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_headertitletags_16(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tittel:Gii boaht\u00e1 Nyst\u00f8 ma\u014bis?\n@LEDtitt:Gii boaht\u00e1 Keskitalo ma\u014bis?\n@tittel:Gii boaht\u00e1 Olli ma\u014bis?\nTITT:njeallje suorpma boaris.\n&amp;lt;pstyle:tittel&amp;gt;Ii\n @tittel: 1\nHOVEDTITTEL: 2\nTITTEL: 3&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;Gii boaht\u00e1 Nyst\u00f8 ma\u014bis?&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Gii boaht\u00e1 Nyst\u00f8 ma\u014bis?&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Gii boaht\u00e1 Keskitalo ma\u014bis?&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Gii boaht\u00e1 Olli ma\u014bis?&lt;/p&gt;\n        &lt;p type=\"title\"&gt;njeallje suorpma boaris.&lt;/p&gt;\n        &lt;p type=\"title\"&gt;Ii&lt;/p&gt;\n        &lt;p type=\"title\"&gt;1&lt;/p&gt;\n        &lt;p type=\"title\"&gt;2&lt;/p&gt;\n        &lt;p type=\"title\"&gt;3&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\n\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_ttt(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@ttt:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_newstags_tit(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tit:Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;Dolo\u0161 s\u00e1megiel m\u00e1innas V\u00e1rjjagis&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_newstags_text_before_titletags(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst: text\n@m.titt: title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;text&lt;/p&gt;\n        &lt;p type=\"title\"&gt;title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_newstags_text_before_headtitletags(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title/&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst: text\n@tittel: title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;title&gt;title&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;text&lt;/p&gt;\n        &lt;p type=\"title\"&gt;title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_newstags_text_before_bylinetags(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;unknown/&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst: text\n@byline: title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;\n        &lt;author&gt;\n            &lt;person firstname=\"\" lastname=\"title\"&gt;&lt;/person&gt;\n        &lt;/author&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        &lt;p&gt;text&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_newstags_text_before_boldtags(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst: text\n@bold: title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;text&lt;/p&gt;\n        &lt;p&gt;&lt;em type=\"bold\"&gt;title&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_newstags_text_before_kursiv(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@tekst: text\n@kursiv: title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;text&lt;/p&gt;\n        &lt;p&gt;&lt;em type=\"italic\"&gt;title&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_newstags_4(self):\n\"\"\"Check that p attributes are kept.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_body_encoding(self):\n        newstext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        text = newstext.content2xml(\n            io.StringIO(\n\"\"\"\u00d0Mun lean njeallje jagi boaris.\n\nNu beaivv\u0087dat.\n\nTITT:njeallje suorpma boaris.\n\nTEKST:Olggobealde \u00e7\u00bb\u00bbu\n\nM:TITT:Lea go dus meahccebiila ?\n\nTEKST:\u00d0Mii lea suohttaseamos geassebargu dus ?\n\n@bold:Suohkana beara\u00bb\u0087sodagaid juohkin\n\nLOGO: S\u0087mi kulturfestivala 1998\n\"\"\"\n            )\n        )\n\n        document_fixer = documentfixer.DocumentFixer(text)\n        document_fixer.fix_body_encoding(\"sme\")\n        got = document_fixer.get_etree()\n\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header&gt;&lt;/header&gt;\n        &lt;body&gt;\n            &lt;p&gt;\u2013Mun lean njeallje jagi boaris.&lt;/p&gt;\n            &lt;p&gt;Nu beaivv\u00e1dat.&lt;/p&gt;\n            &lt;p&gt;TITT:njeallje suorpma boaris.&lt;/p&gt;\n            &lt;p&gt;TEKST:Olggobealde \u00c1\u0161\u0161u&lt;/p&gt;\n            &lt;p&gt;M:TITT:Lea go dus meahccebiila ?&lt;/p&gt;\n            &lt;p&gt;TEKST:\u2013Mii lea suohttaseamos geassebargu dus ?&lt;/p&gt;\n            &lt;p&gt;@bold:Suohkana beara\u0161\u00e1sodagaid juohkin&lt;/p&gt;\n            &lt;p&gt;LOGO: S\u00e1mi kulturfestivala 1998&lt;/p&gt;\n        &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_replace_ligatures(self):\n        xml = svgconverter.convert2intermediate(\n            os.path.join(\n                HERE,\n                \"converter_data/fakecorpus/orig/sme/riddu/\"\n                \"Riddu_Riddu_avis_TXT.200923.svg\",\n            )\n        )\n        document_fixer = documentfixer.DocumentFixer(xml)\n        document_fixer.fix_body_encoding(\"sme\")\n        got = document_fixer.get_etree()\n\n        want = etree.parse(\n            os.path.join(HERE, \"converter_data/Riddu_Riddu_avis_TXT.200923.xml\")\n        )\n\n        self.assertXmlEqual(got, want)\n\n    # def test_word_count(self):\n    # document = (\n    #'&lt;document xml:lang=\"sma\" id=\"no_id\"&gt;&lt;header&gt;&lt;title/&gt;&lt;genre/&gt;'\n    #'&lt;author&gt;&lt;unknown/&gt;&lt;/author&gt;&lt;availability&gt;&lt;free/&gt;'\n    #'&lt;/availability&gt;&lt;multilingual/&gt;&lt;/header&gt;&lt;body&gt;&lt;p&gt;B\u00efevnesh '\n    #'naasjovnalen pry\u00f6voej b\u00efjre&lt;/p&gt;&lt;p&gt;2008&lt;/p&gt;&lt;p&gt;B\u00efevnesh '\n    #'eejhtegidie, tjidtjieh aehtjieh bielide naasjovnalen '\n    #'pry\u00f6voej b\u00efjre giej leah maanah 5. j\u00efh 8. '\n    #'tsiehkine&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;')\n    # if six.PY3:\n    # document = document.encode('utf8')\n    # orig_doc = etree.parse(\n    # io.BytesIO(document))\n\n    # expected_doc = (\n    #'&lt;document xml:lang=\"sma\" id=\"no_id\"&gt;&lt;header&gt;&lt;title/&gt;&lt;genre/&gt;'\n    #'&lt;author&gt;&lt;unknown/&gt;&lt;/author&gt;&lt;wordcount&gt;20&lt;/wordcount&gt;'\n    #'&lt;availability&gt;&lt;free/&gt;&lt;/availability&gt;&lt;multilingual/&gt;&lt;/header&gt;'\n    #'&lt;body&gt;&lt;p&gt;B\u00efevnesh naasjovnalen pry\u00f6voej b\u00efjre&lt;/p&gt;'\n    #'&lt;p&gt;2008&lt;/p&gt;&lt;p&gt;B\u00efevnesh eejhtegidie, tjidtjieh aehtjieh bielide '\n    #'naasjovnalen pry\u00f6voej b\u00efjre giej leah maanah 5. j\u00efh 8. '\n    #'tsiehkine&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;')\n\n    # document_fixer = documentfixer.DocumentFixer(orig_doc)\n    # document_fixer.set_word_count()\n\n    # self.assertXmlEqual(document_fixer.root,\n    # etree.fromstring(expected_doc))\n\n    def test_replace_shy1(self):\n        document = (\n            '&lt;document xml:lang=\"sma\" id=\"no_id\"&gt;&lt;header&gt;&lt;title/&gt;&lt;genre/&gt;'\n            \"&lt;author&gt;&lt;unknown/&gt;&lt;/author&gt;&lt;availability&gt;&lt;free/&gt;\"\n            \"&lt;/availability&gt;&lt;multilingual/&gt;&lt;/header&gt;&lt;body&gt;&lt;p&gt;a\u00adb\u00adc\"\n            \"&lt;span&gt;d\u00ade&lt;/span&gt;f\u00adg&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n        )\n        document = document.encode(\"utf8\")\n        orig_doc = etree.parse(io.BytesIO(document))\n\n        expected_doc = (\n            '&lt;document xml:lang=\"sma\" id=\"no_id\"&gt;&lt;header&gt;&lt;title/&gt;&lt;genre/&gt;'\n            \"&lt;author&gt;&lt;unknown/&gt;&lt;/author&gt;&lt;availability&gt;&lt;free/&gt;&lt;/availability&gt;\"\n            \"&lt;multilingual/&gt;&lt;/header&gt;&lt;body&gt;&lt;p&gt;a&lt;hyph/&gt;b&lt;hyph/&gt;c&lt;span&gt;d&lt;hyph/&gt;\"\n            \"e&lt;/span&gt;f&lt;hyph/&gt;g&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n        )\n\n        document_fixer = documentfixer.DocumentFixer(orig_doc)\n        document_fixer.soft_hyphen_to_hyph_tag()\n\n        self.assertXmlEqual(document_fixer.root, etree.fromstring(expected_doc))\n\n    def test_replace_shy2(self):\n        document = (\n            '&lt;document xml:lang=\"sma\" id=\"no_id\"&gt;'\n            \"&lt;header&gt;&lt;title/&gt;&lt;genre/&gt;&lt;author&gt;&lt;unknown/&gt;&lt;/author&gt;\"\n            \"&lt;availability&gt;&lt;free/&gt;&lt;/availability&gt;&lt;multilingual/&gt;&lt;/header&gt;\"\n            \"&lt;body&gt;&lt;p&gt;a\u00adb\u00adc&lt;span&gt;d\u00ade&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n        )\n        document = document.encode(\"utf8\")\n        orig_doc = etree.parse(io.BytesIO(document))\n\n        expected_doc = (\n            '&lt;document xml:lang=\"sma\" id=\"no_id\"&gt;&lt;header&gt;&lt;title/&gt;&lt;genre/&gt;'\n            \"&lt;author&gt;&lt;unknown/&gt;&lt;/author&gt;&lt;availability&gt;&lt;free/&gt;&lt;/availability&gt;\"\n            \"&lt;multilingual/&gt;&lt;/header&gt;&lt;body&gt;&lt;p&gt;a&lt;hyph/&gt;b&lt;hyph/&gt;c&lt;span&gt;d\"\n            \"&lt;hyph/&gt;e&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/document&gt;\"\n        )\n\n        document_fixer = documentfixer.DocumentFixer(orig_doc)\n        document_fixer.soft_hyphen_to_hyph_tag()\n\n        self.assertXmlEqual(document_fixer.root, etree.fromstring(expected_doc))\n\n    def test_compact_em1(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1&lt;/em&gt; &lt;em&gt;2&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.compact_ems()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1 2&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_compact_em2(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1&lt;/em&gt; &lt;em&gt;2&lt;/em&gt; 3&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.compact_ems()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1 2&lt;/em&gt; 3&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_compact_em3(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1&lt;/em&gt; &lt;em&gt;2&lt;/em&gt; &lt;span/&gt; &lt;em&gt;3&lt;/em&gt; &lt;em&gt;4&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.compact_ems()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1 2&lt;/em&gt; &lt;span/&gt; &lt;em&gt;3 4&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_compact_em4(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1&lt;/em&gt; &lt;em&gt;2&lt;/em&gt; 5&lt;span/&gt; &lt;em&gt;3&lt;/em&gt; &lt;em&gt;4&lt;/em&gt; 6&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.compact_ems()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;1 2&lt;/em&gt; 5&lt;span/&gt; &lt;em&gt;3 4&lt;/em&gt; 6&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_compact_em5(self):\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;&lt;/em&gt; &lt;em&gt;2&lt;/em&gt; 5&lt;span/&gt; &lt;em&gt;3&lt;/em&gt; &lt;em&gt;&lt;/em&gt; 6&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.compact_ems()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em&gt;2&lt;/em&gt; 5&lt;span/&gt; &lt;em&gt;3&lt;/em&gt; 6&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_sms1(self):\nr\"\"\"\\u2019 (\u2019) should be replaced by \\u02BC (\u02bc)\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n                '&lt;document xml:lang=\"sms\"&gt;'\n                \"  &lt;header/&gt;\"\n                \"  &lt;body&gt;\"\n                \"     &lt;p&gt;\"\n                \"       M\u00e4tt\u2019temaaun\u00e2stu\u00e2jj \"\n                \"     &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/document&gt;\"\n            )\n        )\n        document_fixer.fix_body_encoding(\"sms\")\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       M\u00e4tt\u02bctemaaun\u00e2stu\u00e2jj \"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_sms2(self):\nr\"\"\"\\u0027 (')  should be replaced by \\u02BC (\u02bc)\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n                '&lt;document xml:lang=\"sms\"&gt;'\n                \"  &lt;header/&gt;\"\n                \"  &lt;body&gt;\"\n                \"     &lt;p&gt;\"\n                \"       \u01e9i\u00f5ll'la\u017e da kulttuursa\u017e vu\u00f5igg\u00e2dvu\u00f5\u0111i\"\n                \"     &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/document&gt;\"\n            )\n        )\n        document_fixer.fix_body_encoding(\"sms\")\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       \u01e9i\u00f5ll\u02bcla\u017e da kulttuursa\u017e vu\u00f5igg\u00e2dvu\u00f5\u0111i\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_sms3(self):\nr\"\"\"\\u2032 (\u2032)  should be replaced by \\u02B9 (\u02b9)\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n                '&lt;document xml:lang=\"sms\"&gt;'\n                \"  &lt;header/&gt;\"\n                \"  &lt;body&gt;\"\n                \"     &lt;p&gt;\"\n                \"       Mon t\u00f5zz \u0161e njui\u2032\u01e9\u01e9eem t\u00f5\u2032st d\u00f5\u00f5zze.\"\n                \"     &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/document&gt;\"\n            )\n        )\n        document_fixer.fix_body_encoding(\"sms\")\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       Mon t\u00f5zz \u0161e njui\u02b9\u01e9\u01e9eem t\u00f5\u02b9st d\u00f5\u00f5zze.\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_sms4(self):\nr\"\"\"\\u00B4 (\u00b4)  should be replaced by \\u02B9 (\u02b9)\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n                '&lt;document xml:lang=\"sms\"&gt;'\n                \"  &lt;header/&gt;\"\n                \"  &lt;body&gt;\"\n                \"     &lt;p&gt;\"\n                \"       Materialbaa\u014bk \u010du\u00e4\u00b4jtumu\u0161\"\n                \"     &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/document&gt;\"\n            )\n        )\n        document_fixer.fix_body_encoding(\"sms\")\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       Materialbaa\u014bk \u010du\u00e4\u02b9jtumu\u0161\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_fix_sms5(self):\nr\"\"\"\\u0301 ( \u0301)  should be replaced by \\u02B9 (\u02b9)\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\n                '&lt;document xml:lang=\"sms\"&gt;'\n                \"  &lt;header/&gt;\"\n                \"  &lt;body&gt;\"\n                \"     &lt;p&gt;\"\n                \"       Materialbaa\u014bk \u010du\u00e4\u0301jtumu\u0161\"\n                \"     &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/document&gt;\"\n            )\n        )\n        document_fixer.fix_body_encoding(\"sms\")\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       Materialbaa\u014bk \u010du\u00e4\u02b9jtumu\u0161\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_newstags_4","title":"<code>test_fix_newstags_4()</code>","text":"<p>Check that p attributes are kept.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>    def test_fix_newstags_4(self):\n\"\"\"Check that p attributes are kept.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p type=\"title\"&gt;title&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_newstags_bold_1","title":"<code>test_fix_newstags_bold_1()</code>","text":"<p>Test conversion of the @bold: newstag.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>    def test_fix_newstags_bold_1(self):\n\"\"\"Test conversion of the @bold: newstag.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bold:buoidi\nseaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em type=\"bold\"&gt;buoidi&lt;/em&gt;&lt;/p&gt;\n        &lt;p&gt;seaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_newstags_bold_2","title":"<code>test_fix_newstags_bold_2()</code>","text":"<p>Test conversion of the @bold: newstag.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>    def test_fix_newstags_bold_2(self):\n\"\"\"Test conversion of the @bold: newstag.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bold:buoidi\n@tekst:seaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em type=\"bold\"&gt;buoidi&lt;/em&gt;&lt;/p&gt;\n        &lt;p&gt;seaggi&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_newstags_bold_3","title":"<code>test_fix_newstags_bold_3()</code>","text":"<p>Test conversion of the @bold: newstag.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>    def test_fix_newstags_bold_3(self):\n\"\"\"Test conversion of the @bold: newstag.\"\"\"\n        document_fixer = documentfixer.DocumentFixer(\n            etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;@bold :DON&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n            )\n        )\n        document_fixer.fix_newstags()\n        got = document_fixer.get_etree()\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;&lt;em type=\"bold\"&gt;DON&lt;/em&gt;&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_sms1","title":"<code>test_fix_sms1()</code>","text":"<p>\\u2019 (\u2019) should be replaced by \\u02BC (\u02bc)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>def test_fix_sms1(self):\nr\"\"\"\\u2019 (\u2019) should be replaced by \\u02BC (\u02bc)\"\"\"\n    document_fixer = documentfixer.DocumentFixer(\n        etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       M\u00e4tt\u2019temaaun\u00e2stu\u00e2jj \"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n    )\n    document_fixer.fix_body_encoding(\"sms\")\n    got = document_fixer.get_etree()\n    want = etree.fromstring(\n        '&lt;document xml:lang=\"sms\"&gt;'\n        \"  &lt;header/&gt;\"\n        \"  &lt;body&gt;\"\n        \"     &lt;p&gt;\"\n        \"       M\u00e4tt\u02bctemaaun\u00e2stu\u00e2jj \"\n        \"     &lt;/p&gt;\"\n        \"  &lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_sms2","title":"<code>test_fix_sms2()</code>","text":"<p>\\u0027 (')  should be replaced by \\u02BC (\u02bc)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>def test_fix_sms2(self):\nr\"\"\"\\u0027 (')  should be replaced by \\u02BC (\u02bc)\"\"\"\n    document_fixer = documentfixer.DocumentFixer(\n        etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       \u01e9i\u00f5ll'la\u017e da kulttuursa\u017e vu\u00f5igg\u00e2dvu\u00f5\u0111i\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n    )\n    document_fixer.fix_body_encoding(\"sms\")\n    got = document_fixer.get_etree()\n    want = etree.fromstring(\n        '&lt;document xml:lang=\"sms\"&gt;'\n        \"  &lt;header/&gt;\"\n        \"  &lt;body&gt;\"\n        \"     &lt;p&gt;\"\n        \"       \u01e9i\u00f5ll\u02bcla\u017e da kulttuursa\u017e vu\u00f5igg\u00e2dvu\u00f5\u0111i\"\n        \"     &lt;/p&gt;\"\n        \"  &lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_sms3","title":"<code>test_fix_sms3()</code>","text":"<p>\\u2032 (\u2032)  should be replaced by \\u02B9 (\u02b9)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>def test_fix_sms3(self):\nr\"\"\"\\u2032 (\u2032)  should be replaced by \\u02B9 (\u02b9)\"\"\"\n    document_fixer = documentfixer.DocumentFixer(\n        etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       Mon t\u00f5zz \u0161e njui\u2032\u01e9\u01e9eem t\u00f5\u2032st d\u00f5\u00f5zze.\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n    )\n    document_fixer.fix_body_encoding(\"sms\")\n    got = document_fixer.get_etree()\n    want = etree.fromstring(\n        '&lt;document xml:lang=\"sms\"&gt;'\n        \"  &lt;header/&gt;\"\n        \"  &lt;body&gt;\"\n        \"     &lt;p&gt;\"\n        \"       Mon t\u00f5zz \u0161e njui\u02b9\u01e9\u01e9eem t\u00f5\u02b9st d\u00f5\u00f5zze.\"\n        \"     &lt;/p&gt;\"\n        \"  &lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_sms4","title":"<code>test_fix_sms4()</code>","text":"<p>\\u00B4 (\u00b4)  should be replaced by \\u02B9 (\u02b9)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>def test_fix_sms4(self):\nr\"\"\"\\u00B4 (\u00b4)  should be replaced by \\u02B9 (\u02b9)\"\"\"\n    document_fixer = documentfixer.DocumentFixer(\n        etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       Materialbaa\u014bk \u010du\u00e4\u00b4jtumu\u0161\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n    )\n    document_fixer.fix_body_encoding(\"sms\")\n    got = document_fixer.get_etree()\n    want = etree.fromstring(\n        '&lt;document xml:lang=\"sms\"&gt;'\n        \"  &lt;header/&gt;\"\n        \"  &lt;body&gt;\"\n        \"     &lt;p&gt;\"\n        \"       Materialbaa\u014bk \u010du\u00e4\u02b9jtumu\u0161\"\n        \"     &lt;/p&gt;\"\n        \"  &lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.TestDocumentFixer.test_fix_sms5","title":"<code>test_fix_sms5()</code>","text":"<p>\\u0301 ( \u0301)  should be replaced by \\u02B9 (\u02b9)</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>def test_fix_sms5(self):\nr\"\"\"\\u0301 ( \u0301)  should be replaced by \\u02B9 (\u02b9)\"\"\"\n    document_fixer = documentfixer.DocumentFixer(\n        etree.fromstring(\n            '&lt;document xml:lang=\"sms\"&gt;'\n            \"  &lt;header/&gt;\"\n            \"  &lt;body&gt;\"\n            \"     &lt;p&gt;\"\n            \"       Materialbaa\u014bk \u010du\u00e4\u0301jtumu\u0161\"\n            \"     &lt;/p&gt;\"\n            \"  &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n    )\n    document_fixer.fix_body_encoding(\"sms\")\n    got = document_fixer.get_etree()\n    want = etree.fromstring(\n        '&lt;document xml:lang=\"sms\"&gt;'\n        \"  &lt;header/&gt;\"\n        \"  &lt;body&gt;\"\n        \"     &lt;p&gt;\"\n        \"       Materialbaa\u014bk \u010du\u00e4\u02b9jtumu\u0161\"\n        \"     &lt;/p&gt;\"\n        \"  &lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_documentfixer/#corpustools.test.test_documentfixer.test_detect_quote","title":"<code>test_detect_quote()</code>","text":"<p>Test the detect_quote function.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_documentfixer.py</code> <pre><code>def test_detect_quote():\n\"\"\"Test the detect_quote function.\"\"\"\n    quote_tests = [\n        TestItem(\n            name=\"quote within QUOTATION MARK\",\n            orig='&lt;p&gt;bla \"bla\" bla \"bla\" bla &lt;/p&gt;',\n            expected=(\n                '&lt;p&gt;bla &lt;span type=\"quote\"&gt;\"bla\"&lt;/span&gt; bla'\n                '&lt;span type=\"quote\"&gt;\"bla\"&lt;/span&gt; bla&lt;/p&gt;'\n            ),\n        ),\n        TestItem(\n            name=\"quote within RIGHT DOUBLE QUOTATION MARK\",\n            orig=\"&lt;p&gt;bla bla \u201dbla bla\u201d bla bla &lt;/p&gt;\",\n            expected=('&lt;p&gt;bla bla &lt;span type=\"quote\"&gt;\u201dbla bla\u201d&lt;/span&gt; ' \"bla bla&lt;/p&gt;\"),\n        ),\n        TestItem(\n            name=(\n                \"quote within LEFT DOUBLE QUOTATION MARK and \"\n                \"RIGHT DOUBLE QUOTATION MARK\"\n            ),\n            orig=\"&lt;p&gt;bla bla \u201cbla bla\u201d bla bla&lt;/p&gt;\",\n            expected=('&lt;p&gt;bla bla &lt;span type=\"quote\"&gt;\u201cbla bla\u201d&lt;/span&gt; bla bla&lt;/p&gt;'),\n        ),\n        TestItem(\n            name=(\n                \"quote within RIGHT DOUBLE QUOTATION MARK and \"\n                \"quote within LEFT DOUBLE QUOTATION MARK and \"\n                \"RIGHT DOUBLE QUOTATION MARK\"\n            ),\n            orig=\"&lt;p&gt;bla \u201cbla\u201d bla \u201dbla\u201d bla&lt;/p&gt;\",\n            expected=(\n                '&lt;p&gt;bla &lt;span type=\"quote\"&gt;\u201cbla\u201d&lt;/span&gt; bla '\n                '&lt;span type=\"quote\"&gt;\u201dbla\u201d&lt;/span&gt; bla&lt;/p&gt;'\n            ),\n        ),\n        TestItem(\n            name=\"simple_detect_quote3\",\n            orig=\"&lt;p&gt;bla bla \u00abbla bla\u00bb bla bla&lt;/p&gt;\",\n            expected=('&lt;p&gt;bla bla &lt;span type=\"quote\"&gt;\u00abbla bla\u00bb&lt;/span&gt; ' \"bla bla&lt;/p&gt;\"),\n        ),\n        TestItem(\n            name=\"simple_detect_quote4\",\n            orig='&lt;p type=\"title\"&gt;S\u00e1megiel \u010d\u00e1lamearkkat Windows XP v\u00e1r\u00e1s.&lt;/p&gt;',\n            expected=('&lt;p type=\"title\"&gt;S\u00e1megiel \u010d\u00e1lamearkkat Windows XP v\u00e1r\u00e1s.&lt;/p&gt;'),\n        ),\n        TestItem(\n            name=\"simple_detect_quote2_quotes\",\n            orig=\"&lt;p&gt;bla bla \u00abbla bla\u00bb bla bla \u00abbla bla\u00bb bla bla&lt;/p&gt;\",\n            expected=(\n                '&lt;p&gt;bla bla &lt;span type=\"quote\"&gt;\u00abbla bla\u00bb&lt;/span&gt; bla bla '\n                '&lt;span type=\"quote\"&gt;\u00abbla bla\u00bb&lt;/span&gt; bla bla&lt;/p&gt;'\n            ),\n        ),\n        TestItem(\n            name=\"detect_quote_with_following_tag\",\n            orig=\"&lt;p&gt;bla bla \u00abbla bla\u00bb &lt;em&gt;bla bla&lt;/em&gt;&lt;/p&gt;\",\n            expected=(\n                '&lt;p&gt;bla bla &lt;span type=\"quote\"&gt;\u00abbla bla\u00bb&lt;/span&gt; &lt;em&gt;' \"bla bla&lt;/em&gt;&lt;/p&gt;\"\n            ),\n        ),\n        TestItem(\n            name=\"detect_quote_with_tag_infront\",\n            orig=\"&lt;p&gt;bla bla &lt;em&gt;bla bla&lt;/em&gt; \u00abbla bla\u00bb&lt;/p&gt;\",\n            expected=(\n                '&lt;p&gt;bla bla &lt;em&gt;bla bla&lt;/em&gt; &lt;span type=\"quote\"&gt;' \"\u00abbla bla\u00bb&lt;/span&gt;&lt;/p&gt;\"\n            ),\n        ),\n        TestItem(\n            name=\"detect_quote_within_tag\",\n            orig=\"&lt;p&gt;bla bla &lt;em&gt;bla bla \u00abbla bla\u00bb&lt;/em&gt;&lt;/p&gt;\",\n            expected=(\n                '&lt;p&gt;bla bla &lt;em&gt;bla bla &lt;span type=\"quote\"&gt;' \"\u00abbla bla\u00bb&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;\"\n            ),\n        ),\n    ]\n\n    for i in \".,?!:\":\n        quote_tests.append(\n            TestItem(\n                name=f\"quote followed by {i}\",\n                orig=(f\"&lt;p&gt;\u201cbla\u201d{i} bla \u201dbla\u201d&lt;/p&gt;\"),\n                expected=(\n                    '&lt;p&gt;&lt;span type=\"quote\"&gt;\u201cbla\u201d&lt;/span&gt;{} bla '\n                    '&lt;span type=\"quote\"&gt;\u201dbla\u201d&lt;/span&gt;&lt;/p&gt;'.format(i)\n                ),\n            )\n        )\n\n    for name, orig, expected in quote_tests:\n        yield check_quote_detection, name, orig, expected\n</code></pre>"},{"location":"reference/test/test_docxconverter/","title":"test_docxconverter","text":"<p>Test conversion of docx files.</p>"},{"location":"reference/test/test_docxconverter/#corpustools.test.test_docxconverter.TestDocxConverter","title":"<code>TestDocxConverter</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test docx conversion.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_docxconverter.py</code> <pre><code>class TestDocxConverter(XMLTester):\n\"\"\"Test docx conversion.\"\"\"\n\n    def test_convert2intermediate(self):\n\"\"\"Test conversion of a docx file.\"\"\"\n        got = htmlcontentconverter.convert2intermediate(\n            os.path.join(HERE, \"converter_data/fakecorpus/orig/sme/riddu/doc-test.docx\")\n        )\n        want = (\n            \"&lt;document&gt;\"\n            \"    &lt;header&gt;\"\n            \"        &lt;title/&gt;\"\n            \"    &lt;/header&gt;\"\n            \"    &lt;body&gt;\"\n            \"        &lt;p&gt;\u2013Mun lean njeallje jagi boaris.&lt;/p&gt;\"\n            \"        &lt;p&gt;Nu beaivv\u00e1dat.&lt;/p&gt;\"\n            \"        &lt;p&gt;oahppat guovttejuvlla nalde sykkelastit.&lt;/p&gt;\"\n            \"        &lt;p&gt;njeallje suorpma boaris.&lt;/p&gt;\"\n            \"        &lt;p&gt;Olggobealde \u00c1\u0161\u0161u&lt;/p&gt;\"\n            \"        &lt;p&gt;Lea go dus meahccebiila ?&lt;/p&gt;\"\n            \"        &lt;p&gt;\u2013Mii lea suohttaseamos geassebargu dus ?&lt;/p&gt;\"\n            \"        &lt;p&gt;Suohkana beara\u0161\u00e1sodagaid juohkin&lt;/p&gt;\"\n            \"        &lt;p&gt;S\u00e1mi kulturfestiv\u00e1la 1998&lt;/p&gt;\"\n            \"    &lt;/body&gt;\"\n            \"&lt;/document&gt;\"\n        )\n\n        self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_docxconverter/#corpustools.test.test_docxconverter.TestDocxConverter.test_convert2intermediate","title":"<code>test_convert2intermediate()</code>","text":"<p>Test conversion of a docx file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_docxconverter.py</code> <pre><code>def test_convert2intermediate(self):\n\"\"\"Test conversion of a docx file.\"\"\"\n    got = htmlcontentconverter.convert2intermediate(\n        os.path.join(HERE, \"converter_data/fakecorpus/orig/sme/riddu/doc-test.docx\")\n    )\n    want = (\n        \"&lt;document&gt;\"\n        \"    &lt;header&gt;\"\n        \"        &lt;title/&gt;\"\n        \"    &lt;/header&gt;\"\n        \"    &lt;body&gt;\"\n        \"        &lt;p&gt;\u2013Mun lean njeallje jagi boaris.&lt;/p&gt;\"\n        \"        &lt;p&gt;Nu beaivv\u00e1dat.&lt;/p&gt;\"\n        \"        &lt;p&gt;oahppat guovttejuvlla nalde sykkelastit.&lt;/p&gt;\"\n        \"        &lt;p&gt;njeallje suorpma boaris.&lt;/p&gt;\"\n        \"        &lt;p&gt;Olggobealde \u00c1\u0161\u0161u&lt;/p&gt;\"\n        \"        &lt;p&gt;Lea go dus meahccebiila ?&lt;/p&gt;\"\n        \"        &lt;p&gt;\u2013Mii lea suohttaseamos geassebargu dus ?&lt;/p&gt;\"\n        \"        &lt;p&gt;Suohkana beara\u0161\u00e1sodagaid juohkin&lt;/p&gt;\"\n        \"        &lt;p&gt;S\u00e1mi kulturfestiv\u00e1la 1998&lt;/p&gt;\"\n        \"    &lt;/body&gt;\"\n        \"&lt;/document&gt;\"\n    )\n\n    self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_epubchooser/","title":"test_epubchooser","text":"<p>Test the functionality in epubchooser.</p>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler","title":"<code>TestRangeHandler</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test the MetadataHandler class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>class TestRangeHandler(unittest.TestCase):\n\"\"\"Test the MetadataHandler class.\"\"\"\n\n    def setUp(self):\n        self.rangehandler = epubchooser.RangeHandler()\n        self.rangehandler.xpaths = [\n            \".//body/div\",\n            \".//body/div/div\",\n            \".//body/div/div/p\",\n            \".//body/div/div/p[2]\",\n            \".//body/div/div[2]\",\n            \".//body/div[2]\",\n            \".//body/div[2]/div\",\n            \".//body/div[2]/div/p\",\n            \".//body/div[2]/div/p[2]\",\n        ]\n\n    def test1(self):\n\"\"\"Check that an exception is raised when first xpath is empty.\"\"\"\n        with self.assertRaises(KeyError):\n            self.rangehandler.check_range((\"\", \"\"))\n\n    def test2(self):\n\"\"\"Check that an exception is raised when first xpath is invalid.\"\"\"\n        with self.assertRaises(KeyError):\n            self.rangehandler.check_range((\".//body/div/div[3]\", \"\"))\n\n    def test3(self):\n\"\"\"Check that an exception is raised when second xpath is invalid.\"\"\"\n        with self.assertRaises(KeyError):\n            self.rangehandler.check_range((\".//body/div/div\", \".//body/div/div[3]\"))\n\n    def test4(self):\n\"\"\"Valid first part, empty second part is a valid pair.\"\"\"\n        self.assertEqual(\n            self.rangehandler.check_range((self.rangehandler.xpaths[0], \"\")), None\n        )\n\n    def test5(self):\n\"\"\"Valid first part, valid second part is a valid pair.\"\"\"\n        self.assertEqual(\n            self.rangehandler.check_range(\n                (self.rangehandler.xpaths[0], self.rangehandler.xpaths[1])\n            ),\n            None,\n        )\n\n    def test6(self):\n\"\"\"First part of new range is within existing ranges.\"\"\"\n        self.rangehandler._ranges.add(\n            (\n                self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n                self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n            )\n        )\n\n        new_range = ((\".//body/div/div/p[2]\"), (\".//body/div[2]/div\"))\n        with self.assertRaises(IndexError):\n            self.rangehandler.check_overlap(new_range)\n\n    def test7(self):\n\"\"\"Second part of new range is within existing ranges.\"\"\"\n        self.rangehandler._ranges.add(\n            (\n                self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n                self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n            )\n        )\n\n        new_range = ((\".//body/div[2]/div\"), (\".//body/div/div/p[2]\"))\n        with self.assertRaises(IndexError):\n            self.rangehandler.check_overlap(new_range)\n\n    def test8(self):\n\"\"\"First part of new range is equal to first part of existing range.\"\"\"\n        self.rangehandler._ranges.add(\n            (\n                self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n                self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n            )\n        )\n\n        new_range = ((\".//body/div/div/p\"), (\"\"))\n        with self.assertRaises(IndexError):\n            self.rangehandler.check_overlap(new_range)\n\n    def test9(self):\n\"\"\"Check for valid range.\n\n        Second part of new range is equal to first part of existing range.\n        \"\"\"\n        self.rangehandler._ranges.add(\n            (\n                self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n                self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n            )\n        )\n        new_range = ((\".//body/div\"), (\".//body/div/div/p\"))\n        with self.assertRaises(IndexError):\n            self.rangehandler.check_overlap(new_range)\n\n    def test10(self):\n\"\"\"Check that a range is reversed if needed.\"\"\"\n        self.rangehandler.add_range(\n            (self.rangehandler.xpaths[1], self.rangehandler.xpaths[0])\n        )\n        want = set()\n        want.add(\n            (\n                self.rangehandler.xpaths.index(self.rangehandler.xpaths[0]),\n                self.rangehandler.xpaths.index(self.rangehandler.xpaths[1]),\n            )\n        )\n        self.assertEqual(self.rangehandler._ranges, want)\n\n    def test11(self):\n\"\"\"Check that ranges are returned reversed and as text.\"\"\"\n        self.rangehandler.add_range(\n            (self.rangehandler.xpaths[4], self.rangehandler.xpaths[6])\n        )\n        want = \"{};{},{};{}\".format(\n            self.rangehandler.xpaths[4],\n            self.rangehandler.xpaths[6],\n            self.rangehandler.xpaths[0],\n            self.rangehandler.xpaths[1],\n        )\n        self.assertEqual(self.rangehandler.ranges, want)\n\n    def test12(self):\n\"\"\"Check that empty second part of range works as exptected.\"\"\"\n        self.rangehandler.add_range((self.rangehandler.xpaths[7], \"\"))\n        want = \"{};,{};{},{};{}\".format(\n            self.rangehandler.xpaths[7],\n            self.rangehandler.xpaths[4],\n            self.rangehandler.xpaths[6],\n            self.rangehandler.xpaths[0],\n            self.rangehandler.xpaths[1],\n        )\n        self.assertEqual(self.rangehandler.ranges, want)\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test1","title":"<code>test1()</code>","text":"<p>Check that an exception is raised when first xpath is empty.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test1(self):\n\"\"\"Check that an exception is raised when first xpath is empty.\"\"\"\n    with self.assertRaises(KeyError):\n        self.rangehandler.check_range((\"\", \"\"))\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test10","title":"<code>test10()</code>","text":"<p>Check that a range is reversed if needed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test10(self):\n\"\"\"Check that a range is reversed if needed.\"\"\"\n    self.rangehandler.add_range(\n        (self.rangehandler.xpaths[1], self.rangehandler.xpaths[0])\n    )\n    want = set()\n    want.add(\n        (\n            self.rangehandler.xpaths.index(self.rangehandler.xpaths[0]),\n            self.rangehandler.xpaths.index(self.rangehandler.xpaths[1]),\n        )\n    )\n    self.assertEqual(self.rangehandler._ranges, want)\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test11","title":"<code>test11()</code>","text":"<p>Check that ranges are returned reversed and as text.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test11(self):\n\"\"\"Check that ranges are returned reversed and as text.\"\"\"\n    self.rangehandler.add_range(\n        (self.rangehandler.xpaths[4], self.rangehandler.xpaths[6])\n    )\n    want = \"{};{},{};{}\".format(\n        self.rangehandler.xpaths[4],\n        self.rangehandler.xpaths[6],\n        self.rangehandler.xpaths[0],\n        self.rangehandler.xpaths[1],\n    )\n    self.assertEqual(self.rangehandler.ranges, want)\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test12","title":"<code>test12()</code>","text":"<p>Check that empty second part of range works as exptected.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test12(self):\n\"\"\"Check that empty second part of range works as exptected.\"\"\"\n    self.rangehandler.add_range((self.rangehandler.xpaths[7], \"\"))\n    want = \"{};,{};{},{};{}\".format(\n        self.rangehandler.xpaths[7],\n        self.rangehandler.xpaths[4],\n        self.rangehandler.xpaths[6],\n        self.rangehandler.xpaths[0],\n        self.rangehandler.xpaths[1],\n    )\n    self.assertEqual(self.rangehandler.ranges, want)\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test2","title":"<code>test2()</code>","text":"<p>Check that an exception is raised when first xpath is invalid.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test2(self):\n\"\"\"Check that an exception is raised when first xpath is invalid.\"\"\"\n    with self.assertRaises(KeyError):\n        self.rangehandler.check_range((\".//body/div/div[3]\", \"\"))\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test3","title":"<code>test3()</code>","text":"<p>Check that an exception is raised when second xpath is invalid.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test3(self):\n\"\"\"Check that an exception is raised when second xpath is invalid.\"\"\"\n    with self.assertRaises(KeyError):\n        self.rangehandler.check_range((\".//body/div/div\", \".//body/div/div[3]\"))\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test4","title":"<code>test4()</code>","text":"<p>Valid first part, empty second part is a valid pair.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test4(self):\n\"\"\"Valid first part, empty second part is a valid pair.\"\"\"\n    self.assertEqual(\n        self.rangehandler.check_range((self.rangehandler.xpaths[0], \"\")), None\n    )\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test5","title":"<code>test5()</code>","text":"<p>Valid first part, valid second part is a valid pair.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test5(self):\n\"\"\"Valid first part, valid second part is a valid pair.\"\"\"\n    self.assertEqual(\n        self.rangehandler.check_range(\n            (self.rangehandler.xpaths[0], self.rangehandler.xpaths[1])\n        ),\n        None,\n    )\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test6","title":"<code>test6()</code>","text":"<p>First part of new range is within existing ranges.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test6(self):\n\"\"\"First part of new range is within existing ranges.\"\"\"\n    self.rangehandler._ranges.add(\n        (\n            self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n            self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n        )\n    )\n\n    new_range = ((\".//body/div/div/p[2]\"), (\".//body/div[2]/div\"))\n    with self.assertRaises(IndexError):\n        self.rangehandler.check_overlap(new_range)\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test7","title":"<code>test7()</code>","text":"<p>Second part of new range is within existing ranges.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test7(self):\n\"\"\"Second part of new range is within existing ranges.\"\"\"\n    self.rangehandler._ranges.add(\n        (\n            self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n            self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n        )\n    )\n\n    new_range = ((\".//body/div[2]/div\"), (\".//body/div/div/p[2]\"))\n    with self.assertRaises(IndexError):\n        self.rangehandler.check_overlap(new_range)\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test8","title":"<code>test8()</code>","text":"<p>First part of new range is equal to first part of existing range.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test8(self):\n\"\"\"First part of new range is equal to first part of existing range.\"\"\"\n    self.rangehandler._ranges.add(\n        (\n            self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n            self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n        )\n    )\n\n    new_range = ((\".//body/div/div/p\"), (\"\"))\n    with self.assertRaises(IndexError):\n        self.rangehandler.check_overlap(new_range)\n</code></pre>"},{"location":"reference/test/test_epubchooser/#corpustools.test.test_epubchooser.TestRangeHandler.test9","title":"<code>test9()</code>","text":"<p>Check for valid range.</p> <p>Second part of new range is equal to first part of existing range.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubchooser.py</code> <pre><code>def test9(self):\n\"\"\"Check for valid range.\n\n    Second part of new range is equal to first part of existing range.\n    \"\"\"\n    self.rangehandler._ranges.add(\n        (\n            self.rangehandler.xpaths.index(\".//body/div/div/p\"),\n            self.rangehandler.xpaths.index(\".//body/div[2]/div\"),\n        )\n    )\n    new_range = ((\".//body/div\"), (\".//body/div/div/p\"))\n    with self.assertRaises(IndexError):\n        self.rangehandler.check_overlap(new_range)\n</code></pre>"},{"location":"reference/test/test_epubconverter/","title":"test_epubconverter","text":"<p>Test conversion of epub files.</p>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter","title":"<code>TestEpubConverter</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test the epub converter.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>class TestEpubConverter(XMLTester):\n\"\"\"Test the epub converter.\"\"\"\n\n    def setUp(self):\n\"\"\"Setup epub content.\"\"\"\n        self.testdoc = os.path.join(\n            HERE, \"converter_data/fakecorpus/orig/sme/riddu/test.epub\"\n        )\n\n    def test_convert2intermediate_1(self):\n\"\"\"Test without skip_elements.\"\"\"\n        got = htmlcontentconverter.convert2intermediate(self.testdoc)\n        want = \"\"\"\n            &lt;document&gt;\n                &lt;body&gt;\n                    &lt;p type=\"title\"&gt;1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;1asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;2asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;1.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;3asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;2 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;4asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;2.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;5asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;2.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;6asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;3.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;7asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;3.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;8asdf&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n        \"\"\"\n\n        self.assertXmlEqual(got, etree.fromstring(want))\n\n    def test_convert2intermediate_2(self):\n\"\"\"Test with skip_elements.\"\"\"\n        with TempDirectory() as directory:\n            temp_epub = set_data(\n                directory,\n                self.testdoc,\n                \".//html:body/html:div[1]/html:h2[1];\"\n                \".//html:body/html:div[3]/html:div[1]/html:h3[1]\",\n            )\n            got = htmlcontentconverter.convert2intermediate(temp_epub)\n            want = \"\"\"\n                &lt;document&gt;\n                    &lt;body&gt;\n                        &lt;p type=\"title\"&gt;1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;1asdf&lt;/p&gt;\n                        &lt;p type=\"title\"&gt;3.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;8asdf&lt;/p&gt;\n                    &lt;/body&gt;\n                &lt;/document&gt;\n            \"\"\"\n\n            self.assertXmlEqual(got, etree.fromstring(want))\n\n    def test_convert2intermediate_3(self):\n\"\"\"Test with skip_elements that only has first path defined.\"\"\"\n        with TempDirectory() as directory:\n            temp_epub = set_data(\n                directory, self.testdoc, \".//html:body/html:div[1]/html:h2[1];\"\n            )\n            got = htmlcontentconverter.convert2intermediate(temp_epub)\n            want = \"\"\"\n                &lt;document&gt;\n                    &lt;body&gt;\n                        &lt;p type=\"title\"&gt;1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;1asdf&lt;/p&gt;\n                        &lt;p&gt;2asdf&lt;/p&gt;\n                        &lt;p type=\"title\"&gt;1.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;3asdf&lt;/p&gt;\n                        &lt;p type=\"title\"&gt;2 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;4asdf&lt;/p&gt;\n                        &lt;p type=\"title\"&gt;2.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;5asdf&lt;/p&gt;\n                        &lt;p type=\"title\"&gt;2.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;6asdf&lt;/p&gt;\n                        &lt;p type=\"title\"&gt;3.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;7asdf&lt;/p&gt;\n                        &lt;p type=\"title\"&gt;3.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                        &lt;p&gt;8asdf&lt;/p&gt;\n                    &lt;/body&gt;\n                &lt;/document&gt;\n            \"\"\"\n\n            self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter.setUp","title":"<code>setUp()</code>","text":"<p>Setup epub content.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def setUp(self):\n\"\"\"Setup epub content.\"\"\"\n    self.testdoc = os.path.join(\n        HERE, \"converter_data/fakecorpus/orig/sme/riddu/test.epub\"\n    )\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter.test_convert2intermediate_1","title":"<code>test_convert2intermediate_1()</code>","text":"<p>Test without skip_elements.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def test_convert2intermediate_1(self):\n\"\"\"Test without skip_elements.\"\"\"\n    got = htmlcontentconverter.convert2intermediate(self.testdoc)\n    want = \"\"\"\n        &lt;document&gt;\n            &lt;body&gt;\n                &lt;p type=\"title\"&gt;1 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;1asdf&lt;/p&gt;\n                &lt;p type=\"title\"&gt;1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;2asdf&lt;/p&gt;\n                &lt;p type=\"title\"&gt;1.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;3asdf&lt;/p&gt;\n                &lt;p type=\"title\"&gt;2 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;4asdf&lt;/p&gt;\n                &lt;p type=\"title\"&gt;2.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;5asdf&lt;/p&gt;\n                &lt;p type=\"title\"&gt;2.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;6asdf&lt;/p&gt;\n                &lt;p type=\"title\"&gt;3.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;7asdf&lt;/p&gt;\n                &lt;p type=\"title\"&gt;3.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                &lt;p&gt;8asdf&lt;/p&gt;\n            &lt;/body&gt;\n        &lt;/document&gt;\n    \"\"\"\n\n    self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter.test_convert2intermediate_2","title":"<code>test_convert2intermediate_2()</code>","text":"<p>Test with skip_elements.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def test_convert2intermediate_2(self):\n\"\"\"Test with skip_elements.\"\"\"\n    with TempDirectory() as directory:\n        temp_epub = set_data(\n            directory,\n            self.testdoc,\n            \".//html:body/html:div[1]/html:h2[1];\"\n            \".//html:body/html:div[3]/html:div[1]/html:h3[1]\",\n        )\n        got = htmlcontentconverter.convert2intermediate(temp_epub)\n        want = \"\"\"\n            &lt;document&gt;\n                &lt;body&gt;\n                    &lt;p type=\"title\"&gt;1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;1asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;3.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;8asdf&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n        \"\"\"\n\n        self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter.test_convert2intermediate_3","title":"<code>test_convert2intermediate_3()</code>","text":"<p>Test with skip_elements that only has first path defined.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def test_convert2intermediate_3(self):\n\"\"\"Test with skip_elements that only has first path defined.\"\"\"\n    with TempDirectory() as directory:\n        temp_epub = set_data(\n            directory, self.testdoc, \".//html:body/html:div[1]/html:h2[1];\"\n        )\n        got = htmlcontentconverter.convert2intermediate(temp_epub)\n        want = \"\"\"\n            &lt;document&gt;\n                &lt;body&gt;\n                    &lt;p type=\"title\"&gt;1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;1asdf&lt;/p&gt;\n                    &lt;p&gt;2asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;1.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;3asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;2 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;4asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;2.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;5asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;2.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;6asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;3.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;7asdf&lt;/p&gt;\n                    &lt;p type=\"title\"&gt;3.1.1 Bajil\u010d\u00e1la&lt;/p&gt;\n                    &lt;p&gt;8asdf&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n        \"\"\"\n\n        self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter1","title":"<code>TestEpubConverter1</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test the epub converter.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>class TestEpubConverter1(XMLTester):\n\"\"\"Test the epub converter.\"\"\"\n\n    def setUp(self):\n\"\"\"Setup epub content.\"\"\"\n        self.testdoc = os.path.join(\n            HERE, \"converter_data/fakecorpus/orig/sme/riddu/test2.epub\"\n        )\n\n    def test_convert2intermediate(self):\n\"\"\"Range of same depth with the same name in the next to last level.\"\"\"\n        with TempDirectory() as directory:\n            temp_epub = set_data(\n                directory,\n                self.testdoc,\n                \".//body/div[1]/div[1]/p[1];.//body/div[2]/div[1]/p[4]\",\n            )\n            got = htmlcontentconverter.convert2intermediate(temp_epub)\n            want = \"\"\"\n                &lt;document&gt;\n                    &lt;body&gt;\n                        &lt;p&gt;igjen g\u00e5r hesten&lt;/p&gt;\n                        &lt;p&gt;baklengs inni framtida&lt;/p&gt;\n                    &lt;/body&gt;\n                &lt;/document&gt;\n            \"\"\"\n\n            self.assertXmlEqual(got, etree.fromstring(want))\n\n    def test_convert2intermediate1(self):\n\"\"\"Range with same parents.\"\"\"\n        with TempDirectory() as directory:\n            temp_epub = set_data(\n                directory,\n                self.testdoc,\n                \".//body/div[2]/div[1]/p[1];.//body/div[2]/div[1]/p[4]\",\n            )\n            got = htmlcontentconverter.convert2intermediate(temp_epub)\n            want = \"\"\"\n                &lt;document&gt;\n                    &lt;body&gt;\n                        &lt;p&gt;alle gir gass&lt;/p&gt;\n                        &lt;p&gt;men ikke&lt;/p&gt;\n                        &lt;p&gt;alle&lt;/p&gt;\n                        &lt;p&gt;har tass&lt;/p&gt;\n                        &lt;p&gt;igjen g\u00e5r hesten&lt;/p&gt;\n                        &lt;p&gt;baklengs inni framtida&lt;/p&gt;\n                    &lt;/body&gt;\n                &lt;/document&gt;\n            \"\"\"\n\n            self.assertXmlEqual(got, etree.fromstring(want))\n\n    def test_convert2intermediate_invalid_skipelements(self):\n\"\"\"Range of same depth with the same name in the next to last level.\"\"\"\n        with TempDirectory() as directory:\n            temp_epub = set_data(\n                directory,\n                self.testdoc,\n                \".//body/div[1]/div[1]/p[1];.//body/div[2]/div[15]/p[4]\",\n            )\n\n            self.assertRaises(\n                util.ConversionError,\n                htmlcontentconverter.convert2intermediate,\n                temp_epub,\n            )\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter1.setUp","title":"<code>setUp()</code>","text":"<p>Setup epub content.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def setUp(self):\n\"\"\"Setup epub content.\"\"\"\n    self.testdoc = os.path.join(\n        HERE, \"converter_data/fakecorpus/orig/sme/riddu/test2.epub\"\n    )\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter1.test_convert2intermediate","title":"<code>test_convert2intermediate()</code>","text":"<p>Range of same depth with the same name in the next to last level.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def test_convert2intermediate(self):\n\"\"\"Range of same depth with the same name in the next to last level.\"\"\"\n    with TempDirectory() as directory:\n        temp_epub = set_data(\n            directory,\n            self.testdoc,\n            \".//body/div[1]/div[1]/p[1];.//body/div[2]/div[1]/p[4]\",\n        )\n        got = htmlcontentconverter.convert2intermediate(temp_epub)\n        want = \"\"\"\n            &lt;document&gt;\n                &lt;body&gt;\n                    &lt;p&gt;igjen g\u00e5r hesten&lt;/p&gt;\n                    &lt;p&gt;baklengs inni framtida&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n        \"\"\"\n\n        self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter1.test_convert2intermediate1","title":"<code>test_convert2intermediate1()</code>","text":"<p>Range with same parents.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def test_convert2intermediate1(self):\n\"\"\"Range with same parents.\"\"\"\n    with TempDirectory() as directory:\n        temp_epub = set_data(\n            directory,\n            self.testdoc,\n            \".//body/div[2]/div[1]/p[1];.//body/div[2]/div[1]/p[4]\",\n        )\n        got = htmlcontentconverter.convert2intermediate(temp_epub)\n        want = \"\"\"\n            &lt;document&gt;\n                &lt;body&gt;\n                    &lt;p&gt;alle gir gass&lt;/p&gt;\n                    &lt;p&gt;men ikke&lt;/p&gt;\n                    &lt;p&gt;alle&lt;/p&gt;\n                    &lt;p&gt;har tass&lt;/p&gt;\n                    &lt;p&gt;igjen g\u00e5r hesten&lt;/p&gt;\n                    &lt;p&gt;baklengs inni framtida&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n        \"\"\"\n\n        self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.TestEpubConverter1.test_convert2intermediate_invalid_skipelements","title":"<code>test_convert2intermediate_invalid_skipelements()</code>","text":"<p>Range of same depth with the same name in the next to last level.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def test_convert2intermediate_invalid_skipelements(self):\n\"\"\"Range of same depth with the same name in the next to last level.\"\"\"\n    with TempDirectory() as directory:\n        temp_epub = set_data(\n            directory,\n            self.testdoc,\n            \".//body/div[1]/div[1]/p[1];.//body/div[2]/div[15]/p[4]\",\n        )\n\n        self.assertRaises(\n            util.ConversionError,\n            htmlcontentconverter.convert2intermediate,\n            temp_epub,\n        )\n</code></pre>"},{"location":"reference/test/test_epubconverter/#corpustools.test.test_epubconverter.set_data","title":"<code>set_data(directory, testdoc, skip_elements)</code>","text":"<p>Set needed testdata.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>testfixtures.TempDirectory</code> <p>path to the directory</p> required <code>testdoc</code> <code>str</code> <p>path to the test document</p> required <code>skip_elements</code> <code>str</code> <p>the range of elements to skip</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>path to the test document in the temporary test directory</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_epubconverter.py</code> <pre><code>def set_data(directory, testdoc, skip_elements):\n\"\"\"Set needed testdata.\n\n    Args:\n        directory (testfixtures.TempDirectory): path to the directory\n        testdoc (str): path to the test document\n        skip_elements (str): the range of elements to skip\n\n    Returns:\n        str: path to the test document in the temporary test directory\n    \"\"\"\n    temp_epub = os.path.join(directory.path, os.path.basename(testdoc))\n    copyfile(testdoc, temp_epub)\n    metadata = xslsetter.MetadataHandler(temp_epub + \".xsl\", create=True)\n    metadata.set_variable(\"skip_elements\", skip_elements)\n    metadata.write_file()\n\n    return temp_epub\n</code></pre>"},{"location":"reference/test/test_errormarkup/","title":"test_errormarkup","text":""},{"location":"reference/test/test_errormarkup/#corpustools.test.test_errormarkup.TestErrorMarkup","title":"<code>TestErrorMarkup</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test errormarkup functions.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_errormarkup.py</code> <pre><code>class TestErrorMarkup(unittest.TestCase):\n\"\"\"Test errormarkup functions.\"\"\"\n\n    @staticmethod\n    def assert_xml_equal(got, want):\n\"\"\"Check if two stringified xml snippets are equal\"\"\"\n        got = etree.tostring(got, encoding=\"unicode\")\n        want = etree.tostring(want, encoding=\"unicode\")\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(want, got, 0):\n            message = checker.output_difference(doctest.Example(\"\", want), got, 0)\n            raise AssertionError(message)\n\n    @parameterized.expand(\n        [\n            (\"{a}${b}\", (3, 7)),\n            (\"{a}${b} {a}${c} \", (11, 15)),\n            (\"{a}${b} {{a}${b}}${d} \", (17, 21)),\n        ]\n    )\n    def test_regex(self, markup, span):\n\"\"\"Testing the most important regex.\"\"\"\n        # match = errormarkup.LAST_CORRECTION_REGEX.search(markup)\n        # self.assertEqual(match.span(), span)\n        match = errormarkup.LAST_CORRECTION_REGEX.search(markup)\n        self.assertEqual(match.span(), span)\n\n    @parameterized.expand(\n        [\n            (\n                \"errorlang_infinity\",\n                \"&lt;p&gt;{molekyl\u00e6rbiologimi}\u221e{kal,bio}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errorlang&gt;molekyl\u00e6rbiologimi&lt;correct&gt;kal,bio&lt;/correct&gt;&lt;/errorlang&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_parser_errorlang_infinity_with_new_lines\",\n                \"&lt;p&gt;\\n\\n\\n\\n{molekyl\u00e6rbiologimi}\u221e{kal,bio}\\n\\n\\n\\n&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errorlang&gt;molekyl\u00e6rbiologimi&lt;correct&gt;kal,bio&lt;/correct&gt;&lt;/errorlang&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"quote_char\",\n                \"&lt;p&gt;{\u201dsjievnnijis\u201d}${conc,vnn-vnnj|sjievnnjis}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorort&gt;\u201dsjievnnijis\u201d&lt;correct errorinfo=\"conc,vnn-vnnj\"&gt;sjievnnjis&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n            ),\n            (\n                \"error_parser_errorort1\",\n                \"&lt;p&gt;{jne.}${adv,typo|jna.}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorort&gt;jne.&lt;correct errorinfo=\"adv,typo\"&gt;jna.&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n            ),\n            (\n                \"error_parser_error_morphsyn1\",\n                \"&lt;p&gt;{Nieiddat leat nuorra}\u00a3{a,spred,nompl,nomsg,agr|Nieiddat leat nuorat}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errormorphsyn&gt;Nieiddat leat nuorra&lt;correct \"\n                'errorinfo=\"a,spred,nompl,nomsg,agr\"&gt;Nieiddat leat nuorat'\n                \"&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_parser_with_two_simple_errors\",\n                \"&lt;p&gt;gitta {Nordkjosbotn'ii}${Nordkjosbotnii} (mii lea ge \"\n                \"{nordkjosbotn}${Nordkjosbotn} s\u00e1megillii? Muhtin, veahket mu!) \"\n                \"gos&lt;/p&gt;\",\n                \"&lt;p&gt;gitta \"\n                \"&lt;errorort&gt;Nordkjosbotn'ii&lt;correct&gt;Nordkjosbotnii&lt;/correct&gt;&lt;/errorort&gt; \"\n                \"(mii lea ge \"\n                \"&lt;errorort&gt;nordkjosbotn&lt;correct&gt;Nordkjosbotn&lt;/correct&gt;&lt;/errorort&gt; \"\n                \"s\u00e1megillii? Muhtin, veahket mu!) gos&lt;/p&gt;\",\n            ),\n            (\n                \"only_text_in_element\",\n                \"&lt;p&gt;Muitt\u00e1n dolo\u017eiid&lt;/p&gt;\",\n                \"&lt;p&gt;Muitt\u00e1n dolo\u017eiid&lt;/p&gt;\",\n            ),\n            (\n                \"paragraph_character\",\n                \"&lt;p&gt;Vuodol\u00e1hkaj \u00a7110a&lt;/p&gt;\",\n                \"&lt;p&gt;Vuodol\u00e1hkaj \u00a7110a&lt;/p&gt;\",\n            ),\n            (\n                \"errorort1\",\n                \"&lt;p&gt;{jne.}${adv,typo|jna.}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorort&gt;jne.&lt;correct errorinfo=\"adv,typo\"&gt;jna.&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n            ),\n            (\n                \"errorort2\",\n                \"&lt;p&gt;{daesn'}${daesnie}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errorort&gt;daesn'&lt;correct&gt;daesnie&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"input_contains_slash\",\n                \"&lt;p&gt;{magistter/}${loan,vowlat,e-a|magisttar}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorort&gt;magistter/&lt;correct errorinfo=\"loan,vowlat,e-a\"&gt;'\n                \"magisttar&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct1\",\n                \"&lt;p&gt;{1]}\u00a7{Ij}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;1]&lt;correct&gt;Ij&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct2\",\n                \"&lt;p&gt;{v\u00e6]keles}\u00a7{v\u00e6jkeles}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;v\u00e6]keles&lt;correct&gt;v\u00e6jkeles&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct3\",\n                \"&lt;p&gt;{sm\u00e1vi-}\u00a7{sm\u00e1vit-}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;sm\u00e1vi-&lt;correct&gt;sm\u00e1vit-&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct4\",\n                \"&lt;p&gt;{CD:t}\u00a7{CD:at}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;CD:t&lt;correct&gt;CD:at&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct5\",\n                \"&lt;p&gt;{DNB-feask\u00e1ris}\u00a7{DnB-feask\u00e1ris}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;DNB-feask\u00e1ris&lt;correct&gt;DnB-feask\u00e1ris&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct6\",\n                \"&lt;p&gt;{boade}\u00a7{boa\u0111e}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;boade&lt;correct&gt;boa\u0111e&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct7\",\n                \"&lt;p&gt;{2005\u2019as}\u00a7{2005:s}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;2005\u2019as&lt;correct&gt;2005:s&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct8\",\n                \"&lt;p&gt;{NSRii}\u00a7{NSR:i}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;NSRii&lt;correct&gt;NSR:i&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_correct9\",\n                \"&lt;p&gt;{Nordkjosbotn'ii}\u00a7{Nordkjosbotnii}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;error&gt;Nordkjosbotn'ii&lt;correct&gt;Nordkjosbotnii&lt;/correct&gt;\"\n                \"&lt;/error&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"errorort3\",\n                \"&lt;p&gt;{nourra}${a,meta|nuorra}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorort&gt;nourra&lt;correct errorinfo=\"a,meta\"&gt;nuorra&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n            ),\n            (\n                \"error_morphsyn1\",\n                \"&lt;p&gt;{Nieiddat leat nuorra}\u00a3{a,spred,nompl,nomsg,agr|Nieiddat leat nuorat}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errormorphsyn&gt;Nieiddat leat nuorra\"\n                '&lt;correct errorinfo=\"a,spred,nompl,nomsg,agr\"&gt;Nieiddat leat '\n                \"nuorat&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_syn1\",\n                \"&lt;p&gt;{ri\u014bgen nieidda lusa}\u00a5{x,pph|ri\u014bgen niidii}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorsyn&gt;ri\u014bgen nieidda lusa&lt;correct errorinfo=\"x,pph\"&gt;'\n                \"ri\u014bgen niidii&lt;/correct&gt;&lt;/errorsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_syn2\",\n                \"&lt;p&gt;{ovtta}\u00a5{num,redun| }&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorsyn&gt;ovtta&lt;correct errorinfo=\"num,redun\"&gt;&lt;/correct&gt;'\n                \"&lt;/errorsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_lex1\",\n                \"&lt;p&gt;{d\u00e1b\u00e1la\u0161}\u20ac{adv,adj,der|d\u00e1b\u00e1la\u010d\u010dat}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorlex&gt;d\u00e1b\u00e1la\u0161&lt;correct errorinfo=\"adv,adj,der\"&gt;d\u00e1b\u00e1la\u010d\u010dat'\n                \"&lt;/correct&gt;&lt;/errorlex&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_ortreal1\",\n                \"&lt;p&gt;{r\u00e1h\u010d\u010damu\u0161aid}\u00a2{noun,mix|rah\u010damu\u0161aid}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorortreal&gt;r\u00e1h\u010d\u010damu\u0161aid&lt;correct errorinfo=\"noun,mix\"&gt;'\n                \"rah\u010damu\u0161aid&lt;/correct&gt;&lt;/errorortreal&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"error_ortreal2\",\n                \"&lt;p&gt;gitta {Nordkjosbotn'ii}${Nordkjosbotnii} (mii lea ge \"\n                \"{nordkjosbotn}${Nordkjosbotn} s\u00e1megillii? Muhtin, veahket mu!) \"\n                \"gos&lt;/p&gt;\",\n                \"&lt;p&gt;gitta &lt;errorort&gt;Nordkjosbotn'ii&lt;correct&gt;Nordkjosbotnii\"\n                \"&lt;/correct&gt;&lt;/errorort&gt; (mii lea ge &lt;errorort&gt;nordkjosbotn\"\n                \"&lt;correct&gt;Nordkjosbotn&lt;/correct&gt;&lt;/errorort&gt; s\u00e1megillii? \"\n                \"Muhtin, veahket mu!) gos&lt;/p&gt;\",\n            ),\n            (\n                \"error_morphsyn2\",\n                \"&lt;p&gt;\u010c\u00e1ppa muohtaskulptuvrraid r\u00e1hkadeapmi VSM olggobealde lei \"\n                \"maidd\u00e1i ovttasbargu gaskal {skuvla ohppiid}\u00a3\"\n                \"{noun,attr,gensg,nomsg,case|skuvlla ohppiid}\"\n                \"ja VSM.&lt;/p&gt;\",\n                \"&lt;p&gt;\u010c\u00e1ppa muohtaskulptuvrraid r\u00e1hkadeapmi VSM olggobealde lei \"\n                \"maidd\u00e1i ovttasbargu gaskal &lt;errormorphsyn&gt;skuvla ohppiid\"\n                '&lt;correct errorinfo=\"noun,attr,gensg,nomsg,case\"&gt;skuvlla ohppiid'\n                \"&lt;/correct&gt;&lt;/errormorphsyn&gt; ja VSM.&lt;/p&gt;\",\n            ),\n            (\n                \"errorort4\",\n                \"&lt;p&gt;- ruksesruon\u00e1\u010dalmmehisvuohta lea sullii \"\n                \"{8%:as}${acr,suf|8%:s}&lt;/p&gt;\",\n                \"&lt;p&gt;- ruksesruon\u00e1\u010dalmmehisvuohta lea sullii &lt;errorort&gt;8%:as\"\n                '&lt;correct errorinfo=\"acr,suf\"&gt;8%:s&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n            ),\n            (\n                \"error_ortreal3\",\n                \"&lt;p&gt;( {nissonin}\u00a2{noun,suf|nissoniin} du\u0161\u0161e {0.6 %:s}\u00a3{0.6 %} )&lt;/p&gt;\",\n                '&lt;p&gt;( &lt;errorortreal&gt;nissonin&lt;correct errorinfo=\"noun,suf\"&gt;'\n                \"nissoniin&lt;/correct&gt;&lt;/errorortreal&gt; du\u0161\u0161e &lt;errormorphsyn&gt;0.6 %:s\"\n                \"&lt;correct&gt;0.6 %&lt;/correct&gt;&lt;/errormorphsyn&gt; )&lt;/p&gt;\",\n            ),\n            (\n                \"errorort5\",\n                \"&lt;p&gt;(haploida) ja {nji\u014b\u014balas}${noun,\u00e1|nji\u014b\u014b\u00e1las} {s\u00e1gahuvvon}\"\n                \"${verb,a|sagahuvvon} manneseallas (diploida)&lt;/p&gt;\",\n                '&lt;p&gt;(haploida) ja &lt;errorort&gt;nji\u014b\u014balas&lt;correct errorinfo=\"noun,\u00e1\"&gt;'\n                \"nji\u014b\u014b\u00e1las&lt;/correct&gt;&lt;/errorort&gt; &lt;errorort&gt;s\u00e1gahuvvon\"\n                '&lt;correct errorinfo=\"verb,a\"&gt;sagahuvvon&lt;/correct&gt;&lt;/errorort&gt; '\n                \"manneseallas (diploida)&lt;/p&gt;\",\n            ),\n            (\n                \"errorort6\",\n                \"&lt;p&gt;(gii oahpaha) {giinu}${x,notcmp|gii nu} manai {inti\u00e1nal\u00e1vlagat}\"\n                \"${loan,conc|indi\u00e1nal\u00e1vlagat} {guov\u017ea-kl\u00e1na}${noun,cmp|guov\u017eakl\u00e1na} \"\n                \"olbmuid&lt;/p&gt;\",\n                '&lt;p&gt;(gii oahpaha) &lt;errorort&gt;giinu&lt;correct errorinfo=\"x,notcmp\"&gt;'\n                \"gii nu&lt;/correct&gt;&lt;/errorort&gt; manai &lt;errorort&gt;inti\u00e1nal\u00e1vlagat\"\n                '&lt;correct errorinfo=\"loan,conc\"&gt;indi\u00e1nal\u00e1vlagat&lt;/correct&gt;'\n                '&lt;/errorort&gt; &lt;errorort&gt;guov\u017ea-kl\u00e1na&lt;correct errorinfo=\"noun,cmp\"&gt;'\n                \"guov\u017eakl\u00e1na&lt;/correct&gt;&lt;/errorort&gt; olbmuid&lt;/p&gt;\",\n            ),\n            (\n                \"error_format\",\n                \"&lt;p&gt;{{A  B}\u2030{notspace|A B}  C}\u2030{notspace|A B C}&lt;/p&gt;\",\n                \"&lt;p&gt;\"\n                \"&lt;errorformat&gt;\"\n                \"&lt;errorformat&gt;\"\n                'A  B&lt;correct errorinfo=\"notspace\"&gt;A B&lt;/correct&gt;&lt;/errorformat&gt;'\n                '  C&lt;correct errorinfo=\"notspace\"&gt;A B C&lt;/correct&gt;&lt;/errorformat&gt;'\n                \"&lt;/p&gt;\",\n            ),\n            (\n                \"preserve_space_at_end_of_sentence\",\n                \"&lt;p&gt;buvttadeaddji Anstein {Mikkelsens}${typo|Mikkelsen} lea \"\n                \"r\u00e1hkadan. &lt;/p&gt;\",\n                '&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. &lt;/p&gt;',\n            ),\n            (\n                \"place_error_elements_before_old_element1\",\n                \"&lt;p&gt;buvttadeaddji Anstein {Mikkelsens}${typo|Mikkelsen} lea \"\n                \"r\u00e1hkadan. {b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} miessem\u00e1nu. &lt;span \"\n                'type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt;&lt;/p&gt;',\n                \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens\"\n                '&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. '\n                '&lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt;'\n                ' miessem\u00e1nu. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts '\n                \"Competition\u00bb&lt;/span&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"place_error_elements_before_old_element2\",\n                \"&lt;p&gt;{Mikkelsens}${typo|Mikkelsen} lea r\u00e1hkadan. \"\n                \"{b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} miessem\u00e1nu. \"\n                '&lt;span type=\"quote\" xml:lang=\"eng\"&gt;'\n                \"\u00abBest Shorts Competition\u00bb&lt;/span&gt;&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errorort&gt;Mikkelsens&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; miessem\u00e1nu. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt;&lt;/p&gt;',\n            ),\n            (\n                \"place_error_element_after_old_element\",\n                '&lt;p&gt;I 1864 ga han ut boka &lt;span type=\"quote\" xml:lang=\"swe\"&gt;'\n                '\"Fornuftigt Madstel\"&lt;/span&gt;. {Asbj\u00f8rsen}${prop,typo|Asbj\u00f8rnsen} '\n                \"d\u00f8de 5. januar 1885, nesten 73 \u00e5r gammel.&lt;/p&gt;\",\n                '&lt;p&gt;I 1864 ga han ut boka &lt;span type=\"quote\" xml:lang=\"swe\"&gt;'\n                '\"Fornuftigt Madstel\"&lt;/span&gt;. &lt;errorort&gt;Asbj\u00f8rsen'\n                '&lt;correct errorinfo=\"prop,typo\"&gt;Asbj\u00f8rnsen&lt;/correct&gt;&lt;/errorort&gt; '\n                \"d\u00f8de 5. januar 1885, nesten 73 \u00e5r gammel.&lt;/p&gt;\",\n            ),\n            (\n                \"place_error_element_before_and_after_old_element\",\n                \"&lt;p&gt;buvttadeaddji Anstein {Mikkelsens}${typo|Mikkelsen} lea \"\n                'r\u00e1hkadan. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts '\n                \"Competition\u00bb&lt;/span&gt; {b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} \"\n                \"miessem\u00e1nu.&lt;/p&gt;\",\n                \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens\"\n                '&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea '\n                'r\u00e1hkadan. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts '\n                \"Competition\u00bb&lt;/span&gt; &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi\"\n                '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; '\n                \"miessem\u00e1nu.&lt;/p&gt;\",\n            ),\n            (\n                \"markup3Levels\",\n                \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens&lt;correct \"\n                'errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. '\n                '&lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb'\n                '&lt;/span&gt; &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;'\n                \"b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; miessem\u00e1nu. &lt;em&gt;buvttadeaddji \"\n                \"Anstein {Mikkelsens}${typo|Mikkelsen} lea r\u00e1hkadan. &lt;span \"\n                'type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt; '\n                \"{b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} miessem\u00e1nu.&lt;/em&gt;&lt;/p&gt;\",\n                \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens&lt;correct \"\n                'errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. '\n                '&lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb'\n                '&lt;/span&gt; &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;'\n                \"b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; miessem\u00e1nu. &lt;em&gt;buvttadeaddji \"\n                'Anstein &lt;errorort&gt;Mikkelsens&lt;correct errorinfo=\"typo\"&gt;Mikkelsen'\n                '&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. &lt;span type=\"quote\" '\n                'xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt; &lt;errorort&gt;'\n                'b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;'\n                \"&lt;/errorort&gt; miessem\u00e1nu.&lt;/em&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"inline multiple corrections\",\n                \"&lt;p&gt;{leimme}\u00a3{leimmet///leat}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errormorphsyn&gt;leimme\"\n                \"&lt;correct&gt;leimmet&lt;/correct&gt;\"\n                \"&lt;correct&gt;leat&lt;/correct&gt;\"\n                \"&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n        ]\n    )\n    def test_convert_to_errormarkupxml(self, name, in_string, want_string):\n\"\"\"Test plain errormarkup.\"\"\"\n        in_elem = etree.fromstring(in_string)\n        want = etree.fromstring(want_string)\n        errormarkup.convert_to_errormarkupxml(in_elem)\n        self.assert_xml_equal(in_elem, want)\n\n    # Nested markup\n    @parameterized.expand(\n        [\n            (\n                \"&lt;p&gt;{{\u0161addai}${verb,conc|\u0161attai} ollu \u00e1\u0161\u0161it}\u00a3{verb,fin,pl3prs,sg3prs,tense|\u0161adde ollu \u00e1\u0161\u0161it}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errormorphsyn&gt;&lt;errorort&gt;\u0161addai&lt;correct errorinfo=\"verb,conc\"&gt;'\n                \"\u0161attai&lt;/correct&gt;&lt;/errorort&gt; ollu \u00e1\u0161\u0161it&lt;correct \"\n                'errorinfo=\"verb,fin,pl3prs,sg3prs,tense\"&gt;\u0161adde ollu \u00e1\u0161\u0161it'\n                \"&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"&lt;p&gt;{guokte {ganddat}\u00a7{n,\u00e1|g\u00e1nddat}}\u00a3{n,nump,gensg,nompl,case|guokte g\u00e1ndda}&lt;/p&gt;\",\n                '&lt;p&gt;&lt;errormorphsyn&gt;guokte &lt;error&gt;ganddat&lt;correct errorinfo=\"n,\u00e1\"&gt;'\n                \"g\u00e1nddat&lt;/correct&gt;&lt;/error&gt;&lt;correct \"\n                'errorinfo=\"n,nump,gensg,nompl,case\"&gt;guokte g\u00e1ndda&lt;/correct&gt;'\n                \"&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"&lt;p&gt;{Nieiddat leat {nourra}${adj,meta|nuorra}}\"\n                \"\u00a3{adj,spred,nompl,nomsg,agr|Nieiddat leat nuorat}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errormorphsyn&gt;Nieiddat leat &lt;errorort&gt;nourra&lt;correct \"\n                'errorinfo=\"adj,meta\"&gt;nuorra&lt;/correct&gt;&lt;/errorort&gt;'\n                '&lt;correct errorinfo=\"adj,spred,nompl,nomsg,agr\"&gt;Nieiddat leat '\n                \"nuorat&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"&lt;p&gt;{leat {okta m\u00e1n\u00e1}\u00a3{n,spred,nomsg,gensg,case|okta m\u00e1nn\u00e1}}\"\n                \"\u00a3{v,v,sg3prs,pl3prs,agr|lea okta m\u00e1nn\u00e1}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errormorphsyn&gt;leat &lt;errormorphsyn&gt;okta m\u00e1n\u00e1&lt;correct \"\n                'errorinfo=\"n,spred,nomsg,gensg,case\"&gt;okta m\u00e1nn\u00e1&lt;/correct&gt;'\n                '&lt;/errormorphsyn&gt;&lt;correct errorinfo=\"v,v,sg3prs,pl3prs,agr\"&gt;'\n                \"lea okta m\u00e1nn\u00e1&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"&lt;p&gt;heaitit {d\u00e1hkaluddame}${verb,a|dahkaluddame} ahte sis \"\n                \"{m\u00e1hka\u0161}\u00a2{adv,\u00e1|mahk\u00e1\u0161} liv\u010d\u010dii {makkarge}${adv,\u00e1|makk\u00e1rge} \"\n                \"politihkka, muhto rahpasit baicca muitaliv\u010d\u010de {{makkar}\"\n                \"${interr,\u00e1|makk\u00e1r} soga}\u20ac{man soga} sii {ovddasttit}\"\n                \"${verb,conc|ovddastit}.&lt;/p&gt;\",\n                '&lt;p&gt;heaitit &lt;errorort&gt;d\u00e1hkaluddame&lt;correct errorinfo=\"verb,a\"&gt;'\n                \"dahkaluddame&lt;/correct&gt;&lt;/errorort&gt; ahte sis &lt;errorortreal&gt;\"\n                'm\u00e1hka\u0161&lt;correct errorinfo=\"adv,\u00e1\"&gt;mahk\u00e1\u0161&lt;/correct&gt;&lt;/errorortreal&gt;'\n                'liv\u010d\u010dii &lt;errorort&gt;makkarge&lt;correct errorinfo=\"adv,\u00e1\"&gt;makk\u00e1rge'\n                \"&lt;/correct&gt;&lt;/errorort&gt; politihkka, muhto rahpasit baicca \"\n                \"muitaliv\u010d\u010de &lt;errorlex&gt;&lt;errorort&gt;makkar&lt;correct \"\n                'errorinfo=\"interr,\u00e1\"&gt;makk\u00e1r&lt;/correct&gt;&lt;/errorort&gt; soga&lt;correct&gt;'\n                \"man soga&lt;/correct&gt;&lt;/errorlex&gt; sii &lt;errorort&gt;ovddasttit\"\n                '&lt;correct errorinfo=\"verb,conc\"&gt;ovddastit&lt;/correct&gt;&lt;/errorort&gt;.&lt;/p&gt;',\n            ),\n            (\n                \"&lt;p&gt;{{Bearpmahat}${noun,svow|Bearpmehat} \"\n                \"{earuha}\u20ac{verb,v,w|sirre}}\u00a3{verb,fin,pl3prs,sg3prs,agr|Bearpmehat\"\n                \" sirrejit} uskki ja loaiddu.&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errormorphsyn&gt;&lt;errorort&gt;Bearpmahat&lt;correct \"\n                'errorinfo=\"noun,svow\"&gt;Bearpmehat&lt;/correct&gt;&lt;/errorort&gt;&lt;errorlex&gt;'\n                'earuha&lt;correct errorinfo=\"verb,v,w\"&gt;sirre&lt;/correct&gt;&lt;/errorlex&gt;'\n                '&lt;correct errorinfo=\"verb,fin,pl3prs,sg3prs,agr\"&gt;Bearpmehat '\n                \"sirrejit&lt;/correct&gt;&lt;/errormorphsyn&gt; uskki ja loaiddu.&lt;/p&gt;\",\n            ),\n            (\n                \"&lt;p&gt;Mirja ja Line leaba {{gulahallan olbmo\u017eat}\"\n                \"\u00a2{noun,cmp|gulahallanolbmo\u017eat}}\u20ac{gulahallanolbmot}&lt;/p&gt;\",\n                \"&lt;p&gt;Mirja ja Line leaba &lt;errorlex&gt;&lt;errorortreal&gt;gulahallan \"\n                'olbmo\u017eat&lt;correct errorinfo=\"noun,cmp\"&gt;gulahallanolbmo\u017eat'\n                \"&lt;/correct&gt;&lt;/errorortreal&gt;&lt;correct&gt;gulahallanolbmot&lt;/correct&gt;\"\n                \"&lt;/errorlex&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"&lt;p&gt;{Ovddit geasis}\u00a3{noun,advl,gensg,locsg,case|Ovddit geasi} \"\n                \"{{{\u010doaggen}${verb,mono|\u010doggen} ollu jok\u014bat}\"\n                \"\u00a3{noun,obj,genpl,nompl,case|\u010doggen ollu jo\u014baid} ja sarridat}\"\n                \"\u00a3{noun,obj,genpl,nompl,case|\u010doggen ollu jo\u014baid ja sarridiid}&lt;/p&gt;\",\n                \"&lt;p&gt;&lt;errormorphsyn&gt;Ovddit geasis&lt;correct \"\n                'errorinfo=\"noun,advl,gensg,locsg,case\"&gt;Ovddit geasi&lt;/correct&gt;'\n                \"&lt;/errormorphsyn&gt;&lt;errormorphsyn&gt;&lt;errormorphsyn&gt;&lt;errorort&gt;\u010doaggen\"\n                '&lt;correct errorinfo=\"verb,mono\"&gt;\u010doggen&lt;/correct&gt;&lt;/errorort&gt; '\n                'ollu jok\u014bat&lt;correct errorinfo=\"noun,obj,genpl,nompl,case\"&gt;'\n                \"\u010doggen ollu jo\u014baid&lt;/correct&gt;&lt;/errormorphsyn&gt; ja sarridat\"\n                '&lt;correct errorinfo=\"noun,obj,genpl,nompl,case\"&gt;\u010doggen ollu '\n                \"jo\u014baid ja sarridiid&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n            ),\n            (\n                \"&lt;p&gt;Bruk {{epoxi}${noun,cons|epoksy} lim}\u00a2{noun,mix|epoksylim} \"\n                \"med god kvalitet.&lt;/p&gt;\",\n                \"&lt;p&gt;Bruk &lt;errorortreal&gt;&lt;errorort&gt;epoxi\"\n                '&lt;correct errorinfo=\"noun,cons\"&gt;epoksy&lt;/correct&gt;&lt;/errorort&gt; lim'\n                '&lt;correct errorinfo=\"noun,mix\"&gt;epoksylim&lt;/correct&gt;&lt;/errorortreal&gt; '\n                \"med god kvalitet.&lt;/p&gt;\",\n            ),\n        ]\n    )\n    def test_nested_markup(self, in_string, want_string):\n        in_elem = etree.fromstring(in_string)\n        want = etree.fromstring(want_string)\n        errormarkup.convert_to_errormarkupxml(in_elem)\n        self.assert_xml_equal(in_elem, want)\n</code></pre>"},{"location":"reference/test/test_errormarkup/#corpustools.test.test_errormarkup.TestErrorMarkup.assert_xml_equal","title":"<code>assert_xml_equal(got, want)</code>  <code>staticmethod</code>","text":"<p>Check if two stringified xml snippets are equal</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_errormarkup.py</code> <pre><code>@staticmethod\ndef assert_xml_equal(got, want):\n\"\"\"Check if two stringified xml snippets are equal\"\"\"\n    got = etree.tostring(got, encoding=\"unicode\")\n    want = etree.tostring(want, encoding=\"unicode\")\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(want, got, 0):\n        message = checker.output_difference(doctest.Example(\"\", want), got, 0)\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_errormarkup/#corpustools.test.test_errormarkup.TestErrorMarkup.test_convert_to_errormarkupxml","title":"<code>test_convert_to_errormarkupxml(name, in_string, want_string)</code>","text":"<p>Test plain errormarkup.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_errormarkup.py</code> <pre><code>@parameterized.expand(\n    [\n        (\n            \"errorlang_infinity\",\n            \"&lt;p&gt;{molekyl\u00e6rbiologimi}\u221e{kal,bio}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;errorlang&gt;molekyl\u00e6rbiologimi&lt;correct&gt;kal,bio&lt;/correct&gt;&lt;/errorlang&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_parser_errorlang_infinity_with_new_lines\",\n            \"&lt;p&gt;\\n\\n\\n\\n{molekyl\u00e6rbiologimi}\u221e{kal,bio}\\n\\n\\n\\n&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;errorlang&gt;molekyl\u00e6rbiologimi&lt;correct&gt;kal,bio&lt;/correct&gt;&lt;/errorlang&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"quote_char\",\n            \"&lt;p&gt;{\u201dsjievnnijis\u201d}${conc,vnn-vnnj|sjievnnjis}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorort&gt;\u201dsjievnnijis\u201d&lt;correct errorinfo=\"conc,vnn-vnnj\"&gt;sjievnnjis&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n        ),\n        (\n            \"error_parser_errorort1\",\n            \"&lt;p&gt;{jne.}${adv,typo|jna.}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorort&gt;jne.&lt;correct errorinfo=\"adv,typo\"&gt;jna.&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n        ),\n        (\n            \"error_parser_error_morphsyn1\",\n            \"&lt;p&gt;{Nieiddat leat nuorra}\u00a3{a,spred,nompl,nomsg,agr|Nieiddat leat nuorat}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;errormorphsyn&gt;Nieiddat leat nuorra&lt;correct \"\n            'errorinfo=\"a,spred,nompl,nomsg,agr\"&gt;Nieiddat leat nuorat'\n            \"&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_parser_with_two_simple_errors\",\n            \"&lt;p&gt;gitta {Nordkjosbotn'ii}${Nordkjosbotnii} (mii lea ge \"\n            \"{nordkjosbotn}${Nordkjosbotn} s\u00e1megillii? Muhtin, veahket mu!) \"\n            \"gos&lt;/p&gt;\",\n            \"&lt;p&gt;gitta \"\n            \"&lt;errorort&gt;Nordkjosbotn'ii&lt;correct&gt;Nordkjosbotnii&lt;/correct&gt;&lt;/errorort&gt; \"\n            \"(mii lea ge \"\n            \"&lt;errorort&gt;nordkjosbotn&lt;correct&gt;Nordkjosbotn&lt;/correct&gt;&lt;/errorort&gt; \"\n            \"s\u00e1megillii? Muhtin, veahket mu!) gos&lt;/p&gt;\",\n        ),\n        (\n            \"only_text_in_element\",\n            \"&lt;p&gt;Muitt\u00e1n dolo\u017eiid&lt;/p&gt;\",\n            \"&lt;p&gt;Muitt\u00e1n dolo\u017eiid&lt;/p&gt;\",\n        ),\n        (\n            \"paragraph_character\",\n            \"&lt;p&gt;Vuodol\u00e1hkaj \u00a7110a&lt;/p&gt;\",\n            \"&lt;p&gt;Vuodol\u00e1hkaj \u00a7110a&lt;/p&gt;\",\n        ),\n        (\n            \"errorort1\",\n            \"&lt;p&gt;{jne.}${adv,typo|jna.}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorort&gt;jne.&lt;correct errorinfo=\"adv,typo\"&gt;jna.&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n        ),\n        (\n            \"errorort2\",\n            \"&lt;p&gt;{daesn'}${daesnie}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;errorort&gt;daesn'&lt;correct&gt;daesnie&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"input_contains_slash\",\n            \"&lt;p&gt;{magistter/}${loan,vowlat,e-a|magisttar}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorort&gt;magistter/&lt;correct errorinfo=\"loan,vowlat,e-a\"&gt;'\n            \"magisttar&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct1\",\n            \"&lt;p&gt;{1]}\u00a7{Ij}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;1]&lt;correct&gt;Ij&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct2\",\n            \"&lt;p&gt;{v\u00e6]keles}\u00a7{v\u00e6jkeles}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;v\u00e6]keles&lt;correct&gt;v\u00e6jkeles&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct3\",\n            \"&lt;p&gt;{sm\u00e1vi-}\u00a7{sm\u00e1vit-}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;sm\u00e1vi-&lt;correct&gt;sm\u00e1vit-&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct4\",\n            \"&lt;p&gt;{CD:t}\u00a7{CD:at}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;CD:t&lt;correct&gt;CD:at&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct5\",\n            \"&lt;p&gt;{DNB-feask\u00e1ris}\u00a7{DnB-feask\u00e1ris}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;DNB-feask\u00e1ris&lt;correct&gt;DnB-feask\u00e1ris&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct6\",\n            \"&lt;p&gt;{boade}\u00a7{boa\u0111e}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;boade&lt;correct&gt;boa\u0111e&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct7\",\n            \"&lt;p&gt;{2005\u2019as}\u00a7{2005:s}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;2005\u2019as&lt;correct&gt;2005:s&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct8\",\n            \"&lt;p&gt;{NSRii}\u00a7{NSR:i}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;NSRii&lt;correct&gt;NSR:i&lt;/correct&gt;&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_correct9\",\n            \"&lt;p&gt;{Nordkjosbotn'ii}\u00a7{Nordkjosbotnii}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;error&gt;Nordkjosbotn'ii&lt;correct&gt;Nordkjosbotnii&lt;/correct&gt;\"\n            \"&lt;/error&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"errorort3\",\n            \"&lt;p&gt;{nourra}${a,meta|nuorra}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorort&gt;nourra&lt;correct errorinfo=\"a,meta\"&gt;nuorra&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n        ),\n        (\n            \"error_morphsyn1\",\n            \"&lt;p&gt;{Nieiddat leat nuorra}\u00a3{a,spred,nompl,nomsg,agr|Nieiddat leat nuorat}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;errormorphsyn&gt;Nieiddat leat nuorra\"\n            '&lt;correct errorinfo=\"a,spred,nompl,nomsg,agr\"&gt;Nieiddat leat '\n            \"nuorat&lt;/correct&gt;&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_syn1\",\n            \"&lt;p&gt;{ri\u014bgen nieidda lusa}\u00a5{x,pph|ri\u014bgen niidii}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorsyn&gt;ri\u014bgen nieidda lusa&lt;correct errorinfo=\"x,pph\"&gt;'\n            \"ri\u014bgen niidii&lt;/correct&gt;&lt;/errorsyn&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_syn2\",\n            \"&lt;p&gt;{ovtta}\u00a5{num,redun| }&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorsyn&gt;ovtta&lt;correct errorinfo=\"num,redun\"&gt;&lt;/correct&gt;'\n            \"&lt;/errorsyn&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_lex1\",\n            \"&lt;p&gt;{d\u00e1b\u00e1la\u0161}\u20ac{adv,adj,der|d\u00e1b\u00e1la\u010d\u010dat}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorlex&gt;d\u00e1b\u00e1la\u0161&lt;correct errorinfo=\"adv,adj,der\"&gt;d\u00e1b\u00e1la\u010d\u010dat'\n            \"&lt;/correct&gt;&lt;/errorlex&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_ortreal1\",\n            \"&lt;p&gt;{r\u00e1h\u010d\u010damu\u0161aid}\u00a2{noun,mix|rah\u010damu\u0161aid}&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorortreal&gt;r\u00e1h\u010d\u010damu\u0161aid&lt;correct errorinfo=\"noun,mix\"&gt;'\n            \"rah\u010damu\u0161aid&lt;/correct&gt;&lt;/errorortreal&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"error_ortreal2\",\n            \"&lt;p&gt;gitta {Nordkjosbotn'ii}${Nordkjosbotnii} (mii lea ge \"\n            \"{nordkjosbotn}${Nordkjosbotn} s\u00e1megillii? Muhtin, veahket mu!) \"\n            \"gos&lt;/p&gt;\",\n            \"&lt;p&gt;gitta &lt;errorort&gt;Nordkjosbotn'ii&lt;correct&gt;Nordkjosbotnii\"\n            \"&lt;/correct&gt;&lt;/errorort&gt; (mii lea ge &lt;errorort&gt;nordkjosbotn\"\n            \"&lt;correct&gt;Nordkjosbotn&lt;/correct&gt;&lt;/errorort&gt; s\u00e1megillii? \"\n            \"Muhtin, veahket mu!) gos&lt;/p&gt;\",\n        ),\n        (\n            \"error_morphsyn2\",\n            \"&lt;p&gt;\u010c\u00e1ppa muohtaskulptuvrraid r\u00e1hkadeapmi VSM olggobealde lei \"\n            \"maidd\u00e1i ovttasbargu gaskal {skuvla ohppiid}\u00a3\"\n            \"{noun,attr,gensg,nomsg,case|skuvlla ohppiid}\"\n            \"ja VSM.&lt;/p&gt;\",\n            \"&lt;p&gt;\u010c\u00e1ppa muohtaskulptuvrraid r\u00e1hkadeapmi VSM olggobealde lei \"\n            \"maidd\u00e1i ovttasbargu gaskal &lt;errormorphsyn&gt;skuvla ohppiid\"\n            '&lt;correct errorinfo=\"noun,attr,gensg,nomsg,case\"&gt;skuvlla ohppiid'\n            \"&lt;/correct&gt;&lt;/errormorphsyn&gt; ja VSM.&lt;/p&gt;\",\n        ),\n        (\n            \"errorort4\",\n            \"&lt;p&gt;- ruksesruon\u00e1\u010dalmmehisvuohta lea sullii \"\n            \"{8%:as}${acr,suf|8%:s}&lt;/p&gt;\",\n            \"&lt;p&gt;- ruksesruon\u00e1\u010dalmmehisvuohta lea sullii &lt;errorort&gt;8%:as\"\n            '&lt;correct errorinfo=\"acr,suf\"&gt;8%:s&lt;/correct&gt;&lt;/errorort&gt;&lt;/p&gt;',\n        ),\n        (\n            \"error_ortreal3\",\n            \"&lt;p&gt;( {nissonin}\u00a2{noun,suf|nissoniin} du\u0161\u0161e {0.6 %:s}\u00a3{0.6 %} )&lt;/p&gt;\",\n            '&lt;p&gt;( &lt;errorortreal&gt;nissonin&lt;correct errorinfo=\"noun,suf\"&gt;'\n            \"nissoniin&lt;/correct&gt;&lt;/errorortreal&gt; du\u0161\u0161e &lt;errormorphsyn&gt;0.6 %:s\"\n            \"&lt;correct&gt;0.6 %&lt;/correct&gt;&lt;/errormorphsyn&gt; )&lt;/p&gt;\",\n        ),\n        (\n            \"errorort5\",\n            \"&lt;p&gt;(haploida) ja {nji\u014b\u014balas}${noun,\u00e1|nji\u014b\u014b\u00e1las} {s\u00e1gahuvvon}\"\n            \"${verb,a|sagahuvvon} manneseallas (diploida)&lt;/p&gt;\",\n            '&lt;p&gt;(haploida) ja &lt;errorort&gt;nji\u014b\u014balas&lt;correct errorinfo=\"noun,\u00e1\"&gt;'\n            \"nji\u014b\u014b\u00e1las&lt;/correct&gt;&lt;/errorort&gt; &lt;errorort&gt;s\u00e1gahuvvon\"\n            '&lt;correct errorinfo=\"verb,a\"&gt;sagahuvvon&lt;/correct&gt;&lt;/errorort&gt; '\n            \"manneseallas (diploida)&lt;/p&gt;\",\n        ),\n        (\n            \"errorort6\",\n            \"&lt;p&gt;(gii oahpaha) {giinu}${x,notcmp|gii nu} manai {inti\u00e1nal\u00e1vlagat}\"\n            \"${loan,conc|indi\u00e1nal\u00e1vlagat} {guov\u017ea-kl\u00e1na}${noun,cmp|guov\u017eakl\u00e1na} \"\n            \"olbmuid&lt;/p&gt;\",\n            '&lt;p&gt;(gii oahpaha) &lt;errorort&gt;giinu&lt;correct errorinfo=\"x,notcmp\"&gt;'\n            \"gii nu&lt;/correct&gt;&lt;/errorort&gt; manai &lt;errorort&gt;inti\u00e1nal\u00e1vlagat\"\n            '&lt;correct errorinfo=\"loan,conc\"&gt;indi\u00e1nal\u00e1vlagat&lt;/correct&gt;'\n            '&lt;/errorort&gt; &lt;errorort&gt;guov\u017ea-kl\u00e1na&lt;correct errorinfo=\"noun,cmp\"&gt;'\n            \"guov\u017eakl\u00e1na&lt;/correct&gt;&lt;/errorort&gt; olbmuid&lt;/p&gt;\",\n        ),\n        (\n            \"error_format\",\n            \"&lt;p&gt;{{A  B}\u2030{notspace|A B}  C}\u2030{notspace|A B C}&lt;/p&gt;\",\n            \"&lt;p&gt;\"\n            \"&lt;errorformat&gt;\"\n            \"&lt;errorformat&gt;\"\n            'A  B&lt;correct errorinfo=\"notspace\"&gt;A B&lt;/correct&gt;&lt;/errorformat&gt;'\n            '  C&lt;correct errorinfo=\"notspace\"&gt;A B C&lt;/correct&gt;&lt;/errorformat&gt;'\n            \"&lt;/p&gt;\",\n        ),\n        (\n            \"preserve_space_at_end_of_sentence\",\n            \"&lt;p&gt;buvttadeaddji Anstein {Mikkelsens}${typo|Mikkelsen} lea \"\n            \"r\u00e1hkadan. &lt;/p&gt;\",\n            '&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. &lt;/p&gt;',\n        ),\n        (\n            \"place_error_elements_before_old_element1\",\n            \"&lt;p&gt;buvttadeaddji Anstein {Mikkelsens}${typo|Mikkelsen} lea \"\n            \"r\u00e1hkadan. {b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} miessem\u00e1nu. &lt;span \"\n            'type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt;&lt;/p&gt;',\n            \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens\"\n            '&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. '\n            '&lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt;'\n            ' miessem\u00e1nu. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts '\n            \"Competition\u00bb&lt;/span&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"place_error_elements_before_old_element2\",\n            \"&lt;p&gt;{Mikkelsens}${typo|Mikkelsen} lea r\u00e1hkadan. \"\n            \"{b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} miessem\u00e1nu. \"\n            '&lt;span type=\"quote\" xml:lang=\"eng\"&gt;'\n            \"\u00abBest Shorts Competition\u00bb&lt;/span&gt;&lt;/p&gt;\",\n            '&lt;p&gt;&lt;errorort&gt;Mikkelsens&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; miessem\u00e1nu. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt;&lt;/p&gt;',\n        ),\n        (\n            \"place_error_element_after_old_element\",\n            '&lt;p&gt;I 1864 ga han ut boka &lt;span type=\"quote\" xml:lang=\"swe\"&gt;'\n            '\"Fornuftigt Madstel\"&lt;/span&gt;. {Asbj\u00f8rsen}${prop,typo|Asbj\u00f8rnsen} '\n            \"d\u00f8de 5. januar 1885, nesten 73 \u00e5r gammel.&lt;/p&gt;\",\n            '&lt;p&gt;I 1864 ga han ut boka &lt;span type=\"quote\" xml:lang=\"swe\"&gt;'\n            '\"Fornuftigt Madstel\"&lt;/span&gt;. &lt;errorort&gt;Asbj\u00f8rsen'\n            '&lt;correct errorinfo=\"prop,typo\"&gt;Asbj\u00f8rnsen&lt;/correct&gt;&lt;/errorort&gt; '\n            \"d\u00f8de 5. januar 1885, nesten 73 \u00e5r gammel.&lt;/p&gt;\",\n        ),\n        (\n            \"place_error_element_before_and_after_old_element\",\n            \"&lt;p&gt;buvttadeaddji Anstein {Mikkelsens}${typo|Mikkelsen} lea \"\n            'r\u00e1hkadan. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts '\n            \"Competition\u00bb&lt;/span&gt; {b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} \"\n            \"miessem\u00e1nu.&lt;/p&gt;\",\n            \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens\"\n            '&lt;correct errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea '\n            'r\u00e1hkadan. &lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts '\n            \"Competition\u00bb&lt;/span&gt; &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi\"\n            '&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; '\n            \"miessem\u00e1nu.&lt;/p&gt;\",\n        ),\n        (\n            \"markup3Levels\",\n            \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens&lt;correct \"\n            'errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. '\n            '&lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb'\n            '&lt;/span&gt; &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;'\n            \"b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; miessem\u00e1nu. &lt;em&gt;buvttadeaddji \"\n            \"Anstein {Mikkelsens}${typo|Mikkelsen} lea r\u00e1hkadan. &lt;span \"\n            'type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt; '\n            \"{b\u00e1lkk\u00e1\u0161umi}${vowlat,\u00e1-a|b\u00e1lkka\u0161umi} miessem\u00e1nu.&lt;/em&gt;&lt;/p&gt;\",\n            \"&lt;p&gt;buvttadeaddji Anstein &lt;errorort&gt;Mikkelsens&lt;correct \"\n            'errorinfo=\"typo\"&gt;Mikkelsen&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. '\n            '&lt;span type=\"quote\" xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb'\n            '&lt;/span&gt; &lt;errorort&gt;b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;'\n            \"b\u00e1lkka\u0161umi&lt;/correct&gt;&lt;/errorort&gt; miessem\u00e1nu. &lt;em&gt;buvttadeaddji \"\n            'Anstein &lt;errorort&gt;Mikkelsens&lt;correct errorinfo=\"typo\"&gt;Mikkelsen'\n            '&lt;/correct&gt;&lt;/errorort&gt; lea r\u00e1hkadan. &lt;span type=\"quote\" '\n            'xml:lang=\"eng\"&gt;\u00abBest Shorts Competition\u00bb&lt;/span&gt; &lt;errorort&gt;'\n            'b\u00e1lkk\u00e1\u0161umi&lt;correct errorinfo=\"vowlat,\u00e1-a\"&gt;b\u00e1lkka\u0161umi&lt;/correct&gt;'\n            \"&lt;/errorort&gt; miessem\u00e1nu.&lt;/em&gt;&lt;/p&gt;\",\n        ),\n        (\n            \"inline multiple corrections\",\n            \"&lt;p&gt;{leimme}\u00a3{leimmet///leat}&lt;/p&gt;\",\n            \"&lt;p&gt;&lt;errormorphsyn&gt;leimme\"\n            \"&lt;correct&gt;leimmet&lt;/correct&gt;\"\n            \"&lt;correct&gt;leat&lt;/correct&gt;\"\n            \"&lt;/errormorphsyn&gt;&lt;/p&gt;\",\n        ),\n    ]\n)\ndef test_convert_to_errormarkupxml(self, name, in_string, want_string):\n\"\"\"Test plain errormarkup.\"\"\"\n    in_elem = etree.fromstring(in_string)\n    want = etree.fromstring(want_string)\n    errormarkup.convert_to_errormarkupxml(in_elem)\n    self.assert_xml_equal(in_elem, want)\n</code></pre>"},{"location":"reference/test/test_errormarkup/#corpustools.test.test_errormarkup.TestErrorMarkup.test_regex","title":"<code>test_regex(markup, span)</code>","text":"<p>Testing the most important regex.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_errormarkup.py</code> <pre><code>@parameterized.expand(\n    [\n        (\"{a}${b}\", (3, 7)),\n        (\"{a}${b} {a}${c} \", (11, 15)),\n        (\"{a}${b} {{a}${b}}${d} \", (17, 21)),\n    ]\n)\ndef test_regex(self, markup, span):\n\"\"\"Testing the most important regex.\"\"\"\n    # match = errormarkup.LAST_CORRECTION_REGEX.search(markup)\n    # self.assertEqual(match.span(), span)\n    match = errormarkup.LAST_CORRECTION_REGEX.search(markup)\n    self.assertEqual(match.span(), span)\n</code></pre>"},{"location":"reference/test/test_htmlcontentconverter/","title":"test_htmlcontentconverter","text":"<p>Test conversion of html content.</p>"},{"location":"reference/test/test_htmlcontentconverter/#corpustools.test.test_htmlcontentconverter.TestHTMLContentConverter","title":"<code>TestHTMLContentConverter</code>","text":"<p>         Bases: <code>xmltester.XMLTester</code></p> <p>Test the HTMLContentConverter class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlcontentconverter.py</code> <pre><code>class TestHTMLContentConverter(xmltester.XMLTester):\n\"\"\"Test the HTMLContentConverter class.\"\"\"\n\n    @parameterized.expand(\n        [\n            (\n                \"Remove an empty p.\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p/&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Do not remove a p with content.\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;span&gt;spanny&lt;/span&gt;&lt;/p&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;span&gt;spanny&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Remove empty class\",\n                '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;div class=\"\"&gt;a&lt;/div&gt;&lt;div class=\"a\"&gt;'\n                '&lt;span class=\"\"&gt;b&lt;/span&gt;&lt;/div&gt;&lt;/html&gt;',\n                '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;div&gt;a&lt;/div&gt;&lt;div class=\"a\"&gt;'\n                \"&lt;span&gt;b&lt;/span&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Remove comment\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b&gt;&lt;!--Hey, buddy. --&gt;&lt;/b&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b/&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Remove processing instruction\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b&gt;&lt;?ProcessingInstruction?&gt;&lt;/b&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b/&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Only text before next significant element\",\n                \"&lt;html&gt;&lt;head&gt;&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;\"\n                \"&lt;/head&gt;&lt;body&gt;&lt;h3&gt;VI&lt;/h3&gt;... Finnerne&lt;p&gt;Der&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head&gt;\"\n                \"&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\"\n                \"&lt;h3&gt;VI&lt;/h3&gt;  &lt;p&gt;... Finnerne&lt;/p&gt;&lt;p&gt;Der&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Text and i element before next significant element\",\n                \"&lt;head&gt;&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;\"\n                \"&lt;/head&gt;&lt;body&gt;&lt;h3&gt;VI&lt;/h3&gt;... Finnerne&lt;i&gt;Der&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head&gt;\"\n                \"&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\"\n                \"&lt;h3&gt;VI&lt;/h3&gt;  &lt;p&gt;... Finnerne&lt;i&gt;Der&lt;/i&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"h2 as a stop element\",\n                \"&lt;html&gt;&lt;head&gt;\"\n                \"&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;\"\n                \"&lt;/head&gt;&lt;body&gt;&lt;h3&gt;VI&lt;/h3&gt;... Finnerne\"\n                \"&lt;h2&gt;Der&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head&gt;&lt;title&gt;\u2013 Den \"\n                \"utd\u00f8ende stammes frykt&lt;/title&gt;\"\n                \"&lt;/head&gt;&lt;body&gt;  &lt;h3&gt;VI&lt;/h3&gt;  \"\n                \"&lt;p&gt;... Finnerne&lt;/p&gt;&lt;h2&gt;Der&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"center2div\",\n                '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;center&gt;&lt;span class=\"\"&gt;b&lt;/span&gt;&lt;/center&gt;&lt;/html&gt;',\n                '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;div class=\"c1\"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/div&gt;&lt;/body&gt;'\n                \"&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_i\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;i&gt;b&lt;/i&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;i&gt;b&lt;/i&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Font elements with only text\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x \"\n                \"&lt;font&gt;a, b &lt;/font&gt;\"\n                \"&lt;font&gt;c&lt;/font&gt;\"\n                \"&lt;font&gt;d&lt;/font&gt;\"\n                \"&lt;font&gt;e&lt;/font&gt;\"\n                \"&lt;font&gt; f&lt;/font&gt;\"\n                \"&lt;font&gt;. &lt;/font&gt;\"\n                \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;\" \"x a, b cde f. \" \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Font element containing other xml elements\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x \"\n                \"&lt;font&gt;a &lt;i&gt;b&lt;/i&gt; c.&lt;/font&gt; d\"\n                \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x \" \"a &lt;i&gt;b&lt;/i&gt; c. d\" \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"Font element containing font elements\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;font&gt;x&lt;/font&gt; \"\n                \"&lt;font&gt;a &lt;i&gt;b&lt;/i&gt; c.&lt;/font&gt; &lt;font&gt;d&lt;/font&gt;\"\n                \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x a &lt;i&gt;b&lt;/i&gt; c. d\" \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_a\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;a&gt;b&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;a&gt;b&lt;/a&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_em\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;em&gt;b&lt;/em&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;em&gt;b&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_font\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;font&gt;b&lt;/font&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;b&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_u\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;u&gt;b&lt;/u&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;u&gt;b&lt;/u&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_strong\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_span\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;span&gt;b&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;span&gt;b&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n            (\n                \"test_body_text\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;b&lt;/body&gt;&lt;/html&gt;\",\n                \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;b&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            ),\n        ]\n    )\n    def test_convert2xhtml(self, testname, test_input, want_input):\n\"\"\"Test convert2xhtml.\n\n        Args:\n            testname (str): name of the test\n            test_input (str): input sent to convert2xhtml\n            want_input (str): input to html.document_fromstring\n\n        Raises:\n            AssertionError if got and want are unequal.\n        \"\"\"\n        hcc = htmlcontentconverter.HTMLBeautifier(html.document_fromstring(test_input))\n        got = hcc.beautify()\n        want = html.document_fromstring(want_input)\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_htmlcontentconverter/#corpustools.test.test_htmlcontentconverter.TestHTMLContentConverter.test_convert2xhtml","title":"<code>test_convert2xhtml(testname, test_input, want_input)</code>","text":"<p>Test convert2xhtml.</p> <p>Parameters:</p> Name Type Description Default <code>testname</code> <code>str</code> <p>name of the test</p> required <code>test_input</code> <code>str</code> <p>input sent to convert2xhtml</p> required <code>want_input</code> <code>str</code> <p>input to html.document_fromstring</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlcontentconverter.py</code> <pre><code>@parameterized.expand(\n    [\n        (\n            \"Remove an empty p.\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p/&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Do not remove a p with content.\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;span&gt;spanny&lt;/span&gt;&lt;/p&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;span&gt;spanny&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Remove empty class\",\n            '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;div class=\"\"&gt;a&lt;/div&gt;&lt;div class=\"a\"&gt;'\n            '&lt;span class=\"\"&gt;b&lt;/span&gt;&lt;/div&gt;&lt;/html&gt;',\n            '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;div&gt;a&lt;/div&gt;&lt;div class=\"a\"&gt;'\n            \"&lt;span&gt;b&lt;/span&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Remove comment\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b&gt;&lt;!--Hey, buddy. --&gt;&lt;/b&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b/&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Remove processing instruction\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b&gt;&lt;?ProcessingInstruction?&gt;&lt;/b&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;b/&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Only text before next significant element\",\n            \"&lt;html&gt;&lt;head&gt;&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;\"\n            \"&lt;/head&gt;&lt;body&gt;&lt;h3&gt;VI&lt;/h3&gt;... Finnerne&lt;p&gt;Der&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head&gt;\"\n            \"&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\"\n            \"&lt;h3&gt;VI&lt;/h3&gt;  &lt;p&gt;... Finnerne&lt;/p&gt;&lt;p&gt;Der&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Text and i element before next significant element\",\n            \"&lt;head&gt;&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;\"\n            \"&lt;/head&gt;&lt;body&gt;&lt;h3&gt;VI&lt;/h3&gt;... Finnerne&lt;i&gt;Der&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head&gt;\"\n            \"&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\"\n            \"&lt;h3&gt;VI&lt;/h3&gt;  &lt;p&gt;... Finnerne&lt;i&gt;Der&lt;/i&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"h2 as a stop element\",\n            \"&lt;html&gt;&lt;head&gt;\"\n            \"&lt;title&gt;\u2013 Den utd\u00f8ende stammes frykt&lt;/title&gt;\"\n            \"&lt;/head&gt;&lt;body&gt;&lt;h3&gt;VI&lt;/h3&gt;... Finnerne\"\n            \"&lt;h2&gt;Der&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head&gt;&lt;title&gt;\u2013 Den \"\n            \"utd\u00f8ende stammes frykt&lt;/title&gt;\"\n            \"&lt;/head&gt;&lt;body&gt;  &lt;h3&gt;VI&lt;/h3&gt;  \"\n            \"&lt;p&gt;... Finnerne&lt;/p&gt;&lt;h2&gt;Der&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"center2div\",\n            '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;center&gt;&lt;span class=\"\"&gt;b&lt;/span&gt;&lt;/center&gt;&lt;/html&gt;',\n            '&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;div class=\"c1\"&gt;&lt;span&gt;b&lt;/span&gt;&lt;/div&gt;&lt;/body&gt;'\n            \"&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_i\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;i&gt;b&lt;/i&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;i&gt;b&lt;/i&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Font elements with only text\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x \"\n            \"&lt;font&gt;a, b &lt;/font&gt;\"\n            \"&lt;font&gt;c&lt;/font&gt;\"\n            \"&lt;font&gt;d&lt;/font&gt;\"\n            \"&lt;font&gt;e&lt;/font&gt;\"\n            \"&lt;font&gt; f&lt;/font&gt;\"\n            \"&lt;font&gt;. &lt;/font&gt;\"\n            \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;\" \"x a, b cde f. \" \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Font element containing other xml elements\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x \"\n            \"&lt;font&gt;a &lt;i&gt;b&lt;/i&gt; c.&lt;/font&gt; d\"\n            \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x \" \"a &lt;i&gt;b&lt;/i&gt; c. d\" \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"Font element containing font elements\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;font&gt;x&lt;/font&gt; \"\n            \"&lt;font&gt;a &lt;i&gt;b&lt;/i&gt; c.&lt;/font&gt; &lt;font&gt;d&lt;/font&gt;\"\n            \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;x a &lt;i&gt;b&lt;/i&gt; c. d\" \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_a\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;a&gt;b&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;a&gt;b&lt;/a&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_em\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;em&gt;b&lt;/em&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;em&gt;b&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_font\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;font&gt;b&lt;/font&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;b&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_u\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;u&gt;b&lt;/u&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;u&gt;b&lt;/u&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_strong\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_span\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;span&gt;b&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;&lt;span&gt;b&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n        (\n            \"test_body_text\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;b&lt;/body&gt;&lt;/html&gt;\",\n            \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;b&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\",\n        ),\n    ]\n)\ndef test_convert2xhtml(self, testname, test_input, want_input):\n\"\"\"Test convert2xhtml.\n\n    Args:\n        testname (str): name of the test\n        test_input (str): input sent to convert2xhtml\n        want_input (str): input to html.document_fromstring\n\n    Raises:\n        AssertionError if got and want are unequal.\n    \"\"\"\n    hcc = htmlcontentconverter.HTMLBeautifier(html.document_fromstring(test_input))\n    got = hcc.beautify()\n    want = html.document_fromstring(want_input)\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_htmlcontentconverter/#corpustools.test.test_htmlcontentconverter.check_unwanted_classes_and_ids","title":"<code>check_unwanted_classes_and_ids(tag, key, value)</code>","text":"<p>Check that unwanted content is removed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlcontentconverter.py</code> <pre><code>def check_unwanted_classes_and_ids(tag, key, value):\n\"\"\"Check that unwanted content is removed.\"\"\"\n    if tag == \"tr\":\n        inner = (\n            '&lt;table&gt;&lt;tbody&gt;&lt;{0} {1}=\"{2}\"&gt;&lt;td&gt;content:{0} {1} {2}&lt;/td&gt;'\n            \"&lt;/tbody&gt;&lt;/table&gt;\".format(tag, key, value)\n        )\n        inner_r = \"&lt;table&gt;&lt;tbody/&gt;&lt;/table&gt;\"\n    elif tag == \"td\":\n        inner = (\n            '&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;{0} {1}=\"{2}\"&gt;content:{0} {1} {2}&lt;/tr&gt;'\n            \"&lt;/tbody&gt;&lt;/table&gt;\".format(tag, key, value)\n        )\n        inner_r = \"&lt;table&gt;&lt;tbody&gt;&lt;tr/&gt;&lt;/tbody&gt;&lt;/table&gt;\"\n    else:\n        inner = '&lt;{0} {1}=\"{2}\"&gt;' \"content:{0} {1} {2}\" \"&lt;/{0}&gt;\".format(tag, key, value)\n        inner_r = \"\"\n    content_xml = html.document_fromstring(\n        f\"&lt;html&gt;&lt;head/&gt;&lt;body&gt;{inner}&lt;/body&gt;&lt;/html&gt;\"\n    )\n    got = htmlcontentconverter.HTMLBeautifier(content_xml).beautify()\n\n    want = html.document_fromstring(\n        f\"&lt;html&gt;&lt;head/&gt;&lt;body&gt;{inner_r}&lt;/body&gt;&lt;/html&gt;\"\n    )\n\n    if etree.tostring(got) != etree.tostring(want):\n        raise AssertionError(\n            \"Remove classes and ids:\\nexpected {}\\n\"\n            \"got {}\".format(etree.tostring(want), etree.tostring(got))\n        )\n</code></pre>"},{"location":"reference/test/test_htmlcontentconverter/#corpustools.test.test_htmlcontentconverter.test_remove_unwanted_content","title":"<code>test_remove_unwanted_content()</code>","text":"<p>Test if unwanted content is removed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlcontentconverter.py</code> <pre><code>def test_remove_unwanted_content():\n\"\"\"Test if unwanted content is removed.\"\"\"\n    unwanted_classes_ids = {\n        \"div\": {\n            \"class\": [\n                \"latestnews_uutisarkisto\",\n                \"InnholdForfatter\",  # unginordland\n                \"QuickNav\",\n                \"ad\",\n                \"andrenyheter\",  # tysfjord.kommune.no\n                \"article-ad\",\n                \"article-bottom-element\",\n                \"article-column\",\n                \"article-dateline article-dateline-footer \"\n                \"meta-widget-content\",  # nrk.no\n                \"article-info\",  # regjeringen.no\n                \"article-related\",\n                \"articleImageRig\",\n                \"articlegooglemap\",  # tysfjord.kommune.no\n                \"articleTags\",  # nord-salten.no\n                \"attribute-related_object\",  # samediggi.no\n                \"authors\",\n                \"authors ui-helper-clearfix\",  # nord-salten.no\n                \"back_button\",\n                \"banner-element\",\n                \"breadcrumbs \",\n                \"breadcrumbs\",\n                \"breadcrums span-12\",\n                \"btm_menu\",\n                \"byline\",  # arran.no\n                \"clearfix breadcrumbsAndSocial noindex\",  # udir.no\n                \"complexDocumentBottom\",  # regjeringen.no\n                \"container_full\",\n                \"documentInfoEm\",\n                \"documentPaging\",\n                \"documentTop\",  # regjeringen.no\n                \"dotList\",  # nord-salten.no\n                \"dropmenudiv\",  # calliidlagadus.org\n                \"egavpi\",  # calliidlagadus.org\n                \"egavpi_fiskes\",  # calliidlagadus.org\n                \"expandable\",\n                \"feedbackContainer noindex\",  # udir.no\n                \"fixed-header\",\n                \"g100 col fc s18 sg6 sg9 sg12 menu-reference\",  # nrk.no\n                \"g100 col fc s18 sg6 sg9 sg12 flow-reference\",  # nrk.no\n                \"g11 col fl s2 sl6 sl9 sl12 sl18\",  # nrk.no\n                \"g22 col fl s4 sl6 sl9 sl12 sl18 \" \"article-header-sidebar\",  # nrk.no\n                \"g94 col fl s17 sl18 sg6 sg9 sg12 meta-widget\",  # nrk.no\n                \"globmenu\",  # visitstetind.no\n                \"grid cf\",  # nrk.no\n                \"help closed hidden-xs\",\n                \"historic-info\",  # regjeringen.no\n                \"historic-label\",  # regjeringen.no\n                \"imagecontainer\",\n                \"innholdsfortegenlse-child\",\n                \"ld-navbar\",\n                \"meta\",\n                \"meta ui-helper-clearfix\",  # nord-salten.no\n                \"authors ui-helper-clearfix\",  # nord-salten.no\n                \"menu\",  # visitstetind.no\n                \"metaWrapper\",\n                \"moduletable_oikopolut\",\n                \"moduletable_etulinkki\",  # www.samediggi.fi\n                \"naviHlp\",  # visitstetind.no\n                \"noindex\",  # ntfk\n                \"nrk-globalfooter\",  # nrk.no\n                \"nrk-globalfooter-dk lp_globalfooter\",  # nrk.no\n                \"nrk-globalnavigation\",  # nrk.no\n                \"outer-column\",\n                \"post-footer\",\n                \"printContact\",\n                \"right\",  # ntfk\n                \"rightverticalgradient\",  # udir.no\n                \"sharing\",\n                \"sidebar\",\n                \"spalte300\",  # osko.no\n                \"subfooter\",  # visitstetind.no\n                \"tabbedmenu\",\n                \"tipformcontainer\",  # tysfjord.kommune.no\n                \"tipsarad mt6 selfClear\",\n                \"titlepage\",\n                \"toc\",\n                \"tools\",  # arran.no\n            ],\n            \"id\": [\n                \"AreaLeft\",\n                \"AreaLeftNav\",\n                \"AreaRight\",\n                \"AreaTopRight\",\n                \"AreaTopSiteNav\",\n                \"NAVbreadcrumbContainer\",\n                \"NAVfooterContainer\",\n                \"NAVheaderContainer\",\n                \"NAVrelevantContentContainer\",\n                \"NAVsubmenuContainer\",\n                \"PageFooter\",\n                \"PrintDocHead\",\n                \"SamiDisclaimer\",\n                \"ShareArticle\",\n                \"WIPSELEMENT_CALENDAR\",  # learoevierhtieh.no\n                \"WIPSELEMENT_HEADING\",  # learoevierhtieh.no\n                \"WIPSELEMENT_MENU\",  # learoevierhtieh.no\n                \"WIPSELEMENT_MENURIGHT\",  # learoevierhtieh.no\n                \"WIPSELEMENT_NEWS\",  # learoevierhtieh.no\n                \"aa\",\n                \"andrenyheter\",  # tysfjord.kommune.no\n                \"article_footer\",\n                \"attached\",  # tysfjord.kommune.no\n                \"blog-pager\",\n                \"breadcrumbs-bottom\",\n                \"bunninformasjon\",  # unginordland\n                \"chatBox\",\n                \"chromemenu\",  # calliidlagadus.org\n                \"crumbs\",  # visitstetind.no\n                \"ctl00_FullRegion_CenterAndRightRegion_HitsControl_\"\n                \"ctl00_FullRegion_CenterAndRightRegion_Sorting_sortByDiv\",\n                \"ctl00_MidtSone_ucArtikkel_ctl00_ctl00_ctl01_divRessurser\",\n                \"ctl00_MidtSone_ucArtikkel_ctl00_divNavigasjon\",\n                \"deleModal\",\n                \"document-header\",\n                \"errorMessageContainer\",  # nord-salten.no\n                \"footer\",  # forrest, too, tysfjord.kommune.no\n                \"footer-wrapper\",\n                \"frontgallery\",  # visitstetind.no\n                \"header\",\n                \"headerBar\",\n                \"headWrapper\",  # osko.no\n                \"hoyre\",  # unginordland\n                \"innholdsfortegnelse\",  # regjeringen.no\n                \"leftMenu\",\n                \"leftPanel\",\n                \"leftbar\",  # forrest (divvun and giellatekno sites)\n                \"leftcol\",  # new samediggi.no\n                \"leftmenu\",\n                \"main_navi_main\",  # www.samediggi.fi\n                \"mainsidebar\",  # arran.no\n                \"menu\",\n                \"murupolku\",  # www.samediggi.fi\n                \"navbar\",  # tysfjord.kommune.no\n                \"ncFooter\",  # visitstetind.no\n                \"ntfkFooter\",  # ntfk\n                \"ntfkHeader\",  # ntfk\n                \"ntfkNavBreadcrumb\",  # ntfk\n                \"ntfkNavMain\",  # ntfk\n                \"pageFooter\",\n                \"PageLanguageInfo\",  # regjeringen.no\n                \"path\",  # new samediggi.no, tysfjord.kommune.no\n                \"readspeaker_button1\",\n                \"rightAds\",\n                \"rightCol\",\n                \"rightside\",\n                \"s4-leftpanel\",  # ntfk\n                \"searchBox\",\n                \"searchHitSummary\",\n                \"sendReminder\",\n                \"share-article\",\n                \"sidebar\",  # finlex.fi, too\n                \"sidebar-wrapper\",\n                \"sitemap\",\n                \"skipLinks\",  # udir.no\n                \"skiplink\",  # tysfjord.kommune.no\n                \"spraakvelger\",  # osko.no\n                \"subfoote\",  # visitstetind.no\n                \"submenu\",  # nord-salten.no\n                \"tipafriend\",\n                \"tools\",  # arran.no\n                \"topHeader\",  # nord-salten.no\n                \"topMenu\",\n                \"topUserMenu\",\n                \"top\",  # arran.no\n                \"topnav\",  # tysfjord.kommune.no\n                \"toppsone\",  # unginordland\n                \"vedleggogregistre\",  # regjeringen.no\n                \"venstre\",  # unginordland\n            ],\n        },\n        \"p\": {\n            \"class\": [\"WebPartReadMoreParagraph\", \"breadcrumbs\", \"langs\"],  # oahpa.no\n        },\n        \"ul\": {\n            \"id\": [\n                \"AreaTopPrintMeny\",\n                \"AreaTopLanguageNav\",\n                \"skiplinks\",  # umo.se\n            ],\n            \"class\": [\n                \"QuickNav\",\n                \"article-tools\",\n                \"byline\",\n                \"chapter-index\",  # lovdata.no\n                \"footer-nav\",  # lovdata.no\n                \"hidden\",  # unginordland\n            ],\n        },\n        \"span\": {\n            \"id\": [\"skiplinks\"],\n            \"class\": [\n                \"K-NOTE-FOTNOTE\",\n                \"graytext\",  # svenskakyrkan.se\n            ],\n        },\n        \"a\": {\n            \"id\": [\n                \"ctl00_IdWelcome_ExplicitLogin\",  # ntfk\n                \"leftPanelTab\",\n            ],\n            \"class\": [\n                \"addthis_button_print\",  # ntfk\n                \"mainlevel\",\n                \"share-paragraf\",  # lovdata.no\n                \"mainlevel_alavalikko\",  # www.samediggi.fi\n                \"sublevel_alavalikko\",  # www.samediggi.fi\n            ],\n        },\n        \"td\": {\n            \"id\": [\n                \"hakulomake\",  # www.samediggi.fi\n                \"paavalikko_linkit\",  # www.samediggi.fi\n                \"sg_oikea\",  # www.samediggi.fi\n                \"sg_vasen\",  # www.samediggi.fi\n            ],\n            \"class\": [\n                \"modifydate\",\n            ],\n        },\n        \"tr\": {\n            \"id\": [\n                \"sg_ylaosa1\",\n                \"sg_ylaosa2\",\n            ]\n        },\n        \"header\": {\n            \"id\": [\n                \"header\",  # umo.se\n            ],\n            \"class\": [\n                \"nrk-masthead-content cf\",  # nrk.no\n                \"pageHeader \",  # regjeringen.no\n            ],\n        },\n        \"section\": {\n            \"class\": [\n                \"tree-menu current\",  # umo.se\n                \"tree-menu\",  # umo.se\n            ],\n        },\n    }\n\n    for tag, attribs in unwanted_classes_ids.items():\n        for key, values in attribs.items():\n            for value in values:\n                yield check_unwanted_classes_and_ids, tag, key, value\n</code></pre>"},{"location":"reference/test/test_htmlcontentconverter/#corpustools.test.test_htmlcontentconverter.test_unwanted_tag","title":"<code>test_unwanted_tag(unwanted_tag)</code>","text":"<p>Check if unwanted tags are removed.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlcontentconverter.py</code> <pre><code>@parameterized(\n    [\n        \"address\",\n        \"script\",\n        \"style\",\n        \"area\",\n        \"object\",\n        \"meta\",\n        \"hr\",\n        \"nf\",\n        \"mb\",\n        \"ms\",\n        \"img\",\n        \"cite\",\n        \"embed\",\n        \"footer\",\n        \"figcaption\",\n        \"aside\",\n        \"time\",\n        \"figure\",\n        \"nav\",\n        \"select\",\n        \"noscript\",\n        \"iframe\",\n        \"map\",\n        \"colgroup\",\n        \"st1:country-region\",\n        \"v:shapetype\",\n        \"v:shape\",\n        \"st1:metricconverter\",\n        \"fb:comments\",\n        \"g:plusone\",\n        \"fb:like\",\n    ]\n)\ndef test_unwanted_tag(unwanted_tag):\n\"\"\"Check if unwanted tags are removed.\"\"\"\n    content_xml = html.document_fromstring(\n        \"&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;p1&lt;/p&gt;&lt;%s/&gt;&lt;p&gt;p2&lt;/p2&gt;&lt;/body&gt;\" \"&lt;/html&gt;\" % unwanted_tag\n    )\n    got = htmlcontentconverter.HTMLBeautifier(content_xml).beautify()\n    want = html.document_fromstring(\n        \"&lt;html&gt;&lt;head/&gt;\" \"&lt;body&gt;&lt;p&gt;p1&lt;/p&gt;&lt;p&gt;p2\" \"&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\"\n    )\n\n    assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_htmlconverter/","title":"test_htmlconverter","text":"<p>Test conversion of html files.</p>"},{"location":"reference/test/test_htmlconverter/#corpustools.test.test_htmlconverter.TestHTMLConverter","title":"<code>TestHTMLConverter</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test conversion of html documents.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlconverter.py</code> <pre><code>class TestHTMLConverter(XMLTester):\n\"\"\"Test conversion of html documents.\"\"\"\n\n    @parameterized.expand(\n        [\n            (\n                \"bare_text_after_p\",\n                \"orig/sme/admin/ugga.html\",\n\"\"\"\n            &lt;html lang=\"no\" dir=\"ltr\"&gt;\n                &lt;head&gt;\n                    &lt;title&gt;\n                        Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre\n                    &lt;/title&gt;\n                &lt;/head&gt;\n                &lt;body&gt;\n                    &lt;div id=\"bbody\"&gt;\n                        &lt;div id=\"mframe\"&gt;\n                            &lt;div class=\"sub\" id=\"masterpage\"&gt;\n                                &lt;div id=\"mpage\"&gt;\n                                    &lt;h1&gt;G\u00e5 St\u00e1dd\u00e1&lt;/h1&gt;\n                                    &lt;div class=\"ingress\"&gt;\n                                        &lt;font size=\"3\"&gt;\n                                            &lt;font&gt;\n                                                G\u00e5 \u00c5N\n                                                &lt;span&gt;\n                                                &lt;/span&gt;\n                                            &lt;/font&gt;\n                                        &lt;/font&gt;\n                                    &lt;/div&gt;\n                                &lt;/div&gt;\n                            &lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/body&gt;\n            &lt;/html&gt;\n            \"\"\",\n\"\"\"\n            &lt;document&gt;\n                &lt;header&gt;\n                    &lt;title&gt;Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre&lt;/title&gt;\n                &lt;/header&gt;\n                &lt;body&gt;\n                    &lt;p type=\"title\"&gt;G\u00e5 St\u00e1dd\u00e1&lt;/p&gt;\n                    &lt;p&gt;G\u00e5 \u00c5N&lt;/p&gt;\n                    &lt;p&gt;&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n            \"\"\",\n            ),\n            (\n                \"bare_text_after_list\",\n                \"orig/sme/admin/ugga.html\",\n\"\"\"\n            &lt;html lang=\"no\" dir=\"ltr\"&gt;\n                &lt;body&gt;\n                    &lt;UL&gt;\n                        &lt;LI&gt;&lt;A href=\"http://www.soff.no\"&gt;www.soff.no&lt;/A&gt;\n                        &lt;LI&gt;&lt;A href=\"http://www.soff.uit.no\"&gt;www.soff.uit.no&lt;/A&gt; &lt;/LI&gt;\n                    &lt;/UL&gt;\n                    &lt;CENTER&gt;&lt;SMALL&gt;\n                            &lt;a href='http://www.fmno.no'&gt;Fylkesmannen i Nordland &amp;copy; 2005&lt;/a&gt;\n                    &lt;/SMALL&gt;&lt;/CENTER&gt;\n                &lt;/body&gt;\n            &lt;/html&gt;\n            \"\"\",  # nopep8\n                DOCUMENT_TEMPLATE.format(\n\"\"\"\n                    &lt;list&gt;\n                        &lt;p type=\"listitem\"&gt;www.soff.no&lt;/p&gt;\n                        &lt;p type=\"listitem\"&gt;www.soff.uit.no&lt;/p&gt;\n                    &lt;/list&gt;\n                    &lt;p&gt;Fylkesmannen i Nordland \u00a9 2005&lt;/p&gt;\n            \"\"\"\n                ),\n            ),\n            (\n                \"body_bare_text\",\n                \"orig/sme/admin/ugga.html\",\n\"\"\"\n            &lt;html lang=\"no\" dir=\"ltr\"&gt;\n                &lt;head&gt;\n                    &lt;title&gt;\n                        Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre\n                    &lt;/title&gt;\n                &lt;/head&gt;\n                &lt;body&gt;\n                    &lt;div id=\"bbody\"&gt;\n                        &lt;div id=\"mframe\"&gt;\n                            &lt;div class=\"sub\" id=\"masterpage\"&gt;\n                                &lt;div id=\"mpage\"&gt;\n                                    &lt;div class=\"ingress\"&gt;\n                                        &lt;font size=\"3\"&gt;\n                                            &lt;font&gt;\n                                                G\u00e5 \u00c5N\n                                                &lt;span&gt;\n                                                &lt;/span&gt;\n                                            &lt;/font&gt;\n                                        &lt;/font&gt;\n                                    &lt;/div&gt;\n                                &lt;/div&gt;\n                            &lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/body&gt;\n            &lt;/html&gt;\n            \"\"\",\n\"\"\"\n            &lt;document&gt;\n                &lt;header&gt;\n                    &lt;title&gt;Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre&lt;/title&gt;\n                &lt;/header&gt;\n                &lt;body&gt;\n                    &lt;p&gt;G\u00e5 \u00c5N&lt;/p&gt;\n                    &lt;p&gt;&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n            \"\"\",\n            ),\n            (\n                \"script_with_tail\",\n                \"orig/sme/admin/ugga.html\",\n\"\"\"\n            &lt;html lang=\"no\" dir=\"ltr\"&gt;\n                &lt;head&gt;\n                    &lt;title&gt;\n                        Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre\n                    &lt;/title&gt;\n                &lt;/head&gt;\n                &lt;body&gt;\n                    &lt;p&gt;abba&lt;/p&gt;\n                        &lt;script&gt;\n                        &lt;/script&gt;uffda\n                    &lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/html&gt;\n            \"\"\",\n\"\"\"\n            &lt;document&gt;\n                &lt;header&gt;\n                    &lt;title&gt;Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre&lt;/title&gt;\n                &lt;/header&gt;\n                &lt;body&gt;\n                    &lt;p&gt;abba&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n            \"\"\",\n            ),\n        ]\n    )\n    def test_convert2intermediate(self, testname, filename, content, want):\n\"\"\"Check that convoluted html is correctly converted to xml.\"\"\"\n        with testfixtures.TempDirectory() as temp_dir:\n            content = content.encode(\"utf8\")\n            temp_dir.write(filename, content)\n            got = htmlcontentconverter.convert2intermediate(\n                os.path.join(temp_dir.path, filename)\n            )\n            self.assertXmlEqual(got, etree.fromstring(want))\n\n    def test_content(self):\n\"\"\"Check that content really is real utf-8.\"\"\"\n        content = \"\"\"\n            &lt;!DOCTYPE html&gt;\n            &lt;html lang=\"sma-NO\"&gt;\n                &lt;head&gt;\n                    &lt;meta name=\"viewport\" content=\"width=device-width,\n                    initial-scale=1.0\"&gt;\n                &lt;/head&gt;\n                &lt;body&gt;\n                    &lt;h1&gt;\u00ef \u00e5&lt;/h1&gt;\n                &lt;/body&gt;\n            &lt;/html&gt;\n        \"\"\".encode(\n            encoding=\"utf-8\"\n        )\n        want = html.fromstring(\n\"\"\"\n            &lt;html lang=\"sma-NO\"&gt;\n                &lt;head&gt;\n                    &lt;meta name=\"viewport\" content=\"width=device-width,\n                    initial-scale=1.0\"&gt;\n                &lt;/head&gt;\n                &lt;body&gt;\n                    &lt;h1&gt;&amp;#239; &amp;#229;&lt;/h1&gt;\n                &lt;/body&gt;\n            &lt;/html&gt;\n        \"\"\"\n        )\n        filename = \"orig/sme/admin/ugga.html\"\n        with testfixtures.TempDirectory() as temp_dir:\n            temp_dir.write(filename, content)\n            got = htmlconverter.to_html_elt(os.path.join(temp_dir.path, filename))\n\n            self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_htmlconverter/#corpustools.test.test_htmlconverter.TestHTMLConverter.test_content","title":"<code>test_content()</code>","text":"<p>Check that content really is real utf-8.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlconverter.py</code> <pre><code>def test_content(self):\n\"\"\"Check that content really is real utf-8.\"\"\"\n    content = \"\"\"\n        &lt;!DOCTYPE html&gt;\n        &lt;html lang=\"sma-NO\"&gt;\n            &lt;head&gt;\n                &lt;meta name=\"viewport\" content=\"width=device-width,\n                initial-scale=1.0\"&gt;\n            &lt;/head&gt;\n            &lt;body&gt;\n                &lt;h1&gt;\u00ef \u00e5&lt;/h1&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;\n    \"\"\".encode(\n        encoding=\"utf-8\"\n    )\n    want = html.fromstring(\n\"\"\"\n        &lt;html lang=\"sma-NO\"&gt;\n            &lt;head&gt;\n                &lt;meta name=\"viewport\" content=\"width=device-width,\n                initial-scale=1.0\"&gt;\n            &lt;/head&gt;\n            &lt;body&gt;\n                &lt;h1&gt;&amp;#239; &amp;#229;&lt;/h1&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;\n    \"\"\"\n    )\n    filename = \"orig/sme/admin/ugga.html\"\n    with testfixtures.TempDirectory() as temp_dir:\n        temp_dir.write(filename, content)\n        got = htmlconverter.to_html_elt(os.path.join(temp_dir.path, filename))\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_htmlconverter/#corpustools.test.test_htmlconverter.TestHTMLConverter.test_convert2intermediate","title":"<code>test_convert2intermediate(testname, filename, content, want)</code>","text":"<p>Check that convoluted html is correctly converted to xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlconverter.py</code> <pre><code>@parameterized.expand(\n    [\n        (\n            \"bare_text_after_p\",\n            \"orig/sme/admin/ugga.html\",\n\"\"\"\n        &lt;html lang=\"no\" dir=\"ltr\"&gt;\n            &lt;head&gt;\n                &lt;title&gt;\n                    Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre\n                &lt;/title&gt;\n            &lt;/head&gt;\n            &lt;body&gt;\n                &lt;div id=\"bbody\"&gt;\n                    &lt;div id=\"mframe\"&gt;\n                        &lt;div class=\"sub\" id=\"masterpage\"&gt;\n                            &lt;div id=\"mpage\"&gt;\n                                &lt;h1&gt;G\u00e5 St\u00e1dd\u00e1&lt;/h1&gt;\n                                &lt;div class=\"ingress\"&gt;\n                                    &lt;font size=\"3\"&gt;\n                                        &lt;font&gt;\n                                            G\u00e5 \u00c5N\n                                            &lt;span&gt;\n                                            &lt;/span&gt;\n                                        &lt;/font&gt;\n                                    &lt;/font&gt;\n                                &lt;/div&gt;\n                            &lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;\n        \"\"\",\n\"\"\"\n        &lt;document&gt;\n            &lt;header&gt;\n                &lt;title&gt;Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre&lt;/title&gt;\n            &lt;/header&gt;\n            &lt;body&gt;\n                &lt;p type=\"title\"&gt;G\u00e5 St\u00e1dd\u00e1&lt;/p&gt;\n                &lt;p&gt;G\u00e5 \u00c5N&lt;/p&gt;\n                &lt;p&gt;&lt;/p&gt;\n            &lt;/body&gt;\n        &lt;/document&gt;\n        \"\"\",\n        ),\n        (\n            \"bare_text_after_list\",\n            \"orig/sme/admin/ugga.html\",\n\"\"\"\n        &lt;html lang=\"no\" dir=\"ltr\"&gt;\n            &lt;body&gt;\n                &lt;UL&gt;\n                    &lt;LI&gt;&lt;A href=\"http://www.soff.no\"&gt;www.soff.no&lt;/A&gt;\n                    &lt;LI&gt;&lt;A href=\"http://www.soff.uit.no\"&gt;www.soff.uit.no&lt;/A&gt; &lt;/LI&gt;\n                &lt;/UL&gt;\n                &lt;CENTER&gt;&lt;SMALL&gt;\n                        &lt;a href='http://www.fmno.no'&gt;Fylkesmannen i Nordland &amp;copy; 2005&lt;/a&gt;\n                &lt;/SMALL&gt;&lt;/CENTER&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;\n        \"\"\",  # nopep8\n            DOCUMENT_TEMPLATE.format(\n\"\"\"\n                &lt;list&gt;\n                    &lt;p type=\"listitem\"&gt;www.soff.no&lt;/p&gt;\n                    &lt;p type=\"listitem\"&gt;www.soff.uit.no&lt;/p&gt;\n                &lt;/list&gt;\n                &lt;p&gt;Fylkesmannen i Nordland \u00a9 2005&lt;/p&gt;\n        \"\"\"\n            ),\n        ),\n        (\n            \"body_bare_text\",\n            \"orig/sme/admin/ugga.html\",\n\"\"\"\n        &lt;html lang=\"no\" dir=\"ltr\"&gt;\n            &lt;head&gt;\n                &lt;title&gt;\n                    Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre\n                &lt;/title&gt;\n            &lt;/head&gt;\n            &lt;body&gt;\n                &lt;div id=\"bbody\"&gt;\n                    &lt;div id=\"mframe\"&gt;\n                        &lt;div class=\"sub\" id=\"masterpage\"&gt;\n                            &lt;div id=\"mpage\"&gt;\n                                &lt;div class=\"ingress\"&gt;\n                                    &lt;font size=\"3\"&gt;\n                                        &lt;font&gt;\n                                            G\u00e5 \u00c5N\n                                            &lt;span&gt;\n                                            &lt;/span&gt;\n                                        &lt;/font&gt;\n                                    &lt;/font&gt;\n                                &lt;/div&gt;\n                            &lt;/div&gt;\n                        &lt;/div&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;\n        \"\"\",\n\"\"\"\n        &lt;document&gt;\n            &lt;header&gt;\n                &lt;title&gt;Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre&lt;/title&gt;\n            &lt;/header&gt;\n            &lt;body&gt;\n                &lt;p&gt;G\u00e5 \u00c5N&lt;/p&gt;\n                &lt;p&gt;&lt;/p&gt;\n            &lt;/body&gt;\n        &lt;/document&gt;\n        \"\"\",\n        ),\n        (\n            \"script_with_tail\",\n            \"orig/sme/admin/ugga.html\",\n\"\"\"\n        &lt;html lang=\"no\" dir=\"ltr\"&gt;\n            &lt;head&gt;\n                &lt;title&gt;\n                    Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre\n                &lt;/title&gt;\n            &lt;/head&gt;\n            &lt;body&gt;\n                &lt;p&gt;abba&lt;/p&gt;\n                    &lt;script&gt;\n                    &lt;/script&gt;uffda\n                &lt;/p&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;\n        \"\"\",\n\"\"\"\n        &lt;document&gt;\n            &lt;header&gt;\n                &lt;title&gt;Visit Stetind: Hist\u00e5vrr\u00e5: Nasjon\u00e1lv\u00e1rre&lt;/title&gt;\n            &lt;/header&gt;\n            &lt;body&gt;\n                &lt;p&gt;abba&lt;/p&gt;\n            &lt;/body&gt;\n        &lt;/document&gt;\n        \"\"\",\n        ),\n    ]\n)\ndef test_convert2intermediate(self, testname, filename, content, want):\n\"\"\"Check that convoluted html is correctly converted to xml.\"\"\"\n    with testfixtures.TempDirectory() as temp_dir:\n        content = content.encode(\"utf8\")\n        temp_dir.write(filename, content)\n        got = htmlcontentconverter.convert2intermediate(\n            os.path.join(temp_dir.path, filename)\n        )\n        self.assertXmlEqual(got, etree.fromstring(want))\n</code></pre>"},{"location":"reference/test/test_htmlconverter/#corpustools.test.test_htmlconverter.test_conversion","title":"<code>test_conversion(testname, html_str, xml_str)</code>","text":"<p>Check that the tidied html is correctly converted to corpus xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_htmlconverter.py</code> <pre><code>@parameterized(\n    [\n        (\n            \"ul-li-a\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;li&gt;\"\n                \"        &lt;a&gt;Geah\u010d\u00e1&lt;/a&gt;\"\n                \"      &lt;/li&gt;\"\n                \"      &lt;li&gt;\"\n                \"        &lt;a&gt;Geah\u010d\u00e1&lt;/a&gt;\"\n                \"      &lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;'\n                \"               Geah\u010d\u00e1\"\n                \"      &lt;/p&gt;\"\n                '      &lt;p type=\"listitem\"&gt;'\n                \"               Geah\u010d\u00e1\"\n                \"      &lt;/p&gt;\"\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"blockquote-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"  &lt;blockquote&gt;\"\n                \"      &lt;p&gt;\u00abat like rettigheter ikke n\u00f8dvendigvis trenger\"\n                \"  &lt;/blockquote&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"  &lt;p&gt;\"\n                '      &lt;span type=\"quote\"&gt;'\n                \"               \u00abat like rettigheter ikke n\u00f8dvendigvis trenger\"\n                \"      &lt;/span&gt;\"\n                \"  &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-a-h2\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"            &lt;a&gt;\"\n                \"                &lt;h2&gt;\"\n                \"                    Pressesenter\"\n                \"                &lt;/h2&gt;\"\n                \"            &lt;/a&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"title\"&gt;' \"            Pressesenter\" \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-a-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"            &lt;a&gt;\"\n                \"                &lt;p&gt;\"\n                \"                    Pressesenter\"\n                \"                &lt;/p&gt;\"\n                \"            &lt;/a&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"  &lt;p&gt;\" \"      Pressesenter\" \"  &lt;/p&gt;\"),\n        ),\n        (\n            \"div-b-and-br\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"  &lt;div&gt;\"\n                \"      &lt;b&gt;\"\n                \"               Ohcan\u00e1igemearri:\"\n                \"      &lt;/b&gt;\"\n                \"      &lt;br /&gt;\"\n                \"           15.09.2006.\"\n                \"  &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"  &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"               Ohcan\u00e1igemearri:\"\n                \"      &lt;/em&gt;\"\n                \"  &lt;/p&gt;\"\n                \"  &lt;p&gt;\"\n                \"           15.09.2006.\"\n                \"  &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-div-a-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"  &lt;div&gt;\"\n                \"      &lt;div&gt;\"\n                \"    &lt;a&gt;\"\n                \"          &lt;span&gt;John-Marcus Kuhmunen&lt;/span&gt;\"\n                \"    &lt;/a&gt;\"\n                \"      &lt;/div&gt;\"\n                \"  &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"  &lt;p&gt;\" \"           John-Marcus Kuhmunen\" \"  &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-div-a-and-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"  &lt;div&gt;\"\n                \"      &lt;div&gt;\"\n                \"    &lt;a&gt;Geah\u010da buot \u00e1\u0161\u0161eb\u00e1hp\u00e1riid&lt;/a&gt;\"\n                '    &lt;div style=\"clear: both\"&gt;&lt;/div&gt;'\n                \"      &lt;/div&gt;\"\n                \"  &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"  &lt;p&gt;Geah\u010da buot \u00e1\u0161\u0161eb\u00e1hp\u00e1riid&lt;/p&gt;\"),\n        ),\n        (\n            \"div-font-span-font\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;font&gt;\"\n                \"        &lt;span&gt;\"\n                \"          &lt;font&gt;\"\n                \"            maajjen\"\n                \"          &lt;/font&gt;\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/font&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      maajjen\" \"   &lt;/p&gt;\"),\n        ),\n        (\n            \"div-i-font-span-font\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;i&gt;\"\n                \"        &lt;font&gt;\"\n                \"          &lt;span&gt;\"\n                \"            &lt;font&gt;\"\n                \"              listeforslag,\"\n                \"            &lt;/font&gt;\"\n                \"          &lt;/span&gt;\"\n                \"        &lt;/font&gt;\"\n                \"      &lt;/i&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"italic\"&gt;'\n                \"        listeforslag,\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-h1-and-a\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;h1&gt;Terje Riis-Johansen&lt;/h1&gt;\"\n                \"      &lt;a&gt;\"\n                \"        Taler og artikler\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"title\"&gt;'\n                \"      Terje Riis-Johansen\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      Taler og artikler\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-h1-and-text-and-br-and-a\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;h1&gt;Ledige stillingar&lt;/h1&gt;\"\n                \"      No kan du s\u00f8ke jobb.&lt;br /&gt;\"\n                \"      &amp;#160;&lt;br /&gt;\"\n                \"      Sjekk ogs\u00e5 v\u00e5re rekrutteringssider\"\n                '      &lt;a title=\"Jobb i AD\"&gt;'\n                \"        Jobb i AD\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"title\"&gt;'\n                \"      Ledige stillingar\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      No kan du s\u00f8ke jobb.\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      Sjekk ogs\u00e5 v\u00e5re rekrutteringssider\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      Jobb i AD\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-hx\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;h1&gt;S\u00e1medikki doarjja&lt;/h1&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format('    &lt;p type=\"title\"&gt;S\u00e1medikki doarjja&lt;/p&gt;'),\n        ),\n        (\n            \"div-p-and-font\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;p&gt;Rikspolitiske verv&lt;/p&gt;\"\n                \"      &lt;font&gt;abc&lt;/font&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;Rikspolitiske verv&lt;/p&gt;\" \"    &lt;p&gt;abc&lt;/p&gt;\"),\n        ),\n        (\n            \"div-p-strong-and-br-and-text\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"  &lt;div&gt;\"\n                \"      &lt;p&gt;\"\n                \"        &lt;strong&gt;\"\n                \"          Poastadreassa:\"\n                \"        &lt;/strong&gt;\"\n                \"        &lt;br /&gt;\"\n                \"        Postboks 8036 Dep\"\n                \"        &lt;br /&gt;\"\n                \"        0030 Oslo\"\n                \"        &lt;br /&gt;\"\n                \"      &lt;/p&gt;\"\n                \"      E-poasta:\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"italic\"&gt;'\n                \"        Poastadreassa:\"\n                \"      &lt;/em&gt;\"\n                \"      Postboks 8036 Dep\"\n                \"      0030 Oslo\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      E-poasta:\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;span&gt;\"\n                \"        Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010\"\n                \"      &lt;/span&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-small-a\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;small&gt;\"\n                \"        &lt;a&gt;\"\n                \"          Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010\"\n                \"        &lt;/a&gt;\"\n                \"      &lt;/small&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"      &lt;p&gt;Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010&lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-small\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;small&gt;\"\n                \"         Harrieth Aira\"\n                \"      &lt;/small&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"      &lt;p&gt;Harrieth Aira&lt;/p&gt;\"),\n        ),\n        (\n            \"div-p-small\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;p&gt;\"\n                \"        &lt;small&gt;\"\n                \"          div-p-small\"\n                \"        &lt;/small&gt;\"\n                \"      &lt;/p&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      div-p-small\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"div-em-p-em\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;em&gt;\"\n                \"        &lt;p&gt;\"\n                \"          &lt;em&gt;\"\n                \"            Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010\"\n                \"          &lt;/em&gt;\"\n                \"        &lt;/p&gt;\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"italic\"&gt;'\n                \"        Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-a-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;a&gt;\"\n                \"        &lt;div&gt;\"\n                \"          Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010\"\n                \"        &lt;/div&gt;\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      Gulaskuddan\u00e1igimearri: guovvam\u00e1nu 20. b. 2010\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-table\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;table&gt;\"\n                \"        &lt;tbody&gt;\"\n                \"          &lt;tr&gt;\"\n                \"            &lt;td&gt;\"\n                \"              abc &lt;a&gt;Nynorsk&lt;/a&gt; def\"\n                \"            &lt;/td&gt;\"\n                \"          &lt;/tr&gt;\"\n                \"        &lt;/tbody&gt;\"\n                \"      &lt;/table&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"      &lt;p&gt;\"\n                \"        abc\"\n                \"      &lt;/p&gt;\"\n                \"      &lt;p&gt;\"\n                \"        Nynorsk\"\n                \"      &lt;/p&gt;\"\n                \"      &lt;p&gt;\"\n                \"        def\"\n                \"      &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-text-and-br-and-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      T\u00e4ll\u00e4 viikolla&lt;br /&gt;\"\n                \"      &lt;br /&gt;\"\n                \"      SPN:n hallitus\"\n                \"      &lt;br /&gt;\"\n                \"      &lt;div /&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      T\u00e4ll\u00e4 viikolla\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      SPN:n hallitus\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-text-and-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      Laitan blogini lukijoille\"\n                \"      &lt;span&gt;\"\n                \"        Voimassa oleva\"\n                \"      &lt;/span&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;Laitan blogini lukijoille&lt;/p&gt;\" \"    &lt;p&gt;Voimassa oleva&lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-text-and-a-text\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      Almmuhan Kuhmunen, John-Marcus.\"\n                \"      &lt;a&gt;Halloi!&lt;/a&gt;\"\n                \"      Ma\u014bumust\u00e1 rievdaduvvon 26.06.2009\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      Almmuhan Kuhmunen, John-Marcus.\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      Halloi!\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      Ma\u014bumust\u00e1 rievdaduvvon 26.06.2009\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-ul-li-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;ul&gt;\"\n                \"        &lt;li&gt;\"\n                \"          &lt;div&gt;\"\n                \"            FoU\"\n                \"          &lt;/div&gt;\"\n                \"         &lt;/li&gt;\"\n                \"      &lt;/ul&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\" '      &lt;p type=\"listitem\"&gt;FoU&lt;/p&gt;' \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"div-ol-li-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;ol&gt;\"\n                \"        &lt;li&gt;\"\n                \"          &lt;div&gt;\"\n                \"            Teknologiaovd\u00e1nahttin ja DGT (IKT)\"\n                \"          &lt;/div&gt;\"\n                \"        &lt;/li&gt;\"\n                \"      &lt;/ol&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;Teknologiaovd\u00e1nahttin ja DGT (IKT)&lt;/p&gt;'\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"div-div-div-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;div&gt;\"\n                \"        &lt;div&gt;\"\n                \"          &lt;p&gt;S\u00e1mediggi lea juolludan doarjaga.&lt;/p&gt;\"\n                \"        &lt;/div&gt;\"\n                \"      &lt;/div&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" \"      S\u00e1mediggi lea juolludan doarjaga.\" \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-div-div-a\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;div&gt;\"\n                \"        &lt;div&gt;\"\n                \"          &lt;a&gt;\"\n                \"            &lt;span&gt;John-Marcus Kuhmunen&lt;/span&gt;\"\n                \"          &lt;/a&gt;\"\n                \"        &lt;/div&gt;\"\n                \"      &lt;/div&gt;\"\n                \"  &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      John-Marcus Kuhmunen\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"font-span-font-sub\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;font&gt;\"\n                \"      &lt;span&gt;\"\n                \"        &lt;font&gt;\"\n                \"          &lt;sub&gt;\"\n                \"            aa\"\n                \"          &lt;/sub&gt;\"\n                \"        &lt;/font&gt;\"\n                \"      &lt;/span&gt;\"\n                \"    &lt;/font&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      aa\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"h1-6\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"  &lt;h1&gt;header1&lt;/h1&gt;\"\n                \"  &lt;h2&gt;header2&lt;/h2&gt;\"\n                \"  &lt;h3&gt;header3&lt;/h3&gt;\"\n                \"  &lt;h4&gt;header4&lt;/h4&gt;\"\n                \"  &lt;h5&gt;header5&lt;/h5&gt;\"\n                \"  &lt;h6&gt;header6&lt;/h6&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"title\"&gt;header1&lt;/p&gt;'\n                '    &lt;p type=\"title\"&gt;header2&lt;/p&gt;'\n                '    &lt;p type=\"title\"&gt;header3&lt;/p&gt;'\n                '    &lt;p type=\"title\"&gt;header4&lt;/p&gt;'\n                '    &lt;p type=\"title\"&gt;header5&lt;/p&gt;'\n                '    &lt;p type=\"title\"&gt;header6&lt;/p&gt;'\n            ),\n        ),\n        (\n            \"h1-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;h1&gt;\"\n                \"      &lt;b&gt;Phone&lt;/b&gt;\"\n                \"    &lt;/h1&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format('    &lt;p type=\"title\"&gt;' \"      Phone\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"note-i\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;note&gt;Geah\u010da &lt;i&gt;S\u00e1mi skuvlahistorj\u00e1 2. -girjjis&lt;/i&gt;&lt;/note&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;Geah\u010da&lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"italic\"&gt;S\u00e1mi skuvlahistorj\u00e1 2. -girjjis&lt;/em&gt;'\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"li-a-b-font\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;li&gt;\"\n                \"      &lt;a&gt;\"\n                \"        &lt;b&gt;\"\n                \"          &lt;font&gt;\"\n                \"            Deltakerloven.\"\n                \"          &lt;/font&gt;\"\n                \"        &lt;/b&gt;\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/li&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"listitem\"&gt;'\n                '      &lt;em type=\"bold\"&gt;'\n                \"        Deltakerloven.\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"ul-strong-li-strong-a-strong\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;strong&gt;\"\n                \"        &lt;li&gt;\"\n                \"          &lt;strong&gt;\"\n                \"            &lt;a&gt;\"\n                \"              &lt;strong&gt;\"\n                \"                Deltakerloven.\"\n                \"              &lt;/strong&gt;\"\n                \"            &lt;/a&gt;\"\n                \"          &lt;/strong&gt;\"\n                \"        &lt;/li&gt;\"\n                \"      &lt;/strong&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;'\n                \"        Deltakerloven.\"\n                \"      &lt;/p&gt;\"\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"ul-li-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;li&gt;\"\n                \"        &lt;div&gt;\"\n                \"          FoU\"\n                \"        &lt;/div&gt;\"\n                \"      &lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\" '      &lt;p type=\"listitem\"&gt;FoU&lt;/p&gt;' \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"nobr-a\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;nobr&gt;\"\n                \"      &lt;a title='Aktuelt - Nyheiter - 2009'&gt;\"\n                \"        2009\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/nobr&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;2009&lt;/p&gt;\"),\n        ),\n        (\n            \"p-a-note\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;a name=\"[1]\"&gt;[1] &lt;note&gt;Vestertana.&lt;/note&gt;&lt;/a&gt;'\n                '      &lt;a name=\"[2]\"&gt;[2] &lt;note&gt;Fra 1918.&lt;/note&gt;&lt;/a&gt;'\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;[1] Vestertana. [2] Fra 1918. &lt;/p&gt;\"),\n        ),\n        (\n            \"wbr\",\n            (\"&lt;html&gt;\" \"  &lt;body&gt;\" \"    &lt;wbr/&gt;\" \"  &lt;/body&gt;\" \"&lt;/html&gt;\"),\n            DOCUMENT_TEMPLATE.format(\"\"),\n        ),\n        (\n            \"i-ol-li\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;i&gt;\"\n                \"      &lt;ol&gt;\"\n                \"        &lt;li&gt;wtf ol!&lt;/li&gt;\"\n                \"      &lt;/ol&gt;\"\n                \"    &lt;/i&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\" '      &lt;p type=\"listitem\"&gt;wtf ol!&lt;/p&gt;' \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"i-ul-li\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;i&gt;\"\n                \"      &lt;ul&gt;\"\n                \"        &lt;li&gt;wtf ul!&lt;/li&gt;\"\n                \"      &lt;/ul&gt;\"\n                \"    &lt;/i&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\" '      &lt;p type=\"listitem\"&gt;wtf ul!&lt;/p&gt;' \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"ol-i-li\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ol&gt;\"\n                \"      &lt;i&gt;\"\n                \"        &lt;li&gt; L\u00e6rer K. Bruflodt&lt;/li&gt;\"\n                \"      &lt;/i&gt;\"\n                \"    &lt;/ol&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;L\u00e6rer K. Bruflodt &lt;/p&gt;'\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"ol-li-ol-li\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                '    &lt;ol type=\"1\" start=\"1\"&gt;'\n                \"      &lt;li&gt;1&lt;/li&gt;\"\n                \"      &lt;li&gt;2\"\n                \"        &lt;ol&gt;\"\n                \"          &lt;li&gt;2.1&lt;/li&gt;\"\n                \"          &lt;li&gt;2.2&lt;/li&gt;\"\n                \"          &lt;li&gt;2.3&lt;/li&gt;\"\n                \"        &lt;/ol&gt;\"\n                \"      &lt;/li&gt;\"\n                \"      &lt;li&gt;3&lt;/li&gt;\"\n                \"      &lt;li&gt;4&lt;/li&gt;\"\n                \"      &lt;li&gt;5&lt;/li&gt;\"\n                \"    &lt;/ol&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;1&lt;/p&gt;'\n                '      &lt;p type=\"listitem\"&gt;'\n                \"        2\"\n                \"        &lt;list&gt;\"\n                '          &lt;p type=\"listitem\"&gt;2.1&lt;/p&gt;'\n                '          &lt;p type=\"listitem\"&gt;2.2&lt;/p&gt;'\n                '          &lt;p type=\"listitem\"&gt;2.3&lt;/p&gt;'\n                \"        &lt;/list&gt;\"\n                \"      &lt;/p&gt;\"\n                '      &lt;p type=\"listitem\"&gt;3&lt;/p&gt;'\n                '      &lt;p type=\"listitem\"&gt;4&lt;/p&gt;'\n                '      &lt;p type=\"listitem\"&gt;5&lt;/p&gt;'\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"ul-li-ul-li\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                '    &lt;ul type=\"1\" start=\"1\"&gt;'\n                \"      &lt;li&gt;1&lt;/li&gt;\"\n                \"      &lt;li&gt;2\"\n                \"        &lt;ul&gt;\"\n                \"          &lt;li&gt;2.1&lt;/li&gt;\"\n                \"          &lt;li&gt;2.2&lt;/li&gt;\"\n                \"          &lt;li&gt;2.3&lt;/li&gt;\"\n                \"        &lt;/ul&gt;\"\n                \"      &lt;/li&gt;\"\n                \"      &lt;li&gt;3&lt;/li&gt;\"\n                \"      &lt;li&gt;4&lt;/li&gt;\"\n                \"      &lt;li&gt;5&lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;1&lt;/p&gt;'\n                '      &lt;p type=\"listitem\"&gt;'\n                \"        2\"\n                \"        &lt;list&gt;\"\n                '          &lt;p type=\"listitem\"&gt;2.1&lt;/p&gt;'\n                '          &lt;p type=\"listitem\"&gt;2.2&lt;/p&gt;'\n                '          &lt;p type=\"listitem\"&gt;2.3&lt;/p&gt;'\n                \"        &lt;/list&gt;\"\n                \"      &lt;/p&gt;\"\n                '      &lt;p type=\"listitem\"&gt;3&lt;/p&gt;'\n                '      &lt;p type=\"listitem\"&gt;4&lt;/p&gt;'\n                '      &lt;p type=\"listitem\"&gt;5&lt;/p&gt;'\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"p-a-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;a name=\"hov8.noteref1\"&gt;'\n                \"        &lt;b&gt;\"\n                \"          [1]\"\n                \"        &lt;/b&gt;\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        [1]\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"p-b-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                \"      &lt;b&gt;\"\n                \"        &lt;span&gt;\"\n                \"          S\u00e1mi oahpponeavvojahki \u2013 S\u00e1mi m\u00e1httolokten\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/b&gt;\"\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        S\u00e1mi oahpponeavvojahki \u2013 S\u00e1mi m\u00e1httolokten\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"p-font-font-b-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                \"      &lt;font&gt;\"\n                \"        &lt;font&gt;\"\n                \"          &lt;b&gt;\"\n                \"            &lt;span&gt;\"\n                \"              Bargit\"\n                \"            &lt;/span&gt;\"\n                \"          &lt;/b&gt;\"\n                \"          &lt;span&gt;\"\n                \"            fertejit dahkat.\"\n                \"          &lt;/span&gt;\"\n                \"        &lt;/font&gt;\"\n                \"      &lt;/font&gt;\"\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;Bargit&lt;/em&gt; fertejit dahkat.'\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-font-font-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;font&gt;\"\n                \"        &lt;font&gt;\"\n                \"          &lt;p&gt;\"\n                \"            Voksenoppl\u00e6ring\"\n                \"          &lt;/p&gt;\"\n                \"        &lt;/font&gt;\"\n                \"      &lt;/font&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      Voksenoppl\u00e6ring\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"div-font-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;font&gt;\"\n                \"          &lt;p&gt;\"\n                \"            Aerpievuekien daajroe\"\n                \"          &lt;/p&gt;\"\n                \"      &lt;/font&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" \"      Aerpievuekien daajroe\" \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"p-span-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                \"      &lt;span&gt;\"\n                \"        &lt;b&gt;\"\n                \"          s\u00e1mi guovdd\u00e1\u017ea viidideapmi st\u00e1htabu\u0161ehttii\"\n                \"        &lt;/b&gt;\"\n                \"      &lt;/span&gt;\"\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        s\u00e1mi guovdd\u00e1\u017ea viidideapmi st\u00e1htabu\u0161ehttii\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"p-to-p-listitem\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\u2022\u00a0mearridit gielddaid &lt;br /&gt;\"\n                \"\u2022\u00a0ovddidit servodatsihkkarvuo\u0111a&lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"listitem\"&gt;mearridit gielddaid &lt;/p&gt;'\n                '    &lt;p type=\"listitem\"&gt;ovddidit servodatsihkkarvuo\u0111a&lt;/p&gt;'\n            ),\n        ),\n        (\n            \"h3-pb\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;h3&gt;&lt;pb&gt;Kapittel&lt;/pb&gt;&lt;/h3&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format('    &lt;p type=\"title\"&gt;Kapittel&lt;/p&gt;'),\n        ),\n        (\n            \"p-pb\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;&lt;pb&gt;&lt;b&gt;&amp;#167; 1-1.&lt;/b&gt;&lt;/pb&gt;&lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format('    &lt;p&gt;&lt;em type=\"bold\"&gt;&amp;#167; 1-1.&lt;/em&gt;&lt;/p&gt;'),\n        ),\n        (\n            \"ul-li-span-a-span-font\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;li&gt;\"\n                \"        &lt;span&gt;\"\n                \"          &lt;a&gt;\"\n                \"            &lt;span&gt;\"\n                \"              &lt;font&gt;Energiija(EV)&lt;/font&gt;\"\n                \"            &lt;/span&gt;\"\n                \"          &lt;/a&gt;\"\n                \"          &lt;a&gt;\"\n                \"            &lt;font&gt;\"\n                \"              &lt;span&gt;(goallostat)&lt;/span&gt;\"\n                \"            &lt;/font&gt;\"\n                \"          &lt;/a&gt;\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;Energiija(EV) (goallostat)&lt;/p&gt;'\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"ul-li-span-a-font-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;li&gt;\"\n                \"        &lt;span&gt;\"\n                \"          &lt;a&gt;\"\n                \"            &lt;font&gt;\"\n                \"              &lt;span&gt;Oljo &lt;/span&gt;\"\n                \"              &lt;span&gt;(goallostat)&lt;/span&gt;\"\n                \"            &lt;/font&gt;\"\n                \"          &lt;/a&gt;\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;Oljo (goallostat)&lt;/p&gt;'\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"p-span-with-a-span-font-and-a-font-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                \"      &lt;span&gt;\"\n                \"        &lt;a&gt;\"\n                \"          &lt;span&gt;\"\n                \"            &lt;font&gt;Energiija&lt;/font&gt;\"\n                \"          &lt;/span&gt;\"\n                \"        &lt;/a&gt;\"\n                \"        &lt;a&gt;\"\n                \"          &lt;font&gt;\"\n                \"            &lt;span&gt;(goallostat)&lt;/span&gt;\"\n                \"          &lt;/font&gt;\"\n                \"        &lt;/a&gt;\"\n                \"      &lt;/span&gt;\"\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" \"           Energiija (goallostat)\" \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"ul-li-sup\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;li&gt;km&lt;sup&gt;2&lt;/sup&gt;&lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\" '            &lt;p type=\"listitem\"&gt;km 2&lt;/p&gt;' \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"p-sup-a-sup\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                \"      bla bla\"\n                \"      &lt;sup&gt;\"\n                \"        &lt;a&gt;\"\n                \"          &lt;sup&gt;2&lt;/sup&gt;\"\n                \"        &lt;/a&gt;\"\n                \"      &lt;/sup&gt;\"\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      bla bla 2\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"td-a-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;&amp;#160;\"\n                \"      &lt;a&gt;\"\n                \"        &lt;b&gt;\"\n                \"          Innholdsfortegnelse\"\n                \"        &lt;/b&gt;\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        Innholdsfortegnelse\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-a-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;a&gt;\"\n                \"        &lt;div&gt;\"\n                \"          Klara\"\n                \"        &lt;/div&gt;\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      Klara\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"table-tr-td-a-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;table&gt;\"\n                \"      &lt;tr&gt;\"\n                \"        &lt;td&gt;\"\n                \"          &lt;a&gt;\"\n                \"            &lt;p&gt;\"\n                \"              Pressesenter\"\n                \"            &lt;/p&gt;\"\n                \"          &lt;/a&gt;\"\n                \"        &lt;/td&gt;\"\n                \"      &lt;/tr&gt;\"\n                \"     &lt;/table&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"   &lt;p&gt;\" \"     Pressesenter\" \"   &lt;/p&gt;\"),\n        ),\n        (\n            \"td-a\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;a&gt;22 24 91 03&lt;/a&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      22 24 91 03\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"td-b-and-text\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;b&gt;\"\n                \"        \u00c5lkine\"\n                \"      &lt;/b&gt;\"\n                \"      &lt;br /&gt;\"\n                \"      (Guvvie: Grete Austad)\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        \u00c5lkine\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      (Guvvie: Grete Austad)\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;b&gt;\"\n                \"        Albert\"\n                \"      &lt;/b&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        Albert\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"table-tr-td-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;table&gt;\"\n                \"      &lt;tr&gt;\"\n                \"        &lt;td&gt;\"\n                \"          &lt;div&gt;\"\n                \"            &lt;a&gt;&lt;/a&gt;\"\n                \"            &lt;h1&gt;L\u00e1hka&lt;/h1&gt;\"\n                \"            &lt;p&gt;L\u00e1ga&lt;/p&gt;\"\n                \"            &lt;blockquote&gt;\"\n                \"              &lt;p&gt;G\u010d. l\u00e1ga suoidnem\u00e1nu&lt;/p&gt;\"\n                \"            &lt;/blockquote&gt;\"\n                \"            &lt;a&gt;&lt;/a&gt;\"\n                \"            &lt;a&gt;&lt;/a&gt;\"\n                \"          &lt;/div&gt;\"\n                \"        &lt;/td&gt;\"\n                \"      &lt;/tr&gt;\"\n                \"    &lt;/table&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"  &lt;p&gt;&lt;/p&gt;\"\n                '    &lt;p type=\"title\"&gt;L\u00e1hka&lt;/p&gt;'\n                \"    &lt;p&gt;L\u00e1ga&lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;span type=\"quote\"&gt;G\u010d. l\u00e1ga suoidnem\u00e1nu&lt;/span&gt;'\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;&lt;/p&gt;\"\n                \"    &lt;p&gt;&lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-font-span-span-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;font&gt;\"\n                \"        &lt;span&gt;\"\n                \"          &lt;span&gt;\"\n                \"            &lt;span&gt;\"\n                \"              M\u00f8re og Romsdal Fylkkadiggemiellahttu\"\n                \"            &lt;/span&gt;\"\n                \"          &lt;/span&gt;\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/font&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"  &lt;p&gt;\" \"           M\u00f8re og Romsdal Fylkkadiggemiellahttu\" \"  &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-font-span-strong\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;font&gt;\"\n                \"        &lt;span&gt;\"\n                \"          &lt;strong&gt;Politihkala\u0161 doaimmat&lt;/strong&gt;\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/font&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        Politihkala\u0161 doaimmat\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-font-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;font&gt;\"\n                \"        &lt;span&gt;\"\n                \"          St\u00e1hta\u010d\u00e1lli, Eanandoallo- ja biebmodepartemeanta\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/font&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      St\u00e1hta\u010d\u00e1lli, Eanandoallo- ja biebmodepartemeanta\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-font\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;font&gt;Kvirrevitt&lt;/font&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"           Kvirrevitt\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"td-h2-and-text-and-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;h2&gt;\"\n                \"        Departementet ber skoledirekt\u00f8ren om hjelp\"\n                \"      &lt;/h2&gt;\"\n                \"      For \u00e5 kunne \"\n                \"      &lt;p&gt;\"\n                \"        Kirkedepartementet\"\n                \"      &lt;/p&gt;\"\n                \"  &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"title\"&gt;'\n                \"      Departementet ber skoledirekt\u00f8ren om hjelp\"\n                \"    &lt;/p&gt;\"\n                \"   &lt;p&gt;\"\n                \"     For \u00e5 kunne \"\n                \"   &lt;/p&gt;\"\n                \"   &lt;p&gt;\"\n                \"     Kirkedepartementet\"\n                \"   &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-h3-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;h3&gt;\"\n                \"      &lt;span&gt;\"\n                \"        &lt;a&gt;&lt;/a&gt;\"\n                \"        Gulaskuddan\u00e1sahusat&lt;/span&gt;\"\n                \"       &lt;/h3&gt;\"\n                \"     &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"title\"&gt;' \"      Gulaskuddan\u00e1sahusat\" \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-p-and-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;p&gt;\"\n                \"        &lt;b&gt;\"\n                \"          er f\u00f8dt i 1937\"\n                \"        &lt;/b&gt;\"\n                \"      &lt;/p&gt;\"\n                \"      &lt;b&gt;\"\n                \"        arbeidd innafor mange yrke\"\n                \"      &lt;/b&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        er f\u00f8dt i 1937\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        arbeidd innafor mange yrke\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-p-span-span-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;p&gt;\"\n                \"        &lt;span&gt;\"\n                \"          &lt;span&gt;\"\n                \"            &lt;span&gt;\"\n                \"              link\"\n                \"            &lt;/span&gt;\"\n                \"            &lt;span&gt;\"\n                \"              int\"\n                \"            &lt;/span&gt;\"\n                \"            &lt;span&gt;\"\n                \"              h\u00f8ringsinstanser\"\n                \"            &lt;/span&gt;\"\n                \"          &lt;/span&gt;\"\n                \"          &lt;span&gt;\"\n                \"            Gulaskuddan\u00e1sahusat\"\n                \"          &lt;/span&gt;\"\n                \"        &lt;/span&gt;\"\n                \"      &lt;/p&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      link\"\n                \"      int\"\n                \"      h\u00f8ringsinstanser\"\n                \"      Gulaskuddan\u00e1sahusat\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"table-tr-td-with-span-font-and-b-and-p-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;table&gt;\"\n                \"      &lt;tr&gt;\"\n                \"        &lt;td&gt;\"\n                \"          &lt;span&gt;\"\n                \"            &lt;font&gt;Riikka\u010doahkkincealk\u00e1mu\u0161at 2006&lt;/font&gt;\"\n                \"          &lt;/span&gt;\"\n                \"          &lt;b&gt;NSR 38. Riikka\u010doahkkin&lt;/b&gt;\"\n                \"          &lt;p&gt;\"\n                \"            &lt;span&gt;\"\n                \"              Norgga S\u00e1miid Riikkasearvvi \"\n                \"            &lt;/span&gt;\"\n                \"            2006\"\n                \"          &lt;/p&gt;\"\n                \"        &lt;/td&gt;\"\n                \"      &lt;/tr&gt;\"\n                \"    &lt;/table&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;Riikka\u010doahkkincealk\u00e1mu\u0161at 2006&lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        NSR 38. Riikka\u010doahkkin\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      Norgga S\u00e1miid Riikkasearvvi  2006\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-with-span-font-and-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;span&gt;\"\n                \"        &lt;font&gt;\"\n                \"          Riikka\u010doahkkincealk\u00e1mu\u0161at 2006\"\n                \"         &lt;/font&gt;\"\n                \"      &lt;/span&gt;\"\n                \"      &lt;b&gt;NSR 38.&lt;/b&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      Riikka\u010doahkkincealk\u00e1mu\u0161at 2006\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"bold\"&gt;'\n                \"        NSR 38.\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-span\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;&lt;span&gt;N\u00e1italan, 3 m\u00e1n\u00e1&lt;/span&gt;&lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;N\u00e1italan, 3 m\u00e1n\u00e1&lt;/p&gt;\"),\n        ),\n        (\n            \"td-strong\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;strong&gt;Gaskavahkku&lt;/strong&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" '      &lt;em type=\"bold\"&gt;Gaskavahkku&lt;/em&gt;' \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-table-tr-td\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;table&gt;\"\n                \"        &lt;tr&gt;\"\n                \"          &lt;td&gt;Kvirrevitt&lt;/td&gt;\"\n                \"        &lt;/tr&gt;\"\n                \"      &lt;/table&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      Kvirrevitt\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"td-text-and-i-and-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      Nuohta:\"\n                \"      &lt;i&gt;\"\n                \"        Jeg g\u00e5r og rusler p\u00e5 Ringerike\"\n                \"      &lt;/i&gt;\"\n                \"      &lt;p&gt;\"\n                \"        Mii l\u00e6t dal \u010doagganan manga guovllos\"\n                \"      &lt;/p&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\"\n                \"      Nuohta:\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                '      &lt;em type=\"italic\"&gt;'\n                \"        Jeg g\u00e5r og rusler p\u00e5 Ringerike\"\n                \"      &lt;/em&gt;\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      Mii l\u00e6t dal \u010doagganan manga guovllos\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"td-u\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;td&gt;\"\n                \"      &lt;u&gt;\u00c1\u0161\u0161i nr. 54/60:&lt;/u&gt;\"\n                \"    &lt;/td&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" '      &lt;em type=\"bold\"&gt;\u00c1\u0161\u0161i nr. 54/60:&lt;/em&gt;' \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"p-span-u-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;p&gt;\"\n                \"      &lt;span&gt;\"\n                \"        &lt;u&gt;\"\n                \"          &lt;b&gt;\"\n                \"            Tysfjord turistsenter\"\n                \"          &lt;/b&gt;\"\n                \"        &lt;/u&gt;\"\n                \"      &lt;/span&gt;\"\n                \"    &lt;/p&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" '      &lt;em type=\"bold\"&gt;Tysfjord turistsenter&lt;/em&gt;' \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"th-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;th&gt;\"\n                \"      &lt;b&gt;Spr\u00e5ktilbudet&lt;/b&gt;\"\n                \"    &lt;/th&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" '      &lt;em type=\"bold\"&gt;Spr\u00e5ktilbudet&lt;/em&gt;' \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"th-div\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;th&gt;\"\n                \"      &lt;div&gt;\"\n                \"        Jan\"\n                \"      &lt;/div&gt;\"\n                \"    &lt;/th&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      Jan\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"th-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;th&gt;\"\n                \"      &lt;p&gt;Kap. Poasta&lt;/p&gt;\"\n                \"    &lt;/th&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\"    &lt;p&gt;\" \"      Kap. Poasta\" \"    &lt;/p&gt;\"),\n        ),\n        (\n            \"thead\",\n            (\"&lt;html&gt;\" \"  &lt;body&gt;\" \"    &lt;thead&gt;\" \"    &lt;/thead&gt;\" \"  &lt;/body&gt;\" \"&lt;/html&gt;\"),\n            DOCUMENT_TEMPLATE.format(\"\"),\n        ),\n        (\n            \"tr-td-em\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;tr&gt;\"\n                \"      &lt;td&gt;\"\n                \"        &lt;em&gt;\"\n                \"          Kapittel 1\"\n                \"        &lt;/em&gt;\"\n                \"      &lt;/td&gt;\"\n                \"    &lt;/tr&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" \"      &lt;em&gt;\" \"        Kapittel 1\" \"      &lt;/em&gt;\" \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"ul-li-div-p\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;li&gt;\"\n                \"        &lt;div&gt;\"\n                \"          &lt;p&gt;\"\n                \"            Friskt\"\n                \"          &lt;/p&gt;\"\n                \"        &lt;/div&gt;\"\n                \"      &lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;'\n                \"        Friskt\"\n                \"      &lt;/p&gt;\"\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"ul-li-p-i\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;li&gt;\"\n                \"        &lt;i&gt;\"\n                \"          4. Slik spr\u00e5kforholdene\"\n                \"        &lt;/i&gt;\"\n                \"        &lt;p&gt;\"\n                \"          &lt;i&gt;\"\n                \"            Som alle andre\"\n                \"          &lt;/i&gt;\"\n                \"        &lt;/p&gt;\"\n                \"        &lt;p&gt;\"\n                \"          &lt;i&gt;\"\n                \"            Vi erkl\u00e6rer\"\n                \"          &lt;/i&gt;\"\n                \"         &lt;/p&gt;\"\n                \"      &lt;/li&gt;\"\n                \"    &lt;/ul&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"  &lt;list&gt;\"\n                '      &lt;p type=\"listitem\"&gt;'\n                \"    &lt;em&gt;\"\n                \"                   4. Slik spr\u00e5kforholdene\"\n                \"    &lt;/em&gt;\"\n                \"    &lt;em&gt;\"\n                \"                   Som alle andre\"\n                \"    &lt;/em&gt;\"\n                \"    &lt;em&gt;\"\n                \"                   Vi erkl\u00e6rer\"\n                \"    &lt;/em&gt;\"\n                \"      &lt;/p&gt;\"\n                \"  &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"ul-strong\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;ul&gt;\"\n                \"      &lt;strong&gt;\"\n                \"        Pressesenter\"\n                \"      &lt;/strong&gt;\"\n                \"    &lt;/li&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;list&gt;\"\n                \"      &lt;p&gt;\"\n                \"        Pressesenter\"\n                \"      &lt;/p&gt;\"\n                \"    &lt;/list&gt;\"\n            ),\n        ),\n        (\n            \"div-div-abbr\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                \"      &lt;div&gt;\"\n                \"        &lt;abbr&gt;\"\n                \"           Kl.\"\n                \"        &lt;/abbr&gt;\"\n                \"        11.00\"\n                \"      &lt;/div&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" \"      Kl.\" \"    &lt;/p&gt;\" \"    &lt;p&gt;\" \"      11.00\" \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"hm\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"&lt;span&gt;\"\n                \"&lt;div&gt;\"\n                \"&lt;table&gt;\"\n                \"&lt;tbody&gt;\"\n                \"    &lt;tr&gt;\"\n                \"      &lt;td&gt;\"\n                \"        &lt;h2&gt;\"\n                \"           Kl.\"\n                \"        &lt;/h2&gt;\"\n                \"        &lt;p&gt;11.00&lt;/p&gt;\"\n                \"      &lt;/td&gt;\"\n                \"    &lt;/tr&gt;\"\n                \"&lt;/tbody&gt;\"\n                \"&lt;/table&gt;\"\n                \"&lt;/div&gt;\"\n                \"&lt;/span&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                '    &lt;p type=\"title\"&gt;'\n                \"      Kl.\"\n                \"    &lt;/p&gt;\"\n                \"    &lt;p&gt;\"\n                \"      11.00\"\n                \"    &lt;/p&gt;\"\n            ),\n        ),\n        (\n            \"div-a-b\",\n            (\n                \"&lt;html&gt;\"\n                \"  &lt;body&gt;\"\n                \"    &lt;div&gt;\"\n                '      &lt;a href=\"http://www.ovdamearka.no\"&gt;'\n                \"        &lt;b&gt;\"\n                \"          ovdamearka\"\n                \"        &lt;/b&gt;\"\n                \"      &lt;/a&gt;\"\n                \"    &lt;/div&gt;\"\n                \"  &lt;/body&gt;\"\n                \"&lt;/html&gt;\"\n            ),\n            DOCUMENT_TEMPLATE.format(\n                \"    &lt;p&gt;\" '      &lt;em type=\"bold\"&gt;ovdamearka&lt;/em&gt;' \"    &lt;/p&gt;\"\n            ),\n        ),\n    ]\n)\ndef test_conversion(testname, html_str, xml_str):\n\"\"\"Check that the tidied html is correctly converted to corpus xml.\"\"\"\n    with testfixtures.TempDirectory() as temp_dir:\n        filepath = os.path.join(\"orig/sme/admin/sd\", testname + \".html\")\n        html_str = html_str.encode(\"utf8\")\n        temp_dir.write(filepath, html_str)\n        got = htmlcontentconverter.convert2intermediate(\n            os.path.join(temp_dir.path, filepath)\n        )\n        want = etree.fromstring(xml_str)\n\n        assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_lang_guessing/","title":"test_lang_guessing","text":"<p>Test language recognition.</p>"},{"location":"reference/test/test_lang_guessing/#corpustools.test.test_lang_guessing.TestTextCat","title":"<code>TestTextCat</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test frases collected from nrk.no article collection.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_lang_guessing.py</code> <pre><code>class TestTextCat(unittest.TestCase):\n\"\"\"Test frases collected from nrk.no article collection.\"\"\"\n\n    def setUp(self):\n\"\"\"Set up common resource.\"\"\"\n        self.guesser = text_cat.Classifier()\n\n    @parameterized.expand(test_sentences)\n    def test_textcat(self, input_text):\n\"\"\"Test language recognition on input strings.\n\n        The input strings have been classified as sme, while they in\n        fact are nob.\n\n        Args:\n            input_text (str): text that should be classified by\n                the language guesser.\n        \"\"\"\n        self.assertEqual(self.guesser.classify(input_text), \"nob\")\n\n    @parameterized.expand(test_sentences)\n    def test_langid(self, input_text):\n\"\"\"Test language recognition on input strings.\n\n        The input strings have been classified as sme, while they in\n        fact are nob.\n\n        Args:\n            input_text (str): text that should be classified by\n                the language guesser.\n        \"\"\"\n        self.assertEqual(langid.classify(input_text)[0], \"no\")\n</code></pre>"},{"location":"reference/test/test_lang_guessing/#corpustools.test.test_lang_guessing.TestTextCat.setUp","title":"<code>setUp()</code>","text":"<p>Set up common resource.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_lang_guessing.py</code> <pre><code>def setUp(self):\n\"\"\"Set up common resource.\"\"\"\n    self.guesser = text_cat.Classifier()\n</code></pre>"},{"location":"reference/test/test_lang_guessing/#corpustools.test.test_lang_guessing.TestTextCat.test_langid","title":"<code>test_langid(input_text)</code>","text":"<p>Test language recognition on input strings.</p> <p>The input strings have been classified as sme, while they in fact are nob.</p> <p>Parameters:</p> Name Type Description Default <code>input_text</code> <code>str</code> <p>text that should be classified by the language guesser.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_lang_guessing.py</code> <pre><code>@parameterized.expand(test_sentences)\ndef test_langid(self, input_text):\n\"\"\"Test language recognition on input strings.\n\n    The input strings have been classified as sme, while they in\n    fact are nob.\n\n    Args:\n        input_text (str): text that should be classified by\n            the language guesser.\n    \"\"\"\n    self.assertEqual(langid.classify(input_text)[0], \"no\")\n</code></pre>"},{"location":"reference/test/test_lang_guessing/#corpustools.test.test_lang_guessing.TestTextCat.test_textcat","title":"<code>test_textcat(input_text)</code>","text":"<p>Test language recognition on input strings.</p> <p>The input strings have been classified as sme, while they in fact are nob.</p> <p>Parameters:</p> Name Type Description Default <code>input_text</code> <code>str</code> <p>text that should be classified by the language guesser.</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_lang_guessing.py</code> <pre><code>@parameterized.expand(test_sentences)\ndef test_textcat(self, input_text):\n\"\"\"Test language recognition on input strings.\n\n    The input strings have been classified as sme, while they in\n    fact are nob.\n\n    Args:\n        input_text (str): text that should be classified by\n            the language guesser.\n    \"\"\"\n    self.assertEqual(self.guesser.classify(input_text), \"nob\")\n</code></pre>"},{"location":"reference/test/test_languagedetector/","title":"test_languagedetector","text":""},{"location":"reference/test/test_languagedetector/#corpustools.test.test_languagedetector.TestLanguageDetector","title":"<code>TestLanguageDetector</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test the functionality of LanguageDetector</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_languagedetector.py</code> <pre><code>class TestLanguageDetector(XMLTester):\n\"\"\"Test the functionality of LanguageDetector\"\"\"\n\n    def setUp(self):\n        self.root = etree.parse(\n            os.path.join(\n                HERE,\n                \"converter_data/samediggi-article-48s-before-lang-\"\n                \"detection-with-multilingual-tag.xml\",\n            )\n        ).getroot()\n\n    def test_get_main_lang(self):\n        test_main_lang = \"sme\"\n        language_detector = languagedetector.LanguageDetector(\n            self.root, LANGUAGEGUESSER\n        )\n        self.assertEqual(test_main_lang, language_detector.mainlang)\n\n    def test_set_paragraph_language_preset_language(self):\n        orig_paragraph = '&lt;p xml:lang=\"sme\"&gt;I Orohagat&lt;/p&gt;'\n        expected_paragraph = etree.fromstring('&lt;p xml:lang=\"sme\"&gt;I Orohagat&lt;/p&gt;')\n\n        language_detector = languagedetector.LanguageDetector(\n            self.root, LANGUAGEGUESSER\n        )\n        got_paragraph = language_detector.set_paragraph_language(\n            etree.fromstring(orig_paragraph)\n        )\n\n        self.assertXmlEqual(got_paragraph, expected_paragraph)\n\n    def test_set_paragraph_language_mainlanguage(self):\n        orig_paragraph = (\n            \"&lt;p&gt;S\u00e1megiella lea 2004 \u010dav\u010d\u010da r\u00e1jes stand\u00e1rda giellav\u00e1lga \"\n            \"Microsofta operatiivavuog\u00e1dagas Windows XP. Dat mearkka\u0161a ahte \"\n            \"s\u00e1megiel bust\u00e1vaid ja h\u00e1miid s\u00e1htt\u00e1 v\u00e1lljet buot progr\u00e1mmain. \"\n            \"Buot leat d\u00e1s d\u00e1n fitnodaga Service Pack 2-p\u00e1hkas, maid ferte \"\n            \"vie\u017e\u017eat ja bidjat dihtorii. Boa\u0111us lea ahte buot boahtteva\u0161 \"\n            \"Microsoft progr\u00e1mmat dorjot s\u00e1megiela. Dattetge s\u00e1httet \"\n            \"deaividit v\u00e1ttisvuo\u0111at go \u010d\u00e1l\u00e1t s\u00e1megiela Outlook-kaleandaris \"\n            \"dahje e-poastta namahussajis, ja go \u010d\u00e1l\u00e1t s\u00e1megillii dakk\u00e1r \"\n            \"progr\u00e1mmain, maid Microsoft ii leat r\u00e1hkadan.&lt;/p&gt;\"\n        )\n        expected_paragraph = etree.fromstring(\n            \"&lt;p&gt;S\u00e1megiella lea 2004 \u010dav\u010d\u010da r\u00e1jes stand\u00e1rda giellav\u00e1lga \"\n            \"Microsofta operatiivavuog\u00e1dagas Windows XP. Dat mearkka\u0161a ahte \"\n            \"s\u00e1megiel bust\u00e1vaid ja h\u00e1miid s\u00e1htt\u00e1 v\u00e1lljet buot progr\u00e1mmain. \"\n            \"Buot leat d\u00e1s d\u00e1n fitnodaga Service Pack 2-p\u00e1hkas, maid ferte \"\n            \"vie\u017e\u017eat ja bidjat dihtorii. Boa\u0111us lea ahte buot boahtteva\u0161 \"\n            \"Microsoft progr\u00e1mmat dorjot s\u00e1megiela. Dattetge s\u00e1httet \"\n            \"deaividit v\u00e1ttisvuo\u0111at go \u010d\u00e1l\u00e1t s\u00e1megiela Outlook-kaleandaris \"\n            \"dahje e-poastta namahussajis, ja go \u010d\u00e1l\u00e1t s\u00e1megillii dakk\u00e1r \"\n            \"progr\u00e1mmain, maid Microsoft ii leat r\u00e1hkadan.&lt;/p&gt;\"\n        )\n\n        language_detector = languagedetector.LanguageDetector(\n            self.root, LANGUAGEGUESSER\n        )\n        got_paragraph = language_detector.set_paragraph_language(\n            etree.fromstring(orig_paragraph)\n        )\n\n        self.assertXmlEqual(got_paragraph, expected_paragraph)\n\n    def test_set_paragraph_language_mainlanguage_quote_mainlang(self):\n        orig_paragraph = (\n            \"&lt;p&gt;S\u00e1megiella lea 2004 \u010dav\u010d\u010da r\u00e1jes stand\u00e1rda giellav\u00e1lga \"\n            \"Microsofta operatiivavuog\u00e1dagas Windows XP. Dat mearkka\u0161a ahte \"\n            \"s\u00e1megiel bust\u00e1vaid ja h\u00e1miid s\u00e1htt\u00e1 v\u00e1lljet buot progr\u00e1mmain. \"\n            '&lt;span type=\"quote\"&gt;\u00abBuot leat d\u00e1s d\u00e1n fitnodaga Service Pack 2-'\n            \"p\u00e1hkas, maid ferte vie\u017e\u017eat ja bidjat dihtorii\u00bb&lt;/span&gt;. Boa\u0111us \"\n            \"lea ahte buot boahtteva\u0161 Microsoft progr\u00e1mmat dorjot s\u00e1megiela. \"\n            \"Dattetge s\u00e1httet deaividit v\u00e1ttisvuo\u0111at go \u010d\u00e1l\u00e1t s\u00e1megiela \"\n            \"Outlook-kaleandaris dahje e-poastta namahussajis, ja go \u010d\u00e1l\u00e1t \"\n            \"s\u00e1megillii dakk\u00e1r progr\u00e1mmain, maid Microsoft ii leat \"\n            \"r\u00e1hkadan.&lt;/p&gt;\"\n        )\n        expected_paragraph = etree.fromstring(\n            \"&lt;p&gt;S\u00e1megiella lea 2004 \u010dav\u010d\u010da r\u00e1jes stand\u00e1rda giellav\u00e1lga \"\n            \"Microsofta operatiivavuog\u00e1dagas Windows XP. Dat mearkka\u0161a ahte \"\n            \"s\u00e1megiel bust\u00e1vaid ja h\u00e1miid s\u00e1htt\u00e1 v\u00e1lljet buot progr\u00e1mmain. \"\n            '&lt;span type=\"quote\"&gt;\u00abBuot leat d\u00e1s d\u00e1n fitnodaga Service Pack 2-'\n            \"p\u00e1hkas, maid ferte vie\u017e\u017eat ja bidjat dihtorii\u00bb&lt;/span&gt;. Boa\u0111us \"\n            \"lea ahte buot boahtteva\u0161 Microsoft progr\u00e1mmat dorjot s\u00e1megiela. \"\n            \"Dattetge s\u00e1httet deaividit v\u00e1ttisvuo\u0111at go \u010d\u00e1l\u00e1t s\u00e1megiela \"\n            \"Outlook-kaleandaris dahje e-poastta namahussajis, ja go \u010d\u00e1l\u00e1t \"\n            \"s\u00e1megillii dakk\u00e1r progr\u00e1mmain, maid Microsoft ii leat \"\n            \"r\u00e1hkadan.&lt;/p&gt;\"\n        )\n\n        language_detector = languagedetector.LanguageDetector(\n            self.root, LANGUAGEGUESSER\n        )\n        got_paragraph = language_detector.set_paragraph_language(\n            etree.fromstring(orig_paragraph)\n        )\n\n        self.assertXmlEqual(got_paragraph, expected_paragraph)\n\n    def test_set_paragraph_language_mainlanguage_quote_not_mainlang(self):\n        orig_paragraph = (\n            \"&lt;p&gt;S\u00e1megiella lea 2004 \u010dav\u010d\u010da r\u00e1jes stand\u00e1rda giellav\u00e1lga \"\n            \"Microsofta operatiivavuog\u00e1dagas Windows XP. Dat mearkka\u0161a ahte \"\n            \"s\u00e1megiel bust\u00e1vaid ja h\u00e1miid s\u00e1htt\u00e1 v\u00e1lljet buot progr\u00e1mmain. \"\n            '&lt;span type=\"quote\"&gt;\u00abAlt finnes i den foreliggende Service Pack 2 '\n            \"fra selskapet, som m\u00e5 lastes ned og installeres p\u00e5 din \"\n            \"datamaskin. Konsekvensen er at all framtidig programvare fra \"\n            \"Microsoft vil inneholde st\u00f8tte for samisk\u00bb&lt;/span&gt;. Boa\u0111us lea \"\n            \"ahte buot boahtteva\u0161 Microsoft progr\u00e1mmat dorjot s\u00e1megiela. \"\n            \"Dattetge s\u00e1httet deaividit v\u00e1ttisvuo\u0111at go \u010d\u00e1l\u00e1t s\u00e1megiela \"\n            \"Outlook-kaleandaris dahje e-poastta namahussajis, ja go \u010d\u00e1l\u00e1t \"\n            \"s\u00e1megillii dakk\u00e1r progr\u00e1mmain, maid Microsoft ii leat \"\n            \"r\u00e1hkadan.&lt;/p&gt;\"\n        )\n        expected_paragraph = etree.fromstring(\n            \"&lt;p&gt;S\u00e1megiella lea 2004 \u010dav\u010d\u010da r\u00e1jes stand\u00e1rda giellav\u00e1lga \"\n            \"Microsofta operatiivavuog\u00e1dagas Windows XP. Dat mearkka\u0161a ahte \"\n            \"s\u00e1megiel bust\u00e1vaid ja h\u00e1miid s\u00e1htt\u00e1 v\u00e1lljet buot progr\u00e1mmain. \"\n            '&lt;span type=\"quote\" xml:lang=\"nob\"&gt;\u00abAlt finnes i den foreliggende '\n            \"Service Pack 2 fra selskapet, som m\u00e5 lastes ned og installeres \"\n            \"p\u00e5 din datamaskin. Konsekvensen er at all framtidig programvare \"\n            \"fra Microsoft vil inneholde st\u00f8tte for samisk\u00bb&lt;/span&gt;. Boa\u0111us \"\n            \"lea ahte buot boahtteva\u0161 Microsoft progr\u00e1mmat dorjot s\u00e1megiela. \"\n            \"Dattetge s\u00e1httet deaividit v\u00e1ttisvuo\u0111at go \u010d\u00e1l\u00e1t s\u00e1megiela \"\n            \"Outlook-kaleandaris dahje e-poastta namahussajis, ja go \u010d\u00e1l\u00e1t \"\n            \"s\u00e1megillii dakk\u00e1r progr\u00e1mmain, maid Microsoft ii leat \"\n            \"r\u00e1hkadan.&lt;/p&gt;\"\n        )\n\n        language_detector = languagedetector.LanguageDetector(\n            self.root, LANGUAGEGUESSER\n        )\n        got_paragraph = language_detector.set_paragraph_language(\n            etree.fromstring(orig_paragraph)\n        )\n\n        self.assertXmlEqual(got_paragraph, expected_paragraph)\n\n    def test_set_paragraph_language_not_mainlanguage(self):\n        orig_paragraph = (\n            \"&lt;p&gt;Samisk er fra h\u00f8sten 2004 et standard spr\u00e5kvalg Microsofts \"\n            \"operativsystem Windows XP. I praksis betyr det at samiske \"\n            \"bokstaver og formater kan velges i alle programmer. Alt finnes \"\n            \"i den foreliggende Service Pack 2 fra selskapet, som m\u00e5 lastes \"\n            \"ned og installeres p\u00e5 din datamaskin. Konsekvensen er at all \"\n            \"framtidig programvare fra Microsoft vil inneholde st\u00f8tte for \"\n            \"samisk. Du vil imidlertid fremdeles kunne oppleve problemer med \"\n            \"\u00e5 skrive samisk i Outlook-kalenderen eller i tittel-feltet i \"\n            \"e-post, og med \u00e5 skrive samisk i programmer levert av andre enn \"\n            \"Microsoft.&lt;/p&gt;\"\n        )\n\n        language_detector = languagedetector.LanguageDetector(\n            self.root, LANGUAGEGUESSER\n        )\n        got_paragraph = language_detector.set_paragraph_language(\n            etree.fromstring(orig_paragraph)\n        )\n\n        self.assertEqual(\n            got_paragraph.get(\"{http://www.w3.org/XML/1998/namespace}lang\"), \"nob\"\n        )\n\n    def test_remove_quote(self):\n        orig_paragraph = (\n            '&lt;p&gt;bla bla &lt;span type=\"quote\"&gt;bla1 bla&lt;/span&gt; ble ble '\n            '&lt;span type=\"quote\"&gt;bla2 bla&lt;/span&gt; &lt;b&gt;bli&lt;/b&gt; bli '\n            '&lt;span type=\"quote\"&gt;bla3 bla&lt;/span&gt; blo blo&lt;/p&gt;'\n        )\n        expected_paragraph = \"bla bla  ble ble  bli bli  blo blo\"\n\n        language_detector = languagedetector.LanguageDetector(\n            self.root, LANGUAGEGUESSER\n        )\n        got_paragraph = language_detector.remove_quote(etree.fromstring(orig_paragraph))\n\n        self.assertEqual(got_paragraph, expected_paragraph)\n\n    def test_detect_language_with_multilingualtag(self):\n        root = etree.parse(\n            os.path.join(\n                HERE,\n                \"converter_data/samediggi-article-48s-before-\"\n                \"lang-detection-with-multilingual-tag.xml\",\n            )\n        ).getroot()\n        language_detector = languagedetector.LanguageDetector(root, LANGUAGEGUESSER)\n        language_detector.detect_language()\n        got_document = language_detector.document\n\n        expected_document = etree.parse(\n            os.path.join(\n                HERE,\n                \"converter_data/samediggi-article-48s-after-lang-\"\n                \"detection-with-multilingual-tag.xml\",\n            )\n        )\n\n        self.assertXmlEqual(got_document, expected_document)\n\n    def test_detect_language_without_multilingualtag(self):\n        root = etree.parse(\n            os.path.join(\n                HERE,\n                \"converter_data/samediggi-article-48s-before-lang-\"\n                \"detection-without-multilingual-tag.xml\",\n            )\n        ).getroot()\n        language_detector = languagedetector.LanguageDetector(root, LANGUAGEGUESSER)\n        language_detector.detect_language()\n        got_document = language_detector.document\n\n        expected_document = etree.parse(\n            os.path.join(\n                HERE,\n                \"converter_data/samediggi-article-48s-after-lang-\"\n                \"detection-without-multilingual-tag.xml\",\n            )\n        )\n\n        self.assertXmlEqual(got_document, expected_document)\n\n    def test_no_lang_guessing_without_models(self):\n        test_document = \"\"\"\n            &lt;document xml:lang=\"non_existing_mainlang\"&gt;\n                &lt;header&gt;\n                    &lt;title&gt;title&lt;/title&gt;\n                    &lt;multilingual&gt;\n                        &lt;language xml:lang=\"non_existing_optional_lang\"/&gt;\n                    &lt;/multilingual&gt;\n                &lt;/header&gt;\n                &lt;body&gt;\n                    &lt;p&gt;content&lt;/p&gt;\n                &lt;/body&gt;\n            &lt;/document&gt;\n        \"\"\"\n\n        root = etree.fromstring(test_document)\n        language_detector = languagedetector.LanguageDetector(root, LANGUAGEGUESSER)\n        language_detector = languagedetector.LanguageDetector(root, LANGUAGEGUESSER)\n        language_detector.detect_language()\n        got_document = language_detector.document\n\n        self.assertXmlEqual(got_document, root)\n</code></pre>"},{"location":"reference/test/test_languagedetector/#corpustools.test.test_languagedetector.XMLTester","title":"<code>XMLTester</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_languagedetector.py</code> <pre><code>class XMLTester(unittest.TestCase):\n    @staticmethod\n    def assertXmlEqual(got, want):\n\"\"\"Check if two stringified xml snippets are equal\"\"\"\n        got = etree.tostring(got, encoding=\"unicode\")\n        want = etree.tostring(want, encoding=\"unicode\")\n\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(want, got, 0):\n            message = checker.output_difference(\n                doctest.Example(\"\", want), got, 0\n            ).encode(\"utf-8\")\n            raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_languagedetector/#corpustools.test.test_languagedetector.XMLTester.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>  <code>staticmethod</code>","text":"<p>Check if two stringified xml snippets are equal</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_languagedetector.py</code> <pre><code>@staticmethod\ndef assertXmlEqual(got, want):\n\"\"\"Check if two stringified xml snippets are equal\"\"\"\n    got = etree.tostring(got, encoding=\"unicode\")\n    want = etree.tostring(want, encoding=\"unicode\")\n\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(want, got, 0):\n        message = checker.output_difference(\n            doctest.Example(\"\", want), got, 0\n        ).encode(\"utf-8\")\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_namechanger/","title":"test_namechanger","text":"<p>Navneskifte</p> <p>orig = CorpusPath(orig) \u00f81 = CorpusPath(\u00f8nsket navn) \u00f82 = normaliser(\u00f81) -&gt; endret basename \u00f83 = nyttnavnhvisikkeduplikat(\u00f82) -&gt; endret basename</p>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_are_duplicate_equal_files","title":"<code>test_are_duplicate_equal_files(dupe_setup)</code>","text":"<p>Both files exist, with same content, return True</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_are_duplicate_equal_files(dupe_setup):\n\"\"\"Both files exist, with same content, return True\"\"\"\n    assert (\n        dupe_setup[0].exists()\n        and dupe_setup[1].exists()\n        and namechanger.are_duplicates(dupe_setup[0], dupe_setup[1]) == True\n    )\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_are_duplicate_nonexisting_file","title":"<code>test_are_duplicate_nonexisting_file()</code>","text":"<p>If one or none of the files do not exist, return False</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_are_duplicate_nonexisting_file():\n\"\"\"If one or none of the files do not exist, return False\"\"\"\n    assert namechanger.are_duplicates(\"old.txt\", \"new.txt\") == False\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_are_duplicate_unequal_files","title":"<code>test_are_duplicate_unequal_files(dupe_setup)</code>","text":"<p>Both files exist, not same content, return False</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_are_duplicate_unequal_files(dupe_setup):\n\"\"\"Both files exist, not same content, return False\"\"\"\n    assert (\n        dupe_setup[0].exists()\n        and dupe_setup[2].exists()\n        and namechanger.are_duplicates(\n            dupe_setup[0],\n            dupe_setup[2],\n        )\n        == False\n    )\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_1","title":"<code>test_compute_movepairs_1(tmp_path)</code>","text":"<p>newpath does not exist, no parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_1(tmp_path):\n\"\"\"newpath does not exist, no parallels\"\"\"\n    corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    corpus_dir.mkdir(parents=True)\n\n    mc = namechanger.MovepairComputer()\n\n    file1 = corpus_dir.joinpath(\"a.txt\")\n    mc.compute_all_movepairs(\n        oldpath=file1.as_posix(),\n        newpath=file1.with_stem(\"b\").as_posix(),\n    )\n\n    assert mc.filepairs == [\n        namechanger.PathPair(\n            oldpath=file1.as_posix(),\n            newpath=file1.with_stem(\"b\").as_posix(),\n        )\n    ]\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_10","title":"<code>test_compute_movepairs_10(tmp_path)</code>","text":"<p>newpath is empty, no parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_10(tmp_path):\n\"\"\"newpath is empty, no parallels\"\"\"\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_file = sme_corpus_dir.joinpath(\"a.txt\")\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(sme_file.as_posix(), \"\")\n\n    assert mc.filepairs == [\n        namechanger.PathPair(\n            sme_file.as_posix(),\n            newpath=\"\",\n        )\n    ]\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_11","title":"<code>test_compute_movepairs_11(tmp_path)</code>","text":"<p>newpath is empty, with parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_11(tmp_path):\n\"\"\"newpath is empty, with parallels\"\"\"\n    sma_corpus_dir = tmp_path / \"corpus-sma-orig\" / \"ficti\" / \"sub\"\n    sma_corpus_dir.mkdir(parents=True)\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_corpus_dir.mkdir(parents=True)\n    smj_corpus_dir = tmp_path / \"corpus-smj-orig\" / \"ficti\" / \"sub\"\n    smj_corpus_dir.mkdir(parents=True)\n\n    sme_file = sme_corpus_dir.joinpath(\"f.txt\")\n    sme_corpuspath = corpuspath.CorpusPath(sme_file.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sme_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    smj_file = smj_corpus_dir.joinpath(\"f.txt\")\n    smj_corpuspath = corpuspath.CorpusPath(smj_file.as_posix())\n\n    smj_corpuspath.metadata.set_variable(\"mainlang\", \"smj\")\n    smj_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    smj_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    smj_corpuspath.metadata.write_file()\n\n    sma_file = sma_corpus_dir.joinpath(\"f.txt\")\n    sma_corpuspath = corpuspath.CorpusPath(sma_file.as_posix())\n\n    sma_corpuspath.metadata.set_variable(\"mainlang\", \"sma\")\n    sma_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    sma_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sma_corpuspath.metadata.write_file()\n\n    want = sorted(\n        [\n            namechanger.PathPair(\n                oldpath=sme_file.as_posix(),\n                newpath=\"\",\n            ),\n            namechanger.PathPair(\n                oldpath=smj_file.as_posix(),\n                newpath=smj_file.as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=sma_file.as_posix(),\n                newpath=sma_file.as_posix(),\n            ),\n        ]\n    )\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=sme_file.as_posix(),\n        newpath=\"\",\n    )\n    got = sorted(mc.filepairs)\n\n    assert got == want\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_12","title":"<code>test_compute_movepairs_12(tmp_path)</code>","text":"<p>Newpath is empty, one parallel needs normalisation.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_12(tmp_path):\n\"\"\"Newpath is empty, one parallel needs normalisation.\"\"\"\n    sma_corpus_dir = tmp_path / \"corpus-sma-orig\" / \"ficti\" / \"sub\"\n    sma_corpus_dir.mkdir(parents=True)\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_corpus_dir.mkdir(parents=True)\n    smj_corpus_dir = tmp_path / \"corpus-smj-orig\" / \"ficti\" / \"sub\"\n    smj_corpus_dir.mkdir(parents=True)\n\n    sme_file = sme_corpus_dir.joinpath(\"f.txt\")\n    sme_corpuspath = corpuspath.CorpusPath(sme_file.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"smj\", \"\u00f8.txt\")\n    sme_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    smj_file = smj_corpus_dir.joinpath(\"\u00f8.txt\")\n    smj_corpuspath = corpuspath.CorpusPath(smj_file.as_posix())\n\n    smj_corpuspath.metadata.set_variable(\"mainlang\", \"smj\")\n    smj_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    smj_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    smj_corpuspath.metadata.write_file()\n\n    sma_file = sma_corpus_dir.joinpath(\"f.txt\")\n    sma_corpuspath = corpuspath.CorpusPath(sma_file.as_posix())\n\n    sma_corpuspath.metadata.set_variable(\"mainlang\", \"sma\")\n    sma_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    sma_corpuspath.metadata.set_parallel_text(\"smj\", \"\u00f8.txt\")\n    sma_corpuspath.metadata.write_file()\n\n    want = sorted(\n        [\n            namechanger.PathPair(oldpath=sme_file.as_posix(), newpath=\"\"),\n            namechanger.PathPair(\n                oldpath=smj_file.as_posix(),\n                newpath=smj_file.with_stem(\"o\").as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=sma_file.as_posix(),\n                newpath=sma_file.as_posix(),\n            ),\n        ]\n    )\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=sme_file.as_posix(),\n        newpath=\"\",\n    )\n    got = sorted(mc.filepairs)\n\n    assert got == want\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_2","title":"<code>test_compute_movepairs_2(tmp_path)</code>","text":"<p>newpath does not exist, needs normalisation, no parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_2(tmp_path):\n\"\"\"newpath does not exist, needs normalisation, no parallels\"\"\"\n    corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    corpus_dir.mkdir(parents=True)\n\n    mc = namechanger.MovepairComputer()\n    file1 = corpus_dir.joinpath(\"\u00e6.txt\")\n    mc.compute_all_movepairs(\n        oldpath=file1.as_posix(),\n        newpath=file1.as_posix(),\n    )\n\n    assert mc.filepairs == [\n        namechanger.PathPair(\n            oldpath=file1.as_posix(),\n            newpath=file1.with_stem(\"ae\").as_posix(),\n        )\n    ]\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_3","title":"<code>test_compute_movepairs_3(tmp_path)</code>","text":"<p>newpath exists, not duplicate, no parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_3(tmp_path):\n\"\"\"newpath exists, not duplicate, no parallels\"\"\"\n    corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    corpus_dir.mkdir(parents=True)\n    file1 = corpus_dir.joinpath(\"a.txt\")\n    file1.write_text(\"file1\")\n    file2 = file1.with_stem(\"b\")\n    file2.write_text(\"file2\")\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=file1.as_posix(),\n        newpath=file2.as_posix(),\n    )\n\n    assert mc.filepairs == [\n        namechanger.PathPair(\n            oldpath=file1.as_posix(),\n            newpath=file1.with_stem(\"b_1\").as_posix(),\n        )\n    ]\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_4","title":"<code>test_compute_movepairs_4(tmp_path)</code>","text":"<p>newpath exists, duplicate, no parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_4(tmp_path):\n\"\"\"newpath exists, duplicate, no parallels\"\"\"\n    corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    corpus_dir.mkdir(parents=True)\n    file1 = corpus_dir.joinpath(\"a.txt\")\n    file1.write_text(\"file1\")\n    file2 = file1.with_stem(\"b\")\n    file2.write_text(\"file1\")\n\n    mc = namechanger.MovepairComputer()\n\n    with pytest.raises(UserWarning):\n        mc.compute_all_movepairs(\n            file1.as_posix(),\n            file2.as_posix(),\n        )\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_5","title":"<code>test_compute_movepairs_5(tmp_path)</code>","text":"<p>move to same directory, with parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_5(tmp_path):\n\"\"\"move to same directory, with parallels\"\"\"\n    sma_corpus_dir = tmp_path / \"corpus-sma-orig\" / \"ficti\" / \"sub\"\n    sma_corpus_dir.mkdir(parents=True)\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_corpus_dir.mkdir(parents=True)\n    smj_corpus_dir = tmp_path / \"corpus-smj-orig\" / \"ficti\" / \"sub\"\n    smj_corpus_dir.mkdir(parents=True)\n\n    sme_file = sme_corpus_dir.joinpath(\"f.txt\")\n    sme_corpuspath = corpuspath.CorpusPath(sme_file.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sme_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    smj_file = smj_corpus_dir.joinpath(\"f.txt\")\n    smj_corpuspath = corpuspath.CorpusPath(smj_file.as_posix())\n\n    smj_corpuspath.metadata.set_variable(\"mainlang\", \"smj\")\n    smj_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    smj_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    smj_corpuspath.metadata.write_file()\n\n    sma_file = sma_corpus_dir.joinpath(\"f.txt\")\n    sma_corpuspath = corpuspath.CorpusPath(sma_file.as_posix())\n\n    sma_corpuspath.metadata.set_variable(\"mainlang\", \"sma\")\n    sma_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    sma_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sma_corpuspath.metadata.write_file()\n\n    want = sorted(\n        [\n            namechanger.PathPair(\n                oldpath=sme_file.as_posix(),\n                newpath=sme_file.with_stem(\"g\").as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=smj_file.as_posix(),\n                newpath=smj_file.as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=sma_file.as_posix(),\n                newpath=sma_file.as_posix(),\n            ),\n        ]\n    )\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=sme_file.as_posix(),\n        newpath=sme_file.with_stem(\"g\").as_posix(),\n    )\n    got = sorted(mc.filepairs)\n\n    assert got == want\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_6","title":"<code>test_compute_movepairs_6(tmp_path)</code>","text":"<p>move to different subdir, with parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_6(tmp_path):\n\"\"\"move to different subdir, with parallels\"\"\"\n    sma_corpus_dir = tmp_path / \"corpus-sma-orig\" / \"ficti\" / \"sub\"\n    sma_corpus_dir.mkdir(parents=True)\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_corpus_dir.mkdir(parents=True)\n    smj_corpus_dir = tmp_path / \"corpus-smj-orig\" / \"ficti\" / \"sub\"\n    smj_corpus_dir.mkdir(parents=True)\n\n    sme_file = sme_corpus_dir.joinpath(\"f.txt\")\n    sme_corpuspath = corpuspath.CorpusPath(sme_file.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sme_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    smj_file = smj_corpus_dir.joinpath(\"f.txt\")\n    smj_corpuspath = corpuspath.CorpusPath(smj_file.as_posix())\n\n    smj_corpuspath.metadata.set_variable(\"mainlang\", \"smj\")\n    smj_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    smj_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    smj_corpuspath.metadata.write_file()\n\n    sma_file = sma_corpus_dir.joinpath(\"f.txt\")\n    sma_corpuspath = corpuspath.CorpusPath(sma_file.as_posix())\n\n    sma_corpuspath.metadata.set_variable(\"mainlang\", \"sma\")\n    sma_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    sma_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sma_corpuspath.metadata.write_file()\n\n    want = sorted(\n        [\n            namechanger.PathPair(\n                oldpath=sme_file.as_posix(),\n                newpath=tmp_path.joinpath(\n                    \"corpus-sme-orig\", \"ficti\", \"bub\", \"g.txt\"\n                ).as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=smj_file.as_posix(),\n                newpath=tmp_path.joinpath(\n                    \"corpus-smj-orig\", \"ficti\", \"bub\", \"f.txt\"\n                ).as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=sma_file.as_posix(),\n                newpath=tmp_path.joinpath(\n                    \"corpus-sma-orig\", \"ficti\", \"bub\", \"f.txt\"\n                ).as_posix(),\n            ),\n        ]\n    )\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=sme_file.as_posix(),\n        newpath=tmp_path.joinpath(\n            \"corpus-sme-orig\", \"ficti\", \"bub\", \"g.txt\"\n        ).as_posix(),\n    )\n    got = sorted(mc.filepairs)\n\n    assert got == want\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_7","title":"<code>test_compute_movepairs_7(tmp_path)</code>","text":"<p>move to different genre, with parallels</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_7(tmp_path):\n\"\"\"move to different genre, with parallels\"\"\"\n    sma_corpus_dir = tmp_path / \"corpus-sma-orig\" / \"ficti\" / \"sub\"\n    sma_corpus_dir.mkdir(parents=True)\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_corpus_dir.mkdir(parents=True)\n    smj_corpus_dir = tmp_path / \"corpus-smj-orig\" / \"ficti\" / \"sub\"\n    smj_corpus_dir.mkdir(parents=True)\n\n    sme_file = sme_corpus_dir.joinpath(\"f.txt\")\n    sme_corpuspath = corpuspath.CorpusPath(sme_file.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sme_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    smj_file = smj_corpus_dir.joinpath(\"f.txt\")\n    smj_corpuspath = corpuspath.CorpusPath(smj_file.as_posix())\n\n    smj_corpuspath.metadata.set_variable(\"mainlang\", \"smj\")\n    smj_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    smj_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    smj_corpuspath.metadata.write_file()\n\n    sma_file = sma_corpus_dir.joinpath(\"f.txt\")\n    sma_corpuspath = corpuspath.CorpusPath(sma_file.as_posix())\n\n    sma_corpuspath.metadata.set_variable(\"mainlang\", \"sma\")\n    sma_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    sma_corpuspath.metadata.set_parallel_text(\"smj\", \"f.txt\")\n    sma_corpuspath.metadata.write_file()\n\n    want = sorted(\n        [\n            namechanger.PathPair(\n                oldpath=sme_file.as_posix(),\n                newpath=tmp_path.joinpath(\n                    \"corpus-sme-orig\", \"facta\", \"sub\", \"g.txt\"\n                ).as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=smj_file.as_posix(),\n                newpath=tmp_path.joinpath(\n                    \"corpus-smj-orig\", \"facta\", \"sub\", \"f.txt\"\n                ).as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=sma_file.as_posix(),\n                newpath=tmp_path.joinpath(\n                    \"corpus-sma-orig\", \"facta\", \"sub\", \"f.txt\"\n                ).as_posix(),\n            ),\n        ]\n    )\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=sme_file.as_posix(),\n        newpath=tmp_path.joinpath(\n            \"corpus-sme-orig\", \"facta\", \"sub\", \"g.txt\"\n        ).as_posix(),\n    )\n    got = sorted(mc.filepairs)\n\n    assert got == want\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_8","title":"<code>test_compute_movepairs_8(tmp_path)</code>","text":"<p>Move to different genre, one parallel needs normalisation</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_8(tmp_path):\n\"\"\"Move to different genre, one parallel needs normalisation\"\"\"\n    sma_corpus_dir = tmp_path / \"corpus-sma-orig\" / \"ficti\" / \"sub\"\n    sma_corpus_dir.mkdir(parents=True)\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_corpus_dir.mkdir(parents=True)\n    smj_corpus_dir = tmp_path / \"corpus-smj-orig\" / \"ficti\" / \"sub\"\n    smj_corpus_dir.mkdir(parents=True)\n\n    sme_file = sme_corpus_dir.joinpath(\"f.txt\")\n    sme_corpuspath = corpuspath.CorpusPath(sme_file.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"smj\", \"\u00f8.txt\")\n    sme_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    smj_file = smj_corpus_dir.joinpath(\"\u00f8.txt\")\n    smj_corpuspath = corpuspath.CorpusPath(smj_file.as_posix())\n\n    smj_corpuspath.metadata.set_variable(\"mainlang\", \"smj\")\n    smj_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    smj_corpuspath.metadata.set_parallel_text(\"sma\", \"f.txt\")\n    smj_corpuspath.metadata.write_file()\n\n    sma_file = sma_corpus_dir.joinpath(\"f.txt\")\n    sma_corpuspath = corpuspath.CorpusPath(sma_file.as_posix())\n\n    sma_corpuspath.metadata.set_variable(\"mainlang\", \"sma\")\n    sma_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    sma_corpuspath.metadata.set_parallel_text(\"smj\", \"\u00f8.txt\")\n    sma_corpuspath.metadata.write_file()\n\n    want = sorted(\n        [\n            namechanger.PathPair(\n                oldpath=sme_file.as_posix(), newpath=sme_file.with_stem(\"g\").as_posix()\n            ),\n            namechanger.PathPair(\n                oldpath=smj_file.as_posix(),\n                newpath=smj_file.with_stem(\"o\").as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=sma_file.as_posix(),\n                newpath=sma_file.as_posix(),\n            ),\n        ]\n    )\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=sme_file.as_posix(),\n        newpath=sme_file.with_stem(\"g\").as_posix(),\n    )\n    got = sorted(mc.filepairs)\n\n    assert got == want\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_movepairs_9","title":"<code>test_compute_movepairs_9(tmp_path)</code>","text":"<p>move to same directory, with parallels.</p> <p>Parallel needs normalisation. The new parallel name collides with normalised name, but is not a duplicate of it.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_movepairs_9(tmp_path):\n\"\"\"move to same directory, with parallels.\n\n    Parallel needs normalisation. The new parallel name collides with\n    normalised name, but is not a duplicate of it.\n    \"\"\"\n    sma_corpus_dir = tmp_path / \"corpus-sma-orig\" / \"ficti\" / \"sub\"\n    sma_corpus_dir.mkdir(parents=True)\n    sme_corpus_dir = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\"\n    sme_corpus_dir.mkdir(parents=True)\n\n    sme_file = sme_corpus_dir.joinpath(\"f.txt\")\n    sme_corpuspath = corpuspath.CorpusPath(sme_file.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"sma\", \"\u00f8.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    sma_file = sma_corpus_dir.joinpath(\"\u00f8.txt\")\n    sma_corpuspath = corpuspath.CorpusPath(sma_file.as_posix())\n\n    sma_corpuspath.metadata.set_variable(\"mainlang\", \"sma\")\n    sma_corpuspath.metadata.set_parallel_text(\"sme\", \"f.txt\")\n    sma_corpuspath.metadata.write_file()\n\n    sma_file.write_text(\"content of \u00f8\")\n    sma_file.with_stem(\"o\").write_text(\"content of o\")\n\n    want = sorted(\n        [\n            namechanger.PathPair(\n                oldpath=sme_file.as_posix(),\n                newpath=sme_file.with_stem(\"g\").as_posix(),\n            ),\n            namechanger.PathPair(\n                oldpath=sma_file.as_posix(),\n                newpath=sma_file.with_stem(\"o_1\").as_posix(),\n            ),\n        ]\n    )\n\n    mc = namechanger.MovepairComputer()\n    mc.compute_all_movepairs(\n        oldpath=sme_file.as_posix(),\n        newpath=sme_file.with_stem(\"g\").as_posix(),\n    )\n    got = sorted(mc.filepairs)\n\n    assert got == want\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_new_basename_duplicates","title":"<code>test_compute_new_basename_duplicates(tmp_path)</code>","text":"<p>What happens when the wanted name is taken, and a duplicate</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_new_basename_duplicates(tmp_path):\n\"\"\"What happens when the wanted name is taken, and a duplicate\"\"\"\n    d = tmp_path / \"corpus-sme-orig\"\n    d.mkdir()\n    file1 = d / \"old.txt\"\n    file2 = d / \"new.txt\"\n    file1.write_text(\"a\")\n    file2.write_text(\"a\")\n    with pytest.raises(UserWarning):\n        namechanger.compute_new_basename(\n            oldpath=file1,\n            wanted_path=file2,\n        )\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_compute_new_basename_same_name","title":"<code>test_compute_new_basename_same_name(tmp_path)</code>","text":"<p>What happens when the suggested name is taken, but not duplicate</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_compute_new_basename_same_name(tmp_path):\n\"\"\"What happens when the suggested name is taken, but not duplicate\"\"\"\n    corpus_dir = tmp_path / \"corpus-sme-orig\"\n    corpus_dir.mkdir()\n    file1 = corpus_dir / \"old.txt\"\n    file2 = corpus_dir / \"\u00f8ld.txt\"\n    file1.write_text(\"a\")\n    file2.write_text(\"b\")\n\n    assert (\n        namechanger.compute_new_basename(oldpath=file2, wanted_path=file1)\n        == file1.with_name(\"old_1.txt\").as_posix()\n    )\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_filename_to_ascii","title":"<code>test_filename_to_ascii(orig, expected)</code>","text":"<p>Check that non ascii filenames are converted to ascii only ones.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>@pytest.mark.parametrize(\n    \"orig, expected\",\n    [\n        (\"\u00e1\u0161\u0167\u014b\u0111\u017e\u010d\u00e5\u00f8\u00e6\u00f6\u00e4\u00ef+\", \"astngdzcaoaeoai_\"),\n        (\"\u00c1\u0160\u0166\u014a\u0110\u017d\u010c\u00c5\u00d8\u00c6\u00d6\u00c4\u00cf+\", \"astngdzcaoaeoai_\"),\n        (\"\u00e1\u0161\u0167\u014b\u0111\u017d\u010c\u00c5\u00d8\u00c6\u00d6\u00c4\u00ef+\", \"astngdzcaoaeoai_\"),\n        (\"YoullNeverWalkAlone\", \"youllneverwalkalone\"),\n        (\"Youll Never Walk Alone\", \"youll_never_walk_alone\"),\n        (\"You'll Never Walk Alone\", \"you_ll_never_walk_alone\"),\n        (\"\u0160add\u00e1go beaivi vai idja\", \"saddago_beaivi_vai_idja\"),\n        ('aba\".txt', \"aba_.txt\"),\n        (\"aba&lt;.txt\", \"aba_.txt\"),\n        (\"aba&gt;.txt\", \"aba_.txt\"),\n        (\"__aba.txt\", \"aba.txt\"),\n        (\"--aba.txt\", \"aba.txt\"),\n        (\"--__aba.txt\", \"aba.txt\"),\n        (\n            (\n                \"\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f\"\n                \"\u0410\u0411\u0412\u0413\u0414\u0415\u0401\u0416\u0417\u0418\u0419\u041a\u041b\u041c\u041d\u041e\u041f\u0420\u0421\u0422\u0423\u0424\u0425\u0426\u200c\u200b\u0427\u0428\u0429\u042a\u042b\u042c\u042d\u042e\u042f.txt\"\n            ),\n            (\n                \"abvgdeiozhziiklmnoprstufkhtschshshch_y_eiuia\"\n                \"abvgdeiozhziiklmnoprstufkhts_chshshch_y_eiuia.txt\"\n            ),\n        ),\n    ],\n)\ndef test_filename_to_ascii(orig, expected):\n\"\"\"Check that non ascii filenames are converted to ascii only ones.\"\"\"\n    assert namechanger.normalise_filename(orig) == expected\n</code></pre>"},{"location":"reference/test/test_namechanger/#corpustools.test.test_namechanger.test_move_orig","title":"<code>test_move_orig(tmp_path)</code>","text":"<p>move to different subdir, with parallels.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_namechanger.py</code> <pre><code>def test_move_orig(tmp_path):\n\"\"\"move to different subdir, with parallels.\"\"\"\n    sme_orig = tmp_path / \"corpus-sme-orig\" / \"ficti\" / \"sub\" / \"f.txt\"\n    sme_orig.parent.mkdir(parents=True)\n    sme_orig.write_text(\"content of f\")\n\n    sme_corpuspath = corpuspath.CorpusPath(sme_orig.as_posix())\n\n    sme_corpuspath.metadata.set_variable(\"mainlang\", \"sme\")\n    sme_corpuspath.metadata.set_parallel_text(\"nob\", \"\u00f8.txt\")\n    sme_corpuspath.metadata.write_file()\n\n    if not sme_orig.exists():\n        raise SystemExit(f\"{sme_orig} does not exist\")\n\n    sme_converted = Path(sme_corpuspath.converted)\n    sme_converted.parent.mkdir(parents=True)\n    sme_converted.write_text(\"converted content of f\")\n\n    sme_tmx = Path(sme_corpuspath.tmx(\"nob\"))\n    sme_tmx.parent.mkdir(parents=True)\n    sme_tmx.write_text(\"parallelised content of f\")\n\n    r1 = git.Repo.init(sme_corpuspath.orig_corpus_dir)\n    r1.index.add([\"ficti\"])\n    r1.index.commit(\"a\")\n\n    r2 = git.Repo.init(sme_corpuspath.converted_corpus_dir)\n    r2.index.add([\"tmx\", \"converted\"])\n    r2.index.commit(\"a\")\n    cfm = namechanger.CorpusFileMover(\n        oldpath=sme_corpuspath.orig,\n        newpath=sme_corpuspath.move_orig(genre=\"facta\", subdirs=\"sub\"),\n    )\n    cfm.move_files()\n\n    new_corpuspath = corpuspath.CorpusPath(\n        sme_corpuspath.move_orig(genre=\"facta\", subdirs=\"sub\")\n    )\n    assert new_corpuspath.orig\n    assert new_corpuspath.xsl\n    assert new_corpuspath.converted\n    assert new_corpuspath.tmx(\"nob\")\n</code></pre>"},{"location":"reference/test/test_parallelize/","title":"test_parallelize","text":""},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestParallelizeHunalign","title":"<code>TestParallelizeHunalign</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>A test class for the ParallelizeHunalign class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>class TestParallelizeHunalign(unittest.TestCase):\n\"\"\"A test class for the ParallelizeHunalign class.\"\"\"\n\n    def setUp(self):\n        self.parallelize = parallelize.ParallelizeHunalign(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/sme/facta/skuvlahistorja2/\",\n                \"aarseth2-s.html.xml\",\n            ),\n            \"nob\",\n            quiet=True,\n        )\n\n    def test_hunalign_dict(self):\n        self.assertEqual(\n            self.parallelize.anchor_to_dict(\n                [\n                    (\"foo, bar\", \"fie\"),\n                    (\"1, ein\", \"eins\"),\n                    (\"2, \u0434\u0432\u0430\", \"2, guokte\"),\n                ]\n            ),\n            [\n                (\"foo\", \"fie\"),\n                (\"bar\", \"fie\"),\n                (\"1\", \"eins\"),\n                (\"ein\", \"eins\"),\n                (\"2\", \"2\"),\n                (\"2\", \"guokte\"),\n                (\"\u0434\u0432\u0430\", \"2\"),\n                (\"\u0434\u0432\u0430\", \"guokte\"),\n            ],\n        )\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestParallelizeTCA2","title":"<code>TestParallelizeTCA2</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>A test class for the ParallelizeTCA2 class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>class TestParallelizeTCA2(unittest.TestCase):\n\"\"\"A test class for the ParallelizeTCA2 class.\"\"\"\n\n    def setUp(self):\n        self.parallelize = parallelize.ParallelizeTCA2(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/sme/facta/skuvlahistorja2/\",\n                \"aarseth2-s.html.xml\",\n            ),\n            \"nob\",\n            quiet=True,\n            giella_prefix=os.path.join(HERE, \"giella_shared\"),\n        )\n\n    def test_lang1(self):\n        self.assertEqual(self.parallelize.lang1, \"nob\")\n\n    def test_lang2(self):\n        self.assertEqual(self.parallelize.lang2, \"sme\")\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTca2SentenceDivider","title":"<code>TestTca2SentenceDivider</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>A test class for the Tca2SentenceDivider class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>class TestTca2SentenceDivider(unittest.TestCase):\n\"\"\"A test class for the Tca2SentenceDivider class.\"\"\"\n\n    @staticmethod\n    def assertXmlEqual(got, want):\n\"\"\"Check if two xml snippets are equal.\"\"\"\n        string_got = etree.tostring(got, encoding=\"unicode\")\n        string_want = etree.tostring(want, encoding=\"unicode\")\n\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(string_want, string_got, 0):\n            message = checker.output_difference(\n                doctest.Example(\"\", string_want), string_got, 0\n            )\n            raise AssertionError(message)\n\n    def test_make_sentence_file(self):\n        path = corpuspath.CorpusPath(\n            os.path.join(\n                HERE,\n                \"parallelize_data/converted/sme/facta/skuvlahistorja2/\",\n                \"finnmarkkulahka_web_lettere.pdf.xml\",\n            )\n        )\n\n        sentence_divider = parallelize.Tca2SentenceDivider()\n        got = sentence_divider.make_sentence_xml(\n            path.pathcomponents.lang,\n            path.converted,\n            giella_prefix=os.path.join(HERE, \"giella_shared\"),\n        )\n\n        want = etree.parse(\n            os.path.join(\n                HERE,\n                \"parallelize_data/\",\n                \"finnmarkkulahka_web_lettere.pdfsme_sent.xml.test\",\n            )\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTca2SentenceDivider.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>  <code>staticmethod</code>","text":"<p>Check if two xml snippets are equal.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>@staticmethod\ndef assertXmlEqual(got, want):\n\"\"\"Check if two xml snippets are equal.\"\"\"\n    string_got = etree.tostring(got, encoding=\"unicode\")\n    string_want = etree.tostring(want, encoding=\"unicode\")\n\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(string_want, string_got, 0):\n        message = checker.output_difference(\n            doctest.Example(\"\", string_want), string_got, 0\n        )\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTca2ToTmx","title":"<code>TestTca2ToTmx</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>A test class for the Tca2ToTmx class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>class TestTca2ToTmx(unittest.TestCase):\n\"\"\"A test class for the Tca2ToTmx class.\"\"\"\n\n    def setUp(self):\n\"\"\"Hand the data from the Parallelize class to the tmx class.\"\"\"\n        para = parallelize.ParallelizeTCA2(\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"converted/nob/facta/skuvlahistorja2/\",\n                \"aarseth2-n.html.xml\",\n            ),\n            \"sme\",\n        )\n        self.para = para\n        self.tmx = tmx.Tca2ToTmx(para.origfiles, para.sentfiles)\n\n    def assertXmlEqual(self, got, want):\n\"\"\"Check if two xml snippets are equal.\"\"\"\n        string_got = etree.tostring(got, encoding=\"unicode\")\n        string_want = etree.tostring(want, encoding=\"unicode\")\n\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(string_want, string_got, 0):\n            message = checker.output_difference(\n                doctest.Example(\"\", string_want), string_got, 0\n            )\n            raise AssertionError(message)\n\n    def test_make_tu(self):\n        line1 = '&lt;s id=\"1\"&gt;ubba gubba.&lt;/s&gt; &lt;s id=\"2\"&gt;ibba gibba.&lt;/s&gt;'\n        line2 = '&lt;s id=\"1\"&gt;abba gabba.&lt;/s&gt; &lt;s id=\"2\"&gt;ebba gebba.&lt;/s&gt;'\n\n        got_tu = self.tmx.make_tu(\n            self.tmx.remove_s_tag(line1), self.tmx.remove_s_tag(line2)\n        )\n\n        want_tu = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;ubba gubba. ibba gibba.&lt;/seg&gt;'\n            '&lt;/tuv&gt;&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;abba gabba. ebba gebba.'\n            \"&lt;/seg&gt;&lt;/tuv&gt;&lt;/tu&gt;\"\n        )\n\n        self.assertXmlEqual(got_tu, want_tu)\n\n    def test_make_tuv(self):\n        line = '&lt;s id=\"1\"&gt;ubba gubba.&lt;/s&gt; &lt;s id=\"2\"&gt;ibba gibba.&lt;/s&gt;'\n        lang = \"smi\"\n        got_tuv = self.tmx.make_tuv(self.tmx.remove_s_tag(line), lang)\n\n        want_tuv = etree.XML(\n            '&lt;tuv xml:lang=\"smi\"&gt;&lt;seg&gt;ubba gubba. ibba gibba.&lt;/seg&gt;&lt;/tuv&gt;'\n        )\n\n        self.assertXmlEqual(got_tuv, want_tuv)\n\n    def test_make_tmx_header(self):\n        lang = \"smi\"\n        got_tuv = self.tmx.make_tmx_header(\"filename.tmx\", lang)\n\n        want_tuv = etree.XML(\n            '&lt;header segtype=\"sentence\" o-tmf=\"OmegaT TMX\" adminlang=\"en-US\" '\n            'srclang=\"smi\" datatype=\"plaintext\"&gt;'\n            '&lt;prop type=\"x-filename\"&gt;filename.tmx&lt;/prop&gt;'\n            \"&lt;/header&gt;\"\n        )\n\n        self.assertXmlEqual(got_tuv, want_tuv)\n\n    def test_remove_s_tag(self):\n        got = self.tmx.remove_s_tag(\n            '&lt;s id=\"1\"&gt;ubba gubba.&lt;/s&gt; &lt;s id=\"2\"&gt;ibba gibba.&lt;/s&gt;'\n        )\n        want = \"ubba gubba. ibba gibba.\"\n\n        self.assertEqual(got, want)\n\n    def test_get_outfile_name(self):\n        self.assertEqual(\n            self.para.outfile_name,\n            os.path.join(\n                HERE,\n                \"parallelize_data\",\n                \"prestable/tmx/nob2sme/facta/skuvlahistorja2\",\n                \"aarseth2-n.html.tmx\",\n            ),\n        )\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTca2ToTmx.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>","text":"<p>Check if two xml snippets are equal.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>def assertXmlEqual(self, got, want):\n\"\"\"Check if two xml snippets are equal.\"\"\"\n    string_got = etree.tostring(got, encoding=\"unicode\")\n    string_want = etree.tostring(want, encoding=\"unicode\")\n\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(string_want, string_got, 0):\n        message = checker.output_difference(\n            doctest.Example(\"\", string_want), string_got, 0\n        )\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTca2ToTmx.setUp","title":"<code>setUp()</code>","text":"<p>Hand the data from the Parallelize class to the tmx class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>def setUp(self):\n\"\"\"Hand the data from the Parallelize class to the tmx class.\"\"\"\n    para = parallelize.ParallelizeTCA2(\n        os.path.join(\n            HERE,\n            \"parallelize_data\",\n            \"converted/nob/facta/skuvlahistorja2/\",\n            \"aarseth2-n.html.xml\",\n        ),\n        \"sme\",\n    )\n    self.para = para\n    self.tmx = tmx.Tca2ToTmx(para.origfiles, para.sentfiles)\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTmx","title":"<code>TestTmx</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>A test class for the Tmx class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>class TestTmx(unittest.TestCase):\n\"\"\"A test class for the Tmx class.\"\"\"\n\n    def setUp(self):\n        self.tmx = tmx.Tmx(\n            etree.parse(os.path.join(HERE, \"parallelize_data/aarseth2-n.htm.toktmx\"))\n        )\n\n    def assertXmlEqual(self, got, want):\n\"\"\"Check if two xml snippets are equal.\"\"\"\n        string_got = etree.tostring(got, encoding=\"unicode\")\n        string_want = etree.tostring(want, encoding=\"unicode\")\n\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(string_want, string_got, 0):\n            message = checker.output_difference(\n                doctest.Example(\"\", string_want), string_got, 0\n            )\n            raise AssertionError(message)\n\n    def test_get_src_lang(self):\n\"\"\"Test the get_src_lang routine.\"\"\"\n        self.assertEqual(self.tmx.src_lang, \"nob\")\n\n    def test_tu_to_string(self):\n        tu = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;S\u00e1megiella&lt;/seg&gt;&lt;/tuv&gt;'\n            '&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;Samisk&lt;/seg&gt;&lt;/tuv&gt;&lt;/tu&gt;'\n        )\n\n        self.assertEqual(self.tmx.tu_to_string(tu), \"S\u00e1megiella\\tSamisk\\n\")\n\n    def test_tuv_to_string(self):\n        tuv = etree.XML('&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;S\u00e1megiella&lt;/seg&gt;&lt;/tuv&gt;')\n\n        self.assertEqual(self.tmx.tuv_to_string(tuv), \"S\u00e1megiella\")\n\n    def test_lang_to_string_list(self):\n        toktmx_txt_name = os.path.join(\n            HERE, \"parallelize_data/aarseth2-n.htm.toktmx.as.txt\"\n        )\n        with codecs.open(toktmx_txt_name, encoding=\"utf8\") as toktmx_txt:\n            string_list = toktmx_txt.read().split(\"\\n\")\n\n            nob_list = []\n            sme_list = []\n            for string in string_list:\n                pair_list = string.split(\"\\t\")\n                if len(pair_list) == 2:\n                    nob_list.append(pair_list[0])\n                    sme_list.append(pair_list[1].strip())\n\n            self.assertEqual(self.tmx.lang_to_stringlist(\"nob\"), nob_list)\n            self.assertEqual(self.tmx.lang_to_stringlist(\"sme\"), sme_list)\n\n    def test_tmx_to_stringlist(self):\n        toktmx_txt_name = os.path.join(\n            HERE, \"parallelize_data/aarseth2-n.htm.toktmx.as.txt\"\n        )\n        with codecs.open(toktmx_txt_name, encoding=\"utf8\") as toktmx_txt:\n            want_list = [l for l in toktmx_txt.readlines()]\n            # self.maxDiff = None\n            self.assertEqual(self.tmx.tmx_to_stringlist(), want_list)\n\n    def test_prettify_segs(self):\n        wantXml = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;ubba gubba. ibba gibba.&lt;/seg&gt;&lt;/tuv&gt;'\n            '&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;abba gabba. ebba gebba.'\n            \"&lt;/seg&gt;&lt;/tuv&gt;&lt;/tu&gt;\"\n        )\n        gotXml = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;ubba gubba. ibba gibba.\\n&lt;/seg&gt;'\n            '&lt;/tuv&gt;&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;abba gabba. ebba gebba.\\n&lt;/seg&gt;'\n            \"&lt;/tuv&gt;&lt;/tu&gt;\"\n        )\n        self.assertXmlEqual(self.tmx.prettify_segs(gotXml), wantXml)\n\n    def test_check_if_emtpy_seg(self):\n        empty1 = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;ubba gubba. ibba gibba.&lt;/seg&gt;&lt;/tuv&gt;'\n            '&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;&lt;/seg&gt;&lt;/tuv&gt;&lt;/tu&gt;'\n        )\n        self.assertRaises(AttributeError, self.tmx.check_if_emtpy_seg, empty1)\n\n        empty2 = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;&lt;/seg&gt;&lt;/tuv&gt;&lt;tuv xml:lang=\"sme\"&gt;'\n            \"&lt;seg&gt;abba gabba. ebba gebba.&lt;/seg&gt;&lt;/tuv&gt;&lt;/tu&gt;\"\n        )\n        self.assertRaises(AttributeError, self.tmx.check_if_emtpy_seg, empty2)\n\n    def test_remove_unwanted_space_from_segs(self):\n        wantXml = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;[30] (juli) \u00abskoleturer\u00bb.&lt;/seg&gt;'\n            '&lt;/tuv&gt;&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;[30] (suoidnem\u00e1nnu) '\n            \"\u00abskuvlatuvrrat\u00bb.&lt;/seg&gt;&lt;/tuv&gt;&lt;/tu&gt;\"\n        )\n        gotXml = etree.XML(\n            '&lt;tu&gt;&lt;tuv xml:lang=\"nob\"&gt;&lt;seg&gt;[ 30 ] ( juli ) \u00ab skoleturer \u00bb .\\n'\n            '&lt;/seg&gt;&lt;/tuv&gt;&lt;tuv xml:lang=\"sme\"&gt;&lt;seg&gt;[ 30 ] ( suoidnem\u00e1nnu ) \u00ab '\n            \"skuvlatuvrrat \u00bb .\\n&lt;/seg&gt;&lt;/tuv&gt;&lt;/tu&gt;\"\n        )\n        self.assertXmlEqual(self.tmx.remove_unwanted_space_from_segs(gotXml), wantXml)\n\n    def test_remove_unwanted_space_from_string(self):\n        got = self.tmx.remove_unwanted_space_from_string(\n            \"s\u00e1mesearvvi ; [ 31 ] ( suoidnem\u00e1nnu ) \u00ab skuvlatuvrrat \u00bb \"\n            \"bargu lea :  okta , guokte .\"\n        )\n        want = (\n            \"s\u00e1mesearvvi; [31] (suoidnem\u00e1nnu) \u00abskuvlatuvrrat\u00bb bargu lea: \"\n            \"okta, guokte.\"\n        )\n        self.assertEqual(got, want)\n\n    def test_remove_tu_with_empty_seg(self):\n        got_tmx = tmx.Tmx(\n            etree.parse(os.path.join(HERE, \"parallelize_data/aarseth2-n.htm.toktmx\"))\n        )\n        got_tmx.remove_tu_with_empty_seg()\n\n        want_tmx = tmx.Tmx(\n            etree.parse(\n                os.path.join(\n                    HERE, \"parallelize_data/\", \"aarseth2-n-without-empty-seg.htm.toktmx\"\n                )\n            )\n        )\n\n        self.assertXmlEqual(got_tmx.tmx, want_tmx.tmx)\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTmx.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>","text":"<p>Check if two xml snippets are equal.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>def assertXmlEqual(self, got, want):\n\"\"\"Check if two xml snippets are equal.\"\"\"\n    string_got = etree.tostring(got, encoding=\"unicode\")\n    string_want = etree.tostring(want, encoding=\"unicode\")\n\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(string_want, string_got, 0):\n        message = checker.output_difference(\n            doctest.Example(\"\", string_want), string_got, 0\n        )\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_parallelize/#corpustools.test.test_parallelize.TestTmx.test_get_src_lang","title":"<code>test_get_src_lang()</code>","text":"<p>Test the get_src_lang routine.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_parallelize.py</code> <pre><code>def test_get_src_lang(self):\n\"\"\"Test the get_src_lang routine.\"\"\"\n    self.assertEqual(self.tmx.src_lang, \"nob\")\n</code></pre>"},{"location":"reference/test/test_pdfconverter/","title":"test_pdfconverter","text":"<p>Test conversion of pdf files.</p>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDF2XMLConverter","title":"<code>TestPDF2XMLConverter</code>","text":"<p>         Bases: <code>xmltester.XMLTester</code></p> <p>Test the class that converts from pdf2xml to giellatekno/divvun xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>class TestPDF2XMLConverter(xmltester.XMLTester):\n\"\"\"Test the class that converts from pdf2xml to giellatekno/divvun xml.\"\"\"\n\n    def test_pdf_converter(self):\n        pdfdocument = pdfconverter.PDF2XMLConverter(\n            os.path.join(HERE, \"converter_data/fakecorpus/orig/sme/riddu/pdf-test.pdf\")\n        )\n        got = pdfdocument.convert2intermediate()\n        want = etree.parse(os.path.join(HERE, \"converter_data/pdf-xml2pdf-test.xml\"))\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage","title":"<code>TestPDFPage</code>","text":"<p>         Bases: <code>xmltester.XMLTester</code></p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>class TestPDFPage(xmltester.XMLTester):\n    def test_is_inside_margins1(self):\n\"\"\"top and left inside margins.\"\"\"\n        t = etree.fromstring('&lt;p style=\"top:109px;left:135px\"/&gt;')\n        margins = {}\n        margins[\"left_margin\"] = 62\n        margins[\"right_margin\"] = 802\n        margins[\"top_margin\"] = 88\n        margins[\"bottom_margin\"] = 1174\n\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertTrue(p2x.is_inside_margins(t, margins))\n\n    def test_is_inside_margins2(self):\n\"\"\"top above top margin and left inside margins.\"\"\"\n        t = etree.fromstring('&lt;p style=\"top:85px;left:135px\"/&gt;')\n        margins = {}\n        margins[\"left_margin\"] = 62\n        margins[\"right_margin\"] = 802\n        margins[\"top_margin\"] = 88\n        margins[\"bottom_margin\"] = 1174\n\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertFalse(p2x.is_inside_margins(t, margins))\n\n    def test_is_inside_margins3(self):\n\"\"\"top below bottom margin and left inside margins.\"\"\"\n        t = etree.fromstring('&lt;p style=\"top:1178px;left:135px\"/&gt;')\n        margins = {}\n        margins[\"left_margin\"] = 62\n        margins[\"right_margin\"] = 802\n        margins[\"top_margin\"] = 88\n        margins[\"bottom_margin\"] = 1174\n\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertFalse(p2x.is_inside_margins(t, margins))\n\n    def test_is_inside_margins4(self):\n\"\"\"top inside margins and left outside right margin.\"\"\"\n        t = etree.fromstring('&lt;p style=\"top:1000px;left:50px\"/&gt;')\n        margins = {}\n        margins[\"left_margin\"] = 62\n        margins[\"right_margin\"] = 802\n        margins[\"top_margin\"] = 88\n        margins[\"bottom_margin\"] = 1174\n\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertFalse(p2x.is_inside_margins(t, margins))\n\n    def test_is_inside_margins5(self):\n\"\"\"top inside margins and left outside left margin.\"\"\"\n        t = etree.fromstring('&lt;p style=\"top:1000px;left:805px\"/&gt;')\n        margins = {}\n        margins[\"left_margin\"] = 62\n        margins[\"right_margin\"] = 802\n        margins[\"top_margin\"] = 88\n        margins[\"bottom_margin\"] = 1174\n\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertFalse(p2x.is_inside_margins(t, margins))\n\n    def test_is_skip_page_1(self):\n\"\"\"Odd page should be skipped when odd is in skip_pages.\"\"\"\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page1-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertTrue(p2x.is_skip_page([\"odd\"]))\n\n    def test_is_skip_page_2(self):\n\"\"\"Even page should be skipped when even is in skip_pages.\"\"\"\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertTrue(p2x.is_skip_page([\"even\"]))\n\n    def test_is_skip_page_3(self):\n\"\"\"Even page should not be skipped when odd is in skip_pages.\"\"\"\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertFalse(p2x.is_skip_page([\"odd\"]))\n\n    def test_is_skip_page_4(self):\n\"\"\"Odd page should not be skipped when even is in skip_pages.\"\"\"\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page1-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertFalse(p2x.is_skip_page([\"even\"]))\n\n    def test_is_skip_page_5(self):\n\"\"\"Page should not be skipped when not in skip_range.\"\"\"\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page1-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertFalse(p2x.is_skip_page([\"even\", 3]))\n\n    def test_is_skip_page_6(self):\n\"\"\"Page should be skipped when in skip_range.\"\"\"\n        p2x = pdfconverter.PDFPage(\n            etree.fromstring('&lt;div id=\"page3-div\" style=\"width:862px;height:1263px\"/&gt;')\n        )\n\n        self.assertTrue(p2x.is_skip_page([\"even\", 3]))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_inside_margins1","title":"<code>test_is_inside_margins1()</code>","text":"<p>top and left inside margins.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_inside_margins1(self):\n\"\"\"top and left inside margins.\"\"\"\n    t = etree.fromstring('&lt;p style=\"top:109px;left:135px\"/&gt;')\n    margins = {}\n    margins[\"left_margin\"] = 62\n    margins[\"right_margin\"] = 802\n    margins[\"top_margin\"] = 88\n    margins[\"bottom_margin\"] = 1174\n\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertTrue(p2x.is_inside_margins(t, margins))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_inside_margins2","title":"<code>test_is_inside_margins2()</code>","text":"<p>top above top margin and left inside margins.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_inside_margins2(self):\n\"\"\"top above top margin and left inside margins.\"\"\"\n    t = etree.fromstring('&lt;p style=\"top:85px;left:135px\"/&gt;')\n    margins = {}\n    margins[\"left_margin\"] = 62\n    margins[\"right_margin\"] = 802\n    margins[\"top_margin\"] = 88\n    margins[\"bottom_margin\"] = 1174\n\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertFalse(p2x.is_inside_margins(t, margins))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_inside_margins3","title":"<code>test_is_inside_margins3()</code>","text":"<p>top below bottom margin and left inside margins.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_inside_margins3(self):\n\"\"\"top below bottom margin and left inside margins.\"\"\"\n    t = etree.fromstring('&lt;p style=\"top:1178px;left:135px\"/&gt;')\n    margins = {}\n    margins[\"left_margin\"] = 62\n    margins[\"right_margin\"] = 802\n    margins[\"top_margin\"] = 88\n    margins[\"bottom_margin\"] = 1174\n\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertFalse(p2x.is_inside_margins(t, margins))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_inside_margins4","title":"<code>test_is_inside_margins4()</code>","text":"<p>top inside margins and left outside right margin.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_inside_margins4(self):\n\"\"\"top inside margins and left outside right margin.\"\"\"\n    t = etree.fromstring('&lt;p style=\"top:1000px;left:50px\"/&gt;')\n    margins = {}\n    margins[\"left_margin\"] = 62\n    margins[\"right_margin\"] = 802\n    margins[\"top_margin\"] = 88\n    margins[\"bottom_margin\"] = 1174\n\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertFalse(p2x.is_inside_margins(t, margins))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_inside_margins5","title":"<code>test_is_inside_margins5()</code>","text":"<p>top inside margins and left outside left margin.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_inside_margins5(self):\n\"\"\"top inside margins and left outside left margin.\"\"\"\n    t = etree.fromstring('&lt;p style=\"top:1000px;left:805px\"/&gt;')\n    margins = {}\n    margins[\"left_margin\"] = 62\n    margins[\"right_margin\"] = 802\n    margins[\"top_margin\"] = 88\n    margins[\"bottom_margin\"] = 1174\n\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertFalse(p2x.is_inside_margins(t, margins))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_skip_page_1","title":"<code>test_is_skip_page_1()</code>","text":"<p>Odd page should be skipped when odd is in skip_pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_skip_page_1(self):\n\"\"\"Odd page should be skipped when odd is in skip_pages.\"\"\"\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page1-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertTrue(p2x.is_skip_page([\"odd\"]))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_skip_page_2","title":"<code>test_is_skip_page_2()</code>","text":"<p>Even page should be skipped when even is in skip_pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_skip_page_2(self):\n\"\"\"Even page should be skipped when even is in skip_pages.\"\"\"\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertTrue(p2x.is_skip_page([\"even\"]))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_skip_page_3","title":"<code>test_is_skip_page_3()</code>","text":"<p>Even page should not be skipped when odd is in skip_pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_skip_page_3(self):\n\"\"\"Even page should not be skipped when odd is in skip_pages.\"\"\"\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page2-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertFalse(p2x.is_skip_page([\"odd\"]))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_skip_page_4","title":"<code>test_is_skip_page_4()</code>","text":"<p>Odd page should not be skipped when even is in skip_pages.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_skip_page_4(self):\n\"\"\"Odd page should not be skipped when even is in skip_pages.\"\"\"\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page1-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertFalse(p2x.is_skip_page([\"even\"]))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_skip_page_5","title":"<code>test_is_skip_page_5()</code>","text":"<p>Page should not be skipped when not in skip_range.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_skip_page_5(self):\n\"\"\"Page should not be skipped when not in skip_range.\"\"\"\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page1-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertFalse(p2x.is_skip_page([\"even\", 3]))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPage.test_is_skip_page_6","title":"<code>test_is_skip_page_6()</code>","text":"<p>Page should be skipped when in skip_range.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_is_skip_page_6(self):\n\"\"\"Page should be skipped when in skip_range.\"\"\"\n    p2x = pdfconverter.PDFPage(\n        etree.fromstring('&lt;div id=\"page3-div\" style=\"width:862px;height:1263px\"/&gt;')\n    )\n\n    self.assertTrue(p2x.is_skip_page([\"even\", 3]))\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPageMetaData","title":"<code>TestPDFPageMetaData</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>class TestPDFPageMetaData(unittest.TestCase):\n    def test_compute_default_margins(self):\n\"\"\"Test if the default margins are set.\"\"\"\n        page1 = pdfconverter.PDFPageMetadata(\n            page_id=\"page1-div\", page_style=\"height:1263px;width:862px;\"\n        )\n\n        self.assertEqual(\n            page1.compute_margins(),\n            {\n                \"left_margin\": 60,\n                \"right_margin\": 801,\n                \"top_margin\": 88,\n                \"bottom_margin\": 1174,\n            },\n        )\n\n    def test_compute_margins1(self):\n\"\"\"Test parse_margin_lines.\"\"\"\n        metadata = xslsetter.MetadataHandler(\"test.pdf.xsl\", create=True)\n        metadata.set_variable(\"left_margin\", \"7=5\")\n        metadata.set_variable(\"right_margin\", \"odd=10,even=15,3=5\")\n        metadata.set_variable(\"top_margin\", \"8=8\")\n        metadata.set_variable(\"bottom_margin\", \"9=20\")\n\n        page1 = pdfconverter.PDFPageMetadata(\n            page_id=\"page1-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_margins=metadata.margins,\n        )\n\n        self.assertEqual(\n            page1.compute_margins(),\n            {\n                \"left_margin\": 60,\n                \"right_margin\": 775,\n                \"top_margin\": 88,\n                \"bottom_margin\": 1174,\n            },\n        )\n        page2 = pdfconverter.PDFPageMetadata(\n            page_id=\"page2-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_margins=metadata.margins,\n        )\n        self.assertEqual(\n            page2.compute_margins(),\n            {\n                \"left_margin\": 60,\n                \"right_margin\": 732,\n                \"top_margin\": 88,\n                \"bottom_margin\": 1174,\n            },\n        )\n        page3 = pdfconverter.PDFPageMetadata(\n            page_id=\"page3-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_margins=metadata.margins,\n        )\n        self.assertEqual(\n            page3.compute_margins(),\n            {\n                \"left_margin\": 60,\n                \"right_margin\": 818,\n                \"top_margin\": 88,\n                \"bottom_margin\": 1174,\n            },\n        )\n        page7 = pdfconverter.PDFPageMetadata(\n            page_id=\"page7-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_margins=metadata.margins,\n        )\n        self.assertEqual(\n            page7.compute_margins(),\n            {\n                \"left_margin\": 43,\n                \"right_margin\": 775,\n                \"top_margin\": 88,\n                \"bottom_margin\": 1174,\n            },\n        )\n        page8 = pdfconverter.PDFPageMetadata(\n            page_id=\"page8-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_margins=metadata.margins,\n        )\n        self.assertEqual(\n            page8.compute_margins(),\n            {\n                \"left_margin\": 60,\n                \"right_margin\": 732,\n                \"top_margin\": 101,\n                \"bottom_margin\": 1174,\n            },\n        )\n        page9 = pdfconverter.PDFPageMetadata(\n            page_id=\"page9-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_margins=metadata.margins,\n        )\n        self.assertEqual(\n            page9.compute_margins(),\n            {\n                \"left_margin\": 60,\n                \"right_margin\": 775,\n                \"top_margin\": 88,\n                \"bottom_margin\": 1010,\n            },\n        )\n\n    def test_compute_inner_margins_1(self):\n\"\"\"Test if inner margins is set for the specified page.\"\"\"\n        metadata = xslsetter.MetadataHandler(\"test.pdf.xsl\", create=True)\n        metadata.set_variable(\"inner_top_margin\", \"1=40\")\n        metadata.set_variable(\"inner_bottom_margin\", \"1=40\")\n\n        page1 = pdfconverter.PDFPageMetadata(\n            page_id=\"page1-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_inner_margins=metadata.inner_margins,\n        )\n\n        self.assertEqual(\n            page1.compute_inner_margins(),\n            {\n                \"top_margin\": 505,\n                \"bottom_margin\": 757,\n                \"left_margin\": 0,\n                \"right_margin\": 862,\n            },\n        )\n\n    def test_compute_inner_margins_2(self):\n\"\"\"Test that inner margins is empty for the specified page.\"\"\"\n        metadata = xslsetter.MetadataHandler(\"test.pdf.xsl\", create=True)\n        metadata.set_variable(\"inner_top_margin\", \"1=40\")\n        metadata.set_variable(\"inner_bottom_margin\", \"1=40\")\n\n        page1 = pdfconverter.PDFPageMetadata(\n            page_id=\"page2-div\",\n            page_style=\"height:1263px;width:862px;\",\n            metadata_inner_margins=metadata.inner_margins,\n        )\n\n        self.assertEqual(page1.compute_inner_margins(), {})\n\n    def test_width(self):\n        page = pdfconverter.PDFPageMetadata(\n            page_id=\"page1-div\", page_style=\"height:1263px;width:862px;\"\n        )\n\n        self.assertEqual(page.page_number, 1)\n        self.assertEqual(page.page_height, 1263)\n        self.assertEqual(page.page_width, 862)\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPageMetaData.test_compute_default_margins","title":"<code>test_compute_default_margins()</code>","text":"<p>Test if the default margins are set.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_compute_default_margins(self):\n\"\"\"Test if the default margins are set.\"\"\"\n    page1 = pdfconverter.PDFPageMetadata(\n        page_id=\"page1-div\", page_style=\"height:1263px;width:862px;\"\n    )\n\n    self.assertEqual(\n        page1.compute_margins(),\n        {\n            \"left_margin\": 60,\n            \"right_margin\": 801,\n            \"top_margin\": 88,\n            \"bottom_margin\": 1174,\n        },\n    )\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPageMetaData.test_compute_inner_margins_1","title":"<code>test_compute_inner_margins_1()</code>","text":"<p>Test if inner margins is set for the specified page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_compute_inner_margins_1(self):\n\"\"\"Test if inner margins is set for the specified page.\"\"\"\n    metadata = xslsetter.MetadataHandler(\"test.pdf.xsl\", create=True)\n    metadata.set_variable(\"inner_top_margin\", \"1=40\")\n    metadata.set_variable(\"inner_bottom_margin\", \"1=40\")\n\n    page1 = pdfconverter.PDFPageMetadata(\n        page_id=\"page1-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_inner_margins=metadata.inner_margins,\n    )\n\n    self.assertEqual(\n        page1.compute_inner_margins(),\n        {\n            \"top_margin\": 505,\n            \"bottom_margin\": 757,\n            \"left_margin\": 0,\n            \"right_margin\": 862,\n        },\n    )\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPageMetaData.test_compute_inner_margins_2","title":"<code>test_compute_inner_margins_2()</code>","text":"<p>Test that inner margins is empty for the specified page.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_compute_inner_margins_2(self):\n\"\"\"Test that inner margins is empty for the specified page.\"\"\"\n    metadata = xslsetter.MetadataHandler(\"test.pdf.xsl\", create=True)\n    metadata.set_variable(\"inner_top_margin\", \"1=40\")\n    metadata.set_variable(\"inner_bottom_margin\", \"1=40\")\n\n    page1 = pdfconverter.PDFPageMetadata(\n        page_id=\"page2-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_inner_margins=metadata.inner_margins,\n    )\n\n    self.assertEqual(page1.compute_inner_margins(), {})\n</code></pre>"},{"location":"reference/test/test_pdfconverter/#corpustools.test.test_pdfconverter.TestPDFPageMetaData.test_compute_margins1","title":"<code>test_compute_margins1()</code>","text":"<p>Test parse_margin_lines.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pdfconverter.py</code> <pre><code>def test_compute_margins1(self):\n\"\"\"Test parse_margin_lines.\"\"\"\n    metadata = xslsetter.MetadataHandler(\"test.pdf.xsl\", create=True)\n    metadata.set_variable(\"left_margin\", \"7=5\")\n    metadata.set_variable(\"right_margin\", \"odd=10,even=15,3=5\")\n    metadata.set_variable(\"top_margin\", \"8=8\")\n    metadata.set_variable(\"bottom_margin\", \"9=20\")\n\n    page1 = pdfconverter.PDFPageMetadata(\n        page_id=\"page1-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_margins=metadata.margins,\n    )\n\n    self.assertEqual(\n        page1.compute_margins(),\n        {\n            \"left_margin\": 60,\n            \"right_margin\": 775,\n            \"top_margin\": 88,\n            \"bottom_margin\": 1174,\n        },\n    )\n    page2 = pdfconverter.PDFPageMetadata(\n        page_id=\"page2-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_margins=metadata.margins,\n    )\n    self.assertEqual(\n        page2.compute_margins(),\n        {\n            \"left_margin\": 60,\n            \"right_margin\": 732,\n            \"top_margin\": 88,\n            \"bottom_margin\": 1174,\n        },\n    )\n    page3 = pdfconverter.PDFPageMetadata(\n        page_id=\"page3-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_margins=metadata.margins,\n    )\n    self.assertEqual(\n        page3.compute_margins(),\n        {\n            \"left_margin\": 60,\n            \"right_margin\": 818,\n            \"top_margin\": 88,\n            \"bottom_margin\": 1174,\n        },\n    )\n    page7 = pdfconverter.PDFPageMetadata(\n        page_id=\"page7-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_margins=metadata.margins,\n    )\n    self.assertEqual(\n        page7.compute_margins(),\n        {\n            \"left_margin\": 43,\n            \"right_margin\": 775,\n            \"top_margin\": 88,\n            \"bottom_margin\": 1174,\n        },\n    )\n    page8 = pdfconverter.PDFPageMetadata(\n        page_id=\"page8-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_margins=metadata.margins,\n    )\n    self.assertEqual(\n        page8.compute_margins(),\n        {\n            \"left_margin\": 60,\n            \"right_margin\": 732,\n            \"top_margin\": 101,\n            \"bottom_margin\": 1174,\n        },\n    )\n    page9 = pdfconverter.PDFPageMetadata(\n        page_id=\"page9-div\",\n        page_style=\"height:1263px;width:862px;\",\n        metadata_margins=metadata.margins,\n    )\n    self.assertEqual(\n        page9.compute_margins(),\n        {\n            \"left_margin\": 60,\n            \"right_margin\": 775,\n            \"top_margin\": 88,\n            \"bottom_margin\": 1010,\n        },\n    )\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/","title":"test_pick_parallel_docs","text":"<p>Test the ParallelPicker class.</p>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker","title":"<code>TestParallelPicker</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test the ParallelPicker class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>class TestParallelPicker(unittest.TestCase):\n\"\"\"Test the ParallelPicker class.\"\"\"\n\n    def make_tempdir(self):\n\"\"\"Make tempdir where ParallelPicker will do its magic.\"\"\"\n        tempdir = testfixtures.TempDirectory(ignore=[\".git\"])\n        tempdir.makedir(\"converted/sme/admin\")\n        tempdir.makedir(\"converted/nob/admin\")\n        tempdir.makedir(\"converted/smj/admin\")\n        tempdir.write(\n            \"converted/sme/admin/article-47.html.xml\", ARTICLE47_SME.encode(\"utf8\")\n        )\n        tempdir.write(\n            \"converted/nob/admin/article-47.html.xml\", ARTICLE47_NOB.encode(\"utf8\")\n        )\n        tempdir.write(\n            \"converted/smj/admin/article-47.html.xml\", ARTICLE47_SMJ.encode(\"utf8\")\n        )\n\n        return tempdir\n\n    def setUp(self):\n\"\"\"Make the ParallelPicker work on tempdir.\"\"\"\n        self.tempdir = self.make_tempdir()\n        git.Repo.init(self.tempdir.path)\n        self.language1_converted_dir = os.path.join(\n            self.tempdir.path, \"converted/sme/admin\"\n        )\n        self.picker = pick_parallel_docs.ParallelPicker(\n            self.language1_converted_dir, \"nob\", \"73\", \"110\"\n        )\n\n    def tearDown(self):\n\"\"\"Cleanup after tests are done.\"\"\"\n        self.tempdir.cleanup()\n\n    def test_calculate_language1(self):\n\"\"\"Check that the correct language is found.\"\"\"\n        self.picker.calculate_language1(\"converted/sme/admin\")\n        self.assertEqual(self.picker.language1, \"sme\")\n\n    def test_get_parallel_language(self):\n\"\"\"Check that the correct parallel language is set.\"\"\"\n        self.assertEqual(self.picker.parallel_language, \"nob\")\n\n    def test_has_parallel1(self):\n\"\"\"Parallel exists, parallel_text points to correct place.\"\"\"\n        file_with_parallel1 = corpusxmlfile.CorpusXMLFile(\n            os.path.join(self.language1_converted_dir, \"article-47.html.xml\")\n        )\n        self.assertTrue(self.picker.has_parallel(file_with_parallel1))\n\n    def test_has_parallel2(self):\n\"\"\"parallel_text points to wrong language.\"\"\"\n        file_with_parallel1 = corpusxmlfile.CorpusXMLFile(\n            os.path.join(self.language1_converted_dir, \"article-47.html.xml\")\n        )\n        file_with_parallel1.etree.find(\"//parallel_text\").set(\n            \"{http://www.w3.org/XML/1998/namespace}lang\", \"sma\"\n        )\n        self.assertFalse(self.picker.has_parallel(file_with_parallel1))\n\n    def test_has_parallel3(self):\n\"\"\"parallel_text points to wrong file.\"\"\"\n        file_with_parallel1 = corpusxmlfile.CorpusXMLFile(\n            os.path.join(self.language1_converted_dir, \"article-47.html.xml\")\n        )\n        file_with_parallel1.etree.find(\"//parallel_text\").set(\n            \"location\", \"article-48.html\"\n        )\n        self.assertFalse(self.picker.has_parallel(file_with_parallel1))\n\n    def test_find_lang1_files(self):\n\"\"\"Check that lang1 files are found.\"\"\"\n        self.assertListEqual(\n            glob.glob(self.language1_converted_dir + \"/*.xml\"),\n            [corpus_file.name for corpus_file in self.picker.find_lang1_files()],\n        )\n\n    def test_copy_valid_parallels(self):\n\"\"\"Only copy in the nob-sme pair, and align them.\"\"\"\n        self.picker.copy_valid_parallels()\n        self.tempdir.check_all(\n            \"prestable\",\n            \"converted/\",\n            \"converted/nob/\",\n            \"converted/nob/admin/\",\n            \"converted/nob/admin/article-47.html.xml\",\n            \"converted/sme/\",\n            \"converted/sme/admin/\",\n            \"converted/sme/admin/article-47.html.xml\",\n            \"tmx/\",\n            \"tmx/nob2sme/\",\n            \"tmx/nob2sme/admin/\",\n            \"tmx/nob2sme/admin/article-47.html.tmx\",\n            \"tmx/nob2sme/admin/article-47.html.tmx.html\",\n        )\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.make_tempdir","title":"<code>make_tempdir()</code>","text":"<p>Make tempdir where ParallelPicker will do its magic.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def make_tempdir(self):\n\"\"\"Make tempdir where ParallelPicker will do its magic.\"\"\"\n    tempdir = testfixtures.TempDirectory(ignore=[\".git\"])\n    tempdir.makedir(\"converted/sme/admin\")\n    tempdir.makedir(\"converted/nob/admin\")\n    tempdir.makedir(\"converted/smj/admin\")\n    tempdir.write(\n        \"converted/sme/admin/article-47.html.xml\", ARTICLE47_SME.encode(\"utf8\")\n    )\n    tempdir.write(\n        \"converted/nob/admin/article-47.html.xml\", ARTICLE47_NOB.encode(\"utf8\")\n    )\n    tempdir.write(\n        \"converted/smj/admin/article-47.html.xml\", ARTICLE47_SMJ.encode(\"utf8\")\n    )\n\n    return tempdir\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.setUp","title":"<code>setUp()</code>","text":"<p>Make the ParallelPicker work on tempdir.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def setUp(self):\n\"\"\"Make the ParallelPicker work on tempdir.\"\"\"\n    self.tempdir = self.make_tempdir()\n    git.Repo.init(self.tempdir.path)\n    self.language1_converted_dir = os.path.join(\n        self.tempdir.path, \"converted/sme/admin\"\n    )\n    self.picker = pick_parallel_docs.ParallelPicker(\n        self.language1_converted_dir, \"nob\", \"73\", \"110\"\n    )\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.tearDown","title":"<code>tearDown()</code>","text":"<p>Cleanup after tests are done.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def tearDown(self):\n\"\"\"Cleanup after tests are done.\"\"\"\n    self.tempdir.cleanup()\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.test_calculate_language1","title":"<code>test_calculate_language1()</code>","text":"<p>Check that the correct language is found.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def test_calculate_language1(self):\n\"\"\"Check that the correct language is found.\"\"\"\n    self.picker.calculate_language1(\"converted/sme/admin\")\n    self.assertEqual(self.picker.language1, \"sme\")\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.test_copy_valid_parallels","title":"<code>test_copy_valid_parallels()</code>","text":"<p>Only copy in the nob-sme pair, and align them.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def test_copy_valid_parallels(self):\n\"\"\"Only copy in the nob-sme pair, and align them.\"\"\"\n    self.picker.copy_valid_parallels()\n    self.tempdir.check_all(\n        \"prestable\",\n        \"converted/\",\n        \"converted/nob/\",\n        \"converted/nob/admin/\",\n        \"converted/nob/admin/article-47.html.xml\",\n        \"converted/sme/\",\n        \"converted/sme/admin/\",\n        \"converted/sme/admin/article-47.html.xml\",\n        \"tmx/\",\n        \"tmx/nob2sme/\",\n        \"tmx/nob2sme/admin/\",\n        \"tmx/nob2sme/admin/article-47.html.tmx\",\n        \"tmx/nob2sme/admin/article-47.html.tmx.html\",\n    )\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.test_find_lang1_files","title":"<code>test_find_lang1_files()</code>","text":"<p>Check that lang1 files are found.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def test_find_lang1_files(self):\n\"\"\"Check that lang1 files are found.\"\"\"\n    self.assertListEqual(\n        glob.glob(self.language1_converted_dir + \"/*.xml\"),\n        [corpus_file.name for corpus_file in self.picker.find_lang1_files()],\n    )\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.test_get_parallel_language","title":"<code>test_get_parallel_language()</code>","text":"<p>Check that the correct parallel language is set.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def test_get_parallel_language(self):\n\"\"\"Check that the correct parallel language is set.\"\"\"\n    self.assertEqual(self.picker.parallel_language, \"nob\")\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.test_has_parallel1","title":"<code>test_has_parallel1()</code>","text":"<p>Parallel exists, parallel_text points to correct place.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def test_has_parallel1(self):\n\"\"\"Parallel exists, parallel_text points to correct place.\"\"\"\n    file_with_parallel1 = corpusxmlfile.CorpusXMLFile(\n        os.path.join(self.language1_converted_dir, \"article-47.html.xml\")\n    )\n    self.assertTrue(self.picker.has_parallel(file_with_parallel1))\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.test_has_parallel2","title":"<code>test_has_parallel2()</code>","text":"<p>parallel_text points to wrong language.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def test_has_parallel2(self):\n\"\"\"parallel_text points to wrong language.\"\"\"\n    file_with_parallel1 = corpusxmlfile.CorpusXMLFile(\n        os.path.join(self.language1_converted_dir, \"article-47.html.xml\")\n    )\n    file_with_parallel1.etree.find(\"//parallel_text\").set(\n        \"{http://www.w3.org/XML/1998/namespace}lang\", \"sma\"\n    )\n    self.assertFalse(self.picker.has_parallel(file_with_parallel1))\n</code></pre>"},{"location":"reference/test/test_pick_parallel_docs/#corpustools.test.test_pick_parallel_docs.TestParallelPicker.test_has_parallel3","title":"<code>test_has_parallel3()</code>","text":"<p>parallel_text points to wrong file.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_pick_parallel_docs.py</code> <pre><code>def test_has_parallel3(self):\n\"\"\"parallel_text points to wrong file.\"\"\"\n    file_with_parallel1 = corpusxmlfile.CorpusXMLFile(\n        os.path.join(self.language1_converted_dir, \"article-47.html.xml\")\n    )\n    file_with_parallel1.etree.find(\"//parallel_text\").set(\n        \"location\", \"article-48.html\"\n    )\n    self.assertFalse(self.picker.has_parallel(file_with_parallel1))\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/","title":"test_plaintextconverter","text":"<p>Test conversion of plaintext files.</p>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter","title":"<code>TestPlaintextConverter</code>","text":"<p>         Bases: <code>xmltester.XMLTester</code></p> <p>Test the PlaintextConverter.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>class TestPlaintextConverter(xmltester.XMLTester):\n\"\"\"Test the PlaintextConverter.\"\"\"\n\n    def test_to_unicode(self):\n\"\"\"Check that winsami2 is converted to unicode.\"\"\"\n        plaintext = plaintextconverter.PlaintextConverter(\n            os.path.join(\n                HERE,\n                \"converter_data/fakecorpus/orig/sme/riddu/\" \"winsami2-test-ws2.txt\",\n            )\n        )\n        got = plaintext.to_unicode()\n\n        # Ensure that the data in want is unicode\n        file_ = codecs.open(\n            os.path.join(HERE, \"converter_data/winsami2-test-utf8.txt\"), encoding=\"utf8\"\n        )\n        want = file_.read()\n        file_.close()\n\n        self.assertEqual(got, want)\n\n    def test_strip_chars1(self):\n\"\"\"Check that weird chars are converted as exptected.\"\"\"\n        plaintext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        got = plaintext.strip_chars(\n            \"\\x0d\\n\" \"&lt;ASCII-MAC&gt;\\n\" \"&lt;vsn:3.000000&gt;\\n\" \"&lt;\\\\!q&gt;\\n\" \"&lt;\\\\!h&gt;\\n\"\n        )\n        want = \"\"\"\\n\\n\\n\\n\\n\\n\"\"\"\n\n        self.assertEqual(got, want)\n\n    def test_strip_chars2(self):\n\"\"\"Check that special chars are converted as expected.\"\"\"\n        plaintext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        got = plaintext.strip_chars(\n            \"&lt;0x010C&gt;&lt;0x010D&gt;&lt;0x0110&gt;&lt;0x0111&gt;&lt;0x014A&gt;&lt;0x014B&gt;&lt;0x0160&gt;&lt;0x0161&gt;\"\n            \"&lt;0x0166&gt;&lt;0x0167&gt;&lt;0x017D&gt;&lt;0x017E&gt;&lt;0x2003&gt;\"\n        )\n        want = \"\"\"\u010c\u010d\u0110\u0111\u014a\u014b\u0160\u0161\u0166\u0167\u017d\u017e \"\"\"\n\n        self.assertEqual(got, want)\n\n    def test_plaintext(self):\n\"\"\"Check that an empty line signal paragraph.\"\"\"\n        plaintext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        got = plaintext.content2xml(\n            io.StringIO(\n\"\"\"S\u00e1megiella.\n\nBuot leat.\"\"\"\n            )\n        )\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;\n            S\u00e1megiella.\n        &lt;/p&gt;\n        &lt;p&gt;\n           Buot leat.\n       &lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_two_lines(self):\n\"\"\"Test that two consecutive lines are treated as a paragraph.\"\"\"\n        newstext = plaintextconverter.PlaintextConverter(\"orig/sme/admin/tullball.txt\")\n        got = newstext.content2xml(\n            io.StringIO(\n\"\"\"Guovssahasa nieida.\nFilbma lea.\n\"\"\"\n            )\n        )\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Guovssahasa nieida.\nFilbma lea.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\n\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_hyph(self):\n\"\"\"Check that hyph is conserved.\"\"\"\n        newstext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        got = newstext.content2xml(io.StringIO(\"Guovssa&lt;hyph/&gt;hasa\"))\n        want = etree.fromstring(\n\"\"\"\n            &lt;document&gt;\n            &lt;header/&gt;\n            &lt;body&gt;\n                &lt;p&gt;Guovssa&lt;hyph/&gt;hasa&lt;/p&gt;\n            &lt;/body&gt;\n            &lt;/document&gt; \"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n\n    def test_skip_lines(self):\n\"\"\"Check that lines are skipped.\"\"\"\n        content = \"\"\"\na\n\nb\n\nc\n\nd\n\ne\n\"\"\"\n        want_string = \"\"\"\n&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;a&lt;/p&gt;\n        &lt;p&gt;d&lt;/p&gt;\n        &lt;p&gt;e&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\n\"\"\"\n        text = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        text.metadata.set_variable(\"skip_lines\", \"4-6\")\n        got = text.content2xml(io.StringIO(content))\n        want = etree.fromstring(want_string)\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter.test_hyph","title":"<code>test_hyph()</code>","text":"<p>Check that hyph is conserved.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>def test_hyph(self):\n\"\"\"Check that hyph is conserved.\"\"\"\n    newstext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n    got = newstext.content2xml(io.StringIO(\"Guovssa&lt;hyph/&gt;hasa\"))\n    want = etree.fromstring(\n\"\"\"\n        &lt;document&gt;\n        &lt;header/&gt;\n        &lt;body&gt;\n            &lt;p&gt;Guovssa&lt;hyph/&gt;hasa&lt;/p&gt;\n        &lt;/body&gt;\n        &lt;/document&gt; \"\"\"\n    )\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter.test_plaintext","title":"<code>test_plaintext()</code>","text":"<p>Check that an empty line signal paragraph.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>    def test_plaintext(self):\n\"\"\"Check that an empty line signal paragraph.\"\"\"\n        plaintext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        got = plaintext.content2xml(\n            io.StringIO(\n\"\"\"S\u00e1megiella.\n\nBuot leat.\"\"\"\n            )\n        )\n\n        want = etree.fromstring(\nr\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;\n            S\u00e1megiella.\n        &lt;/p&gt;\n        &lt;p&gt;\n           Buot leat.\n       &lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter.test_skip_lines","title":"<code>test_skip_lines()</code>","text":"<p>Check that lines are skipped.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>    def test_skip_lines(self):\n\"\"\"Check that lines are skipped.\"\"\"\n        content = \"\"\"\na\n\nb\n\nc\n\nd\n\ne\n\"\"\"\n        want_string = \"\"\"\n&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;a&lt;/p&gt;\n        &lt;p&gt;d&lt;/p&gt;\n        &lt;p&gt;e&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\n\"\"\"\n        text = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n        text.metadata.set_variable(\"skip_lines\", \"4-6\")\n        got = text.content2xml(io.StringIO(content))\n        want = etree.fromstring(want_string)\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter.test_strip_chars1","title":"<code>test_strip_chars1()</code>","text":"<p>Check that weird chars are converted as exptected.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>def test_strip_chars1(self):\n\"\"\"Check that weird chars are converted as exptected.\"\"\"\n    plaintext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n    got = plaintext.strip_chars(\n        \"\\x0d\\n\" \"&lt;ASCII-MAC&gt;\\n\" \"&lt;vsn:3.000000&gt;\\n\" \"&lt;\\\\!q&gt;\\n\" \"&lt;\\\\!h&gt;\\n\"\n    )\n    want = \"\"\"\\n\\n\\n\\n\\n\\n\"\"\"\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter.test_strip_chars2","title":"<code>test_strip_chars2()</code>","text":"<p>Check that special chars are converted as expected.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>def test_strip_chars2(self):\n\"\"\"Check that special chars are converted as expected.\"\"\"\n    plaintext = plaintextconverter.PlaintextConverter(\"orig/sme/riddu/tullball.txt\")\n    got = plaintext.strip_chars(\n        \"&lt;0x010C&gt;&lt;0x010D&gt;&lt;0x0110&gt;&lt;0x0111&gt;&lt;0x014A&gt;&lt;0x014B&gt;&lt;0x0160&gt;&lt;0x0161&gt;\"\n        \"&lt;0x0166&gt;&lt;0x0167&gt;&lt;0x017D&gt;&lt;0x017E&gt;&lt;0x2003&gt;\"\n    )\n    want = \"\"\"\u010c\u010d\u0110\u0111\u014a\u014b\u0160\u0161\u0166\u0167\u017d\u017e \"\"\"\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter.test_to_unicode","title":"<code>test_to_unicode()</code>","text":"<p>Check that winsami2 is converted to unicode.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>def test_to_unicode(self):\n\"\"\"Check that winsami2 is converted to unicode.\"\"\"\n    plaintext = plaintextconverter.PlaintextConverter(\n        os.path.join(\n            HERE,\n            \"converter_data/fakecorpus/orig/sme/riddu/\" \"winsami2-test-ws2.txt\",\n        )\n    )\n    got = plaintext.to_unicode()\n\n    # Ensure that the data in want is unicode\n    file_ = codecs.open(\n        os.path.join(HERE, \"converter_data/winsami2-test-utf8.txt\"), encoding=\"utf8\"\n    )\n    want = file_.read()\n    file_.close()\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_plaintextconverter/#corpustools.test.test_plaintextconverter.TestPlaintextConverter.test_two_lines","title":"<code>test_two_lines()</code>","text":"<p>Test that two consecutive lines are treated as a paragraph.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_plaintextconverter.py</code> <pre><code>    def test_two_lines(self):\n\"\"\"Test that two consecutive lines are treated as a paragraph.\"\"\"\n        newstext = plaintextconverter.PlaintextConverter(\"orig/sme/admin/tullball.txt\")\n        got = newstext.content2xml(\n            io.StringIO(\n\"\"\"Guovssahasa nieida.\nFilbma lea.\n\"\"\"\n            )\n        )\n        want = etree.fromstring(\n\"\"\"&lt;document&gt;\n    &lt;header/&gt;\n    &lt;body&gt;\n        &lt;p&gt;Guovssahasa nieida.\nFilbma lea.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/document&gt;\n\"\"\"\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_rtfconverter/","title":"test_rtfconverter","text":"<p>Test conversion of rtf files.</p>"},{"location":"reference/test/test_rtfconverter/#corpustools.test.test_rtfconverter.TestRTFConverter","title":"<code>TestRTFConverter</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test the RTFConverter class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_rtfconverter.py</code> <pre><code>class TestRTFConverter(XMLTester):\n\"\"\"Test the RTFConverter class.\"\"\"\n\n    def test_convert2intermediate(self):\n\"\"\"Test rtf conversion to Giella xml.\"\"\"\n        got = htmlcontentconverter.convert2intermediate(\n            os.path.join(\n                HERE, \"converter_data/fakecorpus/orig/sme/riddu/\" \"folkemote.rtf\"\n            )\n        )\n        want = etree.parse(os.path.join(HERE, \"converter_data/folkemote.xml\"))\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_rtfconverter/#corpustools.test.test_rtfconverter.TestRTFConverter.test_convert2intermediate","title":"<code>test_convert2intermediate()</code>","text":"<p>Test rtf conversion to Giella xml.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_rtfconverter.py</code> <pre><code>def test_convert2intermediate(self):\n\"\"\"Test rtf conversion to Giella xml.\"\"\"\n    got = htmlcontentconverter.convert2intermediate(\n        os.path.join(\n            HERE, \"converter_data/fakecorpus/orig/sme/riddu/\" \"folkemote.rtf\"\n        )\n    )\n    want = etree.parse(os.path.join(HERE, \"converter_data/folkemote.xml\"))\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_samediggi_no_crawler/","title":"test_samediggi_no_crawler","text":"<p>Test the SamediggiNoPage class.</p>"},{"location":"reference/test/test_samediggi_no_crawler/#corpustools.test.test_samediggi_no_crawler.TestSamediggiNoPage","title":"<code>TestSamediggiNoPage</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test the SamediggiNoPage class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_samediggi_no_crawler.py</code> <pre><code>class TestSamediggiNoPage(unittest.TestCase):\n\"\"\"Test the SamediggiNoPage class.\"\"\"\n\n    def test_basics(self):\n\"\"\"Test initial values.\"\"\"\n        with requests_mock.Mocker() as mocker:\n            mocker.get(\n                \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\",\n                text=MY_TEXT,\n                headers={\"content-type\": \"text/html; charset=UTF-8\"},\n            )\n            result = requests.get(\n                \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\"\n            )\n\n            page = samediggi_no_crawler.SamediggiNoPage(result, {})\n            self.assertEqual(\n                page.corpuspath.orig,\n                os.path.join(\n                    os.getenv(\"GTFREE\"),\n                    \"orig/sme/admin/sd/samediggi.no/prd-doarjja-julevsami-giellaproseavttaide.html\",\n                ),\n            )\n            self.assertEqual(\n                page.url,\n                \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\",\n            )\n            self.assertListEqual(\n                page.parallel_links,\n                [\n                    \"https://www.sametinget.no/Nyhetsarkiv/parallel1\",\n                    \"https://www.saemiedigkie.no/Saernievaaarhkoe/parallel1\",\n                    \"https://www.samedigge.no/AAdaasa/PRD-Doarjju-julevsame-giellaprosjevtajda\",\n                ],\n            )\n            self.assertTrue(page.saveable)\n            self.assertEqual(page.lang, \"sme\")\n            self.assertSetEqual(\n                page.links,\n                {\n                        \"https://samediggi.no/Balvalusat2/Dearvvasvuohta-ja-sosiala\",\n                        \"https://samediggi.no/Vuoigatvuodat\",\n                        \"https://samediggi.no/Samedikki-birra2/Rehket-Samediggai\",\n                        \"https://samediggi.no/Samedikki-birra\",\n                        \"https://samediggi.no/Doarjagat-ja-stipeanddat\",\n                        \"https://samediggi.no/Preassa\",\n                        \"https://samediggi.no/Samedikki-birra2/langlink\",\n                        \"https://samediggi.no/Balvalusat2/Ealahusat\",\n                        \"https://samediggi.no/Politihkka2/Assit-ja-dokumeanttat\",\n                        \"https://samediggi.no/Odasarkiiva\",\n                        \"https://samediggi.no/Balvalusat2/Giella\",\n                        \"https://samediggi.no/Samedikki-birra2/langlink2\",\n                        \"https://samediggi.no/Balvalusat2/Kultuvra\",\n                        \"https://samediggi.no/Valga\",\n                        \"https://samediggi.no/Balvalusat2/Dassearvu\",\n                        \"https://samediggi.no/Politihkka2\",\n                        \"https://samediggi.no/Lagideamit\",\n                        \"https://samediggi.no/Balvalusat2/Oahpahus-ja-oahpponeavvut\",\n                        \"https://samediggi.no/Balvalusat2/Riikkaidgaskasas-bargu\",\n                        \"https://samediggi.no/Girjeradju\",\n                        \"https://samediggi.no/Balvalusat2/Biras-areala-ja-kultursuodjaleapmi\",\n                        \"https://samediggi.no/Balvalusat2/Manaidgardi\",\n                },\n            )\n\n            page.set_initial_metadata()\n            self.assertEqual(\n                page.corpuspath.metadata.get_variable(\"title\"),\n                \"PRD: Doarjja julevs\u00e1mi giellapro\u0161eavttaide\",\n            )\n            self.assertEqual(\n                page.corpuspath.metadata.get_variable(\"filename\"),\n                \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\",\n            )\n            self.assertEqual(page.corpuspath.metadata.get_variable(\"mainlang\"), \"sme\")\n            self.assertEqual(page.corpuspath.metadata.get_variable(\"genre\"), \"admin\")\n            self.assertEqual(\n                page.corpuspath.metadata.get_variable(\"translated_from\"), \"nob\"\n            )\n</code></pre>"},{"location":"reference/test/test_samediggi_no_crawler/#corpustools.test.test_samediggi_no_crawler.TestSamediggiNoPage.test_basics","title":"<code>test_basics()</code>","text":"<p>Test initial values.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_samediggi_no_crawler.py</code> <pre><code>def test_basics(self):\n\"\"\"Test initial values.\"\"\"\n    with requests_mock.Mocker() as mocker:\n        mocker.get(\n            \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\",\n            text=MY_TEXT,\n            headers={\"content-type\": \"text/html; charset=UTF-8\"},\n        )\n        result = requests.get(\n            \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\"\n        )\n\n        page = samediggi_no_crawler.SamediggiNoPage(result, {})\n        self.assertEqual(\n            page.corpuspath.orig,\n            os.path.join(\n                os.getenv(\"GTFREE\"),\n                \"orig/sme/admin/sd/samediggi.no/prd-doarjja-julevsami-giellaproseavttaide.html\",\n            ),\n        )\n        self.assertEqual(\n            page.url,\n            \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\",\n        )\n        self.assertListEqual(\n            page.parallel_links,\n            [\n                \"https://www.sametinget.no/Nyhetsarkiv/parallel1\",\n                \"https://www.saemiedigkie.no/Saernievaaarhkoe/parallel1\",\n                \"https://www.samedigge.no/AAdaasa/PRD-Doarjju-julevsame-giellaprosjevtajda\",\n            ],\n        )\n        self.assertTrue(page.saveable)\n        self.assertEqual(page.lang, \"sme\")\n        self.assertSetEqual(\n            page.links,\n            {\n                    \"https://samediggi.no/Balvalusat2/Dearvvasvuohta-ja-sosiala\",\n                    \"https://samediggi.no/Vuoigatvuodat\",\n                    \"https://samediggi.no/Samedikki-birra2/Rehket-Samediggai\",\n                    \"https://samediggi.no/Samedikki-birra\",\n                    \"https://samediggi.no/Doarjagat-ja-stipeanddat\",\n                    \"https://samediggi.no/Preassa\",\n                    \"https://samediggi.no/Samedikki-birra2/langlink\",\n                    \"https://samediggi.no/Balvalusat2/Ealahusat\",\n                    \"https://samediggi.no/Politihkka2/Assit-ja-dokumeanttat\",\n                    \"https://samediggi.no/Odasarkiiva\",\n                    \"https://samediggi.no/Balvalusat2/Giella\",\n                    \"https://samediggi.no/Samedikki-birra2/langlink2\",\n                    \"https://samediggi.no/Balvalusat2/Kultuvra\",\n                    \"https://samediggi.no/Valga\",\n                    \"https://samediggi.no/Balvalusat2/Dassearvu\",\n                    \"https://samediggi.no/Politihkka2\",\n                    \"https://samediggi.no/Lagideamit\",\n                    \"https://samediggi.no/Balvalusat2/Oahpahus-ja-oahpponeavvut\",\n                    \"https://samediggi.no/Balvalusat2/Riikkaidgaskasas-bargu\",\n                    \"https://samediggi.no/Girjeradju\",\n                    \"https://samediggi.no/Balvalusat2/Biras-areala-ja-kultursuodjaleapmi\",\n                    \"https://samediggi.no/Balvalusat2/Manaidgardi\",\n            },\n        )\n\n        page.set_initial_metadata()\n        self.assertEqual(\n            page.corpuspath.metadata.get_variable(\"title\"),\n            \"PRD: Doarjja julevs\u00e1mi giellapro\u0161eavttaide\",\n        )\n        self.assertEqual(\n            page.corpuspath.metadata.get_variable(\"filename\"),\n            \"https://samediggi.no/Odasarkiiva/PRD-Doarjja-julevsami-giellaproseavttaide\",\n        )\n        self.assertEqual(page.corpuspath.metadata.get_variable(\"mainlang\"), \"sme\")\n        self.assertEqual(page.corpuspath.metadata.get_variable(\"genre\"), \"admin\")\n        self.assertEqual(\n            page.corpuspath.metadata.get_variable(\"translated_from\"), \"nob\"\n        )\n</code></pre>"},{"location":"reference/test/test_sentencedivider/","title":"test_sentencedivider","text":"<p>Test sentence division functionality.</p>"},{"location":"reference/test/test_sentencedivider/#corpustools.test.test_sentencedivider.TestSentenceDivider","title":"<code>TestSentenceDivider</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test the SentenceDivider class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_sentencedivider.py</code> <pre><code>class TestSentenceDivider(unittest.TestCase):\n\"\"\"Test the SentenceDivider class.\"\"\"\n\n    def test_ccat_input(self):\n\"\"\"Test the sentence divider.\"\"\"\n        ccat_output = \"\"\"10. ON-vuog\u00e1dat \u00b6\nON doaimmaid oktavuo\u0111as; ovddasv\u00e1st\u00e1dus sihkkarastit? buot ON org\u00e1nat!\n..... \u00b6\nwow.\" \u00b6\nmom.). \u00b6\nmom.: \u00b6\nkult.\u201d \u00b6\nv\u00e1ldo\u010doahkkima nammadit. dievasla\u0161 \u010da\u0111aheami, [2019 \u2013 2020] \u2026 \u00b6\n(r\u00e1vvagiid) \u00b6\n\"\"\"\n        want = [\n            \"10. ON-vuog\u00e1dat\",\n            \"ON doaimmaid oktavuo\u0111as;\",\n            \"ovddasv\u00e1st\u00e1dus sihkkarastit?\",\n            \"buot ON org\u00e1nat!\",\n            \".....\",\n            \"wow.\",\n            '\"',\n            \"mom.).\",\n            \"mom.:\",\n            \"kult.\",\n            \"\u201d\",\n            \"v\u00e1ldo\u010doahkkima nammadit.\",\n            \"dievasla\u0161 \u010da\u0111aheami, [2019 \u2013 2020] \u2026\",\n            \"(r\u00e1vvagiid)\",\n        ]\n        divider = sentencedivider.SentenceDivider(\"sme\")\n        self.assertListEqual(divider.make_valid_sentences(ccat_output), want)\n\n    def test_with_dot_and_paragraph(self):\n\"\"\"Test the sentence divider with a sentence ending with . \u00b6.\"\"\"\n        ccat_output = \"\"\"mielddisbuvttii. \u00b6\nOdd Einar D\u00f8rum \u00b6\n\"\"\"\n        want = [\n            \"mielddisbuvttii.\",\n            \"Odd Einar D\u00f8rum\",\n        ]\n        divider = sentencedivider.SentenceDivider(\"sme\")\n        self.assertEqual(divider.make_valid_sentences(ccat_output), want)\n\n    def test_with_empty_head_sentence(self):\n\"\"\"Test the sentence divider with an empty first sentence.\"\"\"\n        ccat_output = \"\"\". \u00b6\nOdd Einar D\u00f8rum \u00b6\n\"\"\"\n        want = [\n            \".\",\n            \"Odd Einar D\u00f8rum\",\n        ]\n        divider = sentencedivider.SentenceDivider(\"sme\")\n        self.assertEqual(divider.make_valid_sentences(ccat_output), want)\n</code></pre>"},{"location":"reference/test/test_sentencedivider/#corpustools.test.test_sentencedivider.TestSentenceDivider.test_ccat_input","title":"<code>test_ccat_input()</code>","text":"<p>Test the sentence divider.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_sentencedivider.py</code> <pre><code>    def test_ccat_input(self):\n\"\"\"Test the sentence divider.\"\"\"\n        ccat_output = \"\"\"10. ON-vuog\u00e1dat \u00b6\nON doaimmaid oktavuo\u0111as; ovddasv\u00e1st\u00e1dus sihkkarastit? buot ON org\u00e1nat!\n..... \u00b6\nwow.\" \u00b6\nmom.). \u00b6\nmom.: \u00b6\nkult.\u201d \u00b6\nv\u00e1ldo\u010doahkkima nammadit. dievasla\u0161 \u010da\u0111aheami, [2019 \u2013 2020] \u2026 \u00b6\n(r\u00e1vvagiid) \u00b6\n\"\"\"\n        want = [\n            \"10. ON-vuog\u00e1dat\",\n            \"ON doaimmaid oktavuo\u0111as;\",\n            \"ovddasv\u00e1st\u00e1dus sihkkarastit?\",\n            \"buot ON org\u00e1nat!\",\n            \".....\",\n            \"wow.\",\n            '\"',\n            \"mom.).\",\n            \"mom.:\",\n            \"kult.\",\n            \"\u201d\",\n            \"v\u00e1ldo\u010doahkkima nammadit.\",\n            \"dievasla\u0161 \u010da\u0111aheami, [2019 \u2013 2020] \u2026\",\n            \"(r\u00e1vvagiid)\",\n        ]\n        divider = sentencedivider.SentenceDivider(\"sme\")\n        self.assertListEqual(divider.make_valid_sentences(ccat_output), want)\n</code></pre>"},{"location":"reference/test/test_sentencedivider/#corpustools.test.test_sentencedivider.TestSentenceDivider.test_with_dot_and_paragraph","title":"<code>test_with_dot_and_paragraph()</code>","text":"<p>Test the sentence divider with a sentence ending with . \u00b6.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_sentencedivider.py</code> <pre><code>    def test_with_dot_and_paragraph(self):\n\"\"\"Test the sentence divider with a sentence ending with . \u00b6.\"\"\"\n        ccat_output = \"\"\"mielddisbuvttii. \u00b6\nOdd Einar D\u00f8rum \u00b6\n\"\"\"\n        want = [\n            \"mielddisbuvttii.\",\n            \"Odd Einar D\u00f8rum\",\n        ]\n        divider = sentencedivider.SentenceDivider(\"sme\")\n        self.assertEqual(divider.make_valid_sentences(ccat_output), want)\n</code></pre>"},{"location":"reference/test/test_sentencedivider/#corpustools.test.test_sentencedivider.TestSentenceDivider.test_with_empty_head_sentence","title":"<code>test_with_empty_head_sentence()</code>","text":"<p>Test the sentence divider with an empty first sentence.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_sentencedivider.py</code> <pre><code>    def test_with_empty_head_sentence(self):\n\"\"\"Test the sentence divider with an empty first sentence.\"\"\"\n        ccat_output = \"\"\". \u00b6\nOdd Einar D\u00f8rum \u00b6\n\"\"\"\n        want = [\n            \".\",\n            \"Odd Einar D\u00f8rum\",\n        ]\n        divider = sentencedivider.SentenceDivider(\"sme\")\n        self.assertEqual(divider.make_valid_sentences(ccat_output), want)\n</code></pre>"},{"location":"reference/test/test_svgconverter/","title":"test_svgconverter","text":"<p>Test conversion of svg files.</p>"},{"location":"reference/test/test_svgconverter/#corpustools.test.test_svgconverter.TestSVGConverter","title":"<code>TestSVGConverter</code>","text":"<p>         Bases: <code>xmltester.XMLTester</code></p> <p>Test conversion of svg files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_svgconverter.py</code> <pre><code>class TestSVGConverter(xmltester.XMLTester):\n\"\"\"Test conversion of svg files.\"\"\"\n\n    def test_convert2intermediate(self):\n\"\"\"Test conversion of svg files.\"\"\"\n        svg_file = os.path.join(\n            HERE,\n            \"converter_data/fakecorpus/orig/sme/riddu/\"\n            \"Riddu_Riddu_avis_TXT.200923.svg\",\n        )\n\n        got = svgconverter.convert2intermediate(svg_file)\n        want = etree.parse(\n            os.path.join(HERE, \"converter_data/Riddu_Riddu_avis_TXT.200923.svg.xml\")\n        )\n\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_svgconverter/#corpustools.test.test_svgconverter.TestSVGConverter.test_convert2intermediate","title":"<code>test_convert2intermediate()</code>","text":"<p>Test conversion of svg files.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_svgconverter.py</code> <pre><code>def test_convert2intermediate(self):\n\"\"\"Test conversion of svg files.\"\"\"\n    svg_file = os.path.join(\n        HERE,\n        \"converter_data/fakecorpus/orig/sme/riddu/\"\n        \"Riddu_Riddu_avis_TXT.200923.svg\",\n    )\n\n    got = svgconverter.convert2intermediate(svg_file)\n    want = etree.parse(\n        os.path.join(HERE, \"converter_data/Riddu_Riddu_avis_TXT.200923.svg.xml\")\n    )\n\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_text_cat/","title":"test_text_cat","text":""},{"location":"reference/test/test_trainingcorpusmaker/","title":"test_trainingcorpusmaker","text":"<p>Test sentence division functionality.</p>"},{"location":"reference/test/test_trainingcorpusmaker/#corpustools.test.test_trainingcorpusmaker.TestTrainingCorpusMaker","title":"<code>TestTrainingCorpusMaker</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test the TrainingCorpusMaker class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_trainingcorpusmaker.py</code> <pre><code>class TestTrainingCorpusMaker(unittest.TestCase):\n\"\"\"Test the TrainingCorpusMaker class.\n\n    Attributes:\n        sentencemaker (corpustools.TrainingCorpusMaker)\n    \"\"\"\n\n    def setUp(self):\n\"\"\"Set up the TrainingCorpusMaker.\"\"\"\n        self.sentencemaker = trainingcorpusmaker.TrainingCorpusMaker(\"sme\")\n\n    def test_no_unknown(self):\n\"\"\"Test with only known input.\"\"\"\n        test_input = \"\\n\".join(\n            [\n                '\"&lt;Oahpa&gt;\"',\n                '\\t\"Oahpa\" N Prop Sem/Obj Sg Nom &lt;W:0.0000000000&gt; @HNOUN #1-&gt;0',\n                '\"&lt;:&gt;\"',\n                '\\t\":\" CLB &lt;W:0.0000000000&gt; #2-&gt;1',\n                \": \",\n                '\"&lt;Soahki&gt;\"',\n                '\\t\"soahki\" N Sem/Plant Sg Nom &lt;W:0.0000000000&gt; @HNOUN #3-&gt;1',\n                \": \",\n                '\"&lt;\u00b6&gt;\"',\n                '\\t\"\u00b6\" CLB &lt;W:0.0000000000&gt; #4-&gt;1',\n                \":\\n\",\n                '\"&lt;addit&gt;\"',\n                '\\t\"addit\" V TV Inf &lt;W:0.0000000000&gt; @FS-N&lt;IMV #13-&gt;11',\n                \": \",\n                '\"&lt;boahtte&gt;\"',\n                '\\t\"boahtte\" A Sem/Dummytag Attr &lt;W:0.0000000000&gt; @&gt;N #14-&gt;15',\n                \": \",\n                '\"&lt;bulvii&gt;\"',\n                '\\t\"buolva\" N Sem/Body_Group_Hum_Time Sg Ill &lt;W:0.0000000000&gt; @&lt;ADVL #15-&gt;13',\n                '\"&lt;.&gt;\"',\n                '\\t\".\" CLB &lt;W:0.0000000000&gt; #16-&gt;4',\n                \": \",\n                \"\",\n                '\"&lt;\u00b6&gt;\"',\n                '\\t\"\u00b6\" CLB &lt;W:0.0000000000&gt; #1-&gt;1',\n                \":\\n\",\n                \"\",\n            ]\n        )\n\n        want = \"Oahpa: Soahki\\naddit boahtte bulvii.\"\n        got = \"\\n\".join(\n            [\n                sentence\n                for sentence in self.sentencemaker.parse_dependency(test_input)\n                if sentence\n            ]\n        )\n        self.assertEqual(got, want)\n\n    def test_with_comma(self):\n\"\"\"Check that comma is handled correctly.\"\"\"\n        test_input = \"\\n\".join(\n            [\n                '\"&lt;\u00e1hkuin&gt;\"',\n                '\\t\"\u00e1hkku\" N Sem/Hum Sg Com &lt;W:0.0000000000&gt; @&lt;ADVL #6-&gt;1',\n                '\"&lt;,&gt;\"',\n                '\\t\",\" CLB &lt;W:0.0000000000&gt; #7-&gt;6',\n                \": \",\n                '\"&lt;\u00e1dj\u00e1in&gt;\"',\n                '\\t\"\u00e1ddj\u00e1\" N Sem/Hum Sg Com &lt;W:0.0000000000&gt; @&lt;ADVL #8-&gt;1',\n                \": \",\n                '\"&lt;dahje&gt;\"',\n                '\\t\"dahje\" CC &lt;W:0.0000000000&gt; @CNP #9-&gt;8',\n                \": \",\n                '\"&lt;ear\u00e1in&gt;\"',\n                '\\t\"ear\u00e1\" Pron Indef Sg Com &lt;W:0.0000000000&gt; @&lt;ADVL #10-&gt;1',\n                '\"&lt;!&gt;\"',\n                '\\t\"!\" CLB &lt;W:0.0000000000&gt; #13-&gt;1',\n                \": \",\n                \"\",\n                '\"&lt;\u00b6&gt;\"',\n                '\\t\"\u00b6\" CLB &lt;W:0.0000000000&gt; #1-&gt;1',\n                \":\\n\",\n            ]\n        )\n\n        want = \"\u00e1hkuin, \u00e1dj\u00e1in dahje ear\u00e1in!\"\n        got = \"\\n\".join(\n            [\n                sentence\n                for sentence in self.sentencemaker.parse_dependency(test_input)\n                if sentence\n            ]\n        )\n        self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_trainingcorpusmaker/#corpustools.test.test_trainingcorpusmaker.TestTrainingCorpusMaker.setUp","title":"<code>setUp()</code>","text":"<p>Set up the TrainingCorpusMaker.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_trainingcorpusmaker.py</code> <pre><code>def setUp(self):\n\"\"\"Set up the TrainingCorpusMaker.\"\"\"\n    self.sentencemaker = trainingcorpusmaker.TrainingCorpusMaker(\"sme\")\n</code></pre>"},{"location":"reference/test/test_trainingcorpusmaker/#corpustools.test.test_trainingcorpusmaker.TestTrainingCorpusMaker.test_no_unknown","title":"<code>test_no_unknown()</code>","text":"<p>Test with only known input.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_trainingcorpusmaker.py</code> <pre><code>def test_no_unknown(self):\n\"\"\"Test with only known input.\"\"\"\n    test_input = \"\\n\".join(\n        [\n            '\"&lt;Oahpa&gt;\"',\n            '\\t\"Oahpa\" N Prop Sem/Obj Sg Nom &lt;W:0.0000000000&gt; @HNOUN #1-&gt;0',\n            '\"&lt;:&gt;\"',\n            '\\t\":\" CLB &lt;W:0.0000000000&gt; #2-&gt;1',\n            \": \",\n            '\"&lt;Soahki&gt;\"',\n            '\\t\"soahki\" N Sem/Plant Sg Nom &lt;W:0.0000000000&gt; @HNOUN #3-&gt;1',\n            \": \",\n            '\"&lt;\u00b6&gt;\"',\n            '\\t\"\u00b6\" CLB &lt;W:0.0000000000&gt; #4-&gt;1',\n            \":\\n\",\n            '\"&lt;addit&gt;\"',\n            '\\t\"addit\" V TV Inf &lt;W:0.0000000000&gt; @FS-N&lt;IMV #13-&gt;11',\n            \": \",\n            '\"&lt;boahtte&gt;\"',\n            '\\t\"boahtte\" A Sem/Dummytag Attr &lt;W:0.0000000000&gt; @&gt;N #14-&gt;15',\n            \": \",\n            '\"&lt;bulvii&gt;\"',\n            '\\t\"buolva\" N Sem/Body_Group_Hum_Time Sg Ill &lt;W:0.0000000000&gt; @&lt;ADVL #15-&gt;13',\n            '\"&lt;.&gt;\"',\n            '\\t\".\" CLB &lt;W:0.0000000000&gt; #16-&gt;4',\n            \": \",\n            \"\",\n            '\"&lt;\u00b6&gt;\"',\n            '\\t\"\u00b6\" CLB &lt;W:0.0000000000&gt; #1-&gt;1',\n            \":\\n\",\n            \"\",\n        ]\n    )\n\n    want = \"Oahpa: Soahki\\naddit boahtte bulvii.\"\n    got = \"\\n\".join(\n        [\n            sentence\n            for sentence in self.sentencemaker.parse_dependency(test_input)\n            if sentence\n        ]\n    )\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_trainingcorpusmaker/#corpustools.test.test_trainingcorpusmaker.TestTrainingCorpusMaker.test_with_comma","title":"<code>test_with_comma()</code>","text":"<p>Check that comma is handled correctly.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_trainingcorpusmaker.py</code> <pre><code>def test_with_comma(self):\n\"\"\"Check that comma is handled correctly.\"\"\"\n    test_input = \"\\n\".join(\n        [\n            '\"&lt;\u00e1hkuin&gt;\"',\n            '\\t\"\u00e1hkku\" N Sem/Hum Sg Com &lt;W:0.0000000000&gt; @&lt;ADVL #6-&gt;1',\n            '\"&lt;,&gt;\"',\n            '\\t\",\" CLB &lt;W:0.0000000000&gt; #7-&gt;6',\n            \": \",\n            '\"&lt;\u00e1dj\u00e1in&gt;\"',\n            '\\t\"\u00e1ddj\u00e1\" N Sem/Hum Sg Com &lt;W:0.0000000000&gt; @&lt;ADVL #8-&gt;1',\n            \": \",\n            '\"&lt;dahje&gt;\"',\n            '\\t\"dahje\" CC &lt;W:0.0000000000&gt; @CNP #9-&gt;8',\n            \": \",\n            '\"&lt;ear\u00e1in&gt;\"',\n            '\\t\"ear\u00e1\" Pron Indef Sg Com &lt;W:0.0000000000&gt; @&lt;ADVL #10-&gt;1',\n            '\"&lt;!&gt;\"',\n            '\\t\"!\" CLB &lt;W:0.0000000000&gt; #13-&gt;1',\n            \": \",\n            \"\",\n            '\"&lt;\u00b6&gt;\"',\n            '\\t\"\u00b6\" CLB &lt;W:0.0000000000&gt; #1-&gt;1',\n            \":\\n\",\n        ]\n    )\n\n    want = \"\u00e1hkuin, \u00e1dj\u00e1in dahje ear\u00e1in!\"\n    got = \"\\n\".join(\n        [\n            sentence\n            for sentence in self.sentencemaker.parse_dependency(test_input)\n            if sentence\n        ]\n    )\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_typosfile/","title":"test_typosfile","text":""},{"location":"reference/test/test_typosfile/#corpustools.test.test_typosfile.TestTypoline","title":"<code>TestTypoline</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Class to test the typos synchroniser</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_typosfile.py</code> <pre><code>class TestTypoline(unittest.TestCase):\n\"\"\"Class to test the typos synchroniser\"\"\"\n\n    def setUp(self):\n        pass\n\n    def testGetTypo(self):\n        tl = typosfile.Typoline(\"deatala\u0161\\tdea\u0167ala\u0161\")\n        self.assertEqual(tl.getTypo(), \"deatala\u0161\")\n\n        tl = typosfile.Typoline(\"deatala\u0161\\tdea\u0167ala\u0161\")\n        self.assertEqual(tl.getTypo(), \"deatala\u0161\")\n\n    def testGetCorrection(self):\n        tl = typosfile.Typoline(\"deatala\u0161\\tdea\u0167ala\u0161\")\n        self.assertEqual(tl.getCorrection(), \"dea\u0167ala\u0161\")\n\n        tl = typosfile.Typoline(\"deatala\u0161\")\n        self.assertEqual(tl.getCorrection(), None)\n\n    def testMakeTypoline(self):\n        tl = typosfile.Typoline(\"deatala\u0161\\tdea\u0167ala\u0161\")\n        self.assertEqual(tl.makeTypoline(), \"deatala\u0161\\tdea\u0167ala\u0161\")\n\n        tl = typosfile.Typoline(\"deatala\u0161\\tdeatala\u0161\")\n        self.assertEqual(tl.makeTypoline(), \"deatala\u0161\")\n\n    def testSetCorrection(self):\n        tl = typosfile.Typoline(\"deatala\u0161\\tdea\u0167ala\u0161\")\n        tl.setCorrection(\"ditala\u0161\")\n        self.assertEqual(tl.getCorrection(), \"ditala\u0161\")\n</code></pre>"},{"location":"reference/test/test_util/","title":"test_util","text":""},{"location":"reference/test/test_xhtml2corpus/","title":"test_xhtml2corpus","text":""},{"location":"reference/test/test_xhtml2corpus/#corpustools.test.test_xhtml2corpus.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>","text":"<p>Check if two xml snippets are equal</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xhtml2corpus.py</code> <pre><code>def assertXmlEqual(got, want):\n\"\"\"Check if two xml snippets are equal\"\"\"\n    got = lxml.etree.tostring(got, encoding=\"unicode\")\n    want = lxml.etree.tostring(want, encoding=\"unicode\")\n    checker = lxml.doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(want, got, 0):\n        message = checker.output_difference(doctest.Example(\"\", want), got, 0)\n        raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/test_xslmaker/","title":"test_xslmaker","text":"<p>Test the XslMaker class.</p>"},{"location":"reference/test/test_xslmaker/#corpustools.test.test_xslmaker.TestXslMaker","title":"<code>TestXslMaker</code>","text":"<p>         Bases: <code>XMLTester</code></p> <p>Test the Xslmaker class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslmaker.py</code> <pre><code>class TestXslMaker(XMLTester):\n\"\"\"Test the Xslmaker class.\"\"\"\n\n    def test_get_xsl(self):\n\"\"\"Test the functionality of the XslMaker class.\"\"\"\n        xsl_maker = xslmaker.XslMaker(\n            etree.parse(\n                os.path.join(HERE, \"converter_data/samediggi-article-48.html.xsl\")\n            )\n        )\n        got = xsl_maker.xsl\n\n        # The import href is different for each user testing, so just\n        # check that it looks OK:\n        import_elt = got.find(\n            \"/xsl:import\", namespaces={\"xsl\": \"http://www.w3.org/1999/XSL/Transform\"}\n        )\n        self.assertTrue(import_elt.attrib[\"href\"].startswith(\"file:///\"))\n        self.assertTrue(import_elt.attrib[\"href\"].endswith(\"common.xsl\"))\n        with open(import_elt.attrib[\"href\"][7:].replace(\"%20\", \" \")) as xsl:\n            self.assertGreater(len(xsl.read()), 0)\n        # ... and set it to the hardcoded path in test.xsl:\n        import_elt.attrib[\"href\"] = (\n            \"file:///home/boerre/langtech/trunk/tools/CorpusTools/\"\n            \"corpustools/xslt/common.xsl\"\n        )\n\n        want = etree.parse(os.path.join(HERE, \"converter_data/test.xsl\"))\n        self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslmaker/#corpustools.test.test_xslmaker.TestXslMaker.test_get_xsl","title":"<code>test_get_xsl()</code>","text":"<p>Test the functionality of the XslMaker class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslmaker.py</code> <pre><code>def test_get_xsl(self):\n\"\"\"Test the functionality of the XslMaker class.\"\"\"\n    xsl_maker = xslmaker.XslMaker(\n        etree.parse(\n            os.path.join(HERE, \"converter_data/samediggi-article-48.html.xsl\")\n        )\n    )\n    got = xsl_maker.xsl\n\n    # The import href is different for each user testing, so just\n    # check that it looks OK:\n    import_elt = got.find(\n        \"/xsl:import\", namespaces={\"xsl\": \"http://www.w3.org/1999/XSL/Transform\"}\n    )\n    self.assertTrue(import_elt.attrib[\"href\"].startswith(\"file:///\"))\n    self.assertTrue(import_elt.attrib[\"href\"].endswith(\"common.xsl\"))\n    with open(import_elt.attrib[\"href\"][7:].replace(\"%20\", \" \")) as xsl:\n        self.assertGreater(len(xsl.read()), 0)\n    # ... and set it to the hardcoded path in test.xsl:\n    import_elt.attrib[\"href\"] = (\n        \"file:///home/boerre/langtech/trunk/tools/CorpusTools/\"\n        \"corpustools/xslt/common.xsl\"\n    )\n\n    want = etree.parse(os.path.join(HERE, \"converter_data/test.xsl\"))\n    self.assertXmlEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/","title":"test_xslsetter","text":"<p>Test the MetadataHandler class.</p>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler","title":"<code>TestMetadataHandler</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test the MetadataHandler class.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>class TestMetadataHandler(unittest.TestCase):\n\"\"\"Test the MetadataHandler class.\"\"\"\n\n    def test_set_skip_lines1(self):\n\"\"\"Test a valid skip_pages line.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"skip_lines\", \"1, 4-5, 7\")\n        got = md.skip_lines\n        want = [1, 4, 5, 7]\n\n        self.assertEqual(got, want)\n\n    def test_set_skip_lines2(self):\n\"\"\"Test an invalid skip_lines line.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n        md.set_variable(\"skip_lines\", \"1, 4 5, 7\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.skip_lines\n\n    def test_set_skip_lines3(self):\n\"\"\"Test an empty skip_lines line.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n        md.set_variable(\"skip_lines\", \" \")\n        got = md.skip_lines\n        want = []\n\n        self.assertEqual(got, want)\n\n    def test_set_skip_pages1(self):\n\"\"\"Test a valid skip_pages line.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"skip_pages\", \"1, 4-5, 7\")\n        got = md.skip_pages\n        want = [1, 4, 5, 7]\n\n        self.assertEqual(got, want)\n\n    def test_set_skip_pages2(self):\n\"\"\"Test an invalid skip_pages line.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n        md.set_variable(\"skip_pages\", \"1, 4 5, 7\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.skip_pages\n\n    def test_set_skip_pages3(self):\n\"\"\"Test an empty skip_pages line.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n        md.set_variable(\"skip_pages\", \" \")\n        got = md.skip_pages\n        want = []\n\n        self.assertEqual(got, want)\n\n    def test_set_skip_pages4(self):\n\"\"\"Test with odd as a page range.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n        md.set_variable(\"skip_pages\", \"odd, 2\")\n        got = md.skip_pages\n        want = [\"odd\", 2]\n\n        self.assertEqual(got, want)\n\n    def test_set_skip_pages5(self):\n\"\"\"Test with even as a page range.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n        md.set_variable(\"skip_pages\", \"even, 1\")\n        got = md.skip_pages\n        want = [\"even\", 1]\n\n        self.assertEqual(got, want)\n\n    def test_set_skip_pages6(self):\n\"\"\"Raise an exception if both odd and even are used.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n        md.set_variable(\"skip_pages\", \"odd, even\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.skip_pages\n\n    def test_set_linespacing_1(self):\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"linespacing\", \"odd=2\")\n        got = md.linespacing\n        want = {\"odd\": 2.0}\n\n        self.assertDictEqual(got, want)\n\n    def test_set_linespacing_2(self):\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"linespacing\", \"even=2\")\n        got = md.linespacing\n        want = {\"even\": 2.0}\n\n        self.assertDictEqual(got, want)\n\n    def test_set_linespacing_3(self):\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"linespacing\", \"all=2\")\n        got = md.linespacing\n        want = {\"all\": 2.0}\n\n        self.assertDictEqual(got, want)\n\n    def test_set_linespacing_4(self):\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"linespacing\", \"all=2, even=1.6\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.linespacing\n\n    def test_set_linespacing_5(self):\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"linespacing\", \"all=2,0\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.linespacing\n\n    def test_set_linespacing_6(self):\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"linespacing\", \"1;2;3=0.5\")\n\n        got = md.linespacing\n        want = {\"1\": 0.5, \"2\": 0.5, \"3\": 0.5}\n\n        self.assertDictEqual(got, want)\n\n    def test_set_linespacing_7(self):\n\"\"\"Test the default value.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n\n        got = md.linespacing\n        want = {}\n\n        self.assertDictEqual(got, want)\n\n    def test_set_margin(self):\n\"\"\"Test if the margin is set correctly.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n\n        self.assertEqual(\n            md.parse_margin_line(\"odd=230, even = 540 , 8 = 340\"),\n            {\"odd\": 230, \"even\": 540, \"8\": 340},\n        )\n\n    def test_parse_margin_lines1(self):\n\"\"\"Test parse_margin_lines.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"left_margin\", \"7=7\")\n        md.set_variable(\"right_margin\", \"odd=4,even=8,3=6\")\n        md.set_variable(\"top_margin\", \"8=8\")\n        md.set_variable(\"bottom_margin\", \"9=2\")\n\n        self.assertEqual(\n            md.margins,\n            {\n                \"left_margin\": {\"7\": 7},\n                \"right_margin\": {\"odd\": 4, \"even\": 8, \"3\": 6},\n                \"top_margin\": {\"8\": 8},\n                \"bottom_margin\": {\"9\": 2},\n            },\n        )\n\n    def test_parse_margin_lines2(self):\n\"\"\"Raise ConversionError if both 'all' and 'even' is found.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"right_margin\", \"all=40,even=80\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.margins\n\n    def test_parse_margin_lines3(self):\n\"\"\"Raise ConversionError if 'all' and 'odd' is found.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"right_margin\", \"all=40,odd=80\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.margins\n\n    def test_parse_margin_lines4(self):\n\"\"\"Raise ConversionError if text after '=' is found.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"right_margin\", \"all=tullball\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.margins\n\n    def test_parse_margin_lines5(self):\n\"\"\"Raise ConversionError if no '=' is found.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"right_margin\", \"all 50\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.margins\n\n    def test_parse_margin_lines6(self):\n\"\"\"Line with no comma between values should raise an exception.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"right_margin\", \"all=50 3\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.margins\n\n    def test_parse_margin_lines7(self):\n\"\"\"Multiple pages with the same margin are separated by semicolon.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"right_margin\", \"1;3=50, 2=30\")\n\n        self.assertEqual(md.margins, {\"right_margin\": {\"1\": 50, \"2\": 30, \"3\": 50}})\n\n    def test_inner_margin1(self):\n\"\"\"Raise exception if inner_right is set and not inner_left.\"\"\"\n        for p in [\"top\", \"bottom\", \"right\", \"left\"]:\n            md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n            md.set_variable(\"inner_\" + p + \"_margin\", \"5=30\")\n\n            with self.assertRaises(xslsetter.XsltError):\n                md.inner_margins\n\n    def test_inner_margin2(self):\n\"\"\"Raise exception if not the same pages are set.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"inner_top_margin\", \"5=30\")\n        md.set_variable(\"inner_bottom_margin\", \"6=30\")\n        with self.assertRaises(xslsetter.XsltError):\n            md.inner_margins\n\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"inner_left_margin\", \"5=30\")\n        md.set_variable(\"inner_right_margin\", \"6=30\")\n        with self.assertRaises(xslsetter.XsltError):\n            md.inner_margins\n\n    def test_inner_margin3(self):\n\"\"\"Test whether a correctly set inner margin gives the wanted result.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"inner_top_margin\", \"6=20, 5=20\")\n        md.set_variable(\"inner_bottom_margin\", \"5=30, 6=50\")\n\n        self.assertEqual(\n            md.inner_margins,\n            {\n                \"inner_bottom_margin\": {\"5\": 30, \"6\": 50},\n                \"inner_top_margin\": {\"5\": 20, \"6\": 20},\n            },\n        )\n\n    def test_inner_margin4(self):\n\"\"\"Test whether a correctly set inner margin gives the wanted result.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"inner_left_margin\", \"6=20, 5=20\")\n        md.set_variable(\"inner_right_margin\", \"5=30, 6=50\")\n\n        self.assertEqual(\n            md.inner_margins,\n            {\n                \"inner_right_margin\": {\"5\": 30, \"6\": 50},\n                \"inner_left_margin\": {\"5\": 20, \"6\": 20},\n            },\n        )\n\n    def test_skip_elements_1(self):\n\"\"\"Test if getting skip_elements is possible.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n        md.set_variable(\n            \"skip_elements\", \".//body/div[1]/h2[1];.//body/div[3]/div[1]/h3[1]\"\n        )\n\n        self.assertEqual(\n            md.skip_elements,\n            [\n                (\n                    \".//html:body/html:div[1]/html:h2[1]\",\n                    \".//html:body/html:div[3]/html:div[1]/html:h3[1]\",\n                )\n            ],\n        )\n\n    def test_skip_elements_2(self):\n\"\"\"Test if getting a pair of skip_elements is possible.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n        md.set_variable(\n            \"skip_elements\",\n            \".//body/div[5];.//body/div[8]/div[3]/h1[1], \"\n            \".//body/div[11]/div[2];.//body/div[11]/div[5]\",\n        )\n\n        self.assertEqual(\n            md.skip_elements,\n            [\n                (\n                    \".//html:body/html:div[5]\",\n                    \".//html:body/html:div[8]/html:div[3]/html:h1[1]\",\n                ),\n                (\n                    \".//html:body/html:div[11]/html:div[2]\",\n                    \".//html:body/html:div[11]/html:div[5]\",\n                ),\n            ],\n        )\n\n    def test_skip_elements_empty(self):\n\"\"\"Empty skip_elements returns None.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n        self.assertIsNone(md.skip_elements)\n\n    def test_mlangs_empty(self):\n\"\"\"Check for empty mlangs.\"\"\"\n        md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n\n        self.assertSetEqual(set(), md.mlangs)\n\n    def test_mlangs_set(self):\n\"\"\"Check if languages are set and picked up.\"\"\"\n        languages = {\"nob\", \"sme\", \"sma\"}\n\n        md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n\n        for language in languages:\n            md.set_mlang(language)\n\n        self.assertSetEqual(languages, md.mlangs)\n\n    def test_epub_chosen_chapters(self):\n        md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n        md.set_variable(\"epub_excluded_chapters\", \"1, 4-8, 15\")\n        got = md.epub_excluded_chapters\n        want = [1, 4, 5, 6, 7, 8, 15]\n\n        self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_inner_margin1","title":"<code>test_inner_margin1()</code>","text":"<p>Raise exception if inner_right is set and not inner_left.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_inner_margin1(self):\n\"\"\"Raise exception if inner_right is set and not inner_left.\"\"\"\n    for p in [\"top\", \"bottom\", \"right\", \"left\"]:\n        md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n        md.set_variable(\"inner_\" + p + \"_margin\", \"5=30\")\n\n        with self.assertRaises(xslsetter.XsltError):\n            md.inner_margins\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_inner_margin2","title":"<code>test_inner_margin2()</code>","text":"<p>Raise exception if not the same pages are set.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_inner_margin2(self):\n\"\"\"Raise exception if not the same pages are set.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"inner_top_margin\", \"5=30\")\n    md.set_variable(\"inner_bottom_margin\", \"6=30\")\n    with self.assertRaises(xslsetter.XsltError):\n        md.inner_margins\n\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"inner_left_margin\", \"5=30\")\n    md.set_variable(\"inner_right_margin\", \"6=30\")\n    with self.assertRaises(xslsetter.XsltError):\n        md.inner_margins\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_inner_margin3","title":"<code>test_inner_margin3()</code>","text":"<p>Test whether a correctly set inner margin gives the wanted result.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_inner_margin3(self):\n\"\"\"Test whether a correctly set inner margin gives the wanted result.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"inner_top_margin\", \"6=20, 5=20\")\n    md.set_variable(\"inner_bottom_margin\", \"5=30, 6=50\")\n\n    self.assertEqual(\n        md.inner_margins,\n        {\n            \"inner_bottom_margin\": {\"5\": 30, \"6\": 50},\n            \"inner_top_margin\": {\"5\": 20, \"6\": 20},\n        },\n    )\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_inner_margin4","title":"<code>test_inner_margin4()</code>","text":"<p>Test whether a correctly set inner margin gives the wanted result.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_inner_margin4(self):\n\"\"\"Test whether a correctly set inner margin gives the wanted result.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"inner_left_margin\", \"6=20, 5=20\")\n    md.set_variable(\"inner_right_margin\", \"5=30, 6=50\")\n\n    self.assertEqual(\n        md.inner_margins,\n        {\n            \"inner_right_margin\": {\"5\": 30, \"6\": 50},\n            \"inner_left_margin\": {\"5\": 20, \"6\": 20},\n        },\n    )\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_mlangs_empty","title":"<code>test_mlangs_empty()</code>","text":"<p>Check for empty mlangs.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_mlangs_empty(self):\n\"\"\"Check for empty mlangs.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n\n    self.assertSetEqual(set(), md.mlangs)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_mlangs_set","title":"<code>test_mlangs_set()</code>","text":"<p>Check if languages are set and picked up.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_mlangs_set(self):\n\"\"\"Check if languages are set and picked up.\"\"\"\n    languages = {\"nob\", \"sme\", \"sma\"}\n\n    md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n\n    for language in languages:\n        md.set_mlang(language)\n\n    self.assertSetEqual(languages, md.mlangs)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_parse_margin_lines1","title":"<code>test_parse_margin_lines1()</code>","text":"<p>Test parse_margin_lines.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_parse_margin_lines1(self):\n\"\"\"Test parse_margin_lines.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"left_margin\", \"7=7\")\n    md.set_variable(\"right_margin\", \"odd=4,even=8,3=6\")\n    md.set_variable(\"top_margin\", \"8=8\")\n    md.set_variable(\"bottom_margin\", \"9=2\")\n\n    self.assertEqual(\n        md.margins,\n        {\n            \"left_margin\": {\"7\": 7},\n            \"right_margin\": {\"odd\": 4, \"even\": 8, \"3\": 6},\n            \"top_margin\": {\"8\": 8},\n            \"bottom_margin\": {\"9\": 2},\n        },\n    )\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_parse_margin_lines2","title":"<code>test_parse_margin_lines2()</code>","text":"<p>Raise ConversionError if both 'all' and 'even' is found.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_parse_margin_lines2(self):\n\"\"\"Raise ConversionError if both 'all' and 'even' is found.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"right_margin\", \"all=40,even=80\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.margins\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_parse_margin_lines3","title":"<code>test_parse_margin_lines3()</code>","text":"<p>Raise ConversionError if 'all' and 'odd' is found.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_parse_margin_lines3(self):\n\"\"\"Raise ConversionError if 'all' and 'odd' is found.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"right_margin\", \"all=40,odd=80\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.margins\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_parse_margin_lines4","title":"<code>test_parse_margin_lines4()</code>","text":"<p>Raise ConversionError if text after '=' is found.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_parse_margin_lines4(self):\n\"\"\"Raise ConversionError if text after '=' is found.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"right_margin\", \"all=tullball\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.margins\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_parse_margin_lines5","title":"<code>test_parse_margin_lines5()</code>","text":"<p>Raise ConversionError if no '=' is found.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_parse_margin_lines5(self):\n\"\"\"Raise ConversionError if no '=' is found.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"right_margin\", \"all 50\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.margins\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_parse_margin_lines6","title":"<code>test_parse_margin_lines6()</code>","text":"<p>Line with no comma between values should raise an exception.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_parse_margin_lines6(self):\n\"\"\"Line with no comma between values should raise an exception.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"right_margin\", \"all=50 3\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.margins\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_parse_margin_lines7","title":"<code>test_parse_margin_lines7()</code>","text":"<p>Multiple pages with the same margin are separated by semicolon.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_parse_margin_lines7(self):\n\"\"\"Multiple pages with the same margin are separated by semicolon.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"right_margin\", \"1;3=50, 2=30\")\n\n    self.assertEqual(md.margins, {\"right_margin\": {\"1\": 50, \"2\": 30, \"3\": 50}})\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_linespacing_7","title":"<code>test_set_linespacing_7()</code>","text":"<p>Test the default value.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_linespacing_7(self):\n\"\"\"Test the default value.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n\n    got = md.linespacing\n    want = {}\n\n    self.assertDictEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_margin","title":"<code>test_set_margin()</code>","text":"<p>Test if the margin is set correctly.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_margin(self):\n\"\"\"Test if the margin is set correctly.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n\n    self.assertEqual(\n        md.parse_margin_line(\"odd=230, even = 540 , 8 = 340\"),\n        {\"odd\": 230, \"even\": 540, \"8\": 340},\n    )\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_lines1","title":"<code>test_set_skip_lines1()</code>","text":"<p>Test a valid skip_pages line.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_lines1(self):\n\"\"\"Test a valid skip_pages line.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"skip_lines\", \"1, 4-5, 7\")\n    got = md.skip_lines\n    want = [1, 4, 5, 7]\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_lines2","title":"<code>test_set_skip_lines2()</code>","text":"<p>Test an invalid skip_lines line.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_lines2(self):\n\"\"\"Test an invalid skip_lines line.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n    md.set_variable(\"skip_lines\", \"1, 4 5, 7\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.skip_lines\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_lines3","title":"<code>test_set_skip_lines3()</code>","text":"<p>Test an empty skip_lines line.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_lines3(self):\n\"\"\"Test an empty skip_lines line.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n    md.set_variable(\"skip_lines\", \" \")\n    got = md.skip_lines\n    want = []\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_pages1","title":"<code>test_set_skip_pages1()</code>","text":"<p>Test a valid skip_pages line.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_pages1(self):\n\"\"\"Test a valid skip_pages line.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.pdf\", create=True)\n    md.set_variable(\"skip_pages\", \"1, 4-5, 7\")\n    got = md.skip_pages\n    want = [1, 4, 5, 7]\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_pages2","title":"<code>test_set_skip_pages2()</code>","text":"<p>Test an invalid skip_pages line.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_pages2(self):\n\"\"\"Test an invalid skip_pages line.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n    md.set_variable(\"skip_pages\", \"1, 4 5, 7\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.skip_pages\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_pages3","title":"<code>test_set_skip_pages3()</code>","text":"<p>Test an empty skip_pages line.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_pages3(self):\n\"\"\"Test an empty skip_pages line.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n    md.set_variable(\"skip_pages\", \" \")\n    got = md.skip_pages\n    want = []\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_pages4","title":"<code>test_set_skip_pages4()</code>","text":"<p>Test with odd as a page range.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_pages4(self):\n\"\"\"Test with odd as a page range.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n    md.set_variable(\"skip_pages\", \"odd, 2\")\n    got = md.skip_pages\n    want = [\"odd\", 2]\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_pages5","title":"<code>test_set_skip_pages5()</code>","text":"<p>Test with even as a page range.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_pages5(self):\n\"\"\"Test with even as a page range.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n    md.set_variable(\"skip_pages\", \"even, 1\")\n    got = md.skip_pages\n    want = [\"even\", 1]\n\n    self.assertEqual(got, want)\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_set_skip_pages6","title":"<code>test_set_skip_pages6()</code>","text":"<p>Raise an exception if both odd and even are used.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_set_skip_pages6(self):\n\"\"\"Raise an exception if both odd and even are used.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.xml\", create=True)\n    md.set_variable(\"skip_pages\", \"odd, even\")\n\n    with self.assertRaises(xslsetter.XsltError):\n        md.skip_pages\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_skip_elements_1","title":"<code>test_skip_elements_1()</code>","text":"<p>Test if getting skip_elements is possible.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_skip_elements_1(self):\n\"\"\"Test if getting skip_elements is possible.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n    md.set_variable(\n        \"skip_elements\", \".//body/div[1]/h2[1];.//body/div[3]/div[1]/h3[1]\"\n    )\n\n    self.assertEqual(\n        md.skip_elements,\n        [\n            (\n                \".//html:body/html:div[1]/html:h2[1]\",\n                \".//html:body/html:div[3]/html:div[1]/html:h3[1]\",\n            )\n        ],\n    )\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_skip_elements_2","title":"<code>test_skip_elements_2()</code>","text":"<p>Test if getting a pair of skip_elements is possible.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_skip_elements_2(self):\n\"\"\"Test if getting a pair of skip_elements is possible.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n    md.set_variable(\n        \"skip_elements\",\n        \".//body/div[5];.//body/div[8]/div[3]/h1[1], \"\n        \".//body/div[11]/div[2];.//body/div[11]/div[5]\",\n    )\n\n    self.assertEqual(\n        md.skip_elements,\n        [\n            (\n                \".//html:body/html:div[5]\",\n                \".//html:body/html:div[8]/html:div[3]/html:h1[1]\",\n            ),\n            (\n                \".//html:body/html:div[11]/html:div[2]\",\n                \".//html:body/html:div[11]/html:div[5]\",\n            ),\n        ],\n    )\n</code></pre>"},{"location":"reference/test/test_xslsetter/#corpustools.test.test_xslsetter.TestMetadataHandler.test_skip_elements_empty","title":"<code>test_skip_elements_empty()</code>","text":"<p>Empty skip_elements returns None.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/test_xslsetter.py</code> <pre><code>def test_skip_elements_empty(self):\n\"\"\"Empty skip_elements returns None.\"\"\"\n    md = xslsetter.MetadataHandler(\"bogus.epub.xsl\", create=True)\n    self.assertIsNone(md.skip_elements)\n</code></pre>"},{"location":"reference/test/xmltester/","title":"xmltester","text":"<p>Class to test xml snippets.</p>"},{"location":"reference/test/xmltester/#corpustools.test.xmltester.XMLTester","title":"<code>XMLTester</code>","text":"<p>         Bases: <code>unittest.TestCase</code></p> <p>Test xml equality.</p> Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/xmltester.py</code> <pre><code>class XMLTester(unittest.TestCase):\n\"\"\"Test xml equality.\"\"\"\n\n    @staticmethod\n    def assertXmlEqual(got, want):\n\"\"\"Check if two stringified xml snippets are equal.\n\n        Args:\n            got (etree.Element): the xml part given by the tester\n            got (etree.Element): the wanted xml\n\n        Raises: AssertionError\n        \"\"\"\n        got = etree.tostring(got, encoding=\"unicode\")\n        want = etree.tostring(want, encoding=\"unicode\")\n\n        checker = doctestcompare.LXMLOutputChecker()\n        if not checker.check_output(want, got, 0):\n            message = checker.output_difference(doctest.Example(\"\", want), got, 0)\n            raise AssertionError(message)\n</code></pre>"},{"location":"reference/test/xmltester/#corpustools.test.xmltester.XMLTester.assertXmlEqual","title":"<code>assertXmlEqual(got, want)</code>  <code>staticmethod</code>","text":"<p>Check if two stringified xml snippets are equal.</p> <p>Parameters:</p> Name Type Description Default <code>got</code> <code>etree.Element</code> <p>the xml part given by the tester</p> required <code>got</code> <code>etree.Element</code> <p>the wanted xml</p> required Source code in <code>/home/anders/projects/CorpusTools/corpustools/test/xmltester.py</code> <pre><code>@staticmethod\ndef assertXmlEqual(got, want):\n\"\"\"Check if two stringified xml snippets are equal.\n\n    Args:\n        got (etree.Element): the xml part given by the tester\n        got (etree.Element): the wanted xml\n\n    Raises: AssertionError\n    \"\"\"\n    got = etree.tostring(got, encoding=\"unicode\")\n    want = etree.tostring(want, encoding=\"unicode\")\n\n    checker = doctestcompare.LXMLOutputChecker()\n    if not checker.check_output(want, got, 0):\n        message = checker.output_difference(doctest.Example(\"\", want), got, 0)\n        raise AssertionError(message)\n</code></pre>"},{"location":"scripts/","title":"Overview","text":"<p>When the CorpusTools are installed through pipx, many commands are available on the command line. These are:</p> <ul> <li>convert2xml</li> <li>add_files_to_corpus</li> </ul>"},{"location":"scripts/add_files_to_corpus/","title":"add_files_to_corpus","text":"<p><code>add_files_to_corpus = corpustools.adder:main\"</code></p>"},{"location":"scripts/ccat/","title":"ccat","text":""},{"location":"scripts/ccat/#ccat","title":"ccat","text":"<p>Convert corpus format xml to clean text.</p> <p>ccat has three usage modes, print to stdout the content of:</p> <ul> <li>converted files (produced by convert2xml)</li> <li>converted files containing errormarkup (produced by convert2xml)</li> <li>analysed files (produced by analyse_corpus)</li> </ul>"},{"location":"scripts/ccat/#printing-content-of-converted-files-to-stdout","title":"Printing content of converted files to stdout","text":"<p>To print out all sme content of all the converted files found in $GTFREE/converted/sme/admin and its subdirectories, issue the command:</p> <pre><code>ccat -a -l sme $GTFREE/converted/sme/admin\n</code></pre> <p>It is also possible to print a file at a time:</p> <pre><code>ccat -a -l sme $GTFREE/converted/sme/admin/sd/other_files/vl_05_1.doc.xml\n</code></pre> <p>To print out the content of e.g. all converted pdf files found in a directory and its subdirectories, issue this command:</p> <pre><code>find converted/sme/science/ -name \"*.pdf.xml\" | xargs ccat -a -l sme\n</code></pre>"},{"location":"scripts/ccat/#printing-content-of-analysed-files-to-stdout","title":"Printing content of analysed files to stdout","text":"<p>The analysed files produced by analyse_corpus contain among other one dependency element and one disambiguation element, that contain the dependency and disambiguation analysis of the original files content.</p> <pre><code>ccat -dis sda/sda_2006_1_aikio1.pdf.xml\n</code></pre> <p>Prints the content of the disambiguation element.</p> <pre><code>ccat -dep sda/sda_2006_1_aikio1.pdf.xml\n</code></pre> <p>Prints the content of the dependency element.</p> <p>The usage pattern for printing these elements is otherwise the same as printing the content of converted files.</p> <p>Printing dependency elements</p> <pre><code>ccat -dep $GTFREE/analysed/sme/admin\nccat -dep $GTFREE/analysed/sme/admin/sd/other_files/vl_05_1.doc.xml\nfind analysed/sme/science/ -name \"*.pdf.xml\" | xargs ccat -dep\n</code></pre> <p>Printing disambiguation elements</p> <pre><code>ccat -dis $GTFREE/analysed/sme/admin\nccat -dis $GTFREE/analysed/sme/admin/sd/other_files/vl_05_1.doc.xml\nfind analysed/sme/science/ -name \"*.pdf.xml\" | xargs ccat -dis\n</code></pre>"},{"location":"scripts/ccat/#printing-errormarkup-content","title":"Printing errormarkup content","text":"<p>This usage mode is used in the speller tests. Examples of this usage pattern is found in the make files in $GTBIG/prooftools.</p>"},{"location":"scripts/ccat/#the-complete-help-text-from-the-program","title":"The complete help text from the program","text":"<pre><code>usage: ccat [-h] [--version] [-l LANG] [-T] [-L] [-t] [-a] [-c] [-C] [-ort]\n[-ortreal] [-morphsyn] [-syn] [-lex] [-format] [-foreign]\n[-noforeign] [-typos] [-f] [-S] [-dis] [-dep]\n[-hyph HYPH_REPLACEMENT]\ntargets [targets ...]\n\nPrint the contents of a corpus in XML format The default is to print paragraphs\nwith no type (=text type).\n\npositional arguments:\n  targets               Name of the files or directories to process. If a\n                        directory is given, all files in this directory and\n                        its subdirectories will be listed.\n\noptional arguments:\n  -h, --help            show this help message and exit\n--version             show program's version number and exit\n-l LANG               Print only elements in language LANG. Default is all\n                        languages.\n  -T                    Print paragraphs with title type\n-L                    Print paragraphs with list type\n-t                    Print paragraphs with table type\n-a                    Print all text elements\n  -c                    Print corrected text instead of the original typos &amp;\nerrors\n  -C                    Only print unclassified (\u00a7/&lt;error..&gt;) corrections\n  -ort                  Only print ortoghraphic, non-word ($/&lt;errorort..&gt;)\ncorrections\n  -ortreal              Only print ortoghraphic, real-word\n                        (\u00a2/&lt;errorortreal..&gt;) corrections\n  -morphsyn             Only print morphosyntactic (\u00a3/&lt;errormorphsyn..&gt;)\ncorrections\n  -syn                  Only print syntactic (\u00a5/&lt;errorsyn..&gt;) corrections\n  -lex                  Only print lexical (\u20ac/&lt;errorlex..&gt;) corrections\n  -format               Only print format (\u2030/&lt;errorformat..&gt;) corrections\n  -foreign              Only print foreign (\u221e/&lt;errorlang..&gt;) corrections\n  -noforeign            Do not print anything from foreign (\u221e/&lt;errorlang..&gt;)\ncorrections\n  -typos                Print only the errors/typos in the text, with\n                        corrections tab-separated\n  -f                    Add the source filename as a comment after each error\n                        word.\n  -S                    Print the whole text one word per line; typos have tab\n                        separated corrections\n  -dis                  Print the disambiguation element\n  -dep                  Print the dependency element\n  -hyph HYPH_REPLACEMENT\n                        Replace hyph tags with the given argument\n</code></pre>"},{"location":"scripts/convert2xml/","title":"convert2xml","text":"<p>The <code>convert2xml</code> script runs <code>corpustools.convertermanager:main</code>.</p>"},{"location":"scripts/convert2xml/#overview","title":"Overview","text":"<p>Convert original files in a corpus to giellatekno/divvun xml format.</p>"},{"location":"scripts/convert2xml/#dependencies","title":"Dependencies","text":"<p>convert2xml depends on these external programs:</p> <ul> <li>pdftotext</li> <li>wvhtml</li> </ul>"}]}